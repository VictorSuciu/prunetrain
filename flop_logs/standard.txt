bash: /azureml-envs/azureml_fd71f2370c59f1f45a36b18b907af511/lib/libtinfo.so.5: no version information available (required by bash)
2021/06/20 02:48:06 Starting App Insight Logger for task:  runTaskLet
2021/06/20 02:48:06 Version: 3.0.01622.0001 Branch: .SourceBranch Commit: 1141612
2021/06/20 02:48:06 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/info
bash: /azureml-envs/azureml_fd71f2370c59f1f45a36b18b907af511/lib/libtinfo.so.5: no version information available (required by bash)
2021/06/20 02:48:06 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status
[2021-06-20T02:48:06.561780] Entering context manager injector.
[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['python cifar.py --arch vgg11_bn_flat --dataset cifar100 --sparse_interval 200 --var_group_lasso_coeff 0.2 --threshold 0.0001 --epochs 180 --learning-rate 0.1 --train_batch 128 --test_batch 100 --workers 4 --manualSeed 15'])
Script type = COMMAND
[2021-06-20T02:48:07.220442] Command=python cifar.py --arch vgg11_bn_flat --dataset cifar100 --sparse_interval 200 --var_group_lasso_coeff 0.2 --threshold 0.0001 --epochs 180 --learning-rate 0.1 --train_batch 128 --test_batch 100 --workers 4 --manualSeed 15
[2021-06-20T02:48:07.220753] Entering Run History Context Manager.
[2021-06-20T02:48:07.814771] Command Working Directory=/mnt/batch/tasks/shared/LS_root/jobs/prunetrain/azureml/standard1/wd/azureml/Standard1
[2021-06-20T02:48:07.815019] Starting Linux command : python cifar.py --arch vgg11_bn_flat --dataset cifar100 --sparse_interval 200 --var_group_lasso_coeff 0.2 --threshold 0.0001 --epochs 180 --learning-rate 0.1 --train_batch 128 --test_batch 100 --workers 4 --manualSeed 15
no display found. Using non-interactive Agg backend
==> Preparing dataset cifar100
Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./dataset/data/torch/cifar-100-python.tar.gz
0.0%0.0%0.0%0.0%0.0%0.0%0.0%0.0%0.0%0.0%0.0%0.1%0.1%0.1%0.1%0.1%0.1%0.1%0.1%0.1%0.1%0.1%0.1%0.1%0.1%0.1%0.1%0.1%0.1%0.1%0.1%0.2%0.2%0.2%0.2%0.2%0.2%0.2%0.2%0.2%0.2%0.2%0.2%0.2%0.2%0.2%0.2%0.2%0.2%0.2%0.2%0.2%0.3%0.3%0.3%0.3%0.3%0.3%0.3%0.3%0.3%0.3%0.3%0.3%0.3%0.3%0.3%0.3%0.3%0.3%0.3%0.3%0.3%0.4%0.4%0.4%0.4%0.4%0.4%0.4%0.4%0.4%0.4%0.4%0.4%0.4%0.4%0.4%0.4%0.4%0.4%0.4%0.4%0.5%0.5%0.5%0.5%0.5%0.5%0.5%0.5%0.5%0.5%0.5%0.5%0.5%0.5%0.5%0.5%0.5%0.5%0.5%0.5%0.5%0.6%0.6%0.6%0.6%0.6%0.6%0.6%0.6%0.6%0.6%0.6%0.6%0.6%0.6%0.6%0.6%0.6%0.6%0.6%0.6%0.6%0.7%0.7%0.7%0.7%0.7%0.7%0.7%0.7%0.7%0.7%0.7%0.7%0.7%0.7%0.7%0.7%0.7%0.7%0.7%0.7%0.8%0.8%0.8%0.8%0.8%0.8%0.8%0.8%0.8%0.8%0.8%0.8%0.8%0.8%0.8%0.8%0.8%0.8%0.8%0.8%0.8%0.9%0.9%0.9%0.9%0.9%0.9%0.9%0.9%0.9%0.9%0.9%0.9%0.9%0.9%0.9%0.9%0.9%0.9%0.9%0.9%1.0%1.0%1.0%1.0%1.0%1.0%1.0%1.0%1.0%1.0%1.0%1.0%1.0%1.0%1.0%1.0%1.0%1.0%1.0%1.0%1.0%1.1%1.1%1.1%1.1%1.1%1.1%1.1%1.1%1.1%1.1%1.1%1.1%1.1%1.1%1.1%1.1%1.1%1.1%1.1%1.1%1.1%1.2%1.2%1.2%1.2%1.2%1.2%1.2%1.2%1.2%1.2%1.2%1.2%1.2%1.2%1.2%1.2%1.2%1.2%1.2%1.2%1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.3%1.4%1.4%1.4%1.4%1.4%1.4%1.4%1.4%1.4%1.4%1.4%1.4%1.4%1.4%1.4%1.4%1.4%1.4%1.4%1.4%1.4%1.5%1.5%1.5%1.5%1.5%1.5%1.5%1.5%1.5%1.5%1.5%1.5%1.5%1.5%1.5%1.5%1.5%1.5%1.5%1.5%1.6%1.6%1.6%1.6%1.6%1.6%1.6%1.6%1.6%1.6%1.6%1.6%1.6%1.6%1.6%1.6%1.6%1.6%1.6%1.6%1.6%1.7%1.7%1.7%1.7%1.7%1.7%1.7%1.7%1.7%1.7%1.7%1.7%1.7%1.7%1.7%1.7%1.7%1.7%1.7%1.7%1.7%1.8%1.8%1.8%1.8%1.8%1.8%1.8%1.8%1.8%1.8%1.8%1.8%1.8%1.8%1.8%1.8%1.8%1.8%1.8%1.8%1.9%1.9%1.9%1.9%1.9%1.9%1.9%1.9%1.9%1.9%1.9%1.9%1.9%1.9%1.9%1.9%1.9%1.9%1.9%1.9%1.9%2.0%2.0%2.0%2.0%2.0%2.0%2.0%2.0%2.0%2.0%2.0%2.0%2.0%2.0%2.0%2.0%2.0%2.0%2.0%2.0%2.1%2.1%2.1%2.1%2.1%2.1%2.1%2.1%2.1%2.1%2.1%2.1%2.1%2.1%2.1%2.1%2.1%2.1%2.1%2.1%2.1%2.2%2.2%2.2%2.2%2.2%2.2%2.2%2.2%2.2%2.2%2.2%2.2%2.2%2.2%2.2%2.2%2.2%2.2%2.2%2.2%2.2%2.3%2.3%2.3%2.3%2.3%2.3%2.3%2.3%2.3%2.3%2.3%2.3%2.3%2.3%2.3%2.3%2.3%2.3%2.3%2.3%2.4%2.4%2.4%2.4%2.4%2.4%2.4%2.4%2.4%2.4%2.4%2.4%2.4%2.4%2.4%2.4%2.4%2.4%2.4%2.4%2.4%2.5%2.5%2.5%2.5%2.5%2.5%2.5%2.5%2.5%2.5%2.5%2.5%2.5%2.5%2.5%2.5%2.5%2.5%2.5%2.5%2.5%2.6%2.6%2.6%2.6%2.6%2.6%2.6%2.6%2.6%2.6%2.6%2.6%2.6%2.6%2.6%2.6%2.6%2.6%2.6%2.6%2.7%2.7%2.7%2.7%2.7%2.7%2.7%2.7%2.7%2.7%2.7%2.7%2.7%2.7%2.7%2.7%2.7%2.7%2.7%2.7%2.7%2.8%2.8%2.8%2.8%2.8%2.8%2.8%2.8%2.8%2.8%2.8%2.8%2.8%2.8%2.8%2.8%2.8%2.8%2.8%2.8%2.9%2.9%2.9%2.9%2.9%2.9%2.9%2.9%2.9%2.9%2.9%2.9%2.9%2.9%2.9%2.9%2.9%2.9%2.9%2.9%2.9%3.0%3.0%3.0%3.0%3.0%3.0%3.0%3.0%3.0%3.0%3.0%3.0%3.0%3.0%3.0%3.0%3.0%3.0%3.0%3.0%3.0%3.1%3.1%3.1%3.1%3.1%3.1%3.1%3.1%3.1%3.1%3.1%3.1%3.1%3.1%3.1%3.1%3.1%3.1%3.1%3.1%3.2%3.2%3.2%3.2%3.2%3.2%3.2%3.2%3.2%3.2%3.2%3.2%3.2%3.2%3.2%3.2%3.2%3.2%3.2%3.2%3.2%3.3%3.3%3.3%3.3%3.3%3.3%3.3%3.3%3.3%3.3%3.3%3.3%3.3%3.3%3.3%3.3%3.3%3.3%3.3%3.3%3.3%3.4%3.4%3.4%3.4%3.4%3.4%3.4%3.4%3.4%3.4%3.4%3.4%3.4%3.4%3.4%3.4%3.4%3.4%3.4%3.4%3.5%3.5%3.5%3.5%3.5%3.5%3.5%3.5%3.5%3.5%3.5%3.5%3.5%3.5%3.5%3.5%3.5%3.5%3.5%3.5%3.5%3.6%3.6%3.6%3.6%3.6%3.6%3.6%3.6%3.6%3.6%3.6%3.6%3.6%3.6%3.6%3.6%3.6%3.6%3.6%3.6%3.7%3.7%3.7%3.7%3.7%3.7%3.7%3.7%3.7%3.7%3.7%3.7%3.7%3.7%3.7%3.7%3.7%3.7%3.7%3.7%3.7%3.8%3.8%3.8%3.8%3.8%3.8%3.8%3.8%3.8%3.8%3.8%3.8%3.8%3.8%3.8%3.8%3.8%3.8%3.8%3.8%3.8%3.9%3.9%3.9%3.9%3.9%3.9%3.9%3.9%3.9%3.9%3.9%3.9%3.9%3.9%3.9%3.9%3.9%3.9%3.9%3.9%4.0%4.0%4.0%4.0%4.0%4.0%4.0%4.0%4.0%4.0%4.0%4.0%4.0%4.0%4.0%4.0%4.0%4.0%4.0%4.0%4.0%4.1%4.1%4.1%4.1%4.1%4.1%4.1%4.1%4.1%4.1%4.1%4.1%4.1%4.1%4.1%4.1%4.1%4.1%4.1%4.1%4.1%4.2%4.2%4.2%4.2%4.2%4.2%4.2%4.2%4.2%4.2%4.2%4.2%4.2%4.2%4.2%4.2%4.2%4.2%4.2%4.2%4.3%4.3%4.3%4.3%4.3%4.3%4.3%4.3%4.3%4.3%4.3%4.3%4.3%4.3%4.3%4.3%4.3%4.3%4.3%4.3%4.3%4.4%4.4%4.4%4.4%4.4%4.4%4.4%4.4%4.4%4.4%4.4%4.4%4.4%4.4%4.4%4.4%4.4%4.4%4.4%4.4%4.4%4.5%4.5%4.5%4.5%4.5%4.5%4.5%4.5%4.5%4.5%4.5%4.5%4.5%4.5%4.5%4.5%4.5%4.5%4.5%4.5%4.6%4.6%4.6%4.6%4.6%4.6%4.6%4.6%4.6%4.6%4.6%4.6%4.6%4.6%4.6%4.6%4.6%4.6%4.6%4.6%4.6%4.7%4.7%4.7%4.7%4.7%4.7%4.7%4.7%4.7%4.7%4.7%4.7%4.7%4.7%4.7%4.7%4.7%4.7%4.7%4.7%4.8%4.8%4.8%4.8%4.8%4.8%4.8%4.8%4.8%4.8%4.8%4.8%4.8%4.8%4.8%4.8%4.8%4.8%4.8%4.8%4.8%4.9%4.9%4.9%4.9%4.9%4.9%4.9%4.9%4.9%4.9%4.9%4.9%4.9%4.9%4.9%4.9%4.9%4.9%4.9%4.9%4.9%5.0%5.0%5.0%5.0%5.0%5.0%5.0%5.0%5.0%5.0%5.0%5.0%5.0%5.0%5.0%5.0%5.0%5.0%5.0%5.0%5.1%5.1%5.1%5.1%5.1%5.1%5.1%5.1%5.1%5.1%5.1%5.1%5.1%5.1%5.1%5.1%5.1%5.1%5.1%5.1%5.1%5.2%5.2%5.2%5.2%5.2%5.2%5.2%5.2%5.2%5.2%5.2%5.2%5.2%5.2%5.2%5.2%5.2%5.2%5.2%5.2%5.2%5.3%5.3%5.3%5.3%5.3%5.3%5.3%5.3%5.3%5.3%5.3%5.3%5.3%5.3%5.3%5.3%5.3%5.3%5.3%5.3%5.4%5.4%5.4%5.4%5.4%5.4%5.4%5.4%5.4%5.4%5.4%5.4%5.4%5.4%5.4%5.4%5.4%5.4%5.4%5.4%5.4%5.5%5.5%5.5%5.5%5.5%5.5%5.5%5.5%5.5%5.5%5.5%5.5%5.5%5.5%5.5%5.5%5.5%5.5%5.5%5.5%5.6%5.6%5.6%5.6%5.6%5.6%5.6%5.6%5.6%5.6%5.6%5.6%5.6%5.6%5.6%5.6%5.6%5.6%5.6%5.6%5.6%5.7%5.7%5.7%5.7%5.7%5.7%5.7%5.7%5.7%5.7%5.7%5.7%5.7%5.7%5.7%5.7%5.7%5.7%5.7%5.7%5.7%5.8%5.8%5.8%5.8%5.8%5.8%5.8%5.8%5.8%5.8%5.8%5.8%5.8%5.8%5.8%5.8%5.8%5.8%5.8%5.8%5.9%5.9%5.9%5.9%5.9%5.9%5.9%5.9%5.9%5.9%5.9%5.9%5.9%5.9%5.9%5.9%5.9%5.9%5.9%5.9%5.9%6.0%6.0%6.0%6.0%6.0%6.0%6.0%6.0%6.0%6.0%6.0%6.0%6.0%6.0%6.0%6.0%6.0%6.0%6.0%6.0%6.0%6.1%6.1%6.1%6.1%6.1%6.1%6.1%6.1%6.1%6.1%6.1%6.1%6.1%6.1%6.1%6.1%6.1%6.1%6.1%6.1%6.2%6.2%6.2%6.2%6.2%6.2%6.2%6.2%6.2%6.2%6.2%6.2%6.2%6.2%6.2%6.2%6.2%6.2%6.2%6.2%6.2%6.3%6.3%6.3%6.3%6.3%6.3%6.3%6.3%6.3%6.3%6.3%6.3%6.3%6.3%6.3%6.3%6.3%6.3%6.3%6.3%6.3%6.4%6.4%6.4%6.4%6.4%6.4%6.4%6.4%6.4%6.4%6.4%6.4%6.4%6.4%6.4%6.4%6.4%6.4%6.4%6.4%6.5%6.5%6.5%6.5%6.5%6.5%6.5%6.5%6.5%6.5%6.5%6.5%6.5%6.5%6.5%6.5%6.5%6.5%6.5%6.5%6.5%6.6%6.6%6.6%6.6%6.6%6.6%6.6%6.6%6.6%6.6%6.6%6.6%6.6%6.6%6.6%6.6%6.6%6.6%6.6%6.6%6.7%6.7%6.7%6.7%6.7%6.7%6.7%6.7%6.7%6.7%6.7%6.7%6.7%6.7%6.7%6.7%6.7%6.7%6.7%6.7%6.7%6.8%6.8%6.8%6.8%6.8%6.8%6.8%6.8%6.8%6.8%6.8%6.8%6.8%6.8%6.8%6.8%6.8%6.8%6.8%6.8%6.8%6.9%6.9%6.9%6.9%6.9%6.9%6.9%6.9%6.9%6.9%6.9%6.9%6.9%6.9%6.9%6.9%6.9%6.9%6.9%6.9%7.0%7.0%7.0%7.0%7.0%7.0%7.0%7.0%7.0%7.0%7.0%7.0%7.0%7.0%7.0%7.0%7.0%7.0%7.0%7.0%7.0%7.1%7.1%7.1%7.1%7.1%7.1%7.1%7.1%7.1%7.1%7.1%7.1%7.1%7.1%7.1%7.1%7.1%7.1%7.1%7.1%7.1%7.2%7.2%7.2%7.2%7.2%7.2%7.2%7.2%7.2%7.2%7.2%7.2%7.2%7.2%7.2%7.2%7.2%7.2%7.2%7.2%7.3%7.3%7.3%7.3%7.3%7.3%7.3%7.3%7.3%7.3%7.3%7.3%7.3%7.3%7.3%7.3%7.3%7.3%7.3%7.3%7.3%7.4%7.4%7.4%7.4%7.4%7.4%7.4%7.4%7.4%7.4%7.4%7.4%7.4%7.4%7.4%7.4%7.4%7.4%7.4%7.4%7.5%7.5%7.5%7.5%7.5%7.5%7.5%7.5%7.5%7.5%7.5%7.5%7.5%7.5%7.5%7.5%7.5%7.5%7.5%7.5%7.5%7.6%7.6%7.6%7.6%7.6%7.6%7.6%7.6%7.6%7.6%7.6%7.6%7.6%7.6%7.6%7.6%7.6%7.6%7.6%7.6%7.6%7.7%7.7%7.7%7.7%7.7%7.7%7.7%7.7%7.7%7.7%7.7%7.7%7.7%7.7%7.7%7.7%7.7%7.7%7.7%7.7%7.8%7.8%7.8%7.8%7.8%7.8%7.8%7.8%7.8%7.8%7.8%7.8%7.8%7.8%7.8%7.8%7.8%7.8%7.8%7.8%7.8%7.9%7.9%7.9%7.9%7.9%7.9%7.9%7.9%7.9%7.9%7.9%7.9%7.9%7.9%7.9%7.9%7.9%7.9%7.9%7.9%7.9%8.0%8.0%8.0%8.0%8.0%8.0%8.0%8.0%8.0%8.0%8.0%8.0%8.0%8.0%8.0%8.0%8.0%8.0%8.0%8.0%8.1%8.1%8.1%8.1%8.1%8.1%8.1%8.1%8.1%8.1%8.1%8.1%8.1%8.1%8.1%8.1%8.1%8.1%8.1%8.1%8.1%8.2%8.2%8.2%8.2%8.2%8.2%8.2%8.2%8.2%8.2%8.2%8.2%8.2%8.2%8.2%8.2%8.2%8.2%8.2%8.2%8.3%8.3%8.3%8.3%8.3%8.3%8.3%8.3%8.3%8.3%8.3%8.3%8.3%8.3%8.3%8.3%8.3%8.3%8.3%8.3%8.3%8.4%8.4%8.4%8.4%8.4%8.4%8.4%8.4%8.4%8.4%8.4%8.4%8.4%8.4%8.4%8.4%8.4%8.4%8.4%8.4%8.4%8.5%8.5%8.5%8.5%8.5%8.5%8.5%8.5%8.5%8.5%8.5%8.5%8.5%8.5%8.5%8.5%8.5%8.5%8.5%8.5%8.6%8.6%8.6%8.6%8.6%8.6%8.6%8.6%8.6%8.6%8.6%8.6%8.6%8.6%8.6%8.6%8.6%8.6%8.6%8.6%8.6%8.7%8.7%8.7%8.7%8.7%8.7%8.7%8.7%8.7%8.7%8.7%8.7%8.7%8.7%8.7%8.7%8.7%8.7%8.7%8.7%8.7%8.8%8.8%8.8%8.8%8.8%8.8%8.8%8.8%8.8%8.8%8.8%8.8%8.8%8.8%8.8%8.8%8.8%8.8%8.8%8.8%8.9%8.9%8.9%8.9%8.9%8.9%8.9%8.9%8.9%8.9%8.9%8.9%8.9%8.9%8.9%8.9%8.9%8.9%8.9%8.9%8.9%9.0%9.0%9.0%9.0%9.0%9.0%9.0%9.0%9.0%9.0%9.0%9.0%9.0%9.0%9.0%9.0%9.0%9.0%9.0%9.0%9.0%9.1%9.1%9.1%9.1%9.1%9.1%9.1%9.1%9.1%9.1%9.1%9.1%9.1%9.1%9.1%9.1%9.1%9.1%9.1%9.1%9.2%9.2%9.2%9.2%9.2%9.2%9.2%9.2%9.2%9.2%9.2%9.2%9.2%9.2%9.2%9.2%9.2%9.2%9.2%9.2%9.2%9.3%9.3%9.3%9.3%9.3%9.3%9.3%9.3%9.3%9.3%9.3%9.3%9.3%9.3%9.3%9.3%9.3%9.3%9.3%9.3%9.4%9.4%9.4%9.4%9.4%9.4%9.4%9.4%9.4%9.4%9.4%9.4%9.4%9.4%9.4%9.4%9.4%9.4%9.4%9.4%9.4%9.5%9.5%9.5%9.5%9.5%9.5%9.5%9.5%9.5%9.5%9.5%9.5%9.5%9.5%9.5%9.5%9.5%9.5%9.5%9.5%9.5%9.6%9.6%9.6%9.6%9.6%9.6%9.6%9.6%9.6%9.6%9.6%9.6%9.6%9.6%9.6%9.6%9.6%9.6%9.6%9.6%9.7%9.7%9.7%9.7%9.7%9.7%9.7%9.7%9.7%9.7%9.7%9.7%9.7%9.7%9.7%9.7%9.7%9.7%9.7%9.7%9.7%9.8%9.8%9.8%9.8%9.8%9.8%9.8%9.8%9.8%9.8%9.8%9.8%9.8%9.8%9.8%9.8%9.8%9.8%9.8%9.8%9.8%9.9%9.9%9.9%9.9%9.9%9.9%9.9%9.9%9.9%9.9%9.9%9.9%9.9%9.9%9.9%9.9%9.9%9.9%9.9%9.9%10.0%10.0%10.0%10.0%10.0%10.0%10.0%10.0%10.0%10.0%10.0%10.0%10.0%10.0%10.0%10.0%10.0%10.0%10.0%10.0%10.0%10.1%10.1%10.1%10.1%10.1%10.1%10.1%10.1%10.1%10.1%10.1%10.1%10.1%10.1%10.1%10.1%10.1%10.1%10.1%10.1%10.2%10.2%10.2%10.2%10.2%10.2%10.2%10.2%10.2%10.2%10.2%10.2%10.2%10.2%10.2%10.2%10.2%10.2%10.2%10.2%10.2%10.3%10.3%10.3%10.3%10.3%10.3%10.3%10.3%10.3%10.3%10.3%10.3%10.3%10.3%10.3%10.3%10.3%10.3%10.3%10.3%10.3%10.4%10.4%10.4%10.4%10.4%10.4%10.4%10.4%10.4%10.4%10.4%10.4%10.4%10.4%10.4%10.4%10.4%10.4%10.4%10.4%10.5%10.5%10.5%10.5%10.5%10.5%10.5%10.5%10.5%10.5%10.5%10.5%10.5%10.5%10.5%10.5%10.5%10.5%10.5%10.5%10.5%10.6%10.6%10.6%10.6%10.6%10.6%10.6%10.6%10.6%10.6%10.6%10.6%10.6%10.6%10.6%10.6%10.6%10.6%10.6%10.6%10.6%10.7%10.7%10.7%10.7%10.7%10.7%10.7%10.7%10.7%10.7%10.7%10.7%10.7%10.7%10.7%10.7%10.7%10.7%10.7%10.7%10.8%10.8%10.8%10.8%10.8%10.8%10.8%10.8%10.8%10.8%10.8%10.8%10.8%10.8%10.8%10.8%10.8%10.8%10.8%10.8%10.8%10.9%10.9%10.9%10.9%10.9%10.9%10.9%10.9%10.9%10.9%10.9%10.9%10.9%10.9%10.9%10.9%10.9%10.9%10.9%10.9%11.0%11.0%11.0%11.0%11.0%11.0%11.0%11.0%11.0%11.0%11.0%11.0%11.0%11.0%11.0%11.0%11.0%11.0%11.0%11.0%11.0%11.1%11.1%11.1%11.1%11.1%11.1%11.1%11.1%11.1%11.1%11.1%11.1%11.1%11.1%11.1%11.1%11.1%11.1%11.1%11.1%11.1%11.2%11.2%11.2%11.2%11.2%11.2%11.2%11.2%11.2%11.2%11.2%11.2%11.2%11.2%11.2%11.2%11.2%11.2%11.2%11.2%11.3%11.3%11.3%11.3%11.3%11.3%11.3%11.3%11.3%11.3%11.3%11.3%11.3%11.3%11.3%11.3%11.3%11.3%11.3%11.3%11.3%11.4%11.4%11.4%11.4%11.4%11.4%11.4%11.4%11.4%11.4%11.4%11.4%11.4%11.4%11.4%11.4%11.4%11.4%11.4%11.4%11.4%11.5%11.5%11.5%11.5%11.5%11.5%11.5%11.5%11.5%11.5%11.5%11.5%11.5%11.5%11.5%11.5%11.5%11.5%11.5%11.5%11.6%11.6%11.6%11.6%11.6%11.6%11.6%11.6%11.6%11.6%11.6%11.6%11.6%11.6%11.6%11.6%11.6%11.6%11.6%11.6%11.6%11.7%11.7%11.7%11.7%11.7%11.7%11.7%11.7%11.7%11.7%11.7%11.7%11.7%11.7%11.7%11.7%11.7%11.7%11.7%11.7%11.7%11.8%11.8%11.8%11.8%11.8%11.8%11.8%11.8%11.8%11.8%11.8%11.8%11.8%11.8%11.8%11.8%11.8%11.8%11.8%11.8%11.9%11.9%11.9%11.9%11.9%11.9%11.9%11.9%11.9%11.9%11.9%11.9%11.9%11.9%11.9%11.9%11.9%11.9%11.9%11.9%11.9%12.0%12.0%12.0%12.0%12.0%12.0%12.0%12.0%12.0%12.0%12.0%12.0%12.0%12.0%12.0%12.0%12.0%12.0%12.0%12.0%12.1%12.1%12.1%12.1%12.1%12.1%12.1%12.1%12.1%12.1%12.1%12.1%12.1%12.1%12.1%12.1%12.1%12.1%12.1%12.1%12.1%12.2%12.2%12.2%12.2%12.2%12.2%12.2%12.2%12.2%12.2%12.2%12.2%12.2%12.2%12.2%12.2%12.2%12.2%12.2%12.2%12.2%12.3%12.3%12.3%12.3%12.3%12.3%12.3%12.3%12.3%12.3%12.3%12.3%12.3%12.3%12.3%12.3%12.3%12.3%12.3%12.3%12.4%12.4%12.4%12.4%12.4%12.4%12.4%12.4%12.4%12.4%12.4%12.4%12.4%12.4%12.4%12.4%12.4%12.4%12.4%12.4%12.4%12.5%12.5%12.5%12.5%12.5%12.5%12.5%12.5%12.5%12.5%12.5%12.5%12.5%12.5%12.5%12.5%12.5%12.5%12.5%12.5%12.5%12.6%12.6%12.6%12.6%12.6%12.6%12.6%12.6%12.6%12.6%12.6%12.6%12.6%12.6%12.6%12.6%12.6%12.6%12.6%12.6%12.7%12.7%12.7%12.7%12.7%12.7%12.7%12.7%12.7%12.7%12.7%12.7%12.7%12.7%12.7%12.7%12.7%12.7%12.7%12.7%12.7%12.8%12.8%12.8%12.8%12.8%12.8%12.8%12.8%12.8%12.8%12.8%12.8%12.8%12.8%12.8%12.8%12.8%12.8%12.8%12.8%12.9%12.9%12.9%12.9%12.9%12.9%12.9%12.9%12.9%12.9%12.9%12.9%12.9%12.9%12.9%12.9%12.9%12.9%12.9%12.9%12.9%13.0%13.0%13.0%13.0%13.0%13.0%13.0%13.0%13.0%13.0%13.0%13.0%13.0%13.0%13.0%13.0%13.0%13.0%13.0%13.0%13.0%13.1%13.1%13.1%13.1%13.1%13.1%13.1%13.1%13.1%13.1%13.1%13.1%13.1%13.1%13.1%13.1%13.1%13.1%13.1%13.1%13.2%13.2%13.2%13.2%13.2%13.2%13.2%13.2%13.2%13.2%13.2%13.2%13.2%13.2%13.2%13.2%13.2%13.2%13.2%13.2%13.2%13.3%13.3%13.3%13.3%13.3%13.3%13.3%13.3%13.3%13.3%13.3%13.3%13.3%13.3%13.3%13.3%13.3%13.3%13.3%13.3%13.3%13.4%13.4%13.4%13.4%13.4%13.4%13.4%13.4%13.4%13.4%13.4%13.4%13.4%13.4%13.4%13.4%13.4%13.4%13.4%13.4%13.5%13.5%13.5%13.5%13.5%13.5%13.5%13.5%13.5%13.5%13.5%13.5%13.5%13.5%13.5%13.5%13.5%13.5%13.5%13.5%13.5%13.6%13.6%13.6%13.6%13.6%13.6%13.6%13.6%13.6%13.6%13.6%13.6%13.6%13.6%13.6%13.6%13.6%13.6%13.6%13.6%13.6%13.7%13.7%13.7%13.7%13.7%13.7%13.7%13.7%13.7%13.7%13.7%13.7%13.7%13.7%13.7%13.7%13.7%13.7%13.7%13.7%13.8%13.8%13.8%13.8%13.8%13.8%13.8%13.8%13.8%13.8%13.8%13.8%13.8%13.8%13.8%13.8%13.8%13.8%13.8%13.8%13.8%13.9%13.9%13.9%13.9%13.9%13.9%13.9%13.9%13.9%13.9%13.9%13.9%13.9%13.9%13.9%13.9%13.9%13.9%13.9%13.9%14.0%14.0%14.0%14.0%14.0%14.0%14.0%14.0%14.0%14.0%14.0%14.0%14.0%14.0%14.0%14.0%14.0%14.0%14.0%14.0%14.0%14.1%14.1%14.1%14.1%14.1%14.1%14.1%14.1%14.1%14.1%14.1%14.1%14.1%14.1%14.1%14.1%14.1%14.1%14.1%14.1%14.1%14.2%14.2%14.2%14.2%14.2%14.2%14.2%14.2%14.2%14.2%14.2%14.2%14.2%14.2%14.2%14.2%14.2%14.2%14.2%14.2%14.3%14.3%14.3%14.3%14.3%14.3%14.3%14.3%14.3%14.3%14.3%14.3%14.3%14.3%14.3%14.3%14.3%14.3%14.3%14.3%14.3%14.4%14.4%14.4%14.4%14.4%14.4%14.4%14.4%14.4%14.4%14.4%14.4%14.4%14.4%14.4%14.4%14.4%14.4%14.4%14.4%14.4%14.5%14.5%14.5%14.5%14.5%14.5%14.5%14.5%14.5%14.5%14.5%14.5%14.5%14.5%14.5%14.5%14.5%14.5%14.5%14.5%14.6%14.6%14.6%14.6%14.6%14.6%14.6%14.6%14.6%14.6%14.6%14.6%14.6%14.6%14.6%14.6%14.6%14.6%14.6%14.6%14.6%14.7%14.7%14.7%14.7%14.7%14.7%14.7%14.7%14.7%14.7%14.7%14.7%14.7%14.7%14.7%14.7%14.7%14.7%14.7%14.7%14.8%14.8%14.8%14.8%14.8%14.8%14.8%14.8%14.8%14.8%14.8%14.8%14.8%14.8%14.8%14.8%14.8%14.8%14.8%14.8%14.8%14.9%14.9%14.9%14.9%14.9%14.9%14.9%14.9%14.9%14.9%14.9%14.9%14.9%14.9%14.9%14.9%14.9%14.9%14.9%14.9%14.9%15.0%15.0%15.0%15.0%15.0%15.0%15.0%15.0%15.0%15.0%15.0%15.0%15.0%15.0%15.0%15.0%15.0%15.0%15.0%15.0%15.1%15.1%15.1%15.1%15.1%15.1%15.1%15.1%15.1%15.1%15.1%15.1%15.1%15.1%15.1%15.1%15.1%15.1%15.1%15.1%15.1%15.2%15.2%15.2%15.2%15.2%15.2%15.2%15.2%15.2%15.2%15.2%15.2%15.2%15.2%15.2%15.2%15.2%15.2%15.2%15.2%15.2%15.3%15.3%15.3%15.3%15.3%15.3%15.3%15.3%15.3%15.3%15.3%15.3%15.3%15.3%15.3%15.3%15.3%15.3%15.3%15.3%15.4%15.4%15.4%15.4%15.4%15.4%15.4%15.4%15.4%15.4%15.4%15.4%15.4%15.4%15.4%15.4%15.4%15.4%15.4%15.4%15.4%15.5%15.5%15.5%15.5%15.5%15.5%15.5%15.5%15.5%15.5%15.5%15.5%15.5%15.5%15.5%15.5%15.5%15.5%15.5%15.5%15.6%15.6%15.6%15.6%15.6%15.6%15.6%15.6%15.6%15.6%15.6%15.6%15.6%15.6%15.6%15.6%15.6%15.6%15.6%15.6%15.6%15.7%15.7%15.7%15.7%15.7%15.7%15.7%15.7%15.7%15.7%15.7%15.7%15.7%15.7%15.7%15.7%15.7%15.7%15.7%15.7%15.7%15.8%15.8%15.8%15.8%15.8%15.8%15.8%15.8%15.8%15.8%15.8%15.8%15.8%15.8%15.8%15.8%15.8%15.8%15.8%15.8%15.9%15.9%15.9%15.9%15.9%15.9%15.9%15.9%15.9%15.9%15.9%15.9%15.9%15.9%15.9%15.9%15.9%15.9%15.9%15.9%15.9%16.0%16.0%16.0%16.0%16.0%16.0%16.0%16.0%16.0%16.0%16.0%16.0%16.0%16.0%16.0%16.0%16.0%16.0%16.0%16.0%16.0%16.1%16.1%16.1%16.1%16.1%16.1%16.1%16.1%16.1%16.1%16.1%16.1%16.1%16.1%16.1%16.1%16.1%16.1%16.1%16.1%16.2%16.2%16.2%16.2%16.2%16.2%16.2%16.2%16.2%16.2%16.2%16.2%16.2%16.2%16.2%16.2%16.2%16.2%16.2%16.2%16.2%16.3%16.3%16.3%16.3%16.3%16.3%16.3%16.3%16.3%16.3%16.3%16.3%16.3%16.3%16.3%16.3%16.3%16.3%16.3%16.3%16.3%16.4%16.4%16.4%16.4%16.4%16.4%16.4%16.4%16.4%16.4%16.4%16.4%16.4%16.4%16.4%16.4%16.4%16.4%16.4%16.4%16.5%16.5%16.5%16.5%16.5%16.5%16.5%16.5%16.5%16.5%16.5%16.5%16.5%16.5%16.5%16.5%16.5%16.5%16.5%16.5%16.5%16.6%16.6%16.6%16.6%16.6%16.6%16.6%16.6%16.6%16.6%16.6%16.6%16.6%16.6%16.6%16.6%16.6%16.6%16.6%16.6%16.7%16.7%16.7%16.7%16.7%16.7%16.7%16.7%16.7%16.7%16.7%16.7%16.7%16.7%16.7%16.7%16.7%16.7%16.7%16.7%16.7%16.8%16.8%16.8%16.8%16.8%16.8%16.8%16.8%16.8%16.8%16.8%16.8%16.8%16.8%16.8%16.8%16.8%16.8%16.8%16.8%16.8%16.9%16.9%16.9%16.9%16.9%16.9%16.9%16.9%16.9%16.9%16.9%16.9%16.9%16.9%16.9%16.9%16.9%16.9%16.9%16.9%17.0%17.0%17.0%17.0%17.0%17.0%17.0%17.0%17.0%17.0%17.0%17.0%17.0%17.0%17.0%17.0%17.0%17.0%17.0%17.0%17.0%17.1%17.1%17.1%17.1%17.1%17.1%17.1%17.1%17.1%17.1%17.1%17.1%17.1%17.1%17.1%17.1%17.1%17.1%17.1%17.1%17.1%17.2%17.2%17.2%17.2%17.2%17.2%17.2%17.2%17.2%17.2%17.2%17.2%17.2%17.2%17.2%17.2%17.2%17.2%17.2%17.2%17.3%17.3%17.3%17.3%17.3%17.3%17.3%17.3%17.3%17.3%17.3%17.3%17.3%17.3%17.3%17.3%17.3%17.3%17.3%17.3%17.3%17.4%17.4%17.4%17.4%17.4%17.4%17.4%17.4%17.4%17.4%17.4%17.4%17.4%17.4%17.4%17.4%17.4%17.4%17.4%17.4%17.5%17.5%17.5%17.5%17.5%17.5%17.5%17.5%17.5%17.5%17.5%17.5%17.5%17.5%17.5%17.5%17.5%17.5%17.5%17.5%17.5%17.6%17.6%17.6%17.6%17.6%17.6%17.6%17.6%17.6%17.6%17.6%17.6%17.6%17.6%17.6%17.6%17.6%17.6%17.6%17.6%17.6%17.7%17.7%17.7%17.7%17.7%17.7%17.7%17.7%17.7%17.7%17.7%17.7%17.7%17.7%17.7%17.7%17.7%17.7%17.7%17.7%17.8%17.8%17.8%17.8%17.8%17.8%17.8%17.8%17.8%17.8%17.8%17.8%17.8%17.8%17.8%17.8%17.8%17.8%17.8%17.8%17.8%17.9%17.9%17.9%17.9%17.9%17.9%17.9%17.9%17.9%17.9%17.9%17.9%17.9%17.9%17.9%17.9%17.9%17.9%17.9%17.9%17.9%18.0%18.0%18.0%18.0%18.0%18.0%18.0%18.0%18.0%18.0%18.0%18.0%18.0%18.0%18.0%18.0%18.0%18.0%18.0%18.0%18.1%18.1%18.1%18.1%18.1%18.1%18.1%18.1%18.1%18.1%18.1%18.1%18.1%18.1%18.1%18.1%18.1%18.1%18.1%18.1%18.1%18.2%18.2%18.2%18.2%18.2%18.2%18.2%18.2%18.2%18.2%18.2%18.2%18.2%18.2%18.2%18.2%18.2%18.2%18.2%18.2%18.3%18.3%18.3%18.3%18.3%18.3%18.3%18.3%18.3%18.3%18.3%18.3%18.3%18.3%18.3%18.3%18.3%18.3%18.3%18.3%18.3%18.4%18.4%18.4%18.4%18.4%18.4%18.4%18.4%18.4%18.4%18.4%18.4%18.4%18.4%18.4%18.4%18.4%18.4%18.4%18.4%18.4%18.5%18.5%18.5%18.5%18.5%18.5%18.5%18.5%18.5%18.5%18.5%18.5%18.5%18.5%18.5%18.5%18.5%18.5%18.5%18.5%18.6%18.6%18.6%18.6%18.6%18.6%18.6%18.6%18.6%18.6%18.6%18.6%18.6%18.6%18.6%18.6%18.6%18.6%18.6%18.6%18.6%18.7%18.7%18.7%18.7%18.7%18.7%18.7%18.7%18.7%18.7%18.7%18.7%18.7%18.7%18.7%18.7%18.7%18.7%18.7%18.7%18.7%18.8%18.8%18.8%18.8%18.8%18.8%18.8%18.8%18.8%18.8%18.8%18.8%18.8%18.8%18.8%18.8%18.8%18.8%18.8%18.8%18.9%18.9%18.9%18.9%18.9%18.9%18.9%18.9%18.9%18.9%18.9%18.9%18.9%18.9%18.9%18.9%18.9%18.9%18.9%18.9%18.9%19.0%19.0%19.0%19.0%19.0%19.0%19.0%19.0%19.0%19.0%19.0%19.0%19.0%19.0%19.0%19.0%19.0%19.0%19.0%19.0%19.0%19.1%19.1%19.1%19.1%19.1%19.1%19.1%19.1%19.1%19.1%19.1%19.1%19.1%19.1%19.1%19.1%19.1%19.1%19.1%19.1%19.2%19.2%19.2%19.2%19.2%19.2%19.2%19.2%19.2%19.2%19.2%19.2%19.2%19.2%19.2%19.2%19.2%19.2%19.2%19.2%19.2%19.3%19.3%19.3%19.3%19.3%19.3%19.3%19.3%19.3%19.3%19.3%19.3%19.3%19.3%19.3%19.3%19.3%19.3%19.3%19.3%19.4%19.4%19.4%19.4%19.4%19.4%19.4%19.4%19.4%19.4%19.4%19.4%19.4%19.4%19.4%19.4%19.4%19.4%19.4%19.4%19.4%19.5%19.5%19.5%19.5%19.5%19.5%19.5%19.5%19.5%19.5%19.5%19.5%19.5%19.5%19.5%19.5%19.5%19.5%19.5%19.5%19.5%19.6%19.6%19.6%19.6%19.6%19.6%19.6%19.6%19.6%19.6%19.6%19.6%19.6%19.6%19.6%19.6%19.6%19.6%19.6%19.6%19.7%19.7%19.7%19.7%19.7%19.7%19.7%19.7%19.7%19.7%19.7%19.7%19.7%19.7%19.7%19.7%19.7%19.7%19.7%19.7%19.7%19.8%19.8%19.8%19.8%19.8%19.8%19.8%19.8%19.8%19.8%19.8%19.8%19.8%19.8%19.8%19.8%19.8%19.8%19.8%19.8%19.8%19.9%19.9%19.9%19.9%19.9%19.9%19.9%19.9%19.9%19.9%19.9%19.9%19.9%19.9%19.9%19.9%19.9%19.9%19.9%19.9%20.0%20.0%20.0%20.0%20.0%20.0%20.0%20.0%20.0%20.0%20.0%20.0%20.0%20.0%20.0%20.0%20.0%20.0%20.0%20.0%20.0%20.1%20.1%20.1%20.1%20.1%20.1%20.1%20.1%20.1%20.1%20.1%20.1%20.1%20.1%20.1%20.1%20.1%20.1%20.1%20.1%20.2%20.2%20.2%20.2%20.2%20.2%20.2%20.2%20.2%20.2%20.2%20.2%20.2%20.2%2021/06/20 02:48:11 Not exporting to RunHistory as the exporter is either stopped or there is no data.
Stopped: false
OriginalData: 1
FilteredData: 0.
20.2%20.2%20.2%20.2%20.2%20.2%20.2%20.3%20.3%20.3%20.3%20.3%20.3%20.3%20.3%20.3%20.3%20.3%20.3%20.3%20.3%20.3%20.3%20.3%20.3%20.3%20.3%20.3%20.4%20.4%20.4%20.4%20.4%20.4%20.4%20.4%20.4%20.4%20.4%20.4%20.4%20.4%20.4%20.4%20.4%20.4%20.4%20.4%20.5%20.5%20.5%20.5%20.5%20.5%20.5%20.5%20.5%20.5%20.5%20.5%20.5%20.5%20.5%20.5%20.5%20.5%20.5%20.5%20.5%20.6%20.6%20.6%20.6%20.6%20.6%20.6%20.6%20.6%20.6%20.6%20.6%20.6%20.6%20.6%20.6%20.6%20.6%20.6%20.6%20.6%20.7%20.7%20.7%20.7%20.7%20.7%20.7%20.7%20.7%20.7%20.7%20.7%20.7%20.7%20.7%20.7%20.7%20.7%20.7%20.7%20.8%20.8%20.8%20.8%20.8%20.8%20.8%20.8%20.8%20.8%20.8%20.8%20.8%20.8%20.8%20.8%20.8%20.8%20.8%20.8%20.8%20.9%20.9%20.9%20.9%20.9%20.9%20.9%20.9%20.9%20.9%20.9%20.9%20.9%20.9%20.9%20.9%20.9%20.9%20.9%20.9%21.0%21.0%21.0%21.0%21.0%21.0%21.0%21.0%21.0%21.0%21.0%21.0%21.0%21.0%21.0%21.0%21.0%21.0%21.0%21.0%21.0%21.1%21.1%21.1%21.1%21.1%21.1%21.1%21.1%21.1%21.1%21.1%21.1%21.1%21.1%21.1%21.1%21.1%21.1%21.1%21.1%21.1%21.2%21.2%21.2%21.2%21.2%21.2%21.2%21.2%21.2%21.2%21.2%21.2%21.2%21.2%21.2%21.2%21.2%21.2%21.2%21.2%21.3%21.3%21.3%21.3%21.3%21.3%21.3%21.3%21.3%21.3%21.3%21.3%21.3%21.3%21.3%21.3%21.3%21.3%21.3%21.3%21.3%21.4%21.4%21.4%21.4%21.4%21.4%21.4%21.4%21.4%21.4%21.4%21.4%21.4%21.4%21.4%21.4%21.4%21.4%21.4%21.4%21.4%21.5%21.5%21.5%21.5%21.5%21.5%21.5%21.5%21.5%21.5%21.5%21.5%21.5%21.5%21.5%21.5%21.5%21.5%21.5%21.5%21.6%21.6%21.6%21.6%21.6%21.6%21.6%21.6%21.6%21.6%21.6%21.6%21.6%21.6%21.6%21.6%21.6%21.6%21.6%21.6%21.6%21.7%21.7%21.7%21.7%21.7%21.7%21.7%21.7%21.7%21.7%21.7%21.7%21.7%21.7%21.7%21.7%21.7%21.7%21.7%21.7%21.7%21.8%21.8%21.8%21.8%21.8%21.8%21.8%21.8%21.8%21.8%21.8%21.8%21.8%21.8%21.8%21.8%21.8%21.8%21.8%21.8%21.9%21.9%21.9%21.9%21.9%21.9%21.9%21.9%21.9%21.9%21.9%21.9%21.9%21.9%21.9%21.9%21.9%21.9%21.9%21.9%21.9%22.0%22.0%22.0%22.0%22.0%22.0%22.0%22.0%22.0%22.0%22.0%22.0%22.0%22.0%22.0%22.0%22.0%22.0%22.0%22.0%22.1%22.1%22.1%22.1%22.1%22.1%22.1%22.1%22.1%22.1%22.1%22.1%22.1%22.1%22.1%22.1%22.1%22.1%22.1%22.1%22.1%22.2%22.2%22.2%22.2%22.2%22.2%22.2%22.2%22.2%22.2%22.2%22.2%22.2%22.2%22.2%22.2%22.2%22.2%22.2%22.2%22.2%22.3%22.3%22.3%22.3%22.3%22.3%22.3%22.3%22.3%22.3%22.3%22.3%22.3%22.3%22.3%22.3%22.3%22.3%22.3%22.3%22.4%22.4%22.4%22.4%22.4%22.4%22.4%22.4%22.4%22.4%22.4%22.4%22.4%22.4%22.4%22.4%22.4%22.4%22.4%22.4%22.4%22.5%22.5%22.5%22.5%22.5%22.5%22.5%22.5%22.5%22.5%22.5%22.5%22.5%22.5%22.5%22.5%22.5%22.5%22.5%22.5%22.5%22.6%22.6%22.6%22.6%22.6%22.6%22.6%22.6%22.6%22.6%22.6%22.6%22.6%22.6%22.6%22.6%22.6%22.6%22.6%22.6%22.7%22.7%22.7%22.7%22.7%22.7%22.7%22.7%22.7%22.7%22.7%22.7%22.7%22.7%22.7%22.7%22.7%22.7%22.7%22.7%22.7%22.8%22.8%22.8%22.8%22.8%22.8%22.8%22.8%22.8%22.8%22.8%22.8%22.8%22.8%22.8%22.8%22.8%22.8%22.8%22.8%22.9%22.9%22.9%22.9%22.9%22.9%22.9%22.9%22.9%22.9%22.9%22.9%22.9%22.9%22.9%22.9%22.9%22.9%22.9%22.9%22.9%23.0%23.0%23.0%23.0%23.0%23.0%23.0%23.0%23.0%23.0%23.0%23.0%23.0%23.0%23.0%23.0%23.0%23.0%23.0%23.0%23.0%23.1%23.1%23.1%23.1%23.1%23.1%23.1%23.1%23.1%23.1%23.1%23.1%23.1%23.1%23.1%23.1%23.1%23.1%23.1%23.1%23.2%23.2%23.2%23.2%23.2%23.2%23.2%23.2%23.2%23.2%23.2%23.2%23.2%23.2%23.2%23.2%23.2%23.2%23.2%23.2%23.2%23.3%23.3%23.3%23.3%23.3%23.3%23.3%23.3%23.3%23.3%23.3%23.3%23.3%23.3%23.3%23.3%23.3%23.3%23.3%23.3%23.3%23.4%23.4%23.4%23.4%23.4%23.4%23.4%23.4%23.4%23.4%23.4%23.4%23.4%23.4%23.4%23.4%23.4%23.4%23.4%23.4%23.5%23.5%23.5%23.5%23.5%23.5%23.5%23.5%23.5%23.5%23.5%23.5%23.5%23.5%23.5%23.5%23.5%23.5%23.5%23.5%23.5%23.6%23.6%23.6%23.6%23.6%23.6%23.6%23.6%23.6%23.6%23.6%23.6%23.6%23.6%23.6%23.6%23.6%23.6%23.6%23.6%23.6%23.7%23.7%23.7%23.7%23.7%23.7%23.7%23.7%23.7%23.7%23.7%23.7%23.7%23.7%23.7%23.7%23.7%23.7%23.7%23.7%23.8%23.8%23.8%23.8%23.8%23.8%23.8%23.8%23.8%23.8%23.8%23.8%23.8%23.8%23.8%23.8%23.8%23.8%23.8%23.8%23.8%23.9%23.9%23.9%23.9%23.9%23.9%23.9%23.9%23.9%23.9%23.9%23.9%23.9%23.9%23.9%23.9%23.9%23.9%23.9%23.9%24.0%24.0%24.0%24.0%24.0%24.0%24.0%24.0%24.0%24.0%24.0%24.0%24.0%24.0%24.0%24.0%24.0%24.0%24.0%24.0%24.0%24.1%24.1%24.1%24.1%24.1%24.1%24.1%24.1%24.1%24.1%24.1%24.1%24.1%24.1%24.1%24.1%24.1%24.1%24.1%24.1%24.1%24.2%24.2%24.2%24.2%24.2%24.2%24.2%24.2%24.2%24.2%24.2%24.2%24.2%24.2%24.2%24.2%24.2%24.2%24.2%24.2%24.3%24.3%24.3%24.3%24.3%24.3%24.3%24.3%24.3%24.3%24.3%24.3%24.3%24.3%24.3%24.3%24.3%24.3%24.3%24.3%24.3%24.4%24.4%24.4%24.4%24.4%24.4%24.4%24.4%24.4%24.4%24.4%24.4%24.4%24.4%24.4%24.4%24.4%24.4%24.4%24.4%24.4%24.5%24.5%24.5%24.5%24.5%24.5%24.5%24.5%24.5%24.5%24.5%24.5%24.5%24.5%24.5%24.5%24.5%24.5%24.5%24.5%24.6%24.6%24.6%24.6%24.6%24.6%24.6%24.6%24.6%24.6%24.6%24.6%24.6%24.6%24.6%24.6%24.6%24.6%24.6%24.6%24.6%24.7%24.7%24.7%24.7%24.7%24.7%24.7%24.7%24.7%24.7%24.7%24.7%24.7%24.7%24.7%24.7%24.7%24.7%24.7%24.7%24.8%24.8%24.8%24.8%24.8%24.8%24.8%24.8%24.8%24.8%24.8%24.8%24.8%24.8%24.8%24.8%24.8%24.8%24.8%24.8%24.8%24.9%24.9%24.9%24.9%24.9%24.9%24.9%24.9%24.9%24.9%24.9%24.9%24.9%24.9%24.9%24.9%24.9%24.9%24.9%24.9%24.9%25.0%25.0%25.0%25.0%25.0%25.0%25.0%25.0%25.0%25.0%25.0%25.0%25.0%25.0%25.0%25.0%25.0%25.0%25.0%25.0%25.1%25.1%25.1%25.1%25.1%25.1%25.1%25.1%25.1%25.1%25.1%25.1%25.1%25.1%25.1%25.1%25.1%25.1%25.1%25.1%25.1%25.2%25.2%25.2%25.2%25.2%25.2%25.2%25.2%25.2%25.2%25.2%25.2%25.2%25.2%25.2%25.2%25.2%25.2%25.2%25.2%25.2%25.3%25.3%25.3%25.3%25.3%25.3%25.3%25.3%25.3%25.3%25.3%25.3%25.3%25.3%25.3%25.3%25.3%25.3%25.3%25.3%25.4%25.4%25.4%25.4%25.4%25.4%25.4%25.4%25.4%25.4%25.4%25.4%25.4%25.4%25.4%25.4%25.4%25.4%25.4%25.4%25.4%25.5%25.5%25.5%25.5%25.5%25.5%25.5%25.5%25.5%25.5%25.5%25.5%25.5%25.5%25.5%25.5%25.5%25.5%25.5%25.5%25.6%25.6%25.6%25.6%25.6%25.6%25.6%25.6%25.6%25.6%25.6%25.6%25.6%25.6%25.6%25.6%25.6%25.6%25.6%25.6%25.6%25.7%25.7%25.7%25.7%25.7%25.7%25.7%25.7%25.7%25.7%25.7%25.7%25.7%25.7%25.7%25.7%25.7%25.7%25.7%25.7%25.7%25.8%25.8%25.8%25.8%25.8%25.8%25.8%25.8%25.8%25.8%25.8%25.8%25.8%25.8%25.8%25.8%25.8%25.8%25.8%25.8%25.9%25.9%25.9%25.9%25.9%25.9%25.9%25.9%25.9%25.9%25.9%25.9%25.9%25.9%25.9%25.9%25.9%25.9%25.9%25.9%25.9%26.0%26.0%26.0%26.0%26.0%26.0%26.0%26.0%26.0%26.0%26.0%26.0%26.0%26.0%26.0%26.0%26.0%26.0%26.0%26.0%26.0%26.1%26.1%26.1%26.1%26.1%26.1%26.1%26.1%26.1%26.1%26.1%26.1%26.1%26.1%26.1%26.1%26.1%26.1%26.1%26.1%26.2%26.2%26.2%26.2%26.2%26.2%26.2%26.2%26.2%26.2%26.2%26.2%26.2%26.2%26.2%26.2%26.2%26.2%26.2%26.2%26.2%26.3%26.3%26.3%26.3%26.3%26.3%26.3%26.3%26.3%26.3%26.3%26.3%26.3%26.3%26.3%26.3%26.3%26.3%26.3%26.3%26.3%26.4%26.4%26.4%26.4%26.4%26.4%26.4%26.4%26.4%26.4%26.4%26.4%26.4%26.4%26.4%26.4%26.4%26.4%26.4%26.4%26.5%26.5%26.5%26.5%26.5%26.5%26.5%26.5%26.5%26.5%26.5%26.5%26.5%26.5%26.5%26.5%26.5%26.5%26.5%26.5%26.5%26.6%26.6%26.6%26.6%26.6%26.6%26.6%26.6%26.6%26.6%26.6%26.6%26.6%26.6%26.6%26.6%26.6%26.6%26.6%26.6%26.7%26.7%26.7%26.7%26.7%26.7%26.7%26.7%26.7%26.7%26.7%26.7%26.7%26.7%26.7%26.7%26.7%26.7%26.7%26.7%26.7%26.8%26.8%26.8%26.8%26.8%26.8%26.8%26.8%26.8%26.8%26.8%26.8%26.8%26.8%26.8%26.8%26.8%26.8%26.8%26.8%26.8%26.9%26.9%26.9%26.9%26.9%26.9%26.9%26.9%26.9%26.9%26.9%26.9%26.9%26.9%26.9%26.9%26.9%26.9%26.9%26.9%27.0%27.0%27.0%27.0%27.0%27.0%27.0%27.0%27.0%27.0%27.0%27.0%27.0%27.0%27.0%27.0%27.0%27.0%27.0%27.0%27.0%27.1%27.1%27.1%27.1%27.1%27.1%27.1%27.1%27.1%27.1%27.1%27.1%27.1%27.1%27.1%27.1%27.1%27.1%27.1%27.1%27.1%27.2%27.2%27.2%27.2%27.2%27.2%27.2%27.2%27.2%27.2%27.2%27.2%27.2%27.2%27.2%27.2%27.2%27.2%27.2%27.2%27.3%27.3%27.3%27.3%27.3%27.3%27.3%27.3%27.3%27.3%27.3%27.3%27.3%27.3%27.3%27.3%27.3%27.3%27.3%27.3%27.3%27.4%27.4%27.4%27.4%27.4%27.4%27.4%27.4%27.4%27.4%27.4%27.4%27.4%27.4%27.4%27.4%27.4%27.4%27.4%27.4%27.5%27.5%27.5%27.5%27.5%27.5%27.5%27.5%27.5%27.5%27.5%27.5%27.5%27.5%27.5%27.5%27.5%27.5%27.5%27.5%27.5%27.6%27.6%27.6%27.6%27.6%27.6%27.6%27.6%27.6%27.6%27.6%27.6%27.6%27.6%27.6%27.6%27.6%27.6%27.6%27.6%27.6%27.7%27.7%27.7%27.7%27.7%27.7%27.7%27.7%27.7%27.7%27.7%27.7%27.7%27.7%27.7%27.7%27.7%27.7%27.7%27.7%27.8%27.8%27.8%27.8%27.8%27.8%27.8%27.8%27.8%27.8%27.8%27.8%27.8%27.8%27.8%27.8%27.8%27.8%27.8%27.8%27.8%27.9%27.9%27.9%27.9%27.9%27.9%27.9%27.9%27.9%27.9%27.9%27.9%27.9%27.9%27.9%27.9%27.9%27.9%27.9%27.9%27.9%28.0%28.0%28.0%28.0%28.0%28.0%28.0%28.0%28.0%28.0%28.0%28.0%28.0%28.0%28.0%28.0%28.0%28.0%28.0%28.0%28.1%28.1%28.1%28.1%28.1%28.1%28.1%28.1%28.1%28.1%28.1%28.1%28.1%28.1%28.1%28.1%28.1%28.1%28.1%28.1%28.1%28.2%28.2%28.2%28.2%28.2%28.2%28.2%28.2%28.2%28.2%28.2%28.2%28.2%28.2%28.2%28.2%28.2%28.2%28.2%28.2%28.3%28.3%28.3%28.3%28.3%28.3%28.3%28.3%28.3%28.3%28.3%28.3%28.3%28.3%28.3%28.3%28.3%28.3%28.3%28.3%28.3%28.4%28.4%28.4%28.4%28.4%28.4%28.4%28.4%28.4%28.4%28.4%28.4%28.4%28.4%28.4%28.4%28.4%28.4%28.4%28.4%28.4%28.5%28.5%28.5%28.5%28.5%28.5%28.5%28.5%28.5%28.5%28.5%28.5%28.5%28.5%28.5%28.5%28.5%28.5%28.5%28.5%28.6%28.6%28.6%28.6%28.6%28.6%28.6%28.6%28.6%28.6%28.6%28.6%28.6%28.6%28.6%28.6%28.6%28.6%28.6%28.6%28.6%28.7%28.7%28.7%28.7%28.7%28.7%28.7%28.7%28.7%28.7%28.7%28.7%28.7%28.7%28.7%28.7%28.7%28.7%28.7%28.7%28.7%28.8%28.8%28.8%28.8%28.8%28.8%28.8%28.8%28.8%28.8%28.8%28.8%28.8%28.8%28.8%28.8%28.8%28.8%28.8%28.8%28.9%28.9%28.9%28.9%28.9%28.9%28.9%28.9%28.9%28.9%28.9%28.9%28.9%28.9%28.9%28.9%28.9%28.9%28.9%28.9%28.9%29.0%29.0%29.0%29.0%29.0%29.0%29.0%29.0%29.0%29.0%29.0%29.0%29.0%29.0%29.0%29.0%29.0%29.0%29.0%29.0%29.0%29.1%29.1%29.1%29.1%29.1%29.1%29.1%29.1%29.1%29.1%29.1%29.1%29.1%29.1%29.1%29.1%29.1%29.1%29.1%29.1%29.2%29.2%29.2%29.2%29.2%29.2%29.2%29.2%29.2%29.2%29.2%29.2%29.2%29.2%29.2%29.2%29.2%29.2%29.2%29.2%29.2%29.3%29.3%29.3%29.3%29.3%29.3%29.3%29.3%29.3%29.3%29.3%29.3%29.3%29.3%29.3%29.3%29.3%29.3%29.3%29.3%29.4%29.4%29.4%29.4%29.4%29.4%29.4%29.4%29.4%29.4%29.4%29.4%29.4%29.4%29.4%29.4%29.4%29.4%29.4%29.4%29.4%29.5%29.5%29.5%29.5%29.5%29.5%29.5%29.5%29.5%29.5%29.5%29.5%29.5%29.5%29.5%29.5%29.5%29.5%29.5%29.5%29.5%29.6%29.6%29.6%29.6%29.6%29.6%29.6%29.6%29.6%29.6%29.6%29.6%29.6%29.6%29.6%29.6%29.6%29.6%29.6%29.6%29.7%29.7%29.7%29.7%29.7%29.7%29.7%29.7%29.7%29.7%29.7%29.7%29.7%29.7%29.7%29.7%29.7%29.7%29.7%29.7%29.7%29.8%29.8%29.8%29.8%29.8%29.8%29.8%29.8%29.8%29.8%29.8%29.8%29.8%29.8%29.8%29.8%29.8%29.8%29.8%29.8%29.8%29.9%29.9%29.9%29.9%29.9%29.9%29.9%29.9%29.9%29.9%29.9%29.9%29.9%29.9%29.9%29.9%29.9%29.9%29.9%29.9%30.0%30.0%30.0%30.0%30.0%30.0%30.0%30.0%30.0%30.0%30.0%30.0%30.0%30.0%30.0%30.0%30.0%30.0%30.0%30.0%30.0%30.1%30.1%30.1%30.1%30.1%30.1%30.1%30.1%30.1%30.1%30.1%30.1%30.1%30.1%30.1%30.1%30.1%30.1%30.1%30.1%30.2%30.2%30.2%30.2%30.2%30.2%30.2%30.2%30.2%30.2%30.2%30.2%30.2%30.2%30.2%30.2%30.2%30.2%30.2%30.2%30.2%30.3%30.3%30.3%30.3%30.3%30.3%30.3%30.3%30.3%30.3%30.3%30.3%30.3%30.3%30.3%30.3%30.3%30.3%30.3%30.3%30.3%30.4%30.4%30.4%30.4%30.4%30.4%30.4%30.4%30.4%30.4%30.4%30.4%30.4%30.4%30.4%30.4%30.4%30.4%30.4%30.4%30.5%30.5%30.5%30.5%30.5%30.5%30.5%30.5%30.5%30.5%30.5%30.5%30.5%30.5%30.5%30.5%30.5%30.5%30.5%30.5%30.5%30.6%30.6%30.6%30.6%30.6%30.6%30.6%30.6%30.6%30.6%30.6%30.6%30.6%30.6%30.6%30.6%30.6%30.6%30.6%30.6%30.6%30.7%30.7%30.7%30.7%30.7%30.7%30.7%30.7%30.7%30.7%30.7%30.7%30.7%30.7%30.7%30.7%30.7%30.7%30.7%30.7%30.8%30.8%30.8%30.8%30.8%30.8%30.8%30.8%30.8%30.8%30.8%30.8%30.8%30.8%30.8%30.8%30.8%30.8%30.8%30.8%30.8%30.9%30.9%30.9%30.9%30.9%30.9%30.9%30.9%30.9%30.9%30.9%30.9%30.9%30.9%30.9%30.9%30.9%30.9%30.9%30.9%30.9%31.0%31.0%31.0%31.0%31.0%31.0%31.0%31.0%31.0%31.0%31.0%31.0%31.0%31.0%31.0%31.0%31.0%31.0%31.0%31.0%31.1%31.1%31.1%31.1%31.1%31.1%31.1%31.1%31.1%31.1%31.1%31.1%31.1%31.1%31.1%31.1%31.1%31.1%31.1%31.1%31.1%31.2%31.2%31.2%31.2%31.2%31.2%31.2%31.2%31.2%31.2%31.2%31.2%31.2%31.2%31.2%31.2%31.2%31.2%31.2%31.2%31.3%31.3%31.3%31.3%31.3%31.3%31.3%31.3%31.3%31.3%31.3%31.3%31.3%31.3%31.3%31.3%31.3%31.3%31.3%31.3%31.3%31.4%31.4%31.4%31.4%31.4%31.4%31.4%31.4%31.4%31.4%31.4%31.4%31.4%31.4%31.4%31.4%31.4%31.4%31.4%31.4%31.4%31.5%31.5%31.5%31.5%31.5%31.5%31.5%31.5%31.5%31.5%31.5%31.5%31.5%31.5%31.5%31.5%31.5%31.5%31.5%31.5%31.6%31.6%31.6%31.6%31.6%31.6%31.6%31.6%31.6%31.6%31.6%31.6%31.6%31.6%31.6%31.6%31.6%31.6%31.6%31.6%31.6%31.7%31.7%31.7%31.7%31.7%31.7%31.7%31.7%31.7%31.7%31.7%31.7%31.7%31.7%31.7%31.7%31.7%31.7%31.7%31.7%31.7%31.8%31.8%31.8%31.8%31.8%31.8%31.8%31.8%31.8%31.8%31.8%31.8%31.8%31.8%31.8%31.8%31.8%31.8%31.8%31.8%31.9%31.9%31.9%31.9%31.9%31.9%31.9%31.9%31.9%31.9%31.9%31.9%31.9%31.9%31.9%31.9%31.9%31.9%31.9%31.9%31.9%32.0%32.0%32.0%32.0%32.0%32.0%32.0%32.0%32.0%32.0%32.0%32.0%32.0%32.0%32.0%32.0%32.0%32.0%32.0%32.0%32.1%32.1%32.1%32.1%32.1%32.1%32.1%32.1%32.1%32.1%32.1%32.1%32.1%32.1%32.1%32.1%32.1%32.1%32.1%32.1%32.1%32.2%32.2%32.2%32.2%32.2%32.2%32.2%32.2%32.2%32.2%32.2%32.2%32.2%32.2%32.2%32.2%32.2%32.2%32.2%32.2%32.2%32.3%32.3%32.3%32.3%32.3%32.3%32.3%32.3%32.3%32.3%32.3%32.3%32.3%32.3%32.3%32.3%32.3%32.3%32.3%32.3%32.4%32.4%32.4%32.4%32.4%32.4%32.4%32.4%32.4%32.4%32.4%32.4%32.4%32.4%32.4%32.4%32.4%32.4%32.4%32.4%32.4%32.5%32.5%32.5%32.5%32.5%32.5%32.5%32.5%32.5%32.5%32.5%32.5%32.5%32.5%32.5%32.5%32.5%32.5%32.5%32.5%32.5%32.6%32.6%32.6%32.6%32.6%32.6%32.6%32.6%32.6%32.6%32.6%32.6%32.6%32.6%32.6%32.6%32.6%32.6%32.6%32.6%32.7%32.7%32.7%32.7%32.7%32.7%32.7%32.7%32.7%32.7%32.7%32.7%32.7%32.7%32.7%32.7%32.7%32.7%32.7%32.7%32.7%32.8%32.8%32.8%32.8%32.8%32.8%32.8%32.8%32.8%32.8%32.8%32.8%32.8%32.8%32.8%32.8%32.8%32.8%32.8%32.8%32.9%32.9%32.9%32.9%32.9%32.9%32.9%32.9%32.9%32.9%32.9%32.9%32.9%32.9%32.9%32.9%32.9%32.9%32.9%32.9%32.9%33.0%33.0%33.0%33.0%33.0%33.0%33.0%33.0%33.0%33.0%33.0%33.0%33.0%33.0%33.0%33.0%33.0%33.0%33.0%33.0%33.0%33.1%33.1%33.1%33.1%33.1%33.1%33.1%33.1%33.1%33.1%33.1%33.1%33.1%33.1%33.1%33.1%33.1%33.1%33.1%33.1%33.2%33.2%33.2%33.2%33.2%33.2%33.2%33.2%33.2%33.2%33.2%33.2%33.2%33.2%33.2%33.2%33.2%33.2%33.2%33.2%33.2%33.3%33.3%33.3%33.3%33.3%33.3%33.3%33.3%33.3%33.3%33.3%33.3%33.3%33.3%33.3%33.3%33.3%33.3%33.3%33.3%33.3%33.4%33.4%33.4%33.4%33.4%33.4%33.4%33.4%33.4%33.4%33.4%33.4%33.4%33.4%33.4%33.4%33.4%33.4%33.4%33.4%33.5%33.5%33.5%33.5%33.5%33.5%33.5%33.5%33.5%33.5%33.5%33.5%33.5%33.5%33.5%33.5%33.5%33.5%33.5%33.5%33.5%33.6%33.6%33.6%33.6%33.6%33.6%33.6%33.6%33.6%33.6%33.6%33.6%33.6%33.6%33.6%33.6%33.6%33.6%33.6%33.6%33.6%33.7%33.7%33.7%33.7%33.7%33.7%33.7%33.7%33.7%33.7%33.7%33.7%33.7%33.7%33.7%33.7%33.7%33.7%33.7%33.7%33.8%33.8%33.8%33.8%33.8%33.8%33.8%33.8%33.8%33.8%33.8%33.8%33.8%33.8%33.8%33.8%33.8%33.8%33.8%33.8%33.8%33.9%33.9%33.9%33.9%33.9%33.9%33.9%33.9%33.9%33.9%33.9%33.9%33.9%33.9%33.9%33.9%33.9%33.9%33.9%33.9%34.0%34.0%34.0%34.0%34.0%34.0%34.0%34.0%34.0%34.0%34.0%34.0%34.0%34.0%34.0%34.0%34.0%34.0%34.0%34.0%34.0%34.1%34.1%34.1%34.1%34.1%34.1%34.1%34.1%34.1%34.1%34.1%34.1%34.1%34.1%34.1%34.1%34.1%34.1%34.1%34.1%34.1%34.2%34.2%34.2%34.2%34.2%34.2%34.2%34.2%34.2%34.2%34.2%34.2%34.2%34.2%34.2%34.2%34.2%34.2%34.2%34.2%34.3%34.3%34.3%34.3%34.3%34.3%34.3%34.3%34.3%34.3%34.3%34.3%34.3%34.3%34.3%34.3%34.3%34.3%34.3%34.3%34.3%34.4%34.4%34.4%34.4%34.4%34.4%34.4%34.4%34.4%34.4%34.4%34.4%34.4%34.4%34.4%34.4%34.4%34.4%34.4%34.4%34.4%34.5%34.5%34.5%34.5%34.5%34.5%34.5%34.5%34.5%34.5%34.5%34.5%34.5%34.5%34.5%34.5%34.5%34.5%34.5%34.5%34.6%34.6%34.6%34.6%34.6%34.6%34.6%34.6%34.6%34.6%34.6%34.6%34.6%34.6%34.6%34.6%34.6%34.6%34.6%34.6%34.6%34.7%34.7%34.7%34.7%34.7%34.7%34.7%34.7%34.7%34.7%34.7%34.7%34.7%34.7%34.7%34.7%34.7%34.7%34.7%34.7%34.8%34.8%34.8%34.8%34.8%34.8%34.8%34.8%34.8%34.8%34.8%34.8%34.8%34.8%34.8%34.8%34.8%34.8%34.8%34.8%34.8%34.9%34.9%34.9%34.9%34.9%34.9%34.9%34.9%34.9%34.9%34.9%34.9%34.9%34.9%34.9%34.9%34.9%34.9%34.9%34.9%34.9%35.0%35.0%35.0%35.0%35.0%35.0%35.0%35.0%35.0%35.0%35.0%35.0%35.0%35.0%35.0%35.0%35.0%35.0%35.0%35.0%35.1%35.1%35.1%35.1%35.1%35.1%35.1%35.1%35.1%35.1%35.1%35.1%35.1%35.1%35.1%35.1%35.1%35.1%35.1%35.1%35.1%35.2%35.2%35.2%35.2%35.2%35.2%35.2%35.2%35.2%35.2%35.2%35.2%35.2%35.2%35.2%35.2%35.2%35.2%35.2%35.2%35.2%35.3%35.3%35.3%35.3%35.3%35.3%35.3%35.3%35.3%35.3%35.3%35.3%35.3%35.3%35.3%35.3%35.3%35.3%35.3%35.3%35.4%35.4%35.4%35.4%35.4%35.4%35.4%35.4%35.4%35.4%35.4%35.4%35.4%35.4%35.4%35.4%35.4%35.4%35.4%35.4%35.4%35.5%35.5%35.5%35.5%35.5%35.5%35.5%35.5%35.5%35.5%35.5%35.5%35.5%35.5%35.5%35.5%35.5%35.5%35.5%35.5%35.6%35.6%35.6%35.6%35.6%35.6%35.6%35.6%35.6%35.6%35.6%35.6%35.6%35.6%35.6%35.6%35.6%35.6%35.6%35.6%35.6%35.7%35.7%35.7%35.7%35.7%35.7%35.7%35.7%35.7%35.7%35.7%35.7%35.7%35.7%35.7%35.7%35.7%35.7%35.7%35.7%35.7%35.8%35.8%35.8%35.8%35.8%35.8%35.8%35.8%35.8%35.8%35.8%35.8%35.8%35.8%35.8%35.8%35.8%35.8%35.8%35.8%35.9%35.9%35.9%35.9%35.9%35.9%35.9%35.9%35.9%35.9%35.9%35.9%35.9%35.9%35.9%35.9%35.9%35.9%35.9%35.9%35.9%36.0%36.0%36.0%36.0%36.0%36.0%36.0%36.0%36.0%36.0%36.0%36.0%36.0%36.0%36.0%36.0%36.0%36.0%36.0%36.0%36.0%36.1%36.1%36.1%36.1%36.1%36.1%36.1%36.1%36.1%36.1%36.1%36.1%36.1%36.1%36.1%36.1%36.1%36.1%36.1%36.1%36.2%36.2%36.2%36.2%36.2%36.2%36.2%36.2%36.2%36.2%36.2%36.2%36.2%36.2%36.2%36.2%36.2%36.2%36.2%36.2%36.2%36.3%36.3%36.3%36.3%36.3%36.3%36.3%36.3%36.3%36.3%36.3%36.3%36.3%36.3%36.3%36.3%36.3%36.3%36.3%36.3%36.3%36.4%36.4%36.4%36.4%36.4%36.4%36.4%36.4%36.4%36.4%36.4%36.4%36.4%36.4%36.4%36.4%36.4%36.4%36.4%36.4%36.5%36.5%36.5%36.5%36.5%36.5%36.5%36.5%36.5%36.5%36.5%36.5%36.5%36.5%36.5%36.5%36.5%36.5%36.5%36.5%36.5%36.6%36.6%36.6%36.6%36.6%36.6%36.6%36.6%36.6%36.6%36.6%36.6%36.6%36.6%36.6%36.6%36.6%36.6%36.6%36.6%36.7%36.7%36.7%36.7%36.7%36.7%36.7%36.7%36.7%36.7%36.7%36.7%36.7%36.7%36.7%36.7%36.7%36.7%36.7%36.7%36.7%36.8%36.8%36.8%36.8%36.8%36.8%36.8%36.8%36.8%36.8%36.8%36.8%36.8%36.8%36.8%36.8%36.8%36.8%36.8%36.8%36.8%36.9%36.9%36.9%36.9%36.9%36.9%36.9%36.9%36.9%36.9%36.9%36.9%36.9%36.9%36.9%36.9%36.9%36.9%36.9%36.9%37.0%37.0%37.0%37.0%37.0%37.0%37.0%37.0%37.0%37.0%37.0%37.0%37.0%37.0%37.0%37.0%37.0%37.0%37.0%37.0%37.0%37.1%37.1%37.1%37.1%37.1%37.1%37.1%37.1%37.1%37.1%37.1%37.1%37.1%37.1%37.1%37.1%37.1%37.1%37.1%37.1%37.1%37.2%37.2%37.2%37.2%37.2%37.2%37.2%37.2%37.2%37.2%37.2%37.2%37.2%37.2%37.2%37.2%37.2%37.2%37.2%37.2%37.3%37.3%37.3%37.3%37.3%37.3%37.3%37.3%37.3%37.3%37.3%37.3%37.3%37.3%37.3%37.3%37.3%37.3%37.3%37.3%37.3%37.4%37.4%37.4%37.4%37.4%37.4%37.4%37.4%37.4%37.4%37.4%37.4%37.4%37.4%37.4%37.4%37.4%37.4%37.4%37.4%37.5%37.5%37.5%37.5%37.5%37.5%37.5%37.5%37.5%37.5%37.5%37.5%37.5%37.5%37.5%37.5%37.5%37.5%37.5%37.5%37.5%37.6%37.6%37.6%37.6%37.6%37.6%37.6%37.6%37.6%37.6%37.6%37.6%37.6%37.6%37.6%37.6%37.6%37.6%37.6%37.6%37.6%37.7%37.7%37.7%37.7%37.7%37.7%37.7%37.7%37.7%37.7%37.7%37.7%37.7%37.7%37.7%37.7%37.7%37.7%37.7%37.7%37.8%37.8%37.8%37.8%37.8%37.8%37.8%37.8%37.8%37.8%37.8%37.8%37.8%37.8%37.8%37.8%37.8%37.8%37.8%37.8%37.8%37.9%37.9%37.9%37.9%37.9%37.9%37.9%37.9%37.9%37.9%37.9%37.9%37.9%37.9%37.9%37.9%37.9%37.9%37.9%37.9%37.9%38.0%38.0%38.0%38.0%38.0%38.0%38.0%38.0%38.0%38.0%38.0%38.0%38.0%38.0%38.0%38.0%38.0%38.0%38.0%38.0%38.1%38.1%38.1%38.1%38.1%38.1%38.1%38.1%38.1%38.1%38.1%38.1%38.1%38.1%38.1%38.1%38.1%38.1%38.1%38.1%38.1%38.2%38.2%38.2%38.2%38.2%38.2%38.2%38.2%38.2%38.2%38.2%38.2%38.2%38.2%38.2%38.2%38.2%38.2%38.2%38.2%38.3%38.3%38.3%38.3%38.3%38.3%38.3%38.3%38.3%38.3%38.3%38.3%38.3%38.3%38.3%38.3%38.3%38.3%38.3%38.3%38.3%38.4%38.4%38.4%38.4%38.4%38.4%38.4%38.4%38.4%38.4%38.4%38.4%38.4%38.4%38.4%38.4%38.4%38.4%38.4%38.4%38.4%38.5%38.5%38.5%38.5%38.5%38.5%38.5%38.5%38.5%38.5%38.5%38.5%38.5%38.5%38.5%38.5%38.5%38.5%38.5%38.5%38.6%38.6%38.6%38.6%38.6%38.6%38.6%38.6%38.6%38.6%38.6%38.6%38.6%38.6%38.6%38.6%38.6%38.6%38.6%38.6%38.6%38.7%38.7%38.7%38.7%38.7%38.7%38.7%38.7%38.7%38.7%38.7%38.7%38.7%38.7%38.7%38.7%38.7%38.7%38.7%38.7%38.7%38.8%38.8%38.8%38.8%38.8%38.8%38.8%38.8%38.8%38.8%38.8%38.8%38.8%38.8%38.8%38.8%38.8%38.8%38.8%38.8%38.9%38.9%38.9%38.9%38.9%38.9%38.9%38.9%38.9%38.9%38.9%38.9%38.9%38.9%38.9%38.9%38.9%38.9%38.9%38.9%38.9%39.0%39.0%39.0%39.0%39.0%39.0%39.0%39.0%39.0%39.0%39.0%39.0%39.0%39.0%39.0%39.0%39.0%39.0%39.0%39.0%39.0%39.1%39.1%39.1%39.1%39.1%39.1%39.1%39.1%39.1%39.1%39.1%39.1%39.1%39.1%39.1%39.1%39.1%39.1%39.1%39.1%39.2%39.2%39.2%39.2%39.2%39.2%39.2%39.2%39.2%39.2%39.2%39.2%39.2%39.2%39.2%39.2%39.2%39.2%39.2%39.2%39.2%39.3%39.3%39.3%39.3%39.3%39.3%39.3%39.3%39.3%39.3%39.3%39.3%39.3%39.3%39.3%39.3%39.3%39.3%39.3%39.3%39.4%39.4%39.4%39.4%39.4%39.4%39.4%39.4%39.4%39.4%39.4%39.4%39.4%39.4%39.4%39.4%39.4%39.4%39.4%39.4%39.4%39.5%39.5%39.5%39.5%39.5%39.5%39.5%39.5%39.5%39.5%39.5%39.5%39.5%39.5%39.5%39.5%39.5%39.5%39.5%39.5%39.5%39.6%39.6%39.6%39.6%39.6%39.6%39.6%39.6%39.6%39.6%39.6%39.6%39.6%39.6%39.6%39.6%39.6%39.6%39.6%39.6%39.7%39.7%39.7%39.7%39.7%39.7%39.7%39.7%39.7%39.7%39.7%39.7%39.7%39.7%39.7%39.7%39.7%39.7%39.7%39.7%39.7%39.8%39.8%39.8%39.8%39.8%39.8%39.8%39.8%39.8%39.8%39.8%39.8%39.8%39.8%39.8%39.8%39.8%39.8%39.8%39.8%39.8%39.9%39.9%39.9%39.9%39.9%39.9%39.9%39.9%39.9%39.9%39.9%39.9%39.9%39.9%39.9%39.9%39.9%39.9%39.9%39.9%40.0%40.0%40.0%40.0%40.0%40.0%40.0%40.0%40.0%40.0%40.0%40.0%40.0%40.0%40.0%40.0%40.0%40.0%40.0%40.0%40.0%40.1%40.1%40.1%40.1%40.1%40.1%40.1%40.1%40.1%40.1%40.1%40.1%40.1%40.1%40.1%40.1%40.1%40.1%40.1%40.1%40.2%40.2%40.2%40.2%40.2%40.2%40.2%40.2%40.2%40.2%40.2%40.2%40.2%40.2%40.2%40.2%40.2%40.2%40.2%40.2%40.2%40.3%40.3%40.3%40.3%40.3%40.3%40.3%40.3%40.3%40.3%40.3%40.3%40.3%40.3%40.3%40.3%40.3%40.3%40.3%40.3%40.3%40.4%40.4%40.4%40.4%40.4%40.4%40.4%40.4%40.4%40.4%40.4%40.4%40.4%40.4%40.4%40.4%40.4%40.4%40.4%40.4%40.5%40.5%40.5%40.5%40.5%40.5%40.5%40.5%40.5%40.5%40.5%40.5%40.5%40.5%40.5%40.5%40.5%40.5%40.5%40.5%40.5%40.6%40.6%40.6%40.6%40.6%40.6%40.6%40.6%40.6%40.6%40.6%40.6%40.6%40.6%40.6%40.6%40.6%40.6%40.6%40.6%40.6%40.7%40.7%40.7%40.7%40.7%40.7%40.7%40.7%40.7%40.7%40.7%40.7%40.7%40.7%40.7%40.7%40.7%40.7%40.7%40.7%40.8%40.8%40.8%40.8%40.8%40.8%40.8%40.8%40.8%40.8%40.8%40.8%40.8%40.8%40.8%40.8%40.8%40.8%40.8%40.8%40.8%40.9%40.9%40.9%40.9%40.9%40.9%40.9%40.9%40.9%40.9%40.9%40.9%40.9%40.9%40.9%40.9%40.9%40.9%40.9%40.9%40.9%41.0%41.0%41.0%41.0%41.0%41.0%41.0%41.0%41.0%41.0%41.0%41.0%41.0%41.0%41.0%41.0%41.0%41.0%41.0%41.0%41.1%41.1%41.1%41.1%41.1%41.1%41.1%41.1%41.1%41.1%41.1%41.1%41.1%41.1%41.1%41.1%41.1%41.1%41.1%41.1%41.1%41.2%41.2%41.2%41.2%41.2%41.2%41.2%41.2%41.2%41.2%41.2%41.2%41.2%41.2%41.2%41.2%41.2%41.2%41.2%41.2%41.3%41.3%41.3%41.3%41.3%41.3%41.3%41.3%41.3%41.3%41.3%41.3%41.3%41.3%41.3%41.3%41.3%41.3%41.3%41.3%41.3%41.4%41.4%41.4%41.4%41.4%41.4%41.4%41.4%41.4%41.4%41.4%41.4%41.4%41.4%41.4%41.4%41.4%41.4%41.4%41.4%41.4%41.5%41.5%41.5%41.5%41.5%41.5%41.5%41.5%41.5%41.5%41.5%41.5%41.5%41.5%41.5%41.5%41.5%41.5%41.5%41.5%41.6%41.6%41.6%41.6%41.6%41.6%41.6%41.6%41.6%41.6%41.6%41.6%41.6%41.6%41.6%41.6%41.6%41.6%41.6%41.6%41.6%41.7%41.7%41.7%41.7%41.7%41.7%41.7%41.7%41.7%41.7%41.7%41.7%41.7%41.7%41.7%41.7%41.7%41.7%41.7%41.7%41.7%41.8%41.8%41.8%41.8%41.8%41.8%41.8%41.8%41.8%41.8%41.8%41.8%41.8%41.8%41.8%41.8%41.8%41.8%41.8%41.8%41.9%41.9%41.9%41.9%41.9%41.9%41.9%41.9%41.9%41.9%41.9%41.9%41.9%41.9%41.9%41.9%41.9%41.9%41.9%41.9%41.9%42.0%42.0%42.0%42.0%42.0%42.0%42.0%42.0%42.0%42.0%42.0%42.0%42.0%42.0%42.0%42.0%42.0%42.0%42.0%42.0%42.1%42.1%42.1%42.1%42.1%42.1%42.1%42.1%42.1%42.1%42.1%42.1%42.1%42.1%42.1%42.1%42.1%42.1%42.1%42.1%42.1%42.2%42.2%42.2%42.2%42.2%42.2%42.2%42.2%42.2%42.2%42.2%42.2%42.2%42.2%42.2%42.2%42.2%42.2%42.2%42.2%42.2%42.3%42.3%42.3%42.3%42.3%42.3%42.3%42.3%42.3%42.3%42.3%42.3%42.3%42.3%42.3%42.3%42.3%42.3%42.3%42.3%42.4%42.4%42.4%42.4%42.4%42.4%42.4%42.4%42.4%42.4%42.4%42.4%42.4%42.4%42.4%42.4%42.4%42.4%42.4%42.4%42.4%42.5%42.5%42.5%42.5%42.5%42.5%42.5%42.5%42.5%42.5%42.5%42.5%42.5%42.5%42.5%42.5%42.5%42.5%42.5%42.5%42.5%42.6%42.6%42.6%42.6%42.6%42.6%42.6%42.6%42.6%42.6%42.6%42.6%42.6%42.6%42.6%42.6%42.6%42.6%42.6%42.6%42.7%42.7%42.7%42.7%42.7%42.7%42.7%42.7%42.7%42.7%42.7%42.7%42.7%42.7%42.7%42.7%42.7%42.7%42.7%42.7%42.7%42.8%42.8%42.8%42.8%42.8%42.8%42.8%42.8%42.8%42.8%42.8%42.8%42.8%42.8%42.8%42.8%42.8%42.8%42.8%42.8%42.9%42.9%42.9%42.9%42.9%42.9%42.9%42.9%42.9%42.9%42.9%42.9%42.9%42.9%42.9%42.9%42.9%42.9%42.9%42.9%42.9%43.0%43.0%43.0%43.0%43.0%43.0%43.0%43.0%43.0%43.0%43.0%43.0%43.0%43.0%43.0%43.0%43.0%43.0%43.0%43.0%43.0%43.1%43.1%43.1%43.1%43.1%43.1%43.1%43.1%43.1%43.1%43.1%43.1%43.1%43.1%43.1%43.1%43.1%43.1%43.1%43.1%43.2%43.2%43.2%43.2%43.2%43.2%43.2%43.2%43.2%43.2%43.2%43.2%43.2%43.2%43.2%43.2%43.2%43.2%43.2%43.2%43.2%43.3%43.3%43.3%43.3%43.3%43.3%43.3%43.3%43.3%43.3%43.3%43.3%43.3%43.3%43.3%43.3%43.3%43.3%43.3%43.3%43.3%43.4%43.4%43.4%43.4%43.4%43.4%43.4%43.4%43.4%43.4%43.4%43.4%43.4%43.4%43.4%43.4%43.4%43.4%43.4%43.4%43.5%43.5%43.5%43.5%43.5%43.5%43.5%43.5%43.5%43.5%43.5%43.5%43.5%43.5%43.5%43.5%43.5%43.5%43.5%43.5%43.5%43.6%43.6%43.6%43.6%43.6%43.6%43.6%43.6%43.6%43.6%43.6%43.6%43.6%43.6%43.6%43.6%43.6%43.6%43.6%43.6%43.6%43.7%43.7%43.7%43.7%43.7%43.7%43.7%43.7%43.7%43.7%43.7%43.7%43.7%43.7%43.7%43.7%43.7%43.7%43.7%43.7%43.8%43.8%43.8%43.8%43.8%43.8%43.8%43.8%43.8%43.8%43.8%43.8%43.8%43.8%43.8%43.8%43.8%43.8%43.8%43.8%43.8%43.9%43.9%43.9%43.9%43.9%43.9%43.9%43.9%43.9%43.9%43.9%43.9%43.9%43.9%43.9%43.9%43.9%43.9%43.9%43.9%44.0%44.0%44.0%44.0%44.0%44.0%44.0%44.0%44.0%44.0%44.0%44.0%44.0%44.0%44.0%44.0%44.0%44.0%44.0%44.0%44.0%44.1%44.1%44.1%44.1%44.1%44.1%44.1%44.1%44.1%44.1%44.1%44.1%44.1%44.1%44.1%44.1%44.1%44.1%44.1%44.1%44.1%44.2%44.2%44.2%44.2%44.2%44.2%44.2%44.2%44.2%44.2%44.2%44.2%44.2%44.2%44.2%44.2%44.2%44.2%44.2%44.2%44.3%44.3%44.3%44.3%44.3%44.3%44.3%44.3%44.3%44.3%44.3%44.3%44.3%44.3%44.3%44.3%44.3%44.3%44.3%44.3%44.3%44.4%44.4%44.4%44.4%44.4%44.4%44.4%44.4%44.4%44.4%44.4%44.4%44.4%44.4%44.4%44.4%44.4%44.4%44.4%44.4%44.4%44.5%44.5%44.5%44.5%44.5%44.5%44.5%44.5%44.5%44.5%44.5%44.5%44.5%44.5%44.5%44.5%44.5%44.5%44.5%44.5%44.6%44.6%44.6%44.6%44.6%44.6%44.6%44.6%44.6%44.6%44.6%44.6%44.6%44.6%44.6%44.6%44.6%44.6%44.6%44.6%44.6%44.7%44.7%44.7%44.7%44.7%44.7%44.7%44.7%44.7%44.7%44.7%44.7%44.7%44.7%44.7%44.7%44.7%44.7%44.7%44.7%44.8%44.8%44.8%44.8%44.8%44.8%44.8%44.8%44.8%44.8%44.8%44.8%44.8%44.8%44.8%44.8%44.8%44.8%44.8%44.8%44.8%44.9%44.9%44.9%44.9%44.9%44.9%44.9%44.9%44.9%44.9%44.9%44.9%44.9%44.9%44.9%44.9%44.9%44.9%44.9%44.9%44.9%45.0%45.0%45.0%45.0%45.0%45.0%45.0%45.0%45.0%45.0%45.0%45.0%45.0%45.0%45.0%45.0%45.0%45.0%45.0%45.0%45.1%45.1%45.1%45.1%45.1%45.1%45.1%45.1%45.1%45.1%45.1%45.1%45.1%45.1%45.1%45.1%45.1%45.1%45.1%45.1%45.1%45.2%45.2%45.2%45.2%45.2%45.2%45.2%45.2%45.2%45.2%45.2%45.2%45.2%45.2%45.2%45.2%45.2%45.2%45.2%45.2%45.2%45.3%45.3%45.3%45.3%45.3%45.3%45.3%45.3%45.3%45.3%45.3%45.3%45.3%45.3%45.3%45.3%45.3%45.3%45.3%45.3%45.4%45.4%45.4%45.4%45.4%45.4%45.4%45.4%45.4%45.4%45.4%45.4%45.4%45.4%45.4%45.4%45.4%45.4%45.4%45.4%45.4%45.5%45.5%45.5%45.5%45.5%45.5%45.5%45.5%45.5%45.5%45.5%45.5%45.5%45.5%45.5%45.5%45.5%45.5%45.5%45.5%45.6%45.6%45.6%45.6%45.6%45.6%45.6%45.6%45.6%45.6%45.6%45.6%45.6%45.6%45.6%45.6%45.6%45.6%45.6%45.6%45.6%45.7%45.7%45.7%45.7%45.7%45.7%45.7%45.7%45.7%45.7%45.7%45.7%45.7%45.7%45.7%45.7%45.7%45.7%45.7%45.7%45.7%45.8%45.8%45.8%45.8%45.8%45.8%45.8%45.8%45.8%45.8%45.8%45.8%45.8%45.8%45.8%45.8%45.8%45.8%45.8%45.8%45.9%45.9%45.9%45.9%45.9%45.9%45.9%45.9%45.9%45.9%45.9%45.9%45.9%45.9%45.9%45.9%45.9%45.9%45.9%45.9%45.9%46.0%46.0%46.0%46.0%46.0%46.0%46.0%46.0%46.0%46.0%46.0%46.0%46.0%46.0%46.0%46.0%46.0%46.0%46.0%46.0%46.0%46.1%46.1%46.1%46.1%46.1%46.1%46.1%46.1%46.1%46.1%46.1%46.1%46.1%46.1%46.1%46.1%46.1%46.1%46.1%46.1%46.2%46.2%46.2%46.2%46.2%46.2%46.2%46.2%46.2%46.2%46.2%46.2%46.2%46.2%46.2%46.2%46.2%46.2%46.2%46.2%46.2%46.3%46.3%46.3%46.3%46.3%46.3%46.3%46.3%46.3%46.3%46.3%46.3%46.3%46.3%46.3%46.3%46.3%46.3%46.3%46.3%46.3%46.4%46.4%46.4%46.4%46.4%46.4%46.4%46.4%46.4%46.4%46.4%46.4%46.4%46.4%46.4%46.4%46.4%46.4%46.4%46.4%46.5%46.5%46.5%46.5%46.5%46.5%46.5%46.5%46.5%46.5%46.5%46.5%46.5%46.5%46.5%46.5%46.5%46.5%46.5%46.5%46.5%46.6%46.6%46.6%46.6%46.6%46.6%46.6%46.6%46.6%46.6%46.6%46.6%46.6%46.6%46.6%46.6%46.6%46.6%46.6%46.6%46.7%46.7%46.7%46.7%46.7%46.7%46.7%46.7%46.7%46.7%46.7%46.7%46.7%46.7%46.7%46.7%46.7%46.7%46.7%46.7%46.7%46.8%46.8%46.8%46.8%46.8%46.8%46.8%46.8%46.8%46.8%46.8%46.8%46.8%46.8%46.8%46.8%46.8%46.8%46.8%46.8%46.8%46.9%46.9%46.9%46.9%46.9%46.9%46.9%46.9%46.9%46.9%46.9%46.9%46.9%46.9%46.9%46.9%46.9%46.9%46.9%46.9%47.0%47.0%47.0%47.0%47.0%47.0%47.0%47.0%47.0%47.0%47.0%47.0%47.0%47.0%47.0%47.0%47.0%47.0%47.0%47.0%47.0%47.1%47.1%47.1%47.1%47.1%47.1%47.1%47.1%47.1%47.1%47.1%47.1%47.1%47.1%47.1%47.1%47.1%47.1%47.1%47.1%47.1%47.2%47.2%47.2%47.2%47.2%47.2%47.2%47.2%47.2%47.2%47.2%47.2%47.2%47.2%47.2%47.2%47.2%47.2%47.2%47.2%47.3%47.3%47.3%47.3%47.3%47.3%47.3%47.3%47.3%47.3%47.3%47.3%47.3%47.3%47.3%47.3%47.3%47.3%47.3%47.3%47.3%47.4%47.4%47.4%47.4%47.4%47.4%47.4%47.4%47.4%47.4%47.4%47.4%47.4%47.4%47.4%47.4%47.4%47.4%47.4%47.4%47.5%47.5%47.5%47.5%47.5%47.5%47.5%47.5%47.5%47.5%47.5%47.5%47.5%47.5%47.5%47.5%47.5%47.5%47.5%47.5%47.5%47.6%47.6%47.6%47.6%47.6%47.6%47.6%47.6%47.6%47.6%47.6%47.6%47.6%47.6%47.6%47.6%47.6%47.6%47.6%47.6%47.6%47.7%47.7%47.7%47.7%47.7%47.7%47.7%47.7%47.7%47.7%47.7%47.7%47.7%47.7%47.7%47.7%47.7%47.7%47.7%47.7%47.8%47.8%47.8%47.8%47.8%47.8%47.8%47.8%47.8%47.8%47.8%47.8%47.8%47.8%47.8%47.8%47.8%47.8%47.8%47.8%47.8%47.9%47.9%47.9%47.9%47.9%47.9%47.9%47.9%47.9%47.9%47.9%47.9%47.9%47.9%47.9%47.9%47.9%47.9%47.9%47.9%47.9%48.0%48.0%48.0%48.0%48.0%48.0%48.0%48.0%48.0%48.0%48.0%48.0%48.0%48.0%48.0%48.0%48.0%48.0%48.0%48.0%48.1%48.1%48.1%48.1%48.1%48.1%48.1%48.1%48.1%48.1%48.1%48.1%48.1%48.1%48.1%48.1%48.1%48.1%48.1%48.1%48.1%48.2%48.2%48.2%48.2%48.2%48.2%48.2%48.2%48.2%48.2%48.2%48.2%48.2%48.2%48.2%48.2%48.2%48.2%48.2%48.2%48.2%48.3%48.3%48.3%48.3%48.3%48.3%48.3%48.3%48.3%48.3%48.3%48.3%48.3%48.3%48.3%48.3%48.3%48.3%48.3%48.3%48.4%48.4%48.4%48.4%48.4%48.4%48.4%48.4%48.4%48.4%48.4%48.4%48.4%48.4%48.4%48.4%48.4%48.4%48.4%48.4%48.4%48.5%48.5%48.5%48.5%48.5%48.5%48.5%48.5%48.5%48.5%48.5%48.5%48.5%48.5%48.5%48.5%48.5%48.5%48.5%48.5%48.6%48.6%48.6%48.6%48.6%48.6%48.6%48.6%48.6%48.6%48.6%48.6%48.6%48.6%48.6%48.6%48.6%48.6%48.6%48.6%48.6%48.7%48.7%48.7%48.7%48.7%48.7%48.7%48.7%48.7%48.7%48.7%48.7%48.7%48.7%48.7%48.7%48.7%48.7%48.7%48.7%48.7%48.8%48.8%48.8%48.8%48.8%48.8%48.8%48.8%48.8%48.8%48.8%48.8%48.8%48.8%48.8%48.8%48.8%48.8%48.8%48.8%48.9%48.9%48.9%48.9%48.9%48.9%48.9%48.9%48.9%48.9%48.9%48.9%48.9%48.9%48.9%48.9%48.9%48.9%48.9%48.9%48.9%49.0%49.0%49.0%49.0%49.0%49.0%49.0%49.0%49.0%49.0%49.0%49.0%49.0%49.0%49.0%49.0%49.0%49.0%49.0%49.0%49.0%49.1%49.1%49.1%49.1%49.1%49.1%49.1%49.1%49.1%49.1%49.1%49.1%49.1%49.1%49.1%49.1%49.1%49.1%49.1%49.1%49.2%49.2%49.2%49.2%49.2%49.2%49.2%49.2%49.2%49.2%49.2%49.2%49.2%49.2%49.2%49.2%49.2%49.2%49.2%49.2%49.2%49.3%49.3%49.3%49.3%49.3%49.3%49.3%49.3%49.3%49.3%49.3%49.3%49.3%49.3%49.3%49.3%49.3%49.3%49.3%49.3%49.4%49.4%49.4%49.4%49.4%49.4%49.4%49.4%49.4%49.4%49.4%49.4%49.4%49.4%49.4%49.4%49.4%49.4%49.4%49.4%49.4%49.5%49.5%49.5%49.5%49.5%49.5%49.5%49.5%49.5%49.5%49.5%49.5%49.5%49.5%49.5%49.5%49.5%49.5%49.5%49.5%49.5%49.6%49.6%49.6%49.6%49.6%49.6%49.6%49.6%49.6%49.6%49.6%49.6%49.6%49.6%49.6%49.6%49.6%49.6%49.6%49.6%49.7%49.7%49.7%49.7%49.7%49.7%49.7%49.7%49.7%49.7%49.7%49.7%49.7%49.7%49.7%49.7%49.7%49.7%49.7%49.7%49.7%49.8%49.8%49.8%49.8%49.8%49.8%49.8%49.8%49.8%49.8%49.8%49.8%49.8%49.8%49.8%49.8%49.8%49.8%49.8%49.8%49.8%49.9%49.9%49.9%49.9%49.9%49.9%49.9%49.9%49.9%49.9%49.9%49.9%49.9%49.9%49.9%49.9%49.9%49.9%49.9%49.9%50.0%50.0%50.0%50.0%50.0%50.0%50.0%50.0%50.0%50.0%50.0%50.0%50.0%50.0%50.0%50.0%50.0%50.0%50.0%50.0%50.0%50.1%50.1%50.1%50.1%50.1%50.1%50.1%50.1%50.1%50.1%50.1%50.1%50.1%50.1%50.1%50.1%50.1%50.1%50.1%50.1%50.2%50.2%50.2%50.2%50.2%50.2%50.2%50.2%50.2%50.2%50.2%50.2%50.2%50.2%50.2%50.2%50.2%50.2%50.2%50.2%50.2%50.3%50.3%50.3%50.3%50.3%50.3%50.3%50.3%50.3%50.3%50.3%50.3%50.3%50.3%50.3%50.3%50.3%50.3%50.3%50.3%50.3%50.4%50.4%50.4%50.4%50.4%50.4%50.4%50.4%50.4%50.4%50.4%50.4%50.4%50.4%50.4%50.4%50.4%50.4%50.4%50.4%50.5%50.5%50.5%50.5%50.5%50.5%50.5%50.5%50.5%50.5%50.5%50.5%50.5%50.5%50.5%50.5%50.5%50.5%50.5%50.5%50.5%50.6%50.6%50.6%50.6%50.6%50.6%50.6%50.6%50.6%50.6%50.6%50.6%50.6%50.6%50.6%50.6%50.6%50.6%50.6%50.6%50.6%50.7%50.7%50.7%50.7%50.7%50.7%50.7%50.7%50.7%50.7%50.7%50.7%50.7%50.7%50.7%50.7%50.7%50.7%50.7%50.7%50.8%50.8%50.8%50.8%50.8%50.8%50.8%50.8%50.8%50.8%50.8%50.8%50.8%50.8%50.8%50.8%50.8%50.8%50.8%50.8%50.8%50.9%50.9%50.9%50.9%50.9%50.9%50.9%50.9%50.9%50.9%50.9%50.9%50.9%50.9%50.9%50.9%50.9%50.9%50.9%50.9%50.9%51.0%51.0%51.0%51.0%51.0%51.0%51.0%51.0%51.0%51.0%51.0%51.0%51.0%51.0%51.0%51.0%51.0%51.0%51.0%51.0%51.1%51.1%51.1%51.1%51.1%51.1%51.1%51.1%51.1%51.1%51.1%51.1%51.1%51.1%51.1%51.1%51.1%51.1%51.1%51.1%51.1%51.2%51.2%51.2%51.2%51.2%51.2%51.2%51.2%51.2%51.2%51.2%51.2%51.2%51.2%51.2%51.2%51.2%51.2%51.2%51.2%51.3%51.3%51.3%51.3%51.3%51.3%51.3%51.3%51.3%51.3%51.3%51.3%51.3%51.3%51.3%51.3%51.3%51.3%51.3%51.3%51.3%51.4%51.4%51.4%51.4%51.4%51.4%51.4%51.4%51.4%51.4%51.4%51.4%51.4%51.4%51.4%51.4%51.4%51.4%51.4%51.4%51.4%51.5%51.5%51.5%51.5%51.5%51.5%51.5%51.5%51.5%51.5%51.5%51.5%51.5%51.5%51.5%51.5%51.5%51.5%51.5%51.5%51.6%51.6%51.6%51.6%51.6%51.6%51.6%51.6%51.6%51.6%51.6%51.6%51.6%51.6%51.6%51.6%51.6%51.6%51.6%51.6%51.6%51.7%51.7%51.7%51.7%51.7%51.7%51.7%51.7%51.7%51.7%51.7%51.7%51.7%51.7%51.7%51.7%51.7%51.7%51.7%51.7%51.7%51.8%51.8%51.8%51.8%51.8%51.8%51.8%51.8%51.8%51.8%51.8%51.8%51.8%51.8%51.8%51.8%51.8%51.8%51.8%51.8%51.9%51.9%51.9%51.9%51.9%51.9%51.9%51.9%51.9%51.9%51.9%51.9%51.9%51.9%51.9%51.9%51.9%51.9%51.9%51.9%51.9%52.0%52.0%52.0%52.0%52.0%52.0%52.0%52.0%52.0%52.0%52.0%52.0%52.0%52.0%52.0%52.0%52.0%52.0%52.0%52.0%52.1%52.1%52.1%52.1%52.1%52.1%52.1%52.1%52.1%52.1%52.1%52.1%52.1%52.1%52.1%52.1%52.1%52.1%52.1%52.1%52.1%52.2%52.2%52.2%52.2%52.2%52.2%52.2%52.2%52.2%52.2%52.2%52.2%52.2%52.2%52.2%52.2%52.2%52.2%52.2%52.2%52.2%52.3%52.3%52.3%52.3%52.3%52.3%52.3%52.3%52.3%52.3%52.3%52.3%52.3%52.3%52.3%52.3%52.3%52.3%52.3%52.3%52.4%52.4%52.4%52.4%52.4%52.4%52.4%52.4%52.4%52.4%52.4%52.4%52.4%52.4%52.4%52.4%52.4%52.4%52.4%52.4%52.4%52.5%52.5%52.5%52.5%52.5%52.5%52.5%52.5%52.5%52.5%52.5%52.5%52.5%52.5%52.5%52.5%52.5%52.5%52.5%52.5%52.5%52.6%52.6%52.6%52.6%52.6%52.6%52.6%52.6%52.6%52.6%52.6%52.6%52.6%52.6%52.6%52.6%52.6%52.6%52.6%52.6%52.7%52.7%52.7%52.7%52.7%52.7%52.7%52.7%52.7%52.7%52.7%52.7%52.7%52.7%52.7%52.7%52.7%52.7%52.7%52.7%52.7%52.8%52.8%52.8%52.8%52.8%52.8%52.8%52.8%52.8%52.8%52.8%52.8%52.8%52.8%52.8%52.8%52.8%52.8%52.8%52.8%52.9%52.9%52.9%52.9%52.9%52.9%52.9%52.9%52.9%52.9%52.9%52.9%52.9%52.9%52.9%52.9%52.9%52.9%52.9%52.9%52.9%53.0%53.0%53.0%53.0%53.0%53.0%53.0%53.0%53.0%53.0%53.0%53.0%53.0%53.0%53.0%53.0%53.0%53.0%53.0%53.0%53.0%53.1%53.1%53.1%53.1%53.1%53.1%53.1%53.1%53.1%53.1%53.1%53.1%53.1%53.1%53.1%53.1%53.1%53.1%53.1%53.1%53.2%53.2%53.2%53.2%53.2%53.2%53.2%53.2%53.2%53.2%53.2%53.2%53.2%53.2%53.2%53.2%53.2%53.2%53.2%53.2%53.2%53.3%53.3%53.3%53.3%53.3%53.3%53.3%53.3%53.3%53.3%53.3%53.3%53.3%53.3%53.3%53.3%53.3%53.3%53.3%53.3%53.3%53.4%53.4%53.4%53.4%53.4%53.4%53.4%53.4%53.4%53.4%53.4%53.4%53.4%53.4%53.4%53.4%53.4%53.4%53.4%53.4%53.5%53.5%53.5%53.5%53.5%53.5%53.5%53.5%53.5%53.5%53.5%53.5%53.5%53.5%53.5%53.5%53.5%53.5%53.5%53.5%53.5%53.6%53.6%53.6%53.6%53.6%53.6%53.6%53.6%53.6%53.6%53.6%53.6%53.6%53.6%53.6%53.6%53.6%53.6%53.6%53.6%53.6%53.7%53.7%53.7%53.7%53.7%53.7%53.7%53.7%53.7%53.7%53.7%53.7%53.7%53.7%53.7%53.7%53.7%53.7%53.7%53.7%53.8%53.8%53.8%53.8%53.8%53.8%53.8%53.8%53.8%53.8%53.8%53.8%53.8%53.8%53.8%53.8%53.8%53.8%53.8%53.8%53.8%53.9%53.9%53.9%53.9%53.9%53.9%53.9%53.9%53.9%53.9%53.9%53.9%53.9%53.9%53.9%53.9%53.9%53.9%53.9%53.9%54.0%54.0%54.0%54.0%54.0%54.0%54.0%54.0%54.0%54.0%54.0%54.0%54.0%54.0%54.0%54.0%54.0%54.0%54.0%54.0%54.0%54.1%54.1%54.1%54.1%54.1%54.1%54.1%54.1%54.1%54.1%54.1%54.1%54.1%54.1%54.1%54.1%54.1%54.1%54.1%54.1%54.1%54.2%54.2%54.2%54.2%54.2%54.2%54.2%54.2%54.2%54.2%54.2%54.2%54.2%54.2%54.2%54.2%54.2%54.2%54.2%54.2%54.3%54.3%54.3%54.3%54.3%54.3%54.3%54.3%54.3%54.3%54.3%54.3%54.3%54.3%54.3%54.3%54.3%54.3%54.3%54.3%54.3%54.4%54.4%54.4%54.4%54.4%54.4%54.4%54.4%54.4%54.4%54.4%54.4%54.4%54.4%54.4%54.4%54.4%54.4%54.4%54.4%54.4%54.5%54.5%54.5%54.5%54.5%54.5%54.5%54.5%54.5%54.5%54.5%54.5%54.5%54.5%54.5%54.5%54.5%54.5%54.5%54.5%54.6%54.6%54.6%54.6%54.6%54.6%54.6%54.6%54.6%54.6%54.6%54.6%54.6%54.6%54.6%54.6%54.6%54.6%54.6%54.6%54.6%54.7%54.7%54.7%54.7%54.7%54.7%54.7%54.7%54.7%54.7%54.7%54.7%54.7%54.7%54.7%54.7%54.7%54.7%54.7%54.7%54.8%54.8%54.8%54.8%54.8%54.8%54.8%54.8%54.8%54.8%54.8%54.8%54.8%54.8%54.8%54.8%54.8%54.8%54.8%54.8%54.8%54.9%54.9%54.9%54.9%54.9%54.9%54.9%54.9%54.9%54.9%54.9%54.9%54.9%54.9%54.9%54.9%54.9%54.9%54.9%54.9%54.9%55.0%55.0%55.0%55.0%55.0%55.0%55.0%55.0%55.0%55.0%55.0%55.0%55.0%55.0%55.0%55.0%55.0%55.0%55.0%55.0%55.1%55.1%55.1%55.1%55.1%55.1%55.1%55.1%55.1%55.1%55.1%55.1%55.1%55.1%55.1%55.1%55.1%55.1%55.1%55.1%55.1%55.2%55.2%55.2%55.2%55.2%55.2%55.2%55.2%55.2%55.2%55.2%55.2%55.2%55.2%55.2%55.2%55.2%55.2%55.2%55.2%55.2%55.3%55.3%55.3%55.3%55.3%55.3%55.3%55.3%55.3%55.3%55.3%55.3%55.3%55.3%55.3%55.3%55.3%55.3%55.3%55.3%55.4%55.4%55.4%55.4%55.4%55.4%55.4%55.4%55.4%55.4%55.4%55.4%55.4%55.4%55.4%55.4%55.4%55.4%55.4%55.4%55.4%55.5%55.5%55.5%55.5%55.5%55.5%55.5%55.5%55.5%55.5%55.5%55.5%55.5%55.5%55.5%55.5%55.5%55.5%55.5%55.5%55.6%55.6%55.6%55.6%55.6%55.6%55.6%55.6%55.6%55.6%55.6%55.6%55.6%55.6%55.6%55.6%55.6%55.6%55.6%55.6%55.6%55.7%55.7%55.7%55.7%55.7%55.7%55.7%55.7%55.7%55.7%55.7%55.7%55.7%55.7%55.7%55.7%55.7%55.7%55.7%55.7%55.7%55.8%55.8%55.8%55.8%55.8%55.8%55.8%55.8%55.8%55.8%55.8%55.8%55.8%55.8%55.8%55.8%55.8%55.8%55.8%55.8%55.9%55.9%55.9%55.9%55.9%55.9%55.9%55.9%55.9%55.9%55.9%55.9%55.9%55.9%55.9%55.9%55.9%55.9%55.9%55.9%55.9%56.0%56.0%56.0%56.0%56.0%56.0%56.0%56.0%56.0%56.0%56.0%56.0%56.0%56.0%56.0%56.0%56.0%56.0%56.0%56.0%56.0%56.1%56.1%56.1%56.1%56.1%56.1%56.1%56.1%56.1%56.1%56.1%56.1%56.1%56.1%56.1%56.1%56.1%56.1%56.1%56.1%56.2%56.2%56.2%56.2%56.2%56.2%56.2%56.2%56.2%56.2%56.2%56.2%56.2%56.2%56.2%56.2%56.2%56.2%56.2%56.2%56.2%56.3%56.3%56.3%56.3%56.3%56.3%56.3%56.3%56.3%56.3%56.3%56.3%56.3%56.3%56.3%56.3%56.3%56.3%56.3%56.3%56.3%56.4%56.4%56.4%56.4%56.4%56.4%56.4%56.4%56.4%56.4%56.4%56.4%56.4%56.4%56.4%56.4%56.4%56.4%56.4%56.4%56.5%56.5%56.5%56.5%56.5%56.5%56.5%56.5%56.5%56.5%56.5%56.5%56.5%56.5%56.5%56.5%56.5%56.5%56.5%56.5%56.5%56.6%56.6%56.6%56.6%56.6%56.6%56.6%56.6%56.6%56.6%56.6%56.6%56.6%56.6%56.6%56.6%56.6%56.6%56.6%56.6%56.7%56.7%56.7%56.7%56.7%56.7%56.7%56.7%56.7%56.7%56.7%56.7%56.7%56.7%56.7%56.7%56.7%56.7%56.7%56.7%56.7%56.8%56.8%56.8%56.8%56.8%56.8%56.8%56.8%56.8%56.8%56.8%56.8%56.8%56.8%56.8%56.8%56.8%56.8%56.8%56.8%56.8%56.9%56.9%56.9%56.9%56.9%56.9%56.9%56.9%56.9%56.9%56.9%56.9%56.9%56.9%56.9%56.9%56.9%56.9%56.9%56.9%57.0%57.0%57.0%57.0%57.0%57.0%57.0%57.0%57.0%57.0%57.0%57.0%57.0%57.0%57.0%57.0%57.0%57.0%57.0%57.0%57.0%57.1%57.1%57.1%57.1%57.1%57.1%57.1%57.1%57.1%57.1%57.1%57.1%57.1%57.1%57.1%57.1%57.1%57.1%57.1%57.1%57.1%57.2%57.2%57.2%57.2%57.2%57.2%57.2%57.2%57.2%57.2%57.2%57.2%57.2%57.2%57.2%57.2%57.2%57.2%57.2%57.2%57.3%57.3%57.3%57.3%57.3%57.3%57.3%57.3%57.3%57.3%57.3%57.3%57.3%57.3%57.3%57.3%57.3%57.3%57.3%57.3%57.3%57.4%57.4%57.4%57.4%57.4%57.4%57.4%57.4%57.4%57.4%57.4%57.4%57.4%57.4%57.4%57.4%57.4%57.4%57.4%57.4%57.5%57.5%57.5%57.5%57.5%57.5%57.5%57.5%57.5%57.5%57.5%57.5%57.5%57.5%57.5%57.5%57.5%57.5%57.5%57.5%57.5%57.6%57.6%57.6%57.6%57.6%57.6%57.6%57.6%57.6%57.6%57.6%57.6%57.6%57.6%57.6%57.6%57.6%57.6%57.6%57.6%57.6%57.7%57.7%57.7%57.7%57.7%57.7%57.7%57.7%57.7%57.7%57.7%57.7%57.7%57.7%57.7%57.7%57.7%57.7%57.7%57.7%57.8%57.8%57.8%57.8%57.8%57.8%57.8%57.8%57.8%57.8%57.8%57.8%57.8%57.8%57.8%57.8%57.8%57.8%57.8%57.8%57.8%57.9%57.9%57.9%57.9%57.9%57.9%57.9%57.9%57.9%57.9%57.9%57.9%57.9%57.9%57.9%57.9%57.9%57.9%57.9%57.9%57.9%58.0%58.0%58.0%58.0%58.0%58.0%58.0%58.0%58.0%58.0%58.0%58.0%58.0%58.0%58.0%58.0%58.0%58.0%58.0%58.0%58.1%58.1%58.1%58.1%58.1%58.1%58.1%58.1%58.1%58.1%58.1%58.1%58.1%58.1%58.1%58.1%58.1%58.1%58.1%58.1%58.1%58.2%58.2%58.2%58.2%58.2%58.2%58.2%58.2%58.2%58.2%58.2%58.2%58.2%58.2%58.2%58.2%58.2%58.2%58.2%58.2%58.2%58.3%58.3%58.3%58.3%58.3%58.3%58.3%58.3%58.3%58.3%58.3%58.3%58.3%58.3%58.3%58.3%58.3%58.3%58.3%58.3%58.4%58.4%58.4%58.4%58.4%58.4%58.4%58.4%58.4%58.4%58.4%58.4%58.4%58.4%58.4%58.4%58.4%58.4%58.4%58.4%58.4%58.5%58.5%58.5%58.5%58.5%58.5%58.5%58.5%58.5%58.5%58.5%58.5%58.5%58.5%58.5%58.5%58.5%58.5%58.5%58.5%58.6%58.6%58.6%58.6%58.6%58.6%58.6%58.6%58.6%58.6%58.6%58.6%58.6%58.6%58.6%58.6%58.6%58.6%58.6%58.6%58.6%58.7%58.7%58.7%58.7%58.7%58.7%58.7%58.7%58.7%58.7%58.7%58.7%58.7%58.7%58.7%58.7%58.7%58.7%58.7%58.7%58.7%58.8%58.8%58.8%58.8%58.8%58.8%58.8%58.8%58.8%58.8%58.8%58.8%58.8%58.8%58.8%58.8%58.8%58.8%58.8%58.8%58.9%58.9%58.9%58.9%58.9%58.9%58.9%58.9%58.9%58.9%58.9%58.9%58.9%58.9%58.9%58.9%58.9%58.9%58.9%58.9%58.9%59.0%59.0%59.0%59.0%59.0%59.0%59.0%59.0%59.0%59.0%59.0%59.0%59.0%59.0%59.0%59.0%59.0%59.0%59.0%59.0%59.0%59.1%59.1%59.1%59.1%59.1%59.1%59.1%59.1%59.1%59.1%59.1%59.1%59.1%59.1%59.1%59.1%59.1%59.1%59.1%59.1%59.2%59.2%59.2%59.2%59.2%59.2%59.2%59.2%59.2%59.2%59.2%59.2%59.2%59.2%59.2%59.2%59.2%59.2%59.2%59.2%59.2%59.3%59.3%59.3%59.3%59.3%59.3%59.3%59.3%59.3%59.3%59.3%59.3%59.3%59.3%59.3%59.3%59.3%59.3%59.3%59.3%59.4%59.4%59.4%59.4%59.4%59.4%59.4%59.4%59.4%59.4%59.4%59.4%59.4%59.4%59.4%59.4%59.4%59.4%59.4%59.4%59.4%59.5%59.5%59.5%59.5%59.5%59.5%59.5%59.5%59.5%59.5%59.5%59.5%59.5%59.5%59.5%59.5%59.5%59.5%59.5%59.5%59.5%59.6%59.6%59.6%59.6%59.6%59.6%59.6%59.6%59.6%59.6%59.6%59.6%59.6%59.6%59.6%59.6%59.6%59.6%59.6%59.6%59.7%59.7%59.7%59.7%59.7%59.7%59.7%59.7%59.7%59.7%59.7%59.7%59.7%59.7%59.7%59.7%59.7%59.7%59.7%59.7%59.7%59.8%59.8%59.8%59.8%59.8%59.8%59.8%59.8%59.8%59.8%59.8%59.8%59.8%59.8%59.8%59.8%59.8%59.8%59.8%59.8%59.8%59.9%59.9%59.9%59.9%59.9%59.9%59.9%59.9%59.9%59.9%59.9%59.9%59.9%59.9%59.9%59.9%59.9%59.9%59.9%59.9%60.0%60.0%60.0%60.0%60.0%60.0%60.0%60.0%60.0%60.0%60.0%60.0%60.0%60.0%60.0%60.0%60.0%60.0%60.0%60.0%60.0%60.1%60.1%60.1%60.1%60.1%60.1%60.1%60.1%60.1%60.1%60.1%60.1%60.1%60.1%60.1%60.1%60.1%60.1%60.1%60.1%60.2%60.2%60.2%60.2%60.2%60.2%60.2%60.2%60.2%60.2%60.2%60.2%60.2%60.2%60.2%60.2%60.2%60.2%60.2%60.2%60.2%60.3%60.3%60.3%60.3%60.3%60.3%60.3%60.3%60.3%60.3%60.3%60.3%60.3%60.3%60.3%60.3%60.3%60.3%60.3%60.3%60.3%60.4%60.4%60.4%60.4%60.4%60.4%60.4%60.4%60.4%60.4%60.4%60.4%60.4%60.4%60.4%60.4%60.4%60.4%60.4%60.4%60.5%60.5%60.5%60.5%60.5%60.5%60.5%60.5%60.5%60.5%60.5%60.5%60.5%60.5%60.5%60.5%60.5%60.5%60.5%60.5%60.5%60.6%60.6%60.6%60.6%60.6%60.6%60.6%60.6%60.6%60.6%60.6%60.6%60.6%60.6%60.6%60.6%60.6%60.6%60.6%60.6%60.6%60.7%60.7%60.7%60.7%60.7%60.7%60.7%60.7%60.7%60.7%60.7%60.7%60.7%60.7%60.7%60.7%60.7%60.7%60.7%60.7%60.8%60.8%60.8%60.8%60.8%60.8%60.8%60.8%60.8%60.8%60.8%60.8%60.8%60.8%60.8%60.8%60.8%60.8%60.8%60.8%60.8%60.9%60.9%60.9%60.9%60.9%60.9%60.9%60.9%60.9%60.9%60.9%60.9%60.9%60.9%60.9%60.9%60.9%60.9%60.9%60.9%60.9%61.0%61.0%61.0%61.0%61.0%61.0%61.0%61.0%61.0%61.0%61.0%61.0%61.0%61.0%61.0%61.0%61.0%61.0%61.0%61.0%61.1%61.1%61.1%61.1%61.1%61.1%61.1%61.1%61.1%61.1%61.1%61.1%61.1%61.1%61.1%61.1%61.1%61.1%61.1%61.1%61.1%61.2%61.2%61.2%61.2%61.2%61.2%61.2%61.2%61.2%61.2%61.2%61.2%61.2%61.2%61.2%61.2%61.2%61.2%61.2%61.2%61.3%61.3%61.3%61.3%61.3%61.3%61.3%61.3%61.3%61.3%61.3%61.3%61.3%61.3%61.3%61.3%61.3%61.3%61.3%61.3%61.3%61.4%61.4%61.4%61.4%61.4%61.4%61.4%61.4%61.4%61.4%61.4%61.4%61.4%61.4%61.4%61.4%61.4%61.4%61.4%61.4%61.4%61.5%61.5%61.5%61.5%61.5%61.5%61.5%61.5%61.5%61.5%61.5%61.5%61.5%61.5%61.5%61.5%61.5%61.5%61.5%61.5%61.6%61.6%61.6%61.6%61.6%61.6%61.6%61.6%61.6%61.6%61.6%61.6%61.6%61.6%61.6%61.6%61.6%61.6%61.6%61.6%61.6%61.7%61.7%61.7%61.7%61.7%61.7%61.7%61.7%61.7%61.7%61.7%61.7%61.7%61.7%61.7%61.7%61.7%61.7%61.7%61.7%61.7%61.8%61.8%61.8%61.8%61.8%61.8%61.8%61.8%61.8%61.8%61.8%61.8%61.8%61.8%61.8%61.8%61.8%61.8%61.8%61.8%61.9%61.9%61.9%61.9%61.9%61.9%61.9%61.9%61.9%61.9%61.9%61.9%61.9%61.9%61.9%61.9%61.9%61.9%61.9%61.9%61.9%62.0%62.0%62.0%62.0%62.0%62.0%62.0%62.0%62.0%62.0%62.0%62.0%62.0%62.0%62.0%62.0%62.0%62.0%62.0%62.0%62.1%62.1%62.1%62.1%62.1%62.1%62.1%62.1%62.1%62.1%62.1%62.1%62.1%62.1%62.1%62.1%62.1%62.1%62.1%62.1%62.1%62.2%62.2%62.2%62.2%62.2%62.2%62.2%62.2%62.2%62.2%62.2%62.2%62.2%62.2%62.2%62.2%62.2%62.2%62.2%62.2%62.2%62.3%62.3%62.3%62.3%62.3%62.3%62.3%62.3%62.3%62.3%62.3%62.3%62.3%62.3%62.3%62.3%62.3%62.3%62.3%62.3%62.4%62.4%62.4%62.4%62.4%62.4%62.4%62.4%62.4%62.4%62.4%62.4%62.4%62.4%62.4%62.4%62.4%62.4%62.4%62.4%62.4%62.5%62.5%62.5%62.5%62.5%62.5%62.5%62.5%62.5%62.5%62.5%62.5%62.5%62.5%62.5%62.5%62.5%62.5%62.5%62.5%62.5%62.6%62.6%62.6%62.6%62.6%62.6%62.6%62.6%62.6%62.6%62.6%62.6%62.6%62.6%62.6%62.6%62.6%62.6%62.6%62.6%62.7%62.7%62.7%62.7%62.7%62.7%62.7%62.7%62.7%62.7%62.7%62.7%62.7%62.7%62.7%62.7%62.7%62.7%62.7%62.7%62.7%62.8%62.8%62.8%62.8%62.8%62.8%62.8%62.8%62.8%62.8%62.8%62.8%62.8%62.8%62.8%62.8%62.8%62.8%62.8%62.8%62.9%62.9%62.9%62.9%62.9%62.9%62.9%62.9%62.9%62.9%62.9%62.9%62.9%62.9%62.9%62.9%62.9%62.9%62.9%62.9%62.9%63.0%63.0%63.0%63.0%63.0%63.0%63.0%63.0%63.0%63.0%63.0%63.0%63.0%63.0%63.0%63.0%63.0%63.0%63.0%63.0%63.0%63.1%63.1%63.1%63.1%63.1%63.1%63.1%63.1%63.1%63.1%63.1%63.1%63.1%63.1%63.1%63.1%63.1%63.1%63.1%63.1%63.2%63.2%63.2%63.2%63.2%63.2%63.2%63.2%63.2%63.2%63.2%63.2%63.2%63.2%63.2%63.2%63.2%63.2%63.2%63.2%63.2%63.3%63.3%63.3%63.3%63.3%63.3%63.3%63.3%63.3%63.3%63.3%63.3%63.3%63.3%63.3%63.3%63.3%63.3%63.3%63.3%63.3%63.4%63.4%63.4%63.4%63.4%63.4%63.4%63.4%63.4%63.4%63.4%63.4%63.4%63.4%63.4%63.4%63.4%63.4%63.4%63.4%63.5%63.5%63.5%63.5%63.5%63.5%63.5%63.5%63.5%63.5%63.5%63.5%63.5%63.5%63.5%63.5%63.5%63.5%63.5%63.5%63.5%63.6%63.6%63.6%63.6%63.6%63.6%63.6%63.6%63.6%63.6%63.6%63.6%63.6%63.6%63.6%63.6%63.6%63.6%63.6%63.6%63.6%63.7%63.7%63.7%63.7%63.7%63.7%63.7%63.7%63.7%63.7%63.7%63.7%63.7%63.7%63.7%63.7%63.7%63.7%63.7%63.7%63.8%63.8%63.8%63.8%63.8%63.8%63.8%63.8%63.8%63.8%63.8%63.8%63.8%63.8%63.8%63.8%63.8%63.8%63.8%63.8%63.8%63.9%63.9%63.9%63.9%63.9%63.9%63.9%63.9%63.9%63.9%63.9%63.9%63.9%63.9%63.9%63.9%63.9%63.9%63.9%63.9%64.0%64.0%64.0%64.0%64.0%64.0%64.0%64.0%64.0%64.0%64.0%64.0%64.0%64.0%64.0%64.0%64.0%64.0%64.0%64.0%64.0%64.1%64.1%64.1%64.1%64.1%64.1%64.1%64.1%64.1%64.1%64.1%64.1%64.1%64.1%64.1%64.1%64.1%64.1%64.1%64.1%64.1%64.2%64.2%64.2%64.2%64.2%64.2%64.2%64.2%64.2%64.2%64.2%64.2%64.2%64.2%64.2%64.2%64.2%64.2%64.2%64.2%64.3%64.3%64.3%64.3%64.3%64.3%64.3%64.3%64.3%64.3%64.3%64.3%64.3%64.3%64.3%64.3%64.3%64.3%64.3%64.3%64.3%64.4%64.4%64.4%64.4%64.4%64.4%64.4%64.4%64.4%64.4%64.4%64.4%64.4%64.4%64.4%64.4%64.4%64.4%64.4%64.4%64.4%64.5%64.5%64.5%64.5%64.5%64.5%64.5%64.5%64.5%64.5%64.5%64.5%64.5%64.5%64.5%64.5%64.5%64.5%64.5%64.5%64.6%64.6%64.6%64.6%64.6%64.6%64.6%64.6%64.6%64.6%64.6%64.6%64.6%64.6%64.6%64.6%64.6%64.6%64.6%64.6%64.6%64.7%64.7%64.7%64.7%64.7%64.7%64.7%64.7%64.7%64.7%64.7%64.7%64.7%64.7%64.7%64.7%64.7%64.7%64.7%64.7%64.8%64.8%64.8%64.8%64.8%64.8%64.8%64.8%64.8%64.8%64.8%64.8%64.8%64.8%64.8%64.8%64.8%64.8%64.8%64.8%64.8%64.9%64.9%64.9%64.9%64.9%64.9%64.9%64.9%64.9%64.9%64.9%64.9%64.9%64.9%64.9%64.9%64.9%64.9%64.9%64.9%64.9%65.0%65.0%65.0%65.0%65.0%65.0%65.0%65.0%65.0%65.0%65.0%65.0%65.0%65.0%65.0%65.0%65.0%65.0%65.0%65.0%65.1%65.1%65.1%65.1%65.1%65.1%65.1%65.1%65.1%65.1%65.1%65.1%65.1%65.1%65.1%65.1%65.1%65.1%65.1%65.1%65.1%65.2%65.2%65.2%65.2%65.2%65.2%65.2%65.2%65.2%65.2%65.2%65.2%65.2%65.2%65.2%65.2%65.2%65.2%65.2%65.2%65.2%65.3%65.3%65.3%65.3%65.3%65.3%65.3%65.3%65.3%65.3%65.3%65.3%65.3%65.3%65.3%65.3%65.3%65.3%65.3%65.3%65.4%65.4%65.4%65.4%65.4%65.4%65.4%65.4%65.4%65.4%65.4%65.4%65.4%65.4%65.4%65.4%65.4%65.4%65.4%65.4%65.4%65.5%65.5%65.5%65.5%65.5%65.5%65.5%65.5%65.5%65.5%65.5%65.5%65.5%65.5%65.5%65.5%65.5%65.5%65.5%65.5%65.5%65.6%65.6%65.6%65.6%65.6%65.6%65.6%65.6%65.6%65.6%65.6%65.6%65.6%65.6%65.6%65.6%65.6%65.6%65.6%65.6%65.7%65.7%65.7%65.7%65.7%65.7%65.7%65.7%65.7%65.7%65.7%65.7%65.7%65.7%65.7%65.7%65.7%65.7%65.7%65.7%65.7%65.8%65.8%65.8%65.8%65.8%65.8%65.8%65.8%65.8%65.8%65.8%65.8%65.8%65.8%65.8%65.8%65.8%65.8%65.8%65.8%65.9%65.9%65.9%65.9%65.9%65.9%65.9%65.9%65.9%65.9%65.9%65.9%65.9%65.9%65.9%65.9%65.9%65.9%65.9%65.9%65.9%66.0%66.0%66.0%66.0%66.0%66.0%66.0%66.0%66.0%66.0%66.0%66.0%66.0%66.0%66.0%66.0%66.0%66.0%66.0%66.0%66.0%66.1%66.1%66.1%66.1%66.1%66.1%66.1%66.1%66.1%66.1%66.1%66.1%66.1%66.1%66.1%66.1%66.1%66.1%66.1%66.1%66.2%66.2%66.2%66.2%66.2%66.2%66.2%66.2%66.2%66.2%66.2%66.2%66.2%66.2%66.2%66.2%66.2%66.2%66.2%66.2%66.2%66.3%66.3%66.3%66.3%66.3%66.3%66.3%66.3%66.3%66.3%66.3%66.3%66.3%66.3%66.3%66.3%66.3%66.3%66.3%66.3%66.3%66.4%66.4%66.4%66.4%66.4%66.4%66.4%66.4%66.4%66.4%66.4%66.4%66.4%66.4%66.4%66.4%66.4%66.4%66.4%66.4%66.5%66.5%66.5%66.5%66.5%66.5%66.5%66.5%66.5%66.5%66.5%66.5%66.5%66.5%66.5%66.5%66.5%66.5%66.5%66.5%66.5%66.6%66.6%66.6%66.6%66.6%66.6%66.6%66.6%66.6%66.6%66.6%66.6%66.6%66.6%66.6%66.6%66.6%66.6%66.6%66.6%66.7%66.7%66.7%66.7%66.7%66.7%66.7%66.7%66.7%66.7%66.7%66.7%66.7%66.7%66.7%66.7%66.7%66.7%66.7%66.7%66.7%66.8%66.8%66.8%66.8%66.8%66.8%66.8%66.8%66.8%66.8%66.8%66.8%66.8%66.8%66.8%66.8%66.8%66.8%66.8%66.8%66.8%66.9%66.9%66.9%66.9%66.9%66.9%66.9%66.9%66.9%66.9%66.9%66.9%66.9%66.9%66.9%66.9%66.9%66.9%66.9%66.9%67.0%67.0%67.0%67.0%67.0%67.0%67.0%67.0%67.0%67.0%67.0%67.0%67.0%67.0%67.0%67.0%67.0%67.0%67.0%67.0%67.0%67.1%67.1%67.1%67.1%67.1%67.1%67.1%67.1%67.1%67.1%67.1%67.1%67.1%67.1%67.1%67.1%67.1%67.1%67.1%67.1%67.1%67.2%67.2%67.2%67.2%67.2%67.2%67.2%67.2%67.2%67.2%67.2%67.2%67.2%67.2%67.2%67.2%67.2%67.2%67.2%67.2%67.3%67.3%67.3%67.3%67.3%67.3%67.3%67.3%67.3%67.3%67.3%67.3%67.3%67.3%67.3%67.3%67.3%67.3%67.3%67.3%67.3%67.4%67.4%67.4%67.4%67.4%67.4%67.4%67.4%67.4%67.4%67.4%67.4%67.4%67.4%67.4%67.4%67.4%67.4%67.4%67.4%67.5%67.5%67.5%67.5%67.5%67.5%67.5%67.5%67.5%67.5%67.5%67.5%67.5%67.5%67.5%67.5%67.5%67.5%67.5%67.5%67.5%67.6%67.6%67.6%67.6%67.6%67.6%67.6%67.6%67.6%67.6%67.6%67.6%67.6%67.6%67.6%67.6%67.6%67.6%67.6%67.6%67.6%67.7%67.7%67.7%67.7%67.7%67.7%67.7%67.7%67.7%67.7%67.7%67.7%67.7%67.7%67.7%67.7%67.7%67.7%67.7%67.7%67.8%67.8%67.8%67.8%67.8%67.8%67.8%67.8%67.8%67.8%67.8%67.8%67.8%67.8%67.8%67.8%67.8%67.8%67.8%67.8%67.8%67.9%67.9%67.9%67.9%67.9%67.9%67.9%67.9%67.9%67.9%67.9%67.9%67.9%67.9%67.9%67.9%67.9%67.9%67.9%67.9%67.9%68.0%68.0%68.0%68.0%68.0%68.0%68.0%68.0%68.0%68.0%68.0%68.0%68.0%68.0%68.0%68.0%68.0%68.0%68.0%68.0%68.1%68.1%68.1%68.1%68.1%68.1%68.1%68.1%68.1%68.1%68.1%68.1%68.1%68.1%68.1%68.1%68.1%68.1%68.1%68.1%68.1%68.2%68.2%68.2%68.2%68.2%68.2%68.2%68.2%68.2%68.2%68.2%68.2%68.2%68.2%68.2%68.2%68.2%68.2%68.2%68.2%68.2%68.3%68.3%68.3%68.3%68.3%68.3%68.3%68.3%68.3%68.3%68.3%68.3%68.3%68.3%68.3%68.3%68.3%68.3%68.3%68.3%68.4%68.4%68.4%68.4%68.4%68.4%68.4%68.4%68.4%68.4%68.4%68.4%68.4%68.4%68.4%68.4%68.4%68.4%68.4%68.4%68.4%68.5%68.5%68.5%68.5%68.5%68.5%68.5%68.5%68.5%68.5%68.5%68.5%68.5%68.5%68.5%68.5%68.5%68.5%68.5%68.5%68.6%68.6%68.6%68.6%68.6%68.6%68.6%68.6%68.6%68.6%68.6%68.6%68.6%68.6%68.6%68.6%68.6%68.6%68.6%68.6%68.6%68.7%68.7%68.7%68.7%68.7%68.7%68.7%68.7%68.7%68.7%68.7%68.7%68.7%68.7%68.7%68.7%68.7%68.7%68.7%68.7%68.7%68.8%68.8%68.8%68.8%68.8%68.8%68.8%68.8%68.8%68.8%68.8%68.8%68.8%68.8%68.8%68.8%68.8%68.8%68.8%68.8%68.9%68.9%68.9%68.9%68.9%68.9%68.9%68.9%68.9%68.9%68.9%68.9%68.9%68.9%68.9%68.9%68.9%68.9%68.9%68.9%68.9%69.0%69.0%69.0%69.0%69.0%69.0%69.0%69.0%69.0%69.0%69.0%69.0%69.0%69.0%69.0%69.0%69.0%69.0%69.0%69.0%69.0%69.1%69.1%69.1%69.1%69.1%69.1%69.1%69.1%69.1%69.1%69.1%69.1%69.1%69.1%69.1%69.1%69.1%69.1%69.1%69.1%69.2%69.2%69.2%69.2%69.2%69.2%69.2%69.2%69.2%69.2%69.2%69.2%69.2%69.2%69.2%69.2%69.2%69.2%69.2%69.2%69.2%69.3%69.3%69.3%69.3%69.3%69.3%69.3%69.3%69.3%69.3%69.3%69.3%69.3%69.3%69.3%69.3%69.3%69.3%69.3%69.3%69.4%69.4%69.4%69.4%69.4%69.4%69.4%69.4%69.4%69.4%69.4%69.4%69.4%69.4%69.4%69.4%69.4%69.4%69.4%69.4%69.4%69.5%69.5%69.5%69.5%69.5%69.5%69.5%69.5%69.5%69.5%69.5%69.5%69.5%69.5%69.5%69.5%69.5%69.5%69.5%69.5%69.5%69.6%69.6%69.6%69.6%69.6%69.6%69.6%69.6%69.6%69.6%69.6%69.6%69.6%69.6%69.6%69.6%69.6%69.6%69.6%69.6%69.7%69.7%69.7%69.7%69.7%69.7%69.7%69.7%69.7%69.7%69.7%69.7%69.7%69.7%69.7%69.7%69.7%69.7%69.7%69.7%69.7%69.8%69.8%69.8%69.8%69.8%69.8%69.8%69.8%69.8%69.8%69.8%69.8%69.8%69.8%69.8%69.8%69.8%69.8%69.8%69.8%69.8%69.9%69.9%69.9%69.9%69.9%69.9%69.9%69.9%69.9%69.9%69.9%69.9%69.9%69.9%69.9%69.9%69.9%69.9%69.9%69.9%70.0%70.0%70.0%70.0%70.0%70.0%70.0%70.0%70.0%70.0%70.0%70.0%70.0%70.0%70.0%70.0%70.0%70.0%70.0%70.0%70.0%70.1%70.1%70.1%70.1%70.1%70.1%70.1%70.1%70.1%70.1%70.1%70.1%70.1%70.1%70.1%70.1%70.1%70.1%70.1%70.1%70.2%70.2%70.2%70.2%70.2%70.2%70.2%70.2%70.2%70.2%70.2%70.2%70.2%70.2%70.2%70.2%70.2%70.2%70.2%70.2%70.2%70.3%70.3%70.3%70.3%70.3%70.3%70.3%70.3%70.3%70.3%70.3%70.3%70.3%70.3%70.3%70.3%70.3%70.3%70.3%70.3%70.3%70.4%70.4%70.4%70.4%70.4%70.4%70.4%70.4%70.4%70.4%70.4%70.4%70.4%70.4%70.4%70.4%70.4%70.4%70.4%70.4%70.5%70.5%70.5%70.5%70.5%70.5%70.5%70.5%70.5%70.5%70.5%70.5%70.5%70.5%70.5%70.5%70.5%70.5%70.5%70.5%70.5%70.6%70.6%70.6%70.6%70.6%70.6%70.6%70.6%70.6%70.6%70.6%70.6%70.6%70.6%70.6%70.6%70.6%70.6%70.6%70.6%70.6%70.7%70.7%70.7%70.7%70.7%70.7%70.7%70.7%70.7%70.7%70.7%70.7%70.7%70.7%70.7%70.7%70.7%70.7%70.7%70.7%70.8%70.8%70.8%70.8%70.8%70.8%70.8%70.8%70.8%70.8%70.8%70.8%70.8%70.8%70.8%70.8%70.8%70.8%70.8%70.8%70.8%70.9%70.9%70.9%70.9%70.9%70.9%70.9%70.9%70.9%70.9%70.9%70.9%70.9%70.9%70.9%70.9%70.9%70.9%70.9%70.9%70.9%71.0%71.0%71.0%71.0%71.0%71.0%71.0%71.0%71.0%71.0%71.0%71.0%71.0%71.0%71.0%71.0%71.0%71.0%71.0%71.0%71.1%71.1%71.1%71.1%71.1%71.1%71.1%71.1%71.1%71.1%71.1%71.1%71.1%71.1%71.1%71.1%71.1%71.1%71.1%71.1%71.1%71.2%71.2%71.2%71.2%71.2%71.2%71.2%71.2%71.2%71.2%71.2%71.2%71.2%71.2%71.2%71.2%71.2%71.2%71.2%71.2%71.3%71.3%71.3%71.3%71.3%71.3%71.3%71.3%71.3%71.3%71.3%71.3%71.3%71.3%71.3%71.3%71.3%71.3%71.3%71.3%71.3%71.4%71.4%71.4%71.4%71.4%71.4%71.4%71.4%71.4%71.4%71.4%71.4%71.4%71.4%71.4%71.4%71.4%71.4%71.4%71.4%71.4%71.5%71.5%71.5%71.5%71.5%71.5%71.5%71.5%71.5%71.5%71.5%71.5%71.5%71.5%71.5%71.5%71.5%71.5%71.5%71.5%71.6%71.6%71.6%71.6%71.6%71.6%71.6%71.6%71.6%71.6%71.6%71.6%71.6%71.6%71.6%71.6%71.6%71.6%71.6%71.6%71.6%71.7%71.7%71.7%71.7%71.7%71.7%71.7%71.7%71.7%71.7%71.7%71.7%71.7%71.7%71.7%71.7%71.7%71.7%71.7%71.7%71.7%71.8%71.8%71.8%71.8%71.8%71.8%71.8%71.8%71.8%71.8%71.8%71.8%71.8%71.8%71.8%71.8%71.8%71.8%71.8%71.8%71.9%71.9%71.9%71.9%71.9%71.9%71.9%71.9%71.9%71.9%71.9%71.9%71.9%71.9%71.9%71.9%71.9%71.9%71.9%71.9%71.9%72.0%72.0%72.0%72.0%72.0%72.0%72.0%72.0%72.0%72.0%72.0%72.0%72.0%72.0%72.0%72.0%72.0%72.0%72.0%72.0%72.1%72.1%72.1%72.1%72.1%72.1%72.1%72.1%72.1%72.1%72.1%72.1%72.1%72.1%72.1%72.1%72.1%72.1%72.1%72.1%72.1%72.2%72.2%72.2%72.2%72.2%72.2%72.2%72.2%72.2%72.2%72.2%72.2%72.2%72.2%72.2%72.2%72.2%72.2%72.2%72.2%72.2%72.3%72.3%72.3%72.3%72.3%72.3%72.3%72.3%72.3%72.3%72.3%72.3%72.3%72.3%72.3%72.3%72.3%72.3%72.3%72.3%72.4%72.4%72.4%72.4%72.4%72.4%72.4%72.4%72.4%72.4%72.4%72.4%72.4%72.4%72.4%72.4%72.4%72.4%72.4%72.4%72.4%72.5%72.5%72.5%72.5%72.5%72.5%72.5%72.5%72.5%72.5%72.5%72.5%72.5%72.5%72.5%72.5%72.5%72.5%72.5%72.5%72.5%72.6%72.6%72.6%72.6%72.6%72.6%72.6%72.6%72.6%72.6%72.6%72.6%72.6%72.6%72.6%72.6%72.6%72.6%72.6%72.6%72.7%72.7%72.7%72.7%72.7%72.7%72.7%72.7%72.7%72.7%72.7%72.7%72.7%72.7%72.7%72.7%72.7%72.7%72.7%72.7%72.7%72.8%72.8%72.8%72.8%72.8%72.8%72.8%72.8%72.8%72.8%72.8%72.8%72.8%72.8%72.8%72.8%72.8%72.8%72.8%72.8%72.9%72.9%72.9%72.9%72.9%72.9%72.9%72.9%72.9%72.9%72.9%72.9%72.9%72.9%72.9%72.9%72.9%72.9%72.9%72.9%72.9%73.0%73.0%73.0%73.0%73.0%73.0%73.0%73.0%73.0%73.0%73.0%73.0%73.0%73.0%73.0%73.0%73.0%73.0%73.0%73.0%73.0%73.1%73.1%73.1%73.1%73.1%73.1%73.1%73.1%73.1%73.1%73.1%73.1%73.1%73.1%73.1%73.1%73.1%73.1%73.1%73.1%73.2%73.2%73.2%73.2%73.2%73.2%73.2%73.2%73.2%73.2%73.2%73.2%73.2%73.2%73.2%73.2%73.2%73.2%73.2%73.2%73.2%73.3%73.3%73.3%73.3%73.3%73.3%73.3%73.3%73.3%73.3%73.3%73.3%73.3%73.3%73.3%73.3%73.3%73.3%73.3%73.3%73.3%73.4%73.4%73.4%73.4%73.4%73.4%73.4%73.4%73.4%73.4%73.4%73.4%73.4%73.4%73.4%73.4%73.4%73.4%73.4%73.4%73.5%73.5%73.5%73.5%73.5%73.5%73.5%73.5%73.5%73.5%73.5%73.5%73.5%73.5%73.5%73.5%73.5%73.5%73.5%73.5%73.5%73.6%73.6%73.6%73.6%73.6%73.6%73.6%73.6%73.6%73.6%73.6%73.6%73.6%73.6%73.6%73.6%73.6%73.6%73.6%73.6%73.6%73.7%73.7%73.7%73.7%73.7%73.7%73.7%73.7%73.7%73.7%73.7%73.7%73.7%73.7%73.7%73.7%73.7%73.7%73.7%73.7%73.8%73.8%73.8%73.8%73.8%73.8%73.8%73.8%73.8%73.8%73.8%73.8%73.8%73.8%73.8%73.8%73.8%73.8%73.8%73.8%73.8%73.9%73.9%73.9%73.9%73.9%73.9%73.9%73.9%73.9%73.9%73.9%73.9%73.9%73.9%73.9%73.9%73.9%73.9%73.9%73.9%74.0%74.0%74.0%74.0%74.0%74.0%74.0%74.0%74.0%74.0%74.0%74.0%74.0%74.0%74.0%74.0%74.0%74.0%74.0%74.0%74.0%74.1%74.1%74.1%74.1%74.1%74.1%74.1%74.1%74.1%74.1%74.1%74.1%74.1%74.1%74.1%74.1%74.1%74.1%74.1%74.1%74.1%74.2%74.2%74.2%74.2%74.2%74.2%74.2%74.2%74.2%74.2%74.2%74.2%74.2%74.2%74.2%74.2%74.2%74.2%74.2%74.2%74.3%74.3%74.3%74.3%74.3%74.3%74.3%74.3%74.3%74.3%74.3%74.3%74.3%74.3%74.3%74.3%74.3%74.3%74.3%74.3%74.3%74.4%74.4%74.4%74.4%74.4%74.4%74.4%74.4%74.4%74.4%74.4%74.4%74.4%74.4%74.4%74.4%74.4%74.4%74.4%74.4%74.4%74.5%74.5%74.5%74.5%74.5%74.5%74.5%74.5%74.5%74.5%74.5%74.5%74.5%74.5%74.5%74.5%74.5%74.5%74.5%74.5%74.6%74.6%74.6%74.6%74.6%74.6%74.6%74.6%74.6%74.6%74.6%74.6%74.6%74.6%74.6%74.6%74.6%74.6%74.6%74.6%74.6%74.7%74.7%74.7%74.7%74.7%74.7%74.7%74.7%74.7%74.7%74.7%74.7%74.7%74.7%74.7%74.7%74.7%74.7%74.7%74.7%74.8%74.8%74.8%74.8%74.8%74.8%74.8%74.8%74.8%74.8%74.8%74.8%74.8%74.8%74.8%74.8%74.8%74.8%74.8%74.8%74.8%74.9%74.9%74.9%74.9%74.9%74.9%74.9%74.9%74.9%74.9%74.9%74.9%74.9%74.9%74.9%74.9%74.9%74.9%74.9%74.9%74.9%75.0%75.0%75.0%75.0%75.0%75.0%75.0%75.0%75.0%75.0%75.0%75.0%75.0%75.0%75.0%75.0%75.0%75.0%75.0%75.0%75.1%75.1%75.1%75.1%75.1%75.1%75.1%75.1%75.1%75.1%75.1%75.1%75.1%75.1%75.1%75.1%75.1%75.1%75.1%75.1%75.1%75.2%75.2%75.2%75.2%75.2%75.2%75.2%75.2%75.2%75.2%75.2%75.2%75.2%75.2%75.2%75.2%75.2%75.2%75.2%75.2%75.2%75.3%75.3%75.3%75.3%75.3%75.3%75.3%75.3%75.3%75.3%75.3%75.3%75.3%75.3%75.3%75.3%75.3%75.3%75.3%75.3%75.4%75.4%75.4%75.4%75.4%75.4%75.4%75.4%75.4%75.4%75.4%75.4%75.4%75.4%75.4%75.4%75.4%75.4%75.4%75.4%75.4%75.5%75.5%75.5%75.5%75.5%75.5%75.5%75.5%75.5%75.5%75.5%75.5%75.5%75.5%75.5%75.5%75.5%75.5%75.5%75.5%75.5%75.6%75.6%75.6%75.6%75.6%75.6%75.6%75.6%75.6%75.6%75.6%75.6%75.6%75.6%75.6%75.6%75.6%75.6%75.6%75.6%75.7%75.7%75.7%75.7%75.7%75.7%75.7%75.7%75.7%75.7%75.7%75.7%75.7%75.7%75.7%75.7%75.7%75.7%75.7%75.7%75.7%75.8%75.8%75.8%75.8%75.8%75.8%75.8%75.8%75.8%75.8%75.8%75.8%75.8%75.8%75.8%75.8%75.8%75.8%75.8%75.8%75.9%75.9%75.9%75.9%75.9%75.9%75.9%75.9%75.9%75.9%75.9%75.9%75.9%75.9%75.9%75.9%75.9%75.9%75.9%75.9%75.9%76.0%76.0%76.0%76.0%76.0%76.0%76.0%76.0%76.0%76.0%76.0%76.0%76.0%76.0%76.0%76.0%76.0%76.0%76.0%76.0%76.0%76.1%76.1%76.1%76.1%76.1%76.1%76.1%76.1%76.1%76.1%76.1%76.1%76.1%76.1%76.1%76.1%76.1%76.1%76.1%76.1%76.2%76.2%76.2%76.2%76.2%76.2%76.2%76.2%76.2%76.2%76.2%76.2%76.2%76.2%76.2%76.2%76.2%76.2%76.2%76.2%76.2%76.3%76.3%76.3%76.3%76.3%76.3%76.3%76.3%76.3%76.3%76.3%76.3%76.3%76.3%76.3%76.3%76.3%76.3%76.3%76.3%76.3%76.4%76.4%76.4%76.4%76.4%76.4%76.4%76.4%76.4%76.4%76.4%76.4%76.4%76.4%76.4%76.4%76.4%76.4%76.4%76.4%76.5%76.5%76.5%76.5%76.5%76.5%76.5%76.5%76.5%76.5%76.5%76.5%76.5%76.5%76.5%76.5%76.5%76.5%76.5%76.5%76.5%76.6%76.6%76.6%76.6%76.6%76.6%76.6%76.6%76.6%76.6%76.6%76.6%76.6%76.6%76.6%76.6%76.6%76.6%76.6%76.6%76.7%76.7%76.7%76.7%76.7%76.7%76.7%76.7%76.7%76.7%76.7%76.7%76.7%76.7%76.7%76.7%76.7%76.7%76.7%76.7%76.7%76.8%76.8%76.8%76.8%76.8%76.8%76.8%76.8%76.8%76.8%76.8%76.8%76.8%76.8%76.8%76.8%76.8%76.8%76.8%76.8%76.8%76.9%76.9%76.9%76.9%76.9%76.9%76.9%76.9%76.9%76.9%76.9%76.9%76.9%76.9%76.9%76.9%76.9%76.9%76.9%76.9%77.0%77.0%77.0%77.0%77.0%77.0%77.0%77.0%77.0%77.0%77.0%77.0%77.0%77.0%77.0%77.0%77.0%77.0%77.0%77.0%77.0%77.1%77.1%77.1%77.1%77.1%77.1%77.1%77.1%77.1%77.1%77.1%77.1%77.1%77.1%77.1%77.1%77.1%77.1%77.1%77.1%77.1%77.2%77.2%77.2%77.2%77.2%77.2%77.2%77.2%77.2%77.2%77.2%77.2%77.2%77.2%77.2%77.2%77.2%77.2%77.2%77.2%77.3%77.3%77.3%77.3%77.3%77.3%77.3%77.3%77.3%77.3%77.3%77.3%77.3%77.3%77.3%77.3%77.3%77.3%77.3%77.3%77.3%77.4%77.4%77.4%77.4%77.4%77.4%77.4%77.4%77.4%77.4%77.4%77.4%77.4%77.4%77.4%77.4%77.4%77.4%77.4%77.4%77.5%77.5%77.5%77.5%77.5%77.5%77.5%77.5%77.5%77.5%77.5%77.5%77.5%77.5%77.5%77.5%77.5%77.5%77.5%77.5%77.5%77.6%77.6%77.6%77.6%77.6%77.6%77.6%77.6%77.6%77.6%77.6%77.6%77.6%77.6%77.6%77.6%77.6%77.6%77.6%77.6%77.6%77.7%77.7%77.7%77.7%77.7%77.7%77.7%77.7%77.7%77.7%77.7%77.7%77.7%77.7%77.7%77.7%77.7%77.7%77.7%77.7%77.8%77.8%77.8%77.8%77.8%77.8%77.8%77.8%77.8%77.8%77.8%77.8%77.8%77.8%77.8%77.8%77.8%77.8%77.8%77.8%77.8%77.9%77.9%77.9%77.9%77.9%77.9%77.9%77.9%77.9%77.9%77.9%77.9%77.9%77.9%77.9%77.9%77.9%77.9%77.9%77.9%77.9%78.0%78.0%78.0%78.0%78.0%78.0%78.0%78.0%78.0%78.0%78.0%78.0%78.0%78.0%78.0%78.0%78.0%78.0%78.0%78.0%78.1%78.1%78.1%78.1%78.1%78.1%78.1%78.1%78.1%78.1%78.1%78.1%78.1%78.1%78.1%78.1%78.1%78.1%78.1%78.1%78.1%78.2%78.2%78.2%78.2%78.2%78.2%78.2%78.2%78.2%78.2%78.2%78.2%78.2%78.2%78.2%78.2%78.2%78.2%78.2%78.2%78.2%78.3%78.3%78.3%78.3%78.3%78.3%78.3%78.3%78.3%78.3%78.3%78.3%78.3%78.3%78.3%78.3%78.3%78.3%78.3%78.3%78.4%78.4%78.4%78.4%78.4%78.4%78.4%78.4%78.4%78.4%78.4%78.4%78.4%78.4%78.4%78.4%78.4%78.4%78.4%78.4%78.4%78.5%78.5%78.5%78.5%78.5%78.5%78.5%78.5%78.5%78.5%78.5%78.5%78.5%78.5%78.5%78.5%78.5%78.5%78.5%78.5%78.6%78.6%78.6%78.6%78.6%78.6%78.6%78.6%78.6%78.6%78.6%78.6%78.6%78.6%78.6%78.6%78.6%78.6%78.6%78.6%78.6%78.7%78.7%78.7%78.7%78.7%78.7%78.7%78.7%78.7%78.7%78.7%78.7%78.7%78.7%78.7%78.7%78.7%78.7%78.7%78.7%78.7%78.8%78.8%78.8%78.8%78.8%78.8%78.8%78.8%78.8%78.8%78.8%78.8%78.8%78.8%78.8%78.8%78.8%78.8%78.8%78.8%78.9%78.9%78.9%78.9%78.9%78.9%78.9%78.9%78.9%78.9%78.9%78.9%78.9%78.9%78.9%78.9%78.9%78.9%78.9%78.9%78.9%79.0%79.0%79.0%79.0%79.0%79.0%79.0%79.0%79.0%79.0%79.0%79.0%79.0%79.0%79.0%79.0%79.0%79.0%79.0%79.0%79.0%79.1%79.1%79.1%79.1%79.1%79.1%79.1%79.1%79.1%79.1%79.1%79.1%79.1%79.1%79.1%79.1%79.1%79.1%79.1%79.1%79.2%79.2%79.2%79.2%79.2%79.2%79.2%79.2%79.2%79.2%79.2%79.2%79.2%79.2%79.2%79.2%79.2%79.2%79.2%79.2%79.2%79.3%79.3%79.3%79.3%79.3%79.3%79.3%79.3%79.3%79.3%79.3%79.3%79.3%79.3%79.3%79.3%79.3%79.3%79.3%79.3%79.4%79.4%79.4%79.4%79.4%79.4%79.4%79.4%79.4%79.4%79.4%79.4%79.4%79.4%79.4%79.4%79.4%79.4%79.4%79.4%79.4%79.5%79.5%79.5%79.5%79.5%79.5%79.5%79.5%79.5%79.5%79.5%79.5%79.5%79.5%79.5%79.5%79.5%79.5%79.5%79.5%79.5%79.6%79.6%79.6%79.6%79.6%79.6%79.6%79.6%79.6%79.6%79.6%79.6%79.6%79.6%79.6%79.6%79.6%79.6%79.6%79.6%79.7%79.7%79.7%79.7%79.7%79.7%79.7%79.7%79.7%79.7%79.7%79.7%79.7%79.7%79.7%79.7%79.7%79.7%79.7%79.7%79.7%79.8%79.8%79.8%79.8%79.8%79.8%79.8%79.8%79.8%79.8%79.8%79.8%79.8%79.8%79.8%79.8%79.8%79.8%79.8%79.8%79.8%79.9%79.9%79.9%79.9%79.9%79.9%79.9%79.9%79.9%79.9%79.9%79.9%79.9%79.9%79.9%79.9%79.9%79.9%79.9%79.9%80.0%80.0%80.0%80.0%80.0%80.0%80.0%80.0%80.0%80.0%80.0%80.0%80.0%80.0%80.0%80.0%80.0%80.0%80.0%80.0%80.0%80.1%80.1%80.1%80.1%80.1%80.1%80.1%80.1%80.1%80.1%80.1%80.1%80.1%80.1%80.1%80.1%80.1%80.1%80.1%80.1%80.2%80.2%80.2%80.2%80.2%80.2%80.2%80.2%80.2%80.2%80.2%80.2%80.2%80.2%80.2%80.2%80.2%80.2%80.2%80.2%80.2%80.3%80.3%80.3%80.3%80.3%80.3%80.3%80.3%80.3%80.3%80.3%80.3%80.3%80.3%80.3%80.3%80.3%80.3%80.3%80.3%80.3%80.4%80.4%80.4%80.4%80.4%80.4%80.4%80.4%80.4%80.4%80.4%80.4%80.4%80.4%80.4%80.4%80.4%80.4%80.4%80.4%80.5%80.5%80.5%80.5%80.5%80.5%80.5%80.5%80.5%80.5%80.5%80.5%80.5%80.5%80.5%80.5%80.5%80.5%80.5%80.5%80.5%80.6%80.6%80.6%80.6%80.6%80.6%80.6%80.6%80.6%80.6%80.6%80.6%80.6%80.6%80.6%80.6%80.6%80.6%80.6%80.6%80.6%80.7%80.7%80.7%80.7%80.7%80.7%80.7%80.7%80.7%80.7%80.7%80.7%80.7%80.7%80.7%80.7%80.7%80.7%80.7%80.7%80.8%80.8%80.8%80.8%80.8%80.8%80.8%80.8%80.8%80.8%80.8%80.8%80.8%80.8%80.8%80.8%80.8%80.8%80.8%80.8%80.8%80.9%80.9%80.9%80.9%80.9%80.9%80.9%80.9%80.9%80.9%80.9%80.9%80.9%80.9%80.9%80.9%80.9%80.9%80.9%80.9%80.9%81.0%81.0%81.0%81.0%81.0%81.0%81.0%81.0%81.0%81.0%81.0%81.0%81.0%81.0%81.0%81.0%81.0%81.0%81.0%81.0%81.1%81.1%81.1%81.1%81.1%81.1%81.1%81.1%81.1%81.1%81.1%81.1%81.1%81.1%81.1%81.1%81.1%81.1%81.1%81.1%81.1%81.2%81.2%81.2%81.2%81.2%81.2%81.2%81.2%81.2%81.2%81.2%81.2%81.2%81.2%81.2%81.2%81.2%81.2%81.2%81.2%81.3%81.3%81.3%81.3%81.3%81.3%81.3%81.3%81.3%81.3%81.3%81.3%81.3%81.3%81.3%81.3%81.3%81.3%81.3%81.3%81.3%81.4%81.4%81.4%81.4%81.4%81.4%81.4%81.4%81.4%81.4%81.4%81.4%81.4%81.4%81.4%81.4%81.4%81.4%81.4%81.4%81.4%81.5%81.5%81.5%81.5%81.5%81.5%81.5%81.5%81.5%81.5%81.5%81.5%81.5%81.5%81.5%81.5%81.5%81.5%81.5%81.5%81.6%81.6%81.6%81.6%81.6%81.6%81.6%81.6%81.6%81.6%81.6%81.6%81.6%81.6%81.6%81.6%81.6%81.6%81.6%81.6%81.6%81.7%81.7%81.7%81.7%81.7%81.7%81.7%81.7%81.7%81.7%81.7%81.7%81.7%81.7%81.7%81.7%81.7%81.7%81.7%81.7%81.7%81.8%81.8%81.8%81.8%81.8%81.8%81.8%81.8%81.8%81.8%81.8%81.8%81.8%81.8%81.8%81.8%81.8%81.8%81.8%81.8%81.9%81.9%81.9%81.9%81.9%81.9%81.9%81.9%81.9%81.9%81.9%81.9%81.9%81.9%81.9%81.9%81.9%81.9%81.9%81.9%81.9%82.0%82.0%82.0%82.0%82.0%82.0%82.0%82.0%82.0%82.0%82.0%82.0%82.0%82.0%82.0%82.0%82.0%82.0%82.0%82.0%82.1%82.1%82.1%82.1%82.1%82.1%82.1%82.1%82.1%82.1%82.1%82.1%82.1%82.1%82.1%82.1%82.1%82.1%82.1%82.1%82.1%82.2%82.2%82.2%82.2%82.2%82.2%82.2%82.2%82.2%82.2%82.2%82.2%82.2%82.2%82.2%82.2%82.2%82.2%82.2%82.2%82.2%82.3%82.3%82.3%82.3%82.3%82.3%82.3%82.3%82.3%82.3%82.3%82.3%82.3%82.3%82.3%82.3%82.3%82.3%82.3%82.3%82.4%82.4%82.4%82.4%82.4%82.4%82.4%82.4%82.4%82.4%82.4%82.4%82.4%82.4%82.4%82.4%82.4%82.4%82.4%82.4%82.4%82.5%82.5%82.5%82.5%82.5%82.5%82.5%82.5%82.5%82.5%82.5%82.5%82.5%82.5%82.5%82.5%82.5%82.5%82.5%82.5%82.5%82.6%82.6%82.6%82.6%82.6%82.6%82.6%82.6%82.6%82.6%82.6%82.6%82.6%82.6%82.6%82.6%82.6%82.6%82.6%82.6%82.7%82.7%82.7%82.7%82.7%82.7%82.7%82.7%82.7%82.7%82.7%82.7%82.7%82.7%82.7%82.7%82.7%82.7%82.7%82.7%82.7%82.8%82.8%82.8%82.8%82.8%82.8%82.8%82.8%82.8%82.8%82.8%82.8%82.8%82.8%82.8%82.8%82.8%82.8%82.8%82.8%82.8%82.9%82.9%82.9%82.9%82.9%82.9%82.9%82.9%82.9%82.9%82.9%82.9%82.9%82.9%82.9%82.9%82.9%82.9%82.9%82.9%83.0%83.0%83.0%83.0%83.0%83.0%83.0%83.0%83.0%83.0%83.0%83.0%83.0%83.0%83.0%83.0%83.0%83.0%83.0%83.0%83.0%83.1%83.1%83.1%83.1%83.1%83.1%83.1%83.1%83.1%83.1%83.1%83.1%83.1%83.1%83.1%83.1%83.1%83.1%83.1%83.1%83.2%83.2%83.2%83.2%83.2%83.2%83.2%83.2%83.2%83.2%83.2%83.2%83.2%83.2%83.2%83.2%83.2%83.2%83.2%83.2%83.2%83.3%83.3%83.3%83.3%83.3%83.3%83.3%83.3%83.3%83.3%83.3%83.3%83.3%83.3%83.3%83.3%83.3%83.3%83.3%83.3%83.3%83.4%83.4%83.4%83.4%83.4%83.4%83.4%83.4%83.4%83.4%83.4%83.4%83.4%83.4%83.4%83.4%83.4%83.4%83.4%83.4%83.5%83.5%83.5%83.5%83.5%83.5%83.5%83.5%83.5%83.5%83.5%83.5%83.5%83.5%83.5%83.5%83.5%83.5%83.5%83.5%83.5%83.6%83.6%83.6%83.6%83.6%83.6%83.6%83.6%83.6%83.6%83.6%83.6%83.6%83.6%83.6%83.6%83.6%83.6%83.6%83.6%83.6%83.7%83.7%83.7%83.7%83.7%83.7%83.7%83.7%83.7%83.7%83.7%83.7%83.7%83.7%83.7%83.7%83.7%83.7%83.7%83.7%83.8%83.8%83.8%83.8%83.8%83.8%83.8%83.8%83.8%83.8%83.8%83.8%83.8%83.8%83.8%83.8%83.8%83.8%83.8%83.8%83.8%83.9%83.9%83.9%83.9%83.9%83.9%83.9%83.9%83.9%83.9%83.9%83.9%83.9%83.9%83.9%83.9%83.9%83.9%83.9%83.9%84.0%84.0%84.0%84.0%84.0%84.0%84.0%84.0%84.0%84.0%84.0%84.0%84.0%84.0%84.0%84.0%84.0%84.0%84.0%84.0%84.0%84.1%84.1%84.1%84.1%84.1%84.1%84.1%84.1%84.1%84.1%84.1%84.1%84.1%84.1%84.1%84.1%84.1%84.1%84.1%84.1%84.1%84.2%84.2%84.2%84.2%84.2%84.2%84.2%84.2%84.2%84.2%84.2%84.2%84.2%84.2%84.2%84.2%84.2%84.2%84.2%84.2%84.3%84.3%84.3%84.3%84.3%84.3%84.3%84.3%84.3%84.3%84.3%84.3%84.3%84.3%84.3%84.3%84.3%84.3%84.3%84.3%84.3%84.4%84.4%84.4%84.4%84.4%84.4%84.4%84.4%84.4%84.4%84.4%84.4%84.4%84.4%84.4%84.4%84.4%84.4%84.4%84.4%84.4%84.5%84.5%84.5%84.5%84.5%84.5%84.5%84.5%84.5%84.5%84.5%84.5%84.5%84.5%84.5%84.5%84.5%84.5%84.5%84.5%84.6%84.6%84.6%84.6%84.6%84.6%84.6%84.6%84.6%84.6%84.6%84.6%84.6%84.6%84.6%84.6%84.6%84.6%84.6%84.6%84.6%84.7%84.7%84.7%84.7%84.7%84.7%84.7%84.7%84.7%84.7%84.7%84.7%84.7%84.7%84.7%84.7%84.7%84.7%84.7%84.7%84.8%84.8%84.8%84.8%84.8%84.8%84.8%84.8%84.8%84.8%84.8%84.8%84.8%84.8%84.8%84.8%84.8%84.8%84.8%84.8%84.8%84.9%84.9%84.9%84.9%84.9%84.9%84.9%84.9%84.9%84.9%84.9%84.9%84.9%84.9%84.9%84.9%84.9%84.9%84.9%84.9%84.9%85.0%85.0%85.0%85.0%85.0%85.0%85.0%85.0%85.0%85.0%85.0%85.0%85.0%85.0%85.0%85.0%85.0%85.0%85.0%85.0%85.1%85.1%85.1%85.1%85.1%85.1%85.1%85.1%85.1%85.1%85.1%85.1%85.1%85.1%85.1%85.1%85.1%85.1%85.1%85.1%85.1%85.2%85.2%85.2%85.2%85.2%85.2%85.2%85.2%85.2%85.2%85.2%85.2%85.2%85.2%85.2%85.2%85.2%85.2%85.2%85.2%85.2%85.3%85.3%85.3%85.3%85.3%85.3%85.3%85.3%85.3%85.3%85.3%85.3%85.3%85.3%85.3%85.3%85.3%85.3%85.3%85.3%85.4%85.4%85.4%85.4%85.4%85.4%85.4%85.4%85.4%85.4%85.4%85.4%85.4%85.4%85.4%85.4%85.4%85.4%85.4%85.4%85.4%85.5%85.5%85.5%85.5%85.5%85.5%85.5%85.5%85.5%85.5%85.5%85.5%85.5%85.5%85.5%85.5%85.5%85.5%85.5%85.5%85.5%85.6%85.6%85.6%85.6%85.6%85.6%85.6%85.6%85.6%85.6%85.6%85.6%85.6%85.6%85.6%85.6%85.6%85.6%85.6%85.6%85.7%85.7%85.7%85.7%85.7%85.7%85.7%85.7%85.7%85.7%85.7%85.7%85.7%85.7%85.7%85.7%85.7%85.7%85.7%85.7%85.7%85.8%85.8%85.8%85.8%85.8%85.8%85.8%85.8%85.8%85.8%85.8%85.8%85.8%85.8%85.8%85.8%85.8%85.8%85.8%85.8%85.9%85.9%85.9%85.9%85.9%85.9%85.9%85.9%85.9%85.9%85.9%85.9%85.9%85.9%85.9%85.9%85.9%85.9%85.9%85.9%85.9%86.0%86.0%86.0%86.0%86.0%86.0%86.0%86.0%86.0%86.0%86.0%86.0%86.0%86.0%86.0%86.0%86.0%86.0%86.0%86.0%86.0%86.1%86.1%86.1%86.1%86.1%86.1%86.1%86.1%86.1%86.1%86.1%86.1%86.1%86.1%86.1%86.1%86.1%86.1%86.1%86.1%86.2%86.2%86.2%86.2%86.2%86.2%86.2%86.2%86.2%86.2%86.2%86.2%86.2%86.2%86.2%86.2%86.2%86.2%86.2%86.2%86.2%86.3%86.3%86.3%86.3%86.3%86.3%86.3%86.3%86.3%86.3%86.3%86.3%86.3%86.3%86.3%86.3%86.3%86.3%86.3%86.3%86.3%86.4%86.4%86.4%86.4%86.4%86.4%86.4%86.4%86.4%86.4%86.4%86.4%86.4%86.4%86.4%86.4%86.4%86.4%86.4%86.4%86.5%86.5%86.5%86.5%86.5%86.5%86.5%86.5%86.5%86.5%86.5%86.5%86.5%86.5%86.5%86.5%86.5%86.5%86.5%86.5%86.5%86.6%86.6%86.6%86.6%86.6%86.6%86.6%86.6%86.6%86.6%86.6%86.6%86.6%86.6%86.6%86.6%86.6%86.6%86.6%86.6%86.7%86.7%86.7%86.7%86.7%86.7%86.7%86.7%86.7%86.7%86.7%86.7%86.7%86.7%86.7%86.7%86.7%86.7%86.7%86.7%86.7%86.8%86.8%86.8%86.8%86.8%86.8%86.8%86.8%86.8%86.8%86.8%86.8%86.8%86.8%86.8%86.8%86.8%86.8%86.8%86.8%86.8%86.9%86.9%86.9%86.9%86.9%86.9%86.9%86.9%86.9%86.9%86.9%86.9%86.9%86.9%86.9%86.9%86.9%86.9%86.9%86.9%87.0%87.0%87.0%87.0%87.0%87.0%87.0%87.0%87.0%87.0%87.0%87.0%87.0%87.0%87.0%87.0%87.0%87.0%87.0%87.0%87.0%87.1%87.1%87.1%87.1%87.1%87.1%87.1%87.1%87.1%87.1%87.1%87.1%87.1%87.1%87.1%87.1%87.1%87.1%87.1%87.1%87.1%87.2%87.2%87.2%87.2%87.2%87.2%87.2%87.2%87.2%87.2%87.2%87.2%87.2%87.2%87.2%87.2%87.2%87.2%87.2%87.2%87.3%87.3%87.3%87.3%87.3%87.3%87.3%87.3%87.3%87.3%87.3%87.3%87.3%87.3%87.3%87.3%87.3%87.3%87.3%87.3%87.3%87.4%87.4%87.4%87.4%87.4%87.4%87.4%87.4%87.4%87.4%87.4%87.4%87.4%87.4%87.4%87.4%87.4%87.4%87.4%87.4%87.5%87.5%87.5%87.5%87.5%87.5%87.5%87.5%87.5%87.5%87.5%87.5%87.5%87.5%87.5%87.5%87.5%87.5%87.5%87.5%87.5%87.6%87.6%87.6%87.6%87.6%87.6%87.6%87.6%87.6%87.6%87.6%87.6%87.6%87.6%87.6%87.6%87.6%87.6%87.6%87.6%87.6%87.7%87.7%87.7%87.7%87.7%87.7%87.7%87.7%87.7%87.7%87.7%87.7%87.7%87.7%87.7%87.7%87.7%87.7%87.7%87.7%87.8%87.8%87.8%87.8%87.8%87.8%87.8%87.8%87.8%87.8%87.8%87.8%87.8%87.8%87.8%87.8%87.8%87.8%87.8%87.8%87.8%87.9%87.9%87.9%87.9%87.9%87.9%87.9%87.9%87.9%87.9%87.9%87.9%87.9%87.9%87.9%87.9%87.9%87.9%87.9%87.9%87.9%88.0%88.0%88.0%88.0%88.0%88.0%88.0%88.0%88.0%88.0%88.0%88.0%88.0%88.0%88.0%88.0%88.0%88.0%88.0%88.0%88.1%88.1%88.1%88.1%88.1%88.1%88.1%88.1%88.1%88.1%88.1%88.1%88.1%88.1%88.1%88.1%88.1%88.1%88.1%88.1%88.1%88.2%88.2%88.2%88.2%88.2%88.2%88.2%88.2%88.2%88.2%88.2%88.2%88.2%88.2%88.2%88.2%88.2%88.2%88.2%88.2%88.2%88.3%88.3%88.3%88.3%88.3%88.3%88.3%88.3%88.3%88.3%88.3%88.3%88.3%88.3%88.3%88.3%88.3%88.3%88.3%88.3%88.4%88.4%88.4%88.4%88.4%88.4%88.4%88.4%88.4%88.4%88.4%88.4%88.4%88.4%88.4%88.4%88.4%88.4%88.4%88.4%88.4%88.5%88.5%88.5%88.5%88.5%88.5%88.5%88.5%88.5%88.5%88.5%88.5%88.5%88.5%88.5%88.5%88.5%88.5%88.5%88.5%88.6%88.6%88.6%88.6%88.6%88.6%88.6%88.6%88.6%88.6%88.6%88.6%88.6%88.6%88.6%88.6%88.6%88.6%88.6%88.6%88.6%88.7%88.7%88.7%88.7%88.7%88.7%88.7%88.7%88.7%88.7%88.7%88.7%88.7%88.7%88.7%88.7%88.7%88.7%88.7%88.7%88.7%88.8%88.8%88.8%88.8%88.8%88.8%88.8%88.8%88.8%88.8%88.8%88.8%88.8%88.8%88.8%88.8%88.8%88.8%88.8%88.8%88.9%88.9%88.9%88.9%88.9%88.9%88.9%88.9%88.9%88.9%88.9%88.9%88.9%88.9%88.9%88.9%88.9%88.9%88.9%88.9%88.9%89.0%89.0%89.0%89.0%89.0%89.0%89.0%89.0%89.0%89.0%89.0%89.0%89.0%89.0%89.0%89.0%89.0%89.0%89.0%89.0%89.0%89.1%89.1%89.1%89.1%89.1%89.1%89.1%89.1%89.1%89.1%89.1%89.1%89.1%89.1%89.1%89.1%89.1%89.1%89.1%89.1%89.2%89.2%89.2%89.2%89.2%89.2%89.2%89.2%89.2%89.2%89.2%89.2%89.2%89.2%89.2%89.2%89.2%89.2%89.2%89.2%89.2%89.3%89.3%89.3%89.3%89.3%89.3%89.3%89.3%89.3%89.3%89.3%89.3%89.3%89.3%89.3%89.3%89.3%89.3%89.3%89.3%89.4%89.4%89.4%89.4%89.4%89.4%89.4%89.4%89.4%89.4%89.4%89.4%89.4%89.4%89.4%89.4%89.4%89.4%89.4%89.4%89.4%89.5%89.5%89.5%89.5%89.5%89.5%89.5%89.5%89.5%89.5%89.5%89.5%89.5%89.5%89.5%89.5%89.5%89.5%89.5%89.5%89.5%89.6%89.6%89.6%89.6%89.6%89.6%89.6%89.6%89.6%89.6%89.6%89.6%89.6%89.6%89.6%89.6%89.6%89.6%89.6%89.6%89.7%89.7%89.7%89.7%89.7%89.7%89.7%89.7%89.7%89.7%89.7%89.7%89.7%89.7%89.7%89.7%89.7%89.7%89.7%89.7%89.7%89.8%89.8%89.8%89.8%89.8%89.8%89.8%89.8%89.8%89.8%89.8%89.8%89.8%89.8%89.8%89.8%89.8%89.8%89.8%89.8%89.8%89.9%89.9%89.9%89.9%89.9%89.9%89.9%89.9%89.9%89.9%89.9%89.9%89.9%89.9%89.9%89.9%89.9%89.9%89.9%89.9%90.0%90.0%90.0%90.0%90.0%90.0%90.0%90.0%90.0%90.0%90.0%90.0%90.0%90.0%90.0%90.0%90.0%90.0%90.0%90.0%90.0%90.1%90.1%90.1%90.1%90.1%90.1%90.1%90.1%90.1%90.1%90.1%90.1%90.1%90.1%90.1%90.1%90.1%90.1%90.1%90.1%90.2%90.2%90.2%90.2%90.2%90.2%90.2%90.2%90.2%90.2%90.2%90.2%90.2%90.2%90.2%90.2%90.2%90.2%90.2%90.2%90.2%90.3%90.3%90.3%90.3%90.3%90.3%90.3%90.3%90.3%90.3%90.3%90.3%90.3%90.3%90.3%90.3%90.3%90.3%90.3%90.3%90.3%90.4%90.4%90.4%90.4%90.4%90.4%90.4%90.4%90.4%90.4%90.4%90.4%90.4%90.4%90.4%90.4%90.4%90.4%90.4%90.4%90.5%90.5%90.5%90.5%90.5%90.5%90.5%90.5%90.5%90.5%90.5%90.5%90.5%90.5%90.5%90.5%90.5%90.5%90.5%90.5%90.5%90.6%90.6%90.6%90.6%90.6%90.6%90.6%90.6%90.6%90.6%90.6%90.6%90.6%90.6%90.6%90.6%90.6%90.6%90.6%90.6%90.6%90.7%90.7%90.7%90.7%90.7%90.7%90.7%90.7%90.7%90.7%90.7%90.7%90.7%90.7%90.7%90.7%90.7%90.7%90.7%90.7%90.8%90.8%90.8%90.8%90.8%90.8%90.8%90.8%90.8%90.8%90.8%90.8%90.8%90.8%90.8%90.8%90.8%90.8%90.8%90.8%90.8%90.9%90.9%90.9%90.9%90.9%90.9%90.9%90.9%90.9%90.9%90.9%90.9%90.9%90.9%90.9%90.9%90.9%90.9%90.9%90.9%90.9%91.0%91.0%91.0%91.0%91.0%91.0%91.0%91.0%91.0%91.0%91.0%91.0%91.0%91.0%91.0%91.0%91.0%91.0%91.0%91.0%91.1%91.1%91.1%91.1%91.1%91.1%91.1%91.1%91.1%91.1%91.1%91.1%91.1%91.1%91.1%91.1%91.1%91.1%91.1%91.1%91.1%91.2%91.2%91.2%91.2%91.2%91.2%91.2%91.2%91.2%91.2%91.2%91.2%91.2%91.2%91.2%91.2%91.2%91.2%91.2%91.2%91.3%91.3%91.3%91.3%91.3%91.3%91.3%91.3%91.3%91.3%91.3%91.3%91.3%91.3%91.3%91.3%91.3%91.3%91.3%91.3%91.3%91.4%91.4%91.4%91.4%91.4%91.4%91.4%91.4%91.4%91.4%91.4%91.4%91.4%91.4%91.4%91.4%91.4%91.4%91.4%91.4%91.4%91.5%91.5%91.5%91.5%91.5%91.5%91.5%91.5%91.5%91.5%91.5%91.5%91.5%91.5%91.5%91.5%91.5%91.5%91.5%91.5%91.6%91.6%91.6%91.6%91.6%91.6%91.6%91.6%91.6%91.6%91.6%91.6%91.6%91.6%91.6%91.6%91.6%91.6%91.6%91.6%91.6%91.7%91.7%91.7%91.7%91.7%91.7%91.7%91.7%91.7%91.7%91.7%91.7%91.7%91.7%91.7%91.7%91.7%91.7%91.7%91.7%91.7%91.8%91.8%91.8%91.8%91.8%91.8%91.8%91.8%91.8%91.8%91.8%91.8%91.8%91.8%91.8%91.8%91.8%91.8%91.8%91.8%91.9%91.9%91.9%91.9%91.9%91.9%91.9%91.9%91.9%91.9%91.9%91.9%91.9%91.9%91.9%91.9%91.9%91.9%91.9%91.9%91.9%92.0%92.0%92.0%92.0%92.0%92.0%92.0%92.0%92.0%92.0%92.0%92.0%92.0%92.0%92.0%92.0%92.0%92.0%92.0%92.0%92.1%92.1%92.1%92.1%92.1%92.1%92.1%92.1%92.1%92.1%92.1%92.1%92.1%92.1%92.1%92.1%92.1%92.1%92.1%92.1%92.1%92.2%92.2%92.2%92.2%92.2%92.2%92.2%92.2%92.2%92.2%92.2%92.2%92.2%92.2%92.2%92.2%92.2%92.2%92.2%92.2%92.2%92.3%92.3%92.3%92.3%92.3%92.3%92.3%92.3%92.3%92.3%92.3%92.3%92.3%92.3%92.3%92.3%92.3%92.3%92.3%92.3%92.4%92.4%92.4%92.4%92.4%92.4%92.4%92.4%92.4%92.4%92.4%92.4%92.4%92.4%92.4%92.4%92.4%92.4%92.4%92.4%92.4%92.5%92.5%92.5%92.5%92.5%92.5%92.5%92.5%92.5%92.5%92.5%92.5%92.5%92.5%92.5%92.5%92.5%92.5%92.5%92.5%92.5%92.6%92.6%92.6%92.6%92.6%92.6%92.6%92.6%92.6%92.6%92.6%92.6%92.6%92.6%92.6%92.6%92.6%92.6%92.6%92.6%92.7%92.7%92.7%92.7%92.7%92.7%92.7%92.7%92.7%92.7%92.7%92.7%92.7%92.7%92.7%92.7%92.7%92.7%92.7%92.7%92.7%92.8%92.8%92.8%92.8%92.8%92.8%92.8%92.8%92.8%92.8%92.8%92.8%92.8%92.8%92.8%92.8%92.8%92.8%92.8%92.8%92.8%92.9%92.9%92.9%92.9%92.9%92.9%92.9%92.9%92.9%92.9%92.9%92.9%92.9%92.9%92.9%92.9%92.9%92.9%92.9%92.9%93.0%93.0%93.0%93.0%93.0%93.0%93.0%93.0%93.0%93.0%93.0%93.0%93.0%93.0%93.0%93.0%93.0%93.0%93.0%93.0%93.0%93.1%93.1%93.1%93.1%93.1%93.1%93.1%93.1%93.1%93.1%93.1%93.1%93.1%93.1%93.1%93.1%93.1%93.1%93.1%93.1%93.2%93.2%93.2%93.2%93.2%93.2%93.2%93.2%93.2%93.2%93.2%93.2%93.2%93.2%93.2%93.2%93.2%93.2%93.2%93.2%93.2%93.3%93.3%93.3%93.3%93.3%93.3%93.3%93.3%93.3%93.3%93.3%93.3%93.3%93.3%93.3%93.3%93.3%93.3%93.3%93.3%93.3%93.4%93.4%93.4%93.4%93.4%93.4%93.4%93.4%93.4%93.4%93.4%93.4%93.4%93.4%93.4%93.4%93.4%93.4%93.4%93.4%93.5%93.5%93.5%93.5%93.5%93.5%93.5%93.5%93.5%93.5%93.5%93.5%93.5%93.5%93.5%93.5%93.5%93.5%93.5%93.5%93.5%93.6%93.6%93.6%93.6%93.6%93.6%93.6%93.6%93.6%93.6%93.6%93.6%93.6%93.6%93.6%93.6%93.6%93.6%93.6%93.6%93.6%93.7%93.7%93.7%93.7%93.7%93.7%93.7%93.7%93.7%93.7%93.7%93.7%93.7%93.7%93.7%93.7%93.7%93.7%93.7%93.7%93.8%93.8%93.8%93.8%93.8%93.8%93.8%93.8%93.8%93.8%93.8%93.8%93.8%93.8%93.8%93.8%93.8%93.8%93.8%93.8%93.8%93.9%93.9%93.9%93.9%93.9%93.9%93.9%93.9%93.9%93.9%93.9%93.9%93.9%93.9%93.9%93.9%93.9%93.9%93.9%93.9%94.0%94.0%94.0%94.0%94.0%94.0%94.0%94.0%94.0%94.0%94.0%94.0%94.0%94.0%94.0%94.0%94.0%94.0%94.0%94.0%94.0%94.1%94.1%94.1%94.1%94.1%94.1%94.1%94.1%94.1%94.1%94.1%94.1%94.1%94.1%94.1%94.1%94.1%94.1%94.1%94.1%94.1%94.2%94.2%94.2%94.2%94.2%94.2%94.2%94.2%94.2%94.2%94.2%94.2%94.2%94.2%94.2%94.2%94.2%94.2%94.2%94.2%94.3%94.3%94.3%94.3%94.3%94.3%94.3%94.3%94.3%94.3%94.3%94.3%94.3%94.3%94.3%94.3%94.3%94.3%94.3%94.3%94.3%94.4%94.4%94.4%94.4%94.4%94.4%94.4%94.4%94.4%94.4%94.4%94.4%94.4%94.4%94.4%94.4%94.4%94.4%94.4%94.4%94.4%94.5%94.5%94.5%94.5%94.5%94.5%94.5%94.5%94.5%94.5%94.5%94.5%94.5%94.5%94.5%94.5%94.5%94.5%94.5%94.5%94.6%94.6%94.6%94.6%94.6%94.6%94.6%94.6%94.6%94.6%94.6%94.6%94.6%94.6%94.6%94.6%94.6%94.6%94.6%94.6%94.6%94.7%94.7%94.7%94.7%94.7%94.7%94.7%94.7%94.7%94.7%94.7%94.7%94.7%94.7%94.7%94.7%94.7%94.7%94.7%94.7%94.8%94.8%94.8%94.8%94.8%94.8%94.8%94.8%94.8%94.8%94.8%94.8%94.8%94.8%94.8%94.8%94.8%94.8%94.8%94.8%94.8%94.9%94.9%94.9%94.9%94.9%94.9%94.9%94.9%94.9%94.9%94.9%94.9%94.9%94.9%94.9%94.9%94.9%94.9%94.9%94.9%94.9%95.0%95.0%95.0%95.0%95.0%95.0%95.0%95.0%95.0%95.0%95.0%95.0%95.0%95.0%95.0%95.0%95.0%95.0%95.0%95.0%95.1%95.1%95.1%95.1%95.1%95.1%95.1%95.1%95.1%95.1%95.1%95.1%95.1%95.1%95.1%95.1%95.1%95.1%95.1%95.1%95.1%95.2%95.2%95.2%95.2%95.2%95.2%95.2%95.2%95.2%95.2%95.2%95.2%95.2%95.2%95.2%95.2%95.2%95.2%95.2%95.2%95.2%95.3%95.3%95.3%95.3%95.3%95.3%95.3%95.3%95.3%95.3%95.3%95.3%95.3%95.3%95.3%95.3%95.3%95.3%95.3%95.3%95.4%95.4%95.4%95.4%95.4%95.4%95.4%95.4%95.4%95.4%95.4%95.4%95.4%95.4%95.4%95.4%95.4%95.4%95.4%95.4%95.4%95.5%95.5%95.5%95.5%95.5%95.5%95.5%95.5%95.5%95.5%95.5%95.5%95.5%95.5%95.5%95.5%95.5%95.5%95.5%95.5%95.5%95.6%95.6%95.6%95.6%95.6%95.6%95.6%95.6%95.6%95.6%95.6%95.6%95.6%95.6%95.6%95.6%95.6%95.6%95.6%95.6%95.7%95.7%95.7%95.7%95.7%95.7%95.7%95.7%95.7%95.7%95.7%95.7%95.7%95.7%95.7%95.7%95.7%95.7%95.7%95.7%95.7%95.8%95.8%95.8%95.8%95.8%95.8%95.8%95.8%95.8%95.8%95.8%95.8%95.8%95.8%95.8%95.8%95.8%95.8%95.8%95.8%95.9%95.9%95.9%95.9%95.9%95.9%95.9%95.9%95.9%95.9%95.9%95.9%95.9%95.9%95.9%95.9%95.9%95.9%95.9%95.9%95.9%96.0%96.0%96.0%96.0%96.0%96.0%96.0%96.0%96.0%96.0%96.0%96.0%96.0%96.0%96.0%96.0%96.0%96.0%96.0%96.0%96.0%96.1%96.1%96.1%96.1%96.1%96.1%96.1%96.1%96.1%96.1%96.1%96.1%96.1%96.1%96.1%96.1%96.1%96.1%96.1%96.1%96.2%96.2%96.2%96.2%96.2%96.2%96.2%96.2%96.2%96.2%96.2%96.2%96.2%96.2%96.2%96.2%96.2%96.2%96.2%96.2%96.2%96.3%96.3%96.3%96.3%96.3%96.3%96.3%96.3%96.3%96.3%96.3%96.3%96.3%96.3%96.3%96.3%96.3%96.3%96.3%96.3%96.3%96.4%96.4%96.4%96.4%96.4%96.4%96.4%96.4%96.4%96.4%96.4%96.4%96.4%96.4%96.4%96.4%96.4%96.4%96.4%96.4%96.5%96.5%96.5%96.5%96.5%96.5%96.5%96.5%96.5%96.5%96.5%96.5%96.5%96.5%96.5%96.5%96.5%96.5%96.5%96.5%96.5%96.6%96.6%96.6%96.6%96.6%96.6%96.6%96.6%96.6%96.6%96.6%96.6%96.6%96.6%96.6%96.6%96.6%96.6%96.6%96.6%96.7%96.7%96.7%96.7%96.7%96.7%96.7%96.7%96.7%96.7%96.7%96.7%96.7%96.7%96.7%96.7%96.7%96.7%96.7%96.7%96.7%96.8%96.8%96.8%96.8%96.8%96.8%96.8%96.8%96.8%96.8%96.8%96.8%96.8%96.8%96.8%96.8%96.8%96.8%96.8%96.8%96.8%96.9%96.9%96.9%96.9%96.9%96.9%96.9%96.9%96.9%96.9%96.9%96.9%96.9%96.9%96.9%96.9%96.9%96.9%96.9%96.9%97.0%97.0%97.0%97.0%97.0%97.0%97.0%97.0%97.0%97.0%97.0%97.0%97.0%97.0%97.0%97.0%97.0%97.0%97.0%97.0%97.0%97.1%97.1%97.1%97.1%97.1%97.1%97.1%97.1%97.1%97.1%97.1%97.1%97.1%97.1%97.1%97.1%97.1%97.1%97.1%97.1%97.1%97.2%97.2%97.2%97.2%97.2%97.2%97.2%97.2%97.2%97.2%97.2%97.2%97.2%97.2%97.2%97.2%97.2%97.2%97.2%97.2%97.3%97.3%97.3%97.3%97.3%97.3%97.3%97.3%97.3%97.3%97.3%97.3%97.3%97.3%97.3%97.3%97.3%97.3%97.3%97.3%97.3%97.4%97.4%97.4%97.4%97.4%97.4%97.4%97.4%97.4%97.4%97.4%97.4%97.4%97.4%97.4%97.4%97.4%97.4%97.4%97.4%97.5%97.5%97.5%97.5%97.5%97.5%97.5%97.5%97.5%97.5%97.5%97.5%97.5%97.5%97.5%97.5%97.5%97.5%97.5%97.5%97.5%97.6%97.6%97.6%97.6%97.6%97.6%97.6%97.6%97.6%97.6%97.6%97.6%97.6%97.6%97.6%97.6%97.6%97.6%97.6%97.6%97.6%97.7%97.7%97.7%97.7%97.7%97.7%97.7%97.7%97.7%97.7%97.7%97.7%97.7%97.7%97.7%97.7%97.7%97.7%97.7%97.7%97.8%97.8%97.8%97.8%97.8%97.8%97.8%97.8%97.8%97.8%97.8%97.8%97.8%97.8%97.8%97.8%97.8%97.8%97.8%97.8%97.8%97.9%97.9%97.9%97.9%97.9%97.9%97.9%97.9%97.9%97.9%97.9%97.9%97.9%97.9%97.9%97.9%97.9%97.9%97.9%97.9%97.9%98.0%98.0%98.0%98.0%98.0%98.0%98.0%98.0%98.0%98.0%98.0%98.0%98.0%98.0%98.0%98.0%98.0%98.0%98.0%98.0%98.1%98.1%98.1%98.1%98.1%98.1%98.1%98.1%98.1%98.1%98.1%98.1%98.1%98.1%98.1%98.1%98.1%98.1%98.1%98.1%98.1%98.2%98.2%98.2%98.2%98.2%98.2%98.2%98.2%98.2%98.2%98.2%98.2%98.2%98.2%98.2%98.2%98.2%98.2%98.2%98.2%98.2%98.3%98.3%98.3%98.3%98.3%98.3%98.3%98.3%98.3%98.3%98.3%98.3%98.3%98.3%98.3%98.3%98.3%98.3%98.3%98.3%98.4%98.4%98.4%98.4%98.4%98.4%98.4%98.4%98.4%98.4%98.4%98.4%98.4%98.4%98.4%98.4%98.4%98.4%98.4%98.4%98.4%98.5%98.5%98.5%98.5%98.5%98.5%98.5%98.5%98.5%98.5%98.5%98.5%98.5%98.5%98.5%98.5%98.5%98.5%98.5%98.5%98.6%98.6%98.6%98.6%98.6%98.6%98.6%98.6%98.6%98.6%98.6%98.6%98.6%98.6%98.6%98.6%98.6%98.6%98.6%98.6%98.6%98.7%98.7%98.7%98.7%98.7%98.7%98.7%98.7%98.7%98.7%98.7%98.7%98.7%98.7%98.7%98.7%98.7%98.7%98.7%98.7%98.7%98.8%98.8%98.8%98.8%98.8%98.8%98.8%98.8%98.8%98.8%98.8%98.8%98.8%98.8%98.8%98.8%98.8%98.8%98.8%98.8%98.9%98.9%98.9%98.9%98.9%98.9%98.9%98.9%98.9%98.9%98.9%98.9%98.9%98.9%98.9%98.9%98.9%98.9%98.9%98.9%98.9%99.0%99.0%99.0%99.0%99.0%99.0%99.0%99.0%99.0%99.0%99.0%99.0%99.0%99.0%99.0%99.0%99.0%99.0%99.0%99.0%99.0%99.1%99.1%99.1%99.1%99.1%99.1%99.1%99.1%99.1%99.1%99.1%99.1%99.1%99.1%99.1%99.1%99.1%99.1%99.1%99.1%99.2%99.2%99.2%99.2%99.2%99.2%99.2%99.2%99.2%99.2%99.2%99.2%99.2%99.2%99.2%99.2%99.2%99.2%99.2%99.2%99.2%99.3%99.3%99.3%99.3%99.3%99.3%99.3%99.3%99.3%99.3%99.3%99.3%99.3%99.3%99.3%99.3%99.3%99.3%99.3%99.3%99.4%99.4%99.4%99.4%99.4%99.4%99.4%99.4%99.4%99.4%99.4%99.4%99.4%99.4%99.4%99.4%99.4%99.4%99.4%99.4%99.4%99.5%99.5%99.5%99.5%99.5%99.5%99.5%99.5%99.5%99.5%99.5%99.5%99.5%99.5%99.5%99.5%99.5%99.5%99.5%99.5%99.5%99.6%99.6%99.6%99.6%99.6%99.6%99.6%99.6%99.6%99.6%99.6%99.6%99.6%99.6%99.6%99.6%99.6%99.6%99.6%99.6%99.7%99.7%99.7%99.7%99.7%99.7%99.7%99.7%99.7%99.7%99.7%99.7%99.7%99.7%99.7%99.7%99.7%99.7%99.7%99.7%99.7%99.8%99.8%99.8%99.8%99.8%99.8%99.8%99.8%99.8%99.8%99.8%99.8%99.8%99.8%99.8%99.8%99.8%99.8%99.8%99.8%99.8%99.9%99.9%99.9%99.9%99.9%99.9%99.9%99.9%99.9%99.9%99.9%99.9%99.9%99.9%99.9%99.9%99.9%99.9%99.9%99.9%100.0%100.0%100.0%100.0%100.0%100.0%100.0%100.0%100.0%100.0%100.0%100.0%Extracting ./dataset/data/torch/cifar-100-python.tar.gz to ./dataset/data/torch
==> creating model 'vgg11_bn_flat'
    Total params: 9.27M
Calculating FLOPS
conv1 --> [64, 3, 3, 3]
conv2 --> [128, 64, 3, 3]
conv3 --> [256, 128, 3, 3]
conv4 --> [256, 256, 3, 3]
conv5 --> [512, 256, 3, 3]
conv6 --> [512, 512, 3, 3]
conv7 --> [512, 512, 3, 3]
conv8 --> [512, 512, 3, 3]
fc --> [512, 100]
1, 708673536, 1769472, 64
2, 7889485824, 18874368, 128
3, 8606711808, 18874368, 256
4, 17213423616, 37748736, 256
5, 10267656192, 18874368, 512
6, 20535312384, 37748736, 512
7, 7247757312, 9437184, 512
8, 7247757312, 9437184, 512
fc, 19660800, 51200, 0
===================
FLOP REPORT: 31147046400000.0 60620800000.0 152815616 151552 2752 17.685302734375

Epoch: [1 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
cifar.py:338: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)
Epoch: [1][0/391]	Time 0.326 (0.326)	Data 0.120 (0.120)	Loss 6.1210 (6.1210)	Acc@1 0.781 (0.781)	Acc@5 0.781 (0.781)
Epoch: [1][10/391]	Time 0.013 (0.041)	Data 0.001 (0.012)	Loss 9.1798 (7.1286)	Acc@1 0.781 (1.705)	Acc@5 4.688 (6.534)
Epoch: [1][20/391]	Time 0.013 (0.028)	Data 0.001 (0.007)	Loss 7.4559 (7.6829)	Acc@1 0.781 (1.562)	Acc@5 3.125 (6.399)
Epoch: [1][30/391]	Time 0.013 (0.023)	Data 0.001 (0.005)	Loss 6.3385 (7.3411)	Acc@1 0.781 (1.487)	Acc@5 6.250 (6.124)
Epoch: [1][40/391]	Time 0.013 (0.021)	Data 0.002 (0.004)	Loss 5.7849 (7.0416)	Acc@1 7.812 (1.562)	Acc@5 13.281 (6.079)
Epoch: [1][50/391]	Time 0.013 (0.019)	Data 0.001 (0.004)	Loss 5.9186 (6.8584)	Acc@1 1.562 (1.562)	Acc@5 5.469 (6.158)
Epoch: [1][60/391]	Time 0.013 (0.018)	Data 0.001 (0.003)	Loss 5.8649 (6.7138)	Acc@1 0.000 (1.575)	Acc@5 6.250 (6.212)
Epoch: [1][70/391]	Time 0.013 (0.018)	Data 0.001 (0.003)	Loss 6.1645 (6.6099)	Acc@1 3.125 (1.607)	Acc@5 7.812 (6.118)
Epoch: [1][80/391]	Time 0.013 (0.017)	Data 0.001 (0.003)	Loss 5.8188 (6.5183)	Acc@1 2.344 (1.630)	Acc@5 8.594 (6.144)
Epoch: [1][90/391]	Time 0.013 (0.017)	Data 0.001 (0.003)	Loss 5.8032 (6.4536)	Acc@1 1.562 (1.605)	Acc@5 7.812 (6.207)
Epoch: [1][100/391]	Time 0.013 (0.016)	Data 0.001 (0.003)	Loss 5.8333 (6.3949)	Acc@1 1.562 (1.578)	Acc@5 6.250 (6.227)
Epoch: [1][110/391]	Time 0.012 (0.016)	Data 0.001 (0.002)	Loss 5.8963 (6.3428)	Acc@1 0.781 (1.513)	Acc@5 6.250 (6.299)
Epoch: [1][120/391]	Time 0.013 (0.016)	Data 0.001 (0.002)	Loss 5.7753 (6.2957)	Acc@1 1.562 (1.472)	Acc@5 6.250 (6.276)
Epoch: [1][130/391]	Time 0.013 (0.016)	Data 0.001 (0.002)	Loss 5.7707 (6.2555)	Acc@1 0.781 (1.437)	Acc@5 3.906 (6.316)
Epoch: [1][140/391]	Time 0.013 (0.015)	Data 0.001 (0.002)	Loss 5.7338 (6.2201)	Acc@1 1.562 (1.457)	Acc@5 6.250 (6.361)
Epoch: [1][150/391]	Time 0.013 (0.015)	Data 0.001 (0.002)	Loss 5.7550 (6.1911)	Acc@1 0.000 (1.449)	Acc@5 3.906 (6.353)
Epoch: [1][160/391]	Time 0.013 (0.015)	Data 0.001 (0.002)	Loss 5.8065 (6.1658)	Acc@1 0.781 (1.422)	Acc@5 4.688 (6.303)
Epoch: [1][170/391]	Time 0.012 (0.015)	Data 0.002 (0.002)	Loss 5.7516 (6.1401)	Acc@1 0.000 (1.462)	Acc@5 5.469 (6.373)
Epoch: [1][180/391]	Time 0.013 (0.015)	Data 0.001 (0.002)	Loss 5.6927 (6.1168)	Acc@1 1.562 (1.468)	Acc@5 6.250 (6.449)
Epoch: [1][190/391]	Time 0.022 (0.015)	Data 0.001 (0.002)	Loss 5.7050 (6.0949)	Acc@1 2.344 (1.477)	Acc@5 6.250 (6.500)
Epoch: [1][200/391]	Time 0.013 (0.015)	Data 0.001 (0.002)	Loss 5.6640 (6.0745)	Acc@1 2.344 (1.454)	Acc@5 7.031 (6.530)
Epoch: [1][210/391]	Time 0.014 (0.015)	Data 0.002 (0.002)	Loss 5.6222 (6.0559)	Acc@1 1.562 (1.455)	Acc@5 4.688 (6.528)
Epoch: [1][220/391]	Time 0.015 (0.015)	Data 0.002 (0.002)	Loss 5.6954 (6.0374)	Acc@1 0.781 (1.499)	Acc@5 7.812 (6.649)
Epoch: [1][230/391]	Time 0.012 (0.015)	Data 0.002 (0.002)	Loss 5.6122 (6.0206)	Acc@1 1.562 (1.498)	Acc@5 8.594 (6.696)
Epoch: [1][240/391]	Time 0.013 (0.015)	Data 0.001 (0.002)	Loss 5.5597 (6.0045)	Acc@1 1.562 (1.491)	Acc@5 8.594 (6.694)
Epoch: [1][250/391]	Time 0.013 (0.015)	Data 0.002 (0.002)	Loss 5.5646 (5.9881)	Acc@1 1.562 (1.510)	Acc@5 10.156 (6.779)
Epoch: [1][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 5.5540 (5.9724)	Acc@1 2.344 (1.527)	Acc@5 10.156 (6.840)
Epoch: [1][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 5.5586 (5.9566)	Acc@1 1.562 (1.548)	Acc@5 7.812 (6.933)
Epoch: [1][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 5.4468 (5.9415)	Acc@1 3.125 (1.574)	Acc@5 7.031 (7.045)
Epoch: [1][290/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 5.4941 (5.9264)	Acc@1 1.562 (1.595)	Acc@5 11.719 (7.187)
Epoch: [1][300/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 5.4353 (5.9109)	Acc@1 2.344 (1.612)	Acc@5 13.281 (7.309)
Epoch: [1][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 5.3232 (5.8940)	Acc@1 4.688 (1.655)	Acc@5 11.719 (7.481)
Epoch: [1][320/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 5.3566 (5.8785)	Acc@1 1.562 (1.682)	Acc@5 9.375 (7.615)
Epoch: [1][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 5.2896 (5.8620)	Acc@1 3.125 (1.735)	Acc@5 13.281 (7.829)
Epoch: [1][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 5.1375 (5.8456)	Acc@1 7.031 (1.789)	Acc@5 23.438 (8.048)
Epoch: [1][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 5.3632 (5.8315)	Acc@1 3.906 (1.790)	Acc@5 14.062 (8.178)
Epoch: [1][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 5.2044 (5.8157)	Acc@1 3.906 (1.840)	Acc@5 15.625 (8.395)
Epoch: [1][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 5.1797 (5.8006)	Acc@1 3.906 (1.891)	Acc@5 16.406 (8.583)
Epoch: [1][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 5.2592 (5.7851)	Acc@1 0.781 (1.950)	Acc@5 11.719 (8.782)
Epoch: [1][390/391]	Time 0.210 (0.015)	Data 0.000 (0.002)	Loss 5.2543 (5.7694)	Acc@1 3.750 (2.006)	Acc@5 13.750 (9.038)
cifar.py:425: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)
num momentum params: 26
[0.1, 5.769370378112793, 4.260796008110046, 2.006, 3.26, tensor(0.1966, device='cuda:0', grad_fn=<DivBackward0>), 5.697633981704712, 0.49488735198974615]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [2 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [2][0/391]	Time 0.028 (0.028)	Data 0.131 (0.131)	Loss 5.2428 (5.2428)	Acc@1 3.125 (3.125)	Acc@5 13.281 (13.281)
Epoch: [2][10/391]	Time 0.014 (0.015)	Data 0.002 (0.013)	Loss 5.0800 (5.1476)	Acc@1 3.906 (4.616)	Acc@5 18.750 (18.821)
Epoch: [2][20/391]	Time 0.013 (0.014)	Data 0.001 (0.008)	Loss 5.2096 (5.1506)	Acc@1 3.906 (4.055)	Acc@5 21.094 (18.192)
Epoch: [2][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 5.0550 (5.1323)	Acc@1 6.250 (4.108)	Acc@5 21.094 (18.372)
Epoch: [2][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 5.1423 (5.1184)	Acc@1 2.344 (4.192)	Acc@5 18.750 (18.312)
Epoch: [2][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 5.1661 (5.1164)	Acc@1 3.125 (4.228)	Acc@5 17.188 (18.321)
Epoch: [2][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 5.0956 (5.1127)	Acc@1 5.469 (4.444)	Acc@5 18.750 (18.776)
Epoch: [2][70/391]	Time 0.011 (0.013)	Data 0.001 (0.003)	Loss 4.9655 (5.0993)	Acc@1 7.031 (4.434)	Acc@5 21.094 (19.113)
Epoch: [2][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 5.0131 (5.0910)	Acc@1 5.469 (4.552)	Acc@5 19.531 (19.184)
Epoch: [2][90/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 5.0688 (5.0821)	Acc@1 3.906 (4.490)	Acc@5 15.625 (19.325)
Epoch: [2][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 5.0048 (5.0710)	Acc@1 1.562 (4.548)	Acc@5 21.094 (19.585)
Epoch: [2][110/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 4.8989 (5.0624)	Acc@1 6.250 (4.744)	Acc@5 22.656 (19.778)
Epoch: [2][120/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 4.9221 (5.0447)	Acc@1 5.469 (4.881)	Acc@5 25.781 (20.196)
Epoch: [2][130/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 4.8859 (5.0368)	Acc@1 5.469 (4.908)	Acc@5 20.312 (20.360)
Epoch: [2][140/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.7680 (5.0241)	Acc@1 8.594 (5.009)	Acc@5 26.562 (20.689)
Epoch: [2][150/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.9673 (5.0142)	Acc@1 6.250 (5.044)	Acc@5 16.406 (20.882)
Epoch: [2][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.7602 (5.0025)	Acc@1 7.812 (5.134)	Acc@5 29.688 (21.016)
Epoch: [2][170/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.6690 (4.9943)	Acc@1 7.812 (5.126)	Acc@5 27.344 (21.176)
Epoch: [2][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.9479 (4.9845)	Acc@1 5.469 (5.236)	Acc@5 21.875 (21.370)
Epoch: [2][190/391]	Time 0.012 (0.013)	Data 0.003 (0.002)	Loss 5.0310 (4.9747)	Acc@1 7.031 (5.403)	Acc@5 22.656 (21.662)
Epoch: [2][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.7945 (4.9672)	Acc@1 5.469 (5.519)	Acc@5 25.000 (21.891)
Epoch: [2][210/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 4.6609 (4.9582)	Acc@1 8.594 (5.576)	Acc@5 25.781 (22.053)
Epoch: [2][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.8219 (4.9516)	Acc@1 6.250 (5.610)	Acc@5 21.875 (22.200)
Epoch: [2][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.7398 (4.9430)	Acc@1 9.375 (5.651)	Acc@5 25.781 (22.399)
Epoch: [2][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.6878 (4.9359)	Acc@1 7.031 (5.725)	Acc@5 28.125 (22.585)
Epoch: [2][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.5644 (4.9257)	Acc@1 12.500 (5.830)	Acc@5 32.031 (22.812)
Epoch: [2][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.6624 (4.9168)	Acc@1 7.031 (5.933)	Acc@5 30.469 (23.009)
Epoch: [2][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.6558 (4.9075)	Acc@1 7.812 (5.993)	Acc@5 28.906 (23.204)
Epoch: [2][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.7690 (4.8969)	Acc@1 7.031 (6.041)	Acc@5 28.906 (23.438)
Epoch: [2][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.5680 (4.8879)	Acc@1 10.938 (6.121)	Acc@5 28.125 (23.617)
Epoch: [2][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.6482 (4.8811)	Acc@1 4.688 (6.162)	Acc@5 27.344 (23.731)
Epoch: [2][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.6126 (4.8723)	Acc@1 6.250 (6.230)	Acc@5 28.906 (23.932)
Epoch: [2][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.6200 (4.8640)	Acc@1 12.500 (6.272)	Acc@5 31.250 (24.146)
Epoch: [2][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.5910 (4.8559)	Acc@1 7.812 (6.356)	Acc@5 28.906 (24.299)
Epoch: [2][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.5645 (4.8505)	Acc@1 8.594 (6.367)	Acc@5 23.438 (24.395)
Epoch: [2][350/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 4.5675 (4.8413)	Acc@1 7.812 (6.481)	Acc@5 30.469 (24.613)
Epoch: [2][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.4584 (4.8315)	Acc@1 16.406 (6.579)	Acc@5 35.938 (24.864)
Epoch: [2][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.4606 (4.8217)	Acc@1 10.938 (6.654)	Acc@5 35.156 (25.063)
Epoch: [2][380/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 4.5128 (4.8141)	Acc@1 9.375 (6.711)	Acc@5 31.250 (25.224)
Epoch: [2][390/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 4.4322 (4.8050)	Acc@1 13.750 (6.808)	Acc@5 36.250 (25.400)
num momentum params: 26
[0.1, 4.805031663513184, 3.746291069984436, 6.808, 10.27, tensor(0.1735, device='cuda:0', grad_fn=<DivBackward0>), 5.169116020202637, 0.3677361011505127]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [3 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [3][0/391]	Time 0.027 (0.027)	Data 0.123 (0.123)	Loss 4.4233 (4.4233)	Acc@1 9.375 (9.375)	Acc@5 30.469 (30.469)
Epoch: [3][10/391]	Time 0.013 (0.014)	Data 0.001 (0.013)	Loss 4.6359 (4.4975)	Acc@1 5.469 (9.091)	Acc@5 28.906 (31.534)
Epoch: [3][20/391]	Time 0.013 (0.014)	Data 0.001 (0.007)	Loss 4.1456 (4.4552)	Acc@1 14.062 (10.454)	Acc@5 46.094 (33.966)
Epoch: [3][30/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 4.3634 (4.4248)	Acc@1 7.031 (10.610)	Acc@5 34.375 (34.602)
Epoch: [3][40/391]	Time 0.013 (0.013)	Data 0.001 (0.004)	Loss 4.2325 (4.3995)	Acc@1 14.062 (10.690)	Acc@5 32.812 (34.947)
Epoch: [3][50/391]	Time 0.013 (0.013)	Data 0.001 (0.004)	Loss 4.5014 (4.3822)	Acc@1 7.812 (11.198)	Acc@5 31.250 (35.662)
Epoch: [3][60/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 4.3680 (4.3884)	Acc@1 9.375 (11.258)	Acc@5 35.938 (35.400)
Epoch: [3][70/391]	Time 0.014 (0.013)	Data 0.001 (0.003)	Loss 4.6015 (4.3918)	Acc@1 6.250 (11.114)	Acc@5 29.688 (35.156)
Epoch: [3][80/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 4.3092 (4.3864)	Acc@1 10.156 (11.208)	Acc@5 38.281 (35.176)
Epoch: [3][90/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 4.3004 (4.3721)	Acc@1 8.594 (11.418)	Acc@5 42.188 (35.534)
Epoch: [3][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 4.1984 (4.3664)	Acc@1 10.938 (11.371)	Acc@5 39.844 (35.528)
Epoch: [3][110/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.3337 (4.3623)	Acc@1 9.375 (11.346)	Acc@5 34.375 (35.550)
Epoch: [3][120/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.3054 (4.3595)	Acc@1 11.719 (11.428)	Acc@5 39.844 (35.569)
Epoch: [3][130/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.3464 (4.3526)	Acc@1 10.938 (11.456)	Acc@5 34.375 (35.818)
Epoch: [3][140/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.1966 (4.3414)	Acc@1 13.281 (11.519)	Acc@5 37.500 (36.148)
Epoch: [3][150/391]	Time 0.029 (0.013)	Data 0.001 (0.002)	Loss 4.1641 (4.3319)	Acc@1 14.062 (11.636)	Acc@5 39.062 (36.398)
Epoch: [3][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.2203 (4.3201)	Acc@1 13.281 (11.845)	Acc@5 37.500 (36.724)
Epoch: [3][170/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.5248 (4.3139)	Acc@1 11.719 (12.016)	Acc@5 30.469 (36.929)
Epoch: [3][180/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 4.1840 (4.3035)	Acc@1 11.719 (12.150)	Acc@5 38.281 (37.064)
Epoch: [3][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.1263 (4.3008)	Acc@1 17.188 (12.185)	Acc@5 45.312 (37.066)
Epoch: [3][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 4.1373 (4.2957)	Acc@1 11.719 (12.263)	Acc@5 40.625 (37.084)
Epoch: [3][210/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 3.9418 (4.2888)	Acc@1 21.094 (12.374)	Acc@5 43.750 (37.185)
Epoch: [3][220/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 4.3129 (4.2815)	Acc@1 13.281 (12.493)	Acc@5 35.938 (37.337)
Epoch: [3][230/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 4.3065 (4.2763)	Acc@1 8.594 (12.497)	Acc@5 35.938 (37.470)
Epoch: [3][240/391]	Time 0.012 (0.013)	Data 0.002 (0.002)	Loss 4.1907 (4.2741)	Acc@1 15.625 (12.532)	Acc@5 39.062 (37.458)
Epoch: [3][250/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 4.0727 (4.2651)	Acc@1 16.406 (12.547)	Acc@5 42.188 (37.674)
Epoch: [3][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.9219 (4.2581)	Acc@1 17.969 (12.602)	Acc@5 46.094 (37.832)
Epoch: [3][270/391]	Time 0.010 (0.013)	Data 0.007 (0.002)	Loss 4.1668 (4.2507)	Acc@1 15.625 (12.716)	Acc@5 50.000 (38.022)
Epoch: [3][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.8819 (4.2405)	Acc@1 21.094 (12.878)	Acc@5 45.312 (38.287)
Epoch: [3][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.7706 (4.2310)	Acc@1 19.531 (12.956)	Acc@5 48.438 (38.485)
Epoch: [3][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.7670 (4.2212)	Acc@1 22.656 (13.081)	Acc@5 52.344 (38.704)
Epoch: [3][310/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 3.9315 (4.2104)	Acc@1 19.531 (13.281)	Acc@5 40.625 (38.929)
Epoch: [3][320/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 3.9592 (4.2034)	Acc@1 14.062 (13.391)	Acc@5 46.094 (39.087)
Epoch: [3][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.8406 (4.1962)	Acc@1 19.531 (13.539)	Acc@5 47.656 (39.273)
Epoch: [3][340/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 3.8189 (4.1893)	Acc@1 18.750 (13.657)	Acc@5 46.094 (39.424)
Epoch: [3][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.8651 (4.1808)	Acc@1 19.531 (13.820)	Acc@5 49.219 (39.643)
Epoch: [3][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.9540 (4.1732)	Acc@1 21.875 (13.900)	Acc@5 46.094 (39.774)
Epoch: [3][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.9670 (4.1645)	Acc@1 17.188 (14.048)	Acc@5 48.438 (39.983)
Epoch: [3][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.7133 (4.1568)	Acc@1 17.969 (14.155)	Acc@5 56.250 (40.160)
Epoch: [3][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 3.9335 (4.1483)	Acc@1 17.500 (14.278)	Acc@5 41.250 (40.350)
num momentum params: 26
[0.1, 4.148294388961792, 3.3864643502235414, 14.278, 17.62, tensor(0.1516, device='cuda:0', grad_fn=<DivBackward0>), 5.197378635406494, 0.3704502582550049]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [4 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [4][0/391]	Time 0.026 (0.026)	Data 0.132 (0.132)	Loss 3.6368 (3.6368)	Acc@1 20.312 (20.312)	Acc@5 53.906 (53.906)
Epoch: [4][10/391]	Time 0.013 (0.014)	Data 0.001 (0.013)	Loss 3.8055 (3.7935)	Acc@1 16.406 (18.537)	Acc@5 45.312 (48.438)
Epoch: [4][20/391]	Time 0.013 (0.014)	Data 0.001 (0.008)	Loss 3.9469 (3.7843)	Acc@1 13.281 (19.606)	Acc@5 42.969 (48.586)
Epoch: [4][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 3.7887 (3.7909)	Acc@1 19.531 (19.607)	Acc@5 50.781 (48.916)
Epoch: [4][40/391]	Time 0.013 (0.013)	Data 0.001 (0.005)	Loss 3.9624 (3.7948)	Acc@1 17.969 (19.722)	Acc@5 43.750 (48.418)
Epoch: [4][50/391]	Time 0.013 (0.013)	Data 0.001 (0.004)	Loss 3.8167 (3.7930)	Acc@1 15.625 (19.593)	Acc@5 52.344 (48.529)
Epoch: [4][60/391]	Time 0.013 (0.013)	Data 0.001 (0.004)	Loss 3.8807 (3.7935)	Acc@1 15.625 (19.493)	Acc@5 47.656 (48.578)
Epoch: [4][70/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 3.8486 (3.7958)	Acc@1 22.656 (19.256)	Acc@5 52.344 (48.559)
Epoch: [4][80/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 3.7136 (3.7748)	Acc@1 25.781 (19.657)	Acc@5 51.562 (49.064)
Epoch: [4][90/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 3.4928 (3.7651)	Acc@1 21.094 (19.780)	Acc@5 57.812 (49.296)
Epoch: [4][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 3.7268 (3.7582)	Acc@1 23.438 (19.848)	Acc@5 50.781 (49.536)
Epoch: [4][110/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 3.8605 (3.7560)	Acc@1 17.969 (19.749)	Acc@5 49.219 (49.528)
Epoch: [4][120/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.4776 (3.7507)	Acc@1 19.531 (19.718)	Acc@5 54.688 (49.567)
Epoch: [4][130/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.7175 (3.7456)	Acc@1 21.094 (19.818)	Acc@5 51.562 (49.744)
Epoch: [4][140/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.6313 (3.7368)	Acc@1 28.125 (19.963)	Acc@5 52.344 (49.900)
Epoch: [4][150/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.6784 (3.7324)	Acc@1 19.531 (20.012)	Acc@5 45.312 (49.933)
Epoch: [4][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.7643 (3.7293)	Acc@1 16.406 (20.050)	Acc@5 46.094 (49.951)
Epoch: [4][170/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.6985 (3.7260)	Acc@1 17.188 (20.070)	Acc@5 47.656 (49.991)
Epoch: [4][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.5410 (3.7269)	Acc@1 24.219 (20.062)	Acc@5 53.906 (49.957)
Epoch: [4][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.6380 (3.7235)	Acc@1 24.219 (20.112)	Acc@5 50.781 (49.992)
Epoch: [4][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.4727 (3.7158)	Acc@1 21.875 (20.258)	Acc@5 55.469 (50.175)
Epoch: [4][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.5689 (3.7134)	Acc@1 18.750 (20.183)	Acc@5 50.781 (50.159)
Epoch: [4][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.6759 (3.7075)	Acc@1 25.000 (20.334)	Acc@5 48.438 (50.308)
Epoch: [4][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.6911 (3.7026)	Acc@1 21.875 (20.434)	Acc@5 49.219 (50.480)
Epoch: [4][240/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 3.8341 (3.6961)	Acc@1 17.188 (20.552)	Acc@5 50.000 (50.642)
Epoch: [4][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.6261 (3.6927)	Acc@1 25.000 (20.633)	Acc@5 50.000 (50.697)
Epoch: [4][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.4217 (3.6850)	Acc@1 25.000 (20.764)	Acc@5 62.500 (50.859)
Epoch: [4][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.4330 (3.6792)	Acc@1 27.344 (20.883)	Acc@5 57.031 (51.058)
Epoch: [4][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.7295 (3.6777)	Acc@1 21.094 (20.921)	Acc@5 48.438 (51.084)
Epoch: [4][290/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 3.4371 (3.6731)	Acc@1 20.312 (21.019)	Acc@5 57.031 (51.200)
Epoch: [4][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.3655 (3.6702)	Acc@1 28.125 (21.122)	Acc@5 57.031 (51.259)
Epoch: [4][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.3447 (3.6636)	Acc@1 24.219 (21.244)	Acc@5 61.719 (51.419)
Epoch: [4][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.6328 (3.6593)	Acc@1 24.219 (21.340)	Acc@5 52.344 (51.524)
Epoch: [4][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.2691 (3.6545)	Acc@1 23.438 (21.386)	Acc@5 58.594 (51.626)
Epoch: [4][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.4105 (3.6491)	Acc@1 25.000 (21.449)	Acc@5 53.125 (51.792)
Epoch: [4][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.2886 (3.6425)	Acc@1 31.250 (21.603)	Acc@5 60.156 (51.928)
Epoch: [4][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.7157 (3.6376)	Acc@1 19.531 (21.717)	Acc@5 50.781 (52.006)
Epoch: [4][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.4999 (3.6325)	Acc@1 26.562 (21.774)	Acc@5 52.344 (52.133)
Epoch: [4][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.5294 (3.6266)	Acc@1 20.312 (21.869)	Acc@5 57.031 (52.276)
Epoch: [4][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 3.8097 (3.6228)	Acc@1 18.750 (21.948)	Acc@5 50.000 (52.372)
num momentum params: 26
[0.1, 3.6227889891052247, 3.0112351083755495, 21.948, 24.49, tensor(0.1449, device='cuda:0', grad_fn=<DivBackward0>), 5.1682868003845215, 0.38398122787475586]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [5 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [5][0/391]	Time 0.028 (0.028)	Data 0.146 (0.146)	Loss 3.1757 (3.1757)	Acc@1 30.469 (30.469)	Acc@5 58.594 (58.594)
Epoch: [5][10/391]	Time 0.013 (0.014)	Data 0.002 (0.015)	Loss 3.2423 (3.4060)	Acc@1 25.781 (24.645)	Acc@5 59.375 (57.528)
Epoch: [5][20/391]	Time 0.013 (0.014)	Data 0.001 (0.008)	Loss 3.2100 (3.3763)	Acc@1 32.812 (25.670)	Acc@5 62.500 (58.185)
Epoch: [5][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 3.1550 (3.3746)	Acc@1 34.375 (26.184)	Acc@5 61.719 (57.863)
Epoch: [5][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 3.2957 (3.3599)	Acc@1 27.344 (26.315)	Acc@5 64.844 (58.689)
Epoch: [5][50/391]	Time 0.013 (0.013)	Data 0.001 (0.004)	Loss 3.4206 (3.3675)	Acc@1 28.906 (26.486)	Acc@5 59.375 (58.425)
Epoch: [5][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 3.2972 (3.3716)	Acc@1 29.688 (26.358)	Acc@5 56.250 (58.210)
Epoch: [5][70/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 3.4800 (3.3778)	Acc@1 21.094 (26.287)	Acc@5 53.125 (57.956)
Epoch: [5][80/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 3.4568 (3.3859)	Acc@1 26.562 (26.042)	Acc@5 53.906 (57.870)
Epoch: [5][90/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 3.3869 (3.3835)	Acc@1 21.094 (26.133)	Acc@5 56.250 (57.812)
Epoch: [5][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 3.4128 (3.3807)	Acc@1 26.562 (26.153)	Acc@5 59.375 (57.890)
Epoch: [5][110/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 3.3532 (3.3856)	Acc@1 25.781 (25.964)	Acc@5 55.469 (57.615)
Epoch: [5][120/391]	Time 0.011 (0.013)	Data 0.003 (0.003)	Loss 3.3682 (3.3866)	Acc@1 25.781 (25.891)	Acc@5 57.812 (57.651)
Epoch: [5][130/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 3.5311 (3.3882)	Acc@1 21.875 (25.787)	Acc@5 58.594 (57.723)
Epoch: [5][140/391]	Time 0.018 (0.014)	Data 0.001 (0.003)	Loss 3.3115 (3.3861)	Acc@1 24.219 (25.820)	Acc@5 55.469 (57.724)
Epoch: [5][150/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 3.0651 (3.3796)	Acc@1 36.719 (26.066)	Acc@5 62.500 (57.859)
Epoch: [5][160/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 3.2834 (3.3767)	Acc@1 25.000 (26.087)	Acc@5 62.500 (57.944)
Epoch: [5][170/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 3.5277 (3.3753)	Acc@1 20.312 (26.119)	Acc@5 59.375 (58.046)
Epoch: [5][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.3118 (3.3718)	Acc@1 28.906 (26.170)	Acc@5 57.031 (58.084)
Epoch: [5][190/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 3.3740 (3.3657)	Acc@1 24.219 (26.301)	Acc@5 57.031 (58.254)
Epoch: [5][200/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 3.2876 (3.3649)	Acc@1 20.312 (26.349)	Acc@5 59.375 (58.263)
Epoch: [5][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 3.0849 (3.3659)	Acc@1 28.125 (26.311)	Acc@5 67.188 (58.231)
Epoch: [5][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 3.4935 (3.3651)	Acc@1 23.438 (26.382)	Acc@5 55.469 (58.208)
Epoch: [5][230/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 3.2738 (3.3653)	Acc@1 27.344 (26.316)	Acc@5 59.375 (58.215)
Epoch: [5][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.2743 (3.3549)	Acc@1 32.031 (26.553)	Acc@5 61.719 (58.474)
Epoch: [5][250/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 3.1117 (3.3573)	Acc@1 32.812 (26.556)	Acc@5 59.375 (58.404)
Epoch: [5][260/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 3.3721 (3.3531)	Acc@1 28.125 (26.577)	Acc@5 57.812 (58.498)
Epoch: [5][270/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 3.3828 (3.3505)	Acc@1 22.656 (26.649)	Acc@5 57.031 (58.539)
Epoch: [5][280/391]	Time 0.010 (0.013)	Data 0.004 (0.002)	Loss 3.1072 (3.3469)	Acc@1 35.938 (26.721)	Acc@5 64.062 (58.622)
Epoch: [5][290/391]	Time 0.018 (0.013)	Data 0.003 (0.002)	Loss 3.3225 (3.3434)	Acc@1 26.562 (26.801)	Acc@5 59.375 (58.693)
Epoch: [5][300/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 3.3904 (3.3381)	Acc@1 25.781 (26.892)	Acc@5 55.469 (58.853)
Epoch: [5][310/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 3.1167 (3.3350)	Acc@1 27.344 (26.964)	Acc@5 65.625 (58.971)
Epoch: [5][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.3086 (3.3323)	Acc@1 25.000 (27.030)	Acc@5 60.156 (59.015)
Epoch: [5][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.1066 (3.3296)	Acc@1 32.031 (27.070)	Acc@5 64.062 (59.094)
Epoch: [5][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.4036 (3.3286)	Acc@1 28.125 (27.089)	Acc@5 55.469 (59.173)
Epoch: [5][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.3991 (3.3259)	Acc@1 24.219 (27.141)	Acc@5 63.281 (59.288)
Epoch: [5][360/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 3.1761 (3.3226)	Acc@1 34.375 (27.197)	Acc@5 62.500 (59.349)
Epoch: [5][370/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 3.1185 (3.3212)	Acc@1 28.125 (27.241)	Acc@5 65.625 (59.411)
Epoch: [5][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.0419 (3.3165)	Acc@1 32.031 (27.336)	Acc@5 64.062 (59.543)
Epoch: [5][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 3.3897 (3.3163)	Acc@1 26.250 (27.358)	Acc@5 55.000 (59.608)
num momentum params: 26
[0.1, 3.316260624694824, 2.9801015043258667, 27.358, 25.17, tensor(0.1489, device='cuda:0', grad_fn=<DivBackward0>), 5.240119457244873, 0.37325429916381836]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [6 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [6][0/391]	Time 0.026 (0.026)	Data 0.132 (0.132)	Loss 3.2783 (3.2783)	Acc@1 27.344 (27.344)	Acc@5 64.062 (64.062)
Epoch: [6][10/391]	Time 0.013 (0.014)	Data 0.001 (0.014)	Loss 3.2962 (3.2325)	Acc@1 21.094 (29.048)	Acc@5 57.812 (61.719)
Epoch: [6][20/391]	Time 0.013 (0.014)	Data 0.001 (0.008)	Loss 3.2829 (3.2168)	Acc@1 25.781 (28.795)	Acc@5 63.281 (62.240)
Epoch: [6][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 3.2255 (3.1957)	Acc@1 30.469 (29.385)	Acc@5 65.625 (63.080)
Epoch: [6][40/391]	Time 0.013 (0.013)	Data 0.001 (0.005)	Loss 3.3928 (3.1849)	Acc@1 32.031 (29.897)	Acc@5 59.375 (63.453)
Epoch: [6][50/391]	Time 0.015 (0.014)	Data 0.001 (0.004)	Loss 3.2563 (3.1882)	Acc@1 28.906 (29.994)	Acc@5 66.406 (63.618)
Epoch: [6][60/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 3.0633 (3.1858)	Acc@1 32.812 (30.020)	Acc@5 64.062 (63.499)
Epoch: [6][70/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 3.0481 (3.1727)	Acc@1 39.062 (30.513)	Acc@5 67.188 (63.644)
Epoch: [6][80/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.9855 (3.1633)	Acc@1 38.281 (30.739)	Acc@5 67.188 (63.889)
Epoch: [6][90/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.9704 (3.1611)	Acc@1 32.031 (30.752)	Acc@5 71.875 (63.934)
Epoch: [6][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.9850 (3.1564)	Acc@1 32.031 (30.832)	Acc@5 66.406 (64.024)
Epoch: [6][110/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.9772 (3.1547)	Acc@1 36.719 (30.807)	Acc@5 67.969 (64.034)
Epoch: [6][120/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.2708 (3.1478)	Acc@1 17.969 (30.798)	Acc@5 64.062 (64.276)
Epoch: [6][130/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.2790 (3.1486)	Acc@1 25.781 (30.833)	Acc@5 64.062 (64.247)
Epoch: [6][140/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 3.1127 (3.1534)	Acc@1 34.375 (30.790)	Acc@5 67.188 (64.123)
Epoch: [6][150/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.2956 (3.1490)	Acc@1 21.875 (30.722)	Acc@5 62.500 (64.218)
Epoch: [6][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8159 (3.1459)	Acc@1 33.594 (30.770)	Acc@5 71.875 (64.359)
Epoch: [6][170/391]	Time 0.011 (0.013)	Data 0.001 (0.002)	Loss 2.8827 (3.1415)	Acc@1 33.594 (30.880)	Acc@5 71.094 (64.519)
Epoch: [6][180/391]	Time 0.011 (0.013)	Data 0.003 (0.002)	Loss 3.1659 (3.1404)	Acc@1 30.469 (30.935)	Acc@5 66.406 (64.555)
Epoch: [6][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.2303 (3.1394)	Acc@1 27.344 (30.894)	Acc@5 62.500 (64.582)
Epoch: [6][200/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.9758 (3.1378)	Acc@1 35.938 (30.955)	Acc@5 68.750 (64.614)
Epoch: [6][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.1372 (3.1384)	Acc@1 31.250 (30.987)	Acc@5 60.938 (64.596)
Epoch: [6][220/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 3.3792 (3.1388)	Acc@1 28.125 (30.911)	Acc@5 61.719 (64.678)
Epoch: [6][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.0057 (3.1376)	Acc@1 32.812 (30.959)	Acc@5 68.750 (64.678)
Epoch: [6][240/391]	Time 0.011 (0.013)	Data 0.004 (0.002)	Loss 2.9747 (3.1336)	Acc@1 34.375 (31.114)	Acc@5 64.844 (64.779)
Epoch: [6][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.3380 (3.1341)	Acc@1 28.125 (31.141)	Acc@5 57.031 (64.716)
Epoch: [6][260/391]	Time 0.012 (0.013)	Data 0.002 (0.002)	Loss 3.0653 (3.1322)	Acc@1 36.719 (31.247)	Acc@5 62.500 (64.688)
Epoch: [6][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.2610 (3.1348)	Acc@1 25.000 (31.161)	Acc@5 64.844 (64.653)
Epoch: [6][280/391]	Time 0.012 (0.013)	Data 0.001 (0.002)	Loss 3.1793 (3.1340)	Acc@1 30.469 (31.169)	Acc@5 61.719 (64.660)
Epoch: [6][290/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.9595 (3.1353)	Acc@1 38.281 (31.212)	Acc@5 64.062 (64.610)
Epoch: [6][300/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 3.2361 (3.1362)	Acc@1 29.688 (31.219)	Acc@5 64.062 (64.597)
Epoch: [6][310/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.9856 (3.1334)	Acc@1 32.812 (31.275)	Acc@5 67.969 (64.658)
Epoch: [6][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9024 (3.1320)	Acc@1 36.719 (31.308)	Acc@5 71.875 (64.737)
Epoch: [6][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9952 (3.1304)	Acc@1 29.688 (31.328)	Acc@5 64.844 (64.756)
Epoch: [6][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8943 (3.1250)	Acc@1 37.500 (31.465)	Acc@5 65.625 (64.887)
Epoch: [6][350/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 3.2414 (3.1222)	Acc@1 25.781 (31.499)	Acc@5 60.156 (64.944)
Epoch: [6][360/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 3.0731 (3.1220)	Acc@1 31.250 (31.477)	Acc@5 67.188 (64.950)
Epoch: [6][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.0004 (3.1205)	Acc@1 37.500 (31.492)	Acc@5 65.625 (65.019)
Epoch: [6][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7992 (3.1173)	Acc@1 34.375 (31.527)	Acc@5 72.656 (65.075)
Epoch: [6][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 3.1312 (3.1184)	Acc@1 23.750 (31.476)	Acc@5 68.750 (65.082)
num momentum params: 26
[0.1, 3.118363669128418, 2.820046453475952, 31.476, 29.44, tensor(0.1627, device='cuda:0', grad_fn=<DivBackward0>), 5.219395637512207, 0.3700411319732666]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [7 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [7][0/391]	Time 0.026 (0.026)	Data 0.144 (0.144)	Loss 2.9569 (2.9569)	Acc@1 30.469 (30.469)	Acc@5 64.844 (64.844)
Epoch: [7][10/391]	Time 0.014 (0.014)	Data 0.001 (0.014)	Loss 3.0989 (3.0891)	Acc@1 31.250 (30.043)	Acc@5 64.062 (65.341)
Epoch: [7][20/391]	Time 0.013 (0.014)	Data 0.001 (0.008)	Loss 2.9641 (3.0649)	Acc@1 40.625 (32.143)	Acc@5 67.188 (65.848)
Epoch: [7][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.9737 (3.0452)	Acc@1 36.719 (32.460)	Acc@5 64.844 (66.583)
Epoch: [7][40/391]	Time 0.013 (0.013)	Data 0.001 (0.005)	Loss 3.3911 (3.0398)	Acc@1 28.125 (32.584)	Acc@5 63.281 (66.883)
Epoch: [7][50/391]	Time 0.013 (0.013)	Data 0.001 (0.004)	Loss 3.0894 (3.0379)	Acc@1 33.594 (32.537)	Acc@5 64.844 (67.050)
Epoch: [7][60/391]	Time 0.013 (0.013)	Data 0.001 (0.004)	Loss 3.0096 (3.0277)	Acc@1 34.375 (33.017)	Acc@5 71.094 (67.405)
Epoch: [7][70/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 3.0451 (3.0183)	Acc@1 32.031 (33.297)	Acc@5 71.094 (67.672)
Epoch: [7][80/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 3.1068 (3.0240)	Acc@1 35.156 (33.189)	Acc@5 65.625 (67.708)
Epoch: [7][90/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.7352 (3.0172)	Acc@1 37.500 (33.388)	Acc@5 75.000 (67.874)
Epoch: [7][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 3.0116 (3.0103)	Acc@1 35.156 (33.524)	Acc@5 68.750 (68.093)
Epoch: [7][110/391]	Time 0.014 (0.013)	Data 0.001 (0.003)	Loss 2.9167 (3.0014)	Acc@1 36.719 (33.713)	Acc@5 71.094 (68.243)
Epoch: [7][120/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 3.0341 (3.0058)	Acc@1 35.156 (33.600)	Acc@5 68.750 (68.182)
Epoch: [7][130/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.1854 (3.0139)	Acc@1 26.562 (33.349)	Acc@5 63.281 (68.016)
Epoch: [7][140/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.0227 (3.0123)	Acc@1 33.594 (33.422)	Acc@5 68.750 (68.068)
Epoch: [7][150/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8638 (3.0073)	Acc@1 39.062 (33.754)	Acc@5 70.312 (68.067)
Epoch: [7][160/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.9834 (3.0116)	Acc@1 35.938 (33.759)	Acc@5 67.188 (67.983)
Epoch: [7][170/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8471 (3.0104)	Acc@1 38.281 (33.776)	Acc@5 68.750 (68.005)
Epoch: [7][180/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 3.0408 (3.0130)	Acc@1 32.812 (33.693)	Acc@5 67.188 (67.947)
Epoch: [7][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.0970 (3.0138)	Acc@1 34.375 (33.716)	Acc@5 67.188 (67.928)
Epoch: [7][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.0884 (3.0144)	Acc@1 38.281 (33.741)	Acc@5 56.250 (67.891)
Epoch: [7][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.0533 (3.0119)	Acc@1 35.938 (33.820)	Acc@5 67.188 (67.898)
Epoch: [7][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9079 (3.0147)	Acc@1 39.062 (33.792)	Acc@5 69.531 (67.933)
Epoch: [7][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.0490 (3.0189)	Acc@1 33.594 (33.712)	Acc@5 69.531 (67.813)
Epoch: [7][240/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 3.0874 (3.0181)	Acc@1 36.719 (33.723)	Acc@5 64.844 (67.852)
Epoch: [7][250/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 3.0035 (3.0171)	Acc@1 35.156 (33.812)	Acc@5 67.188 (67.906)
Epoch: [7][260/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 3.1666 (3.0123)	Acc@1 30.469 (33.941)	Acc@5 65.625 (68.077)
Epoch: [7][270/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 3.0343 (3.0093)	Acc@1 34.375 (34.052)	Acc@5 69.531 (68.156)
Epoch: [7][280/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 3.0057 (3.0095)	Acc@1 31.250 (34.058)	Acc@5 65.625 (68.138)
Epoch: [7][290/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 3.1101 (3.0132)	Acc@1 31.250 (34.066)	Acc@5 62.500 (68.079)
Epoch: [7][300/391]	Time 0.010 (0.013)	Data 0.003 (0.002)	Loss 3.0802 (3.0128)	Acc@1 30.469 (34.160)	Acc@5 64.844 (68.093)
Epoch: [7][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9766 (3.0121)	Acc@1 34.375 (34.217)	Acc@5 67.188 (68.172)
Epoch: [7][320/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.7797 (3.0112)	Acc@1 37.500 (34.248)	Acc@5 75.000 (68.185)
Epoch: [7][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.2140 (3.0127)	Acc@1 35.156 (34.264)	Acc@5 68.750 (68.162)
Epoch: [7][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.0738 (3.0107)	Acc@1 38.281 (34.373)	Acc@5 66.406 (68.159)
Epoch: [7][350/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.9860 (3.0091)	Acc@1 32.031 (34.437)	Acc@5 71.094 (68.198)
Epoch: [7][360/391]	Time 0.014 (0.013)	Data 0.000 (0.002)	Loss 3.1373 (3.0100)	Acc@1 35.156 (34.416)	Acc@5 66.406 (68.177)
Epoch: [7][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8304 (3.0084)	Acc@1 42.188 (34.428)	Acc@5 70.312 (68.228)
Epoch: [7][380/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.9594 (3.0082)	Acc@1 31.250 (34.455)	Acc@5 71.094 (68.254)
Epoch: [7][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 3.2244 (3.0105)	Acc@1 35.000 (34.424)	Acc@5 65.000 (68.248)
num momentum params: 26
[0.1, 3.0104954457855224, 2.830361683368683, 34.424, 29.65, tensor(0.1794, device='cuda:0', grad_fn=<DivBackward0>), 5.249777793884277, 0.38000988960266113]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [8 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [8][0/391]	Time 0.032 (0.032)	Data 0.140 (0.140)	Loss 2.6636 (2.6636)	Acc@1 46.875 (46.875)	Acc@5 78.125 (78.125)
Epoch: [8][10/391]	Time 0.013 (0.015)	Data 0.002 (0.014)	Loss 2.8142 (2.8677)	Acc@1 38.281 (36.932)	Acc@5 72.656 (72.301)
Epoch: [8][20/391]	Time 0.013 (0.014)	Data 0.002 (0.008)	Loss 2.7690 (2.8651)	Acc@1 36.719 (37.463)	Acc@5 71.094 (72.247)
Epoch: [8][30/391]	Time 0.013 (0.014)	Data 0.002 (0.006)	Loss 2.8627 (2.8865)	Acc@1 43.750 (37.828)	Acc@5 69.531 (71.749)
Epoch: [8][40/391]	Time 0.015 (0.014)	Data 0.001 (0.005)	Loss 2.9713 (2.8906)	Acc@1 33.594 (37.710)	Acc@5 75.000 (71.799)
Epoch: [8][50/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 3.1646 (2.8999)	Acc@1 32.031 (37.469)	Acc@5 67.969 (71.584)
Epoch: [8][60/391]	Time 0.011 (0.014)	Data 0.004 (0.004)	Loss 2.8020 (2.8971)	Acc@1 42.969 (37.590)	Acc@5 71.875 (71.440)
Epoch: [8][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 3.1022 (2.9120)	Acc@1 32.031 (37.225)	Acc@5 67.188 (70.973)
Epoch: [8][80/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.5846 (2.9123)	Acc@1 42.188 (37.230)	Acc@5 77.344 (70.997)
Epoch: [8][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.7926 (2.9074)	Acc@1 39.844 (37.414)	Acc@5 72.656 (71.034)
Epoch: [8][100/391]	Time 0.011 (0.014)	Data 0.004 (0.003)	Loss 2.8838 (2.9112)	Acc@1 37.500 (37.214)	Acc@5 71.875 (71.063)
Epoch: [8][110/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.8189 (2.9076)	Acc@1 35.938 (37.317)	Acc@5 75.000 (71.059)
Epoch: [8][120/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.6067 (2.9036)	Acc@1 46.875 (37.448)	Acc@5 77.344 (71.113)
Epoch: [8][130/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.8701 (2.9032)	Acc@1 35.938 (37.506)	Acc@5 71.094 (71.094)
Epoch: [8][140/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.7252 (2.9022)	Acc@1 41.406 (37.478)	Acc@5 75.000 (71.110)
Epoch: [8][150/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.0830 (2.9069)	Acc@1 35.156 (37.433)	Acc@5 66.406 (70.985)
Epoch: [8][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7165 (2.9132)	Acc@1 42.969 (37.374)	Acc@5 75.781 (70.822)
Epoch: [8][170/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9041 (2.9165)	Acc@1 34.375 (37.262)	Acc@5 71.094 (70.820)
Epoch: [8][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.0133 (2.9211)	Acc@1 35.938 (37.176)	Acc@5 72.656 (70.779)
Epoch: [8][190/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.9105 (2.9186)	Acc@1 38.281 (37.287)	Acc@5 71.875 (70.816)
Epoch: [8][200/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.7531 (2.9158)	Acc@1 45.312 (37.294)	Acc@5 70.312 (70.946)
Epoch: [8][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8511 (2.9165)	Acc@1 36.719 (37.233)	Acc@5 71.094 (70.905)
Epoch: [8][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.0453 (2.9154)	Acc@1 35.938 (37.207)	Acc@5 71.094 (70.998)
Epoch: [8][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.1688 (2.9149)	Acc@1 30.469 (37.199)	Acc@5 64.844 (71.029)
Epoch: [8][240/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 3.0858 (2.9122)	Acc@1 32.031 (37.296)	Acc@5 65.625 (71.061)
Epoch: [8][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9827 (2.9131)	Acc@1 39.062 (37.310)	Acc@5 68.750 (71.084)
Epoch: [8][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8398 (2.9161)	Acc@1 39.844 (37.267)	Acc@5 75.781 (71.049)
Epoch: [8][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9891 (2.9193)	Acc@1 37.500 (37.252)	Acc@5 70.312 (71.007)
Epoch: [8][280/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.9615 (2.9199)	Acc@1 32.812 (37.286)	Acc@5 68.750 (70.971)
Epoch: [8][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.1149 (2.9216)	Acc@1 39.844 (37.293)	Acc@5 69.531 (70.954)
Epoch: [8][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.0917 (2.9231)	Acc@1 34.375 (37.279)	Acc@5 68.750 (70.964)
Epoch: [8][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8078 (2.9250)	Acc@1 35.938 (37.236)	Acc@5 71.094 (70.898)
Epoch: [8][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8375 (2.9257)	Acc@1 39.844 (37.208)	Acc@5 71.094 (70.911)
Epoch: [8][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8079 (2.9255)	Acc@1 40.625 (37.245)	Acc@5 74.219 (70.929)
Epoch: [8][340/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.8141 (2.9253)	Acc@1 41.406 (37.273)	Acc@5 73.438 (70.972)
Epoch: [8][350/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.8406 (2.9219)	Acc@1 39.844 (37.335)	Acc@5 69.531 (71.038)
Epoch: [8][360/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.8018 (2.9221)	Acc@1 39.062 (37.366)	Acc@5 71.875 (71.003)
Epoch: [8][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9870 (2.9232)	Acc@1 34.375 (37.344)	Acc@5 71.875 (70.993)
Epoch: [8][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.0544 (2.9234)	Acc@1 36.719 (37.346)	Acc@5 67.969 (70.993)
Epoch: [8][390/391]	Time 0.017 (0.013)	Data 0.001 (0.002)	Loss 2.7202 (2.9228)	Acc@1 43.750 (37.364)	Acc@5 77.500 (71.018)
num momentum params: 26
[0.1, 2.922834775695801, 2.589255647659302, 37.364, 34.28, tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>), 5.229602336883545, 0.3804786205291748]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [9 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [9][0/391]	Time 0.030 (0.030)	Data 0.147 (0.147)	Loss 2.8112 (2.8112)	Acc@1 41.406 (41.406)	Acc@5 74.219 (74.219)
Epoch: [9][10/391]	Time 0.014 (0.015)	Data 0.001 (0.015)	Loss 2.9346 (2.8910)	Acc@1 42.188 (39.276)	Acc@5 70.312 (72.372)
Epoch: [9][20/391]	Time 0.013 (0.014)	Data 0.001 (0.008)	Loss 2.7616 (2.9377)	Acc@1 41.406 (38.170)	Acc@5 78.906 (71.094)
Epoch: [9][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.9730 (2.9283)	Acc@1 37.500 (38.080)	Acc@5 70.312 (71.396)
Epoch: [9][40/391]	Time 0.014 (0.014)	Data 0.001 (0.005)	Loss 2.7848 (2.9116)	Acc@1 42.188 (38.262)	Acc@5 77.344 (71.646)
Epoch: [9][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.8997 (2.8936)	Acc@1 38.281 (38.680)	Acc@5 74.219 (71.936)
Epoch: [9][60/391]	Time 0.013 (0.013)	Data 0.001 (0.004)	Loss 2.9817 (2.8946)	Acc@1 38.281 (38.742)	Acc@5 69.531 (71.939)
Epoch: [9][70/391]	Time 0.014 (0.013)	Data 0.001 (0.003)	Loss 2.8581 (2.8995)	Acc@1 39.844 (38.479)	Acc@5 72.656 (71.765)
Epoch: [9][80/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.9132 (2.8866)	Acc@1 39.844 (38.850)	Acc@5 74.219 (71.991)
Epoch: [9][90/391]	Time 0.013 (0.013)	Data 0.003 (0.003)	Loss 2.9351 (2.8771)	Acc@1 39.844 (39.191)	Acc@5 68.750 (72.158)
Epoch: [9][100/391]	Time 0.014 (0.013)	Data 0.001 (0.003)	Loss 2.8244 (2.8644)	Acc@1 43.750 (39.558)	Acc@5 72.656 (72.393)
Epoch: [9][110/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.8398 (2.8660)	Acc@1 41.406 (39.520)	Acc@5 69.531 (72.431)
Epoch: [9][120/391]	Time 0.013 (0.013)	Data 0.002 (0.003)	Loss 3.0968 (2.8744)	Acc@1 36.719 (39.353)	Acc@5 63.281 (72.346)
Epoch: [9][130/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.8128 (2.8719)	Acc@1 37.500 (39.396)	Acc@5 73.438 (72.400)
Epoch: [9][140/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5728 (2.8699)	Acc@1 49.219 (39.500)	Acc@5 78.125 (72.540)
Epoch: [9][150/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8096 (2.8644)	Acc@1 46.875 (39.564)	Acc@5 76.562 (72.698)
Epoch: [9][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9854 (2.8670)	Acc@1 39.062 (39.490)	Acc@5 69.531 (72.685)
Epoch: [9][170/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9400 (2.8663)	Acc@1 35.156 (39.469)	Acc@5 75.000 (72.789)
Epoch: [9][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.1905 (2.8713)	Acc@1 33.594 (39.429)	Acc@5 64.844 (72.652)
Epoch: [9][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7885 (2.8676)	Acc@1 36.719 (39.508)	Acc@5 73.438 (72.746)
Epoch: [9][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8492 (2.8671)	Acc@1 38.281 (39.475)	Acc@5 76.562 (72.773)
Epoch: [9][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8964 (2.8695)	Acc@1 39.844 (39.374)	Acc@5 72.656 (72.697)
Epoch: [9][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7079 (2.8686)	Acc@1 49.219 (39.490)	Acc@5 73.438 (72.699)
Epoch: [9][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8073 (2.8665)	Acc@1 41.406 (39.583)	Acc@5 69.531 (72.697)
Epoch: [9][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8855 (2.8642)	Acc@1 36.719 (39.620)	Acc@5 70.312 (72.698)
Epoch: [9][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8123 (2.8635)	Acc@1 42.188 (39.635)	Acc@5 70.312 (72.715)
Epoch: [9][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.0027 (2.8642)	Acc@1 39.062 (39.673)	Acc@5 69.531 (72.662)
Epoch: [9][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.1278 (2.8629)	Acc@1 37.500 (39.760)	Acc@5 65.625 (72.659)
Epoch: [9][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7835 (2.8638)	Acc@1 39.062 (39.791)	Acc@5 75.000 (72.590)
Epoch: [9][290/391]	Time 0.011 (0.013)	Data 0.002 (0.002)	Loss 2.9956 (2.8626)	Acc@1 37.500 (39.798)	Acc@5 70.312 (72.600)
Epoch: [9][300/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5941 (2.8627)	Acc@1 46.875 (39.792)	Acc@5 77.344 (72.656)
Epoch: [9][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8464 (2.8614)	Acc@1 36.719 (39.756)	Acc@5 72.656 (72.689)
Epoch: [9][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8428 (2.8622)	Acc@1 39.844 (39.737)	Acc@5 71.875 (72.698)
Epoch: [9][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7236 (2.8625)	Acc@1 45.312 (39.726)	Acc@5 76.562 (72.703)
Epoch: [9][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8135 (2.8616)	Acc@1 42.969 (39.718)	Acc@5 74.219 (72.741)
Epoch: [9][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.0057 (2.8642)	Acc@1 37.500 (39.652)	Acc@5 71.094 (72.705)
Epoch: [9][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5888 (2.8631)	Acc@1 50.000 (39.710)	Acc@5 76.562 (72.723)
Epoch: [9][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7517 (2.8625)	Acc@1 38.281 (39.726)	Acc@5 78.125 (72.745)
Epoch: [9][380/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.9415 (2.8630)	Acc@1 39.062 (39.690)	Acc@5 71.094 (72.757)
Epoch: [9][390/391]	Time 0.018 (0.013)	Data 0.000 (0.002)	Loss 2.5420 (2.8640)	Acc@1 41.250 (39.652)	Acc@5 83.750 (72.748)
num momentum params: 26
[0.1, 2.86396608543396, 2.65763751745224, 39.652, 33.23, tensor(0.2120, device='cuda:0', grad_fn=<DivBackward0>), 5.18234920501709, 0.37157130241394043]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [10 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [10][0/391]	Time 0.027 (0.027)	Data 0.142 (0.142)	Loss 2.5929 (2.5929)	Acc@1 43.750 (43.750)	Acc@5 77.344 (77.344)
Epoch: [10][10/391]	Time 0.013 (0.015)	Data 0.001 (0.014)	Loss 2.7643 (2.7713)	Acc@1 40.625 (41.406)	Acc@5 75.781 (75.142)
Epoch: [10][20/391]	Time 0.013 (0.014)	Data 0.001 (0.008)	Loss 2.9401 (2.7838)	Acc@1 36.719 (41.778)	Acc@5 72.656 (75.112)
Epoch: [10][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.9333 (2.8000)	Acc@1 41.406 (41.457)	Acc@5 67.969 (74.420)
Epoch: [10][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.6024 (2.8068)	Acc@1 40.625 (41.139)	Acc@5 81.250 (74.143)
Epoch: [10][50/391]	Time 0.013 (0.013)	Data 0.001 (0.004)	Loss 2.9494 (2.7921)	Acc@1 40.625 (41.759)	Acc@5 72.656 (74.295)
Epoch: [10][60/391]	Time 0.013 (0.013)	Data 0.001 (0.004)	Loss 2.7771 (2.7833)	Acc@1 42.969 (41.983)	Acc@5 75.000 (74.616)
Epoch: [10][70/391]	Time 0.013 (0.013)	Data 0.002 (0.003)	Loss 2.6692 (2.7694)	Acc@1 42.188 (42.199)	Acc@5 75.000 (75.022)
Epoch: [10][80/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.7282 (2.7743)	Acc@1 42.969 (42.091)	Acc@5 75.000 (74.875)
Epoch: [10][90/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.7781 (2.7728)	Acc@1 38.281 (42.059)	Acc@5 78.906 (74.888)
Epoch: [10][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.9995 (2.7788)	Acc@1 37.500 (41.855)	Acc@5 68.750 (74.830)
Epoch: [10][110/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.8535 (2.7818)	Acc@1 42.969 (41.864)	Acc@5 73.438 (74.775)
Epoch: [10][120/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6534 (2.7764)	Acc@1 42.188 (42.020)	Acc@5 75.781 (74.910)
Epoch: [10][130/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5445 (2.7794)	Acc@1 46.875 (42.021)	Acc@5 80.469 (74.845)
Epoch: [10][140/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6143 (2.7803)	Acc@1 46.875 (42.043)	Acc@5 78.125 (74.778)
Epoch: [10][150/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8580 (2.7815)	Acc@1 41.406 (42.037)	Acc@5 72.656 (74.746)
Epoch: [10][160/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.8598 (2.7773)	Acc@1 35.156 (42.032)	Acc@5 75.000 (74.874)
Epoch: [10][170/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7237 (2.7803)	Acc@1 46.875 (42.037)	Acc@5 73.438 (74.767)
Epoch: [10][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7996 (2.7817)	Acc@1 45.312 (41.993)	Acc@5 74.219 (74.711)
Epoch: [10][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8229 (2.7833)	Acc@1 42.188 (41.873)	Acc@5 75.000 (74.726)
Epoch: [10][200/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.7139 (2.7857)	Acc@1 40.625 (41.849)	Acc@5 79.688 (74.674)
Epoch: [10][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6716 (2.7896)	Acc@1 43.750 (41.743)	Acc@5 75.000 (74.604)
Epoch: [10][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7759 (2.7947)	Acc@1 41.406 (41.689)	Acc@5 74.219 (74.413)
Epoch: [10][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9001 (2.7964)	Acc@1 45.312 (41.714)	Acc@5 69.531 (74.415)
Epoch: [10][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6951 (2.7975)	Acc@1 40.625 (41.766)	Acc@5 78.125 (74.384)
Epoch: [10][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8833 (2.7968)	Acc@1 40.625 (41.761)	Acc@5 73.438 (74.471)
Epoch: [10][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8084 (2.7949)	Acc@1 40.625 (41.849)	Acc@5 74.219 (74.506)
Epoch: [10][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7876 (2.7957)	Acc@1 44.531 (41.853)	Acc@5 75.781 (74.507)
Epoch: [10][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8231 (2.7974)	Acc@1 40.625 (41.798)	Acc@5 69.531 (74.505)
Epoch: [10][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.2344 (2.8011)	Acc@1 37.500 (41.763)	Acc@5 62.500 (74.428)
Epoch: [10][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6360 (2.8031)	Acc@1 43.750 (41.757)	Acc@5 78.906 (74.395)
Epoch: [10][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6638 (2.8023)	Acc@1 47.656 (41.776)	Acc@5 75.781 (74.380)
Epoch: [10][320/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.8498 (2.8017)	Acc@1 43.750 (41.786)	Acc@5 70.312 (74.343)
Epoch: [10][330/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.6644 (2.8027)	Acc@1 42.188 (41.744)	Acc@5 78.125 (74.344)
Epoch: [10][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.0785 (2.8025)	Acc@1 40.625 (41.743)	Acc@5 67.188 (74.352)
Epoch: [10][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7568 (2.8045)	Acc@1 46.094 (41.718)	Acc@5 72.656 (74.286)
Epoch: [10][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.1490 (2.8070)	Acc@1 34.375 (41.707)	Acc@5 65.625 (74.199)
Epoch: [10][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9227 (2.8072)	Acc@1 37.500 (41.707)	Acc@5 74.219 (74.223)
Epoch: [10][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7810 (2.8114)	Acc@1 41.406 (41.638)	Acc@5 74.219 (74.096)
Epoch: [10][390/391]	Time 0.016 (0.013)	Data 0.000 (0.002)	Loss 2.8160 (2.8120)	Acc@1 37.500 (41.640)	Acc@5 72.500 (74.066)
num momentum params: 26
[0.1, 2.811962377548218, 2.222915906906128, 41.64, 41.19, tensor(0.2260, device='cuda:0', grad_fn=<DivBackward0>), 5.195068359375, 0.3806605339050293]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [11 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [11][0/391]	Time 0.033 (0.033)	Data 0.142 (0.142)	Loss 2.6034 (2.6034)	Acc@1 52.344 (52.344)	Acc@5 79.688 (79.688)
Epoch: [11][10/391]	Time 0.013 (0.015)	Data 0.001 (0.014)	Loss 2.6987 (2.7194)	Acc@1 42.969 (45.241)	Acc@5 77.344 (76.776)
Epoch: [11][20/391]	Time 0.013 (0.014)	Data 0.001 (0.008)	Loss 2.6441 (2.7199)	Acc@1 49.219 (45.126)	Acc@5 75.781 (76.376)
Epoch: [11][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.6034 (2.7088)	Acc@1 45.312 (45.312)	Acc@5 76.562 (76.235)
Epoch: [11][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.7608 (2.7110)	Acc@1 42.188 (45.370)	Acc@5 78.906 (76.429)
Epoch: [11][50/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.9656 (2.7292)	Acc@1 37.500 (44.807)	Acc@5 71.875 (75.934)
Epoch: [11][60/391]	Time 0.014 (0.014)	Data 0.002 (0.004)	Loss 2.7610 (2.7299)	Acc@1 42.969 (44.454)	Acc@5 77.344 (76.140)
Epoch: [11][70/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.8976 (2.7450)	Acc@1 35.938 (44.113)	Acc@5 74.219 (75.913)
Epoch: [11][80/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.8253 (2.7448)	Acc@1 42.188 (44.039)	Acc@5 78.906 (76.061)
Epoch: [11][90/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.7813 (2.7392)	Acc@1 42.188 (44.171)	Acc@5 75.781 (76.202)
Epoch: [11][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.6076 (2.7404)	Acc@1 47.656 (44.106)	Acc@5 82.031 (76.300)
Epoch: [11][110/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.9129 (2.7434)	Acc@1 46.094 (44.017)	Acc@5 71.875 (76.189)
Epoch: [11][120/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.8857 (2.7459)	Acc@1 37.500 (43.995)	Acc@5 70.312 (76.149)
Epoch: [11][130/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.6118 (2.7433)	Acc@1 50.000 (44.179)	Acc@5 77.344 (76.121)
Epoch: [11][140/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8761 (2.7488)	Acc@1 44.531 (44.166)	Acc@5 75.781 (76.064)
Epoch: [11][150/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8248 (2.7464)	Acc@1 43.750 (44.273)	Acc@5 77.344 (76.066)
Epoch: [11][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8664 (2.7477)	Acc@1 40.625 (44.211)	Acc@5 76.562 (76.092)
Epoch: [11][170/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.9355 (2.7490)	Acc@1 39.844 (44.102)	Acc@5 69.531 (76.060)
Epoch: [11][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8589 (2.7496)	Acc@1 43.750 (44.100)	Acc@5 74.219 (76.083)
Epoch: [11][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9442 (2.7508)	Acc@1 42.188 (44.065)	Acc@5 68.750 (76.080)
Epoch: [11][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5176 (2.7474)	Acc@1 52.344 (44.049)	Acc@5 81.250 (76.131)
Epoch: [11][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6173 (2.7499)	Acc@1 52.344 (43.980)	Acc@5 77.344 (76.129)
Epoch: [11][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5424 (2.7551)	Acc@1 51.562 (43.934)	Acc@5 81.250 (76.068)
Epoch: [11][230/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.7816 (2.7535)	Acc@1 46.875 (43.983)	Acc@5 74.219 (76.079)
Epoch: [11][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7074 (2.7554)	Acc@1 45.312 (43.880)	Acc@5 76.562 (76.050)
Epoch: [11][250/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.9815 (2.7591)	Acc@1 35.156 (43.744)	Acc@5 71.094 (76.036)
Epoch: [11][260/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.7966 (2.7605)	Acc@1 45.312 (43.717)	Acc@5 76.562 (75.958)
Epoch: [11][270/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.9252 (2.7628)	Acc@1 43.750 (43.643)	Acc@5 70.312 (75.914)
Epoch: [11][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7234 (2.7615)	Acc@1 42.969 (43.642)	Acc@5 76.562 (75.912)
Epoch: [11][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6251 (2.7605)	Acc@1 44.531 (43.648)	Acc@5 77.344 (75.942)
Epoch: [11][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9295 (2.7613)	Acc@1 37.500 (43.633)	Acc@5 71.094 (75.916)
Epoch: [11][310/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.8387 (2.7656)	Acc@1 42.188 (43.587)	Acc@5 72.656 (75.781)
Epoch: [11][320/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.6954 (2.7655)	Acc@1 45.312 (43.526)	Acc@5 78.125 (75.810)
Epoch: [11][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8655 (2.7645)	Acc@1 39.844 (43.556)	Acc@5 74.219 (75.810)
Epoch: [11][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6675 (2.7639)	Acc@1 42.969 (43.553)	Acc@5 76.562 (75.786)
Epoch: [11][350/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.7253 (2.7633)	Acc@1 43.750 (43.605)	Acc@5 77.344 (75.797)
Epoch: [11][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7875 (2.7626)	Acc@1 39.062 (43.650)	Acc@5 72.656 (75.807)
Epoch: [11][370/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.9064 (2.7634)	Acc@1 39.062 (43.655)	Acc@5 73.438 (75.813)
Epoch: [11][380/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.7452 (2.7656)	Acc@1 42.969 (43.600)	Acc@5 73.438 (75.757)
Epoch: [11][390/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 3.0165 (2.7668)	Acc@1 38.750 (43.530)	Acc@5 75.000 (75.738)
num momentum params: 26
[0.1, 2.7668401725006104, 2.3167493557929992, 43.53, 39.88, tensor(0.2388, device='cuda:0', grad_fn=<DivBackward0>), 5.216071844100952, 0.3727288246154785]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [12 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [12][0/391]	Time 0.029 (0.029)	Data 0.139 (0.139)	Loss 2.9385 (2.9385)	Acc@1 37.500 (37.500)	Acc@5 71.094 (71.094)
Epoch: [12][10/391]	Time 0.013 (0.015)	Data 0.001 (0.014)	Loss 2.4671 (2.7513)	Acc@1 49.219 (42.898)	Acc@5 88.281 (77.060)
Epoch: [12][20/391]	Time 0.013 (0.014)	Data 0.001 (0.008)	Loss 2.5449 (2.7266)	Acc@1 43.750 (43.899)	Acc@5 80.469 (76.786)
Epoch: [12][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.6779 (2.6980)	Acc@1 42.969 (44.783)	Acc@5 78.125 (77.218)
Epoch: [12][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.7433 (2.6882)	Acc@1 48.438 (44.836)	Acc@5 78.125 (77.382)
Epoch: [12][50/391]	Time 0.013 (0.013)	Data 0.001 (0.004)	Loss 2.6960 (2.6929)	Acc@1 39.844 (44.868)	Acc@5 79.688 (77.405)
Epoch: [12][60/391]	Time 0.013 (0.013)	Data 0.001 (0.004)	Loss 2.6459 (2.6994)	Acc@1 45.312 (44.800)	Acc@5 81.250 (77.164)
Epoch: [12][70/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.8339 (2.7096)	Acc@1 41.406 (44.663)	Acc@5 75.000 (77.069)
Epoch: [12][80/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.8648 (2.7210)	Acc@1 39.844 (44.242)	Acc@5 71.875 (76.698)
Epoch: [12][90/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.7824 (2.7251)	Acc@1 43.750 (44.214)	Acc@5 76.562 (76.528)
Epoch: [12][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.7375 (2.7311)	Acc@1 46.094 (44.191)	Acc@5 76.562 (76.501)
Epoch: [12][110/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.7525 (2.7337)	Acc@1 42.188 (44.053)	Acc@5 78.125 (76.640)
Epoch: [12][120/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6340 (2.7312)	Acc@1 51.562 (44.073)	Acc@5 79.688 (76.724)
Epoch: [12][130/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5058 (2.7341)	Acc@1 45.312 (43.893)	Acc@5 82.031 (76.634)
Epoch: [12][140/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8570 (2.7322)	Acc@1 41.406 (44.027)	Acc@5 71.875 (76.557)
Epoch: [12][150/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8824 (2.7361)	Acc@1 42.969 (44.091)	Acc@5 70.312 (76.397)
Epoch: [12][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5668 (2.7357)	Acc@1 48.438 (44.051)	Acc@5 77.344 (76.388)
Epoch: [12][170/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6894 (2.7345)	Acc@1 42.969 (44.079)	Acc@5 76.562 (76.467)
Epoch: [12][180/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.5337 (2.7325)	Acc@1 46.875 (44.147)	Acc@5 85.938 (76.476)
Epoch: [12][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5365 (2.7309)	Acc@1 50.000 (44.184)	Acc@5 82.812 (76.505)
Epoch: [12][200/391]	Time 0.021 (0.013)	Data 0.002 (0.002)	Loss 2.7380 (2.7325)	Acc@1 44.531 (44.150)	Acc@5 76.562 (76.481)
Epoch: [12][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7363 (2.7316)	Acc@1 47.656 (44.209)	Acc@5 75.781 (76.474)
Epoch: [12][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7871 (2.7312)	Acc@1 38.281 (44.217)	Acc@5 76.562 (76.456)
Epoch: [12][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9332 (2.7340)	Acc@1 41.406 (44.183)	Acc@5 74.219 (76.407)
Epoch: [12][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5743 (2.7337)	Acc@1 46.094 (44.210)	Acc@5 78.125 (76.452)
Epoch: [12][250/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.9165 (2.7356)	Acc@1 36.719 (44.189)	Acc@5 78.906 (76.432)
Epoch: [12][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6816 (2.7368)	Acc@1 47.656 (44.205)	Acc@5 78.125 (76.422)
Epoch: [12][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7212 (2.7392)	Acc@1 46.875 (44.220)	Acc@5 76.562 (76.395)
Epoch: [12][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6986 (2.7397)	Acc@1 43.750 (44.284)	Acc@5 80.469 (76.390)
Epoch: [12][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8102 (2.7427)	Acc@1 50.000 (44.268)	Acc@5 71.875 (76.326)
Epoch: [12][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6595 (2.7411)	Acc@1 50.781 (44.300)	Acc@5 76.562 (76.368)
Epoch: [12][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5936 (2.7410)	Acc@1 42.969 (44.313)	Acc@5 78.906 (76.351)
Epoch: [12][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6658 (2.7414)	Acc@1 49.219 (44.341)	Acc@5 77.344 (76.365)
Epoch: [12][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6960 (2.7418)	Acc@1 43.750 (44.340)	Acc@5 78.906 (76.407)
Epoch: [12][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8293 (2.7430)	Acc@1 38.281 (44.279)	Acc@5 77.344 (76.404)
Epoch: [12][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6917 (2.7429)	Acc@1 46.094 (44.344)	Acc@5 77.344 (76.382)
Epoch: [12][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6752 (2.7420)	Acc@1 51.562 (44.397)	Acc@5 80.469 (76.420)
Epoch: [12][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8990 (2.7437)	Acc@1 41.406 (44.321)	Acc@5 74.219 (76.377)
Epoch: [12][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6705 (2.7426)	Acc@1 47.656 (44.380)	Acc@5 76.562 (76.411)
Epoch: [12][390/391]	Time 0.017 (0.013)	Data 0.001 (0.002)	Loss 2.6604 (2.7419)	Acc@1 43.750 (44.386)	Acc@5 76.250 (76.390)
num momentum params: 26
[0.1, 2.741883367156982, 2.438623287677765, 44.386, 37.46, tensor(0.2480, device='cuda:0', grad_fn=<DivBackward0>), 5.174015045166016, 0.37670302391052246]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [13 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [13][0/391]	Time 0.032 (0.032)	Data 0.130 (0.130)	Loss 2.9100 (2.9100)	Acc@1 35.938 (35.938)	Acc@5 72.656 (72.656)
Epoch: [13][10/391]	Time 0.014 (0.015)	Data 0.001 (0.013)	Loss 2.6486 (2.6769)	Acc@1 47.656 (45.028)	Acc@5 79.688 (77.273)
Epoch: [13][20/391]	Time 0.013 (0.014)	Data 0.001 (0.008)	Loss 2.7094 (2.6668)	Acc@1 46.094 (45.350)	Acc@5 72.656 (77.641)
Epoch: [13][30/391]	Time 0.014 (0.014)	Data 0.001 (0.006)	Loss 2.7435 (2.6786)	Acc@1 43.750 (45.665)	Acc@5 77.344 (77.797)
Epoch: [13][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.6160 (2.6783)	Acc@1 46.875 (45.636)	Acc@5 75.000 (77.782)
Epoch: [13][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.8386 (2.6754)	Acc@1 45.312 (45.726)	Acc@5 72.656 (77.880)
Epoch: [13][60/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6163 (2.6858)	Acc@1 41.406 (45.581)	Acc@5 83.594 (77.894)
Epoch: [13][70/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.7103 (2.6957)	Acc@1 45.312 (45.279)	Acc@5 79.688 (77.850)
Epoch: [13][80/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.9556 (2.7137)	Acc@1 38.281 (44.821)	Acc@5 75.000 (77.595)
Epoch: [13][90/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.5838 (2.7022)	Acc@1 50.781 (45.064)	Acc@5 78.125 (77.687)
Epoch: [13][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.7867 (2.7045)	Acc@1 48.438 (45.003)	Acc@5 72.656 (77.661)
Epoch: [13][110/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.6792 (2.7052)	Acc@1 46.875 (44.975)	Acc@5 77.344 (77.646)
Epoch: [13][120/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9836 (2.7027)	Acc@1 36.719 (45.106)	Acc@5 69.531 (77.615)
Epoch: [13][130/391]	Time 0.012 (0.013)	Data 0.002 (0.002)	Loss 2.6239 (2.6994)	Acc@1 47.656 (45.241)	Acc@5 81.250 (77.678)
Epoch: [13][140/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.6172 (2.6979)	Acc@1 46.875 (45.301)	Acc@5 75.781 (77.671)
Epoch: [13][150/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9393 (2.7018)	Acc@1 40.625 (45.318)	Acc@5 73.438 (77.483)
Epoch: [13][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7837 (2.7047)	Acc@1 44.531 (45.240)	Acc@5 76.562 (77.489)
Epoch: [13][170/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.7201 (2.7116)	Acc@1 41.406 (45.244)	Acc@5 81.250 (77.380)
Epoch: [13][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6816 (2.7086)	Acc@1 49.219 (45.347)	Acc@5 74.219 (77.413)
Epoch: [13][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7901 (2.7100)	Acc@1 40.625 (45.329)	Acc@5 81.250 (77.389)
Epoch: [13][200/391]	Time 0.012 (0.013)	Data 0.001 (0.002)	Loss 2.4255 (2.7106)	Acc@1 46.875 (45.309)	Acc@5 86.719 (77.402)
Epoch: [13][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9332 (2.7151)	Acc@1 39.844 (45.231)	Acc@5 75.000 (77.281)
Epoch: [13][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6428 (2.7117)	Acc@1 46.875 (45.422)	Acc@5 78.906 (77.312)
Epoch: [13][230/391]	Time 0.011 (0.013)	Data 0.004 (0.002)	Loss 2.5485 (2.7113)	Acc@1 48.438 (45.461)	Acc@5 84.375 (77.337)
Epoch: [13][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6606 (2.7130)	Acc@1 47.656 (45.429)	Acc@5 77.344 (77.318)
Epoch: [13][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7840 (2.7082)	Acc@1 46.094 (45.562)	Acc@5 73.438 (77.381)
Epoch: [13][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8388 (2.7088)	Acc@1 42.969 (45.549)	Acc@5 74.219 (77.410)
Epoch: [13][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6761 (2.7086)	Acc@1 45.312 (45.578)	Acc@5 75.781 (77.407)
Epoch: [13][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6632 (2.7101)	Acc@1 41.406 (45.529)	Acc@5 82.812 (77.430)
Epoch: [13][290/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.8326 (2.7131)	Acc@1 43.750 (45.495)	Acc@5 73.438 (77.349)
Epoch: [13][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6359 (2.7124)	Acc@1 46.875 (45.479)	Acc@5 79.688 (77.409)
Epoch: [13][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7599 (2.7107)	Acc@1 39.844 (45.483)	Acc@5 75.781 (77.469)
Epoch: [13][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6821 (2.7103)	Acc@1 44.531 (45.485)	Acc@5 78.906 (77.473)
Epoch: [13][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5960 (2.7110)	Acc@1 53.125 (45.501)	Acc@5 82.812 (77.478)
Epoch: [13][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.0311 (2.7131)	Acc@1 40.625 (45.475)	Acc@5 71.875 (77.467)
Epoch: [13][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7864 (2.7128)	Acc@1 42.188 (45.475)	Acc@5 78.125 (77.513)
Epoch: [13][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5219 (2.7109)	Acc@1 46.875 (45.518)	Acc@5 82.031 (77.554)
Epoch: [13][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7821 (2.7099)	Acc@1 46.094 (45.544)	Acc@5 72.656 (77.584)
Epoch: [13][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.0486 (2.7101)	Acc@1 46.094 (45.557)	Acc@5 67.969 (77.551)
Epoch: [13][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.8630 (2.7144)	Acc@1 43.750 (45.460)	Acc@5 75.000 (77.480)
num momentum params: 26
[0.1, 2.7143881930541993, 2.8092575740814207, 45.46, 34.44, tensor(0.2568, device='cuda:0', grad_fn=<DivBackward0>), 5.203674554824829, 0.3723633289337158]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [14 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [14][0/391]	Time 0.030 (0.030)	Data 0.134 (0.134)	Loss 2.6344 (2.6344)	Acc@1 49.219 (49.219)	Acc@5 75.000 (75.000)
Epoch: [14][10/391]	Time 0.013 (0.015)	Data 0.001 (0.013)	Loss 2.5458 (2.6912)	Acc@1 46.094 (45.810)	Acc@5 79.688 (77.202)
Epoch: [14][20/391]	Time 0.013 (0.014)	Data 0.001 (0.008)	Loss 2.6295 (2.6915)	Acc@1 52.344 (46.577)	Acc@5 78.125 (77.121)
Epoch: [14][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.6036 (2.6655)	Acc@1 46.875 (46.598)	Acc@5 79.688 (78.024)
Epoch: [14][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.9700 (2.6665)	Acc@1 38.281 (46.780)	Acc@5 75.000 (78.239)
Epoch: [14][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.7713 (2.6695)	Acc@1 44.531 (46.645)	Acc@5 77.344 (78.217)
Epoch: [14][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.5784 (2.6624)	Acc@1 46.094 (46.747)	Acc@5 83.594 (78.573)
Epoch: [14][70/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 3.1085 (2.6659)	Acc@1 38.281 (46.622)	Acc@5 71.094 (78.543)
Epoch: [14][80/391]	Time 0.014 (0.013)	Data 0.001 (0.003)	Loss 2.7086 (2.6754)	Acc@1 44.531 (46.393)	Acc@5 78.125 (78.260)
Epoch: [14][90/391]	Time 0.014 (0.013)	Data 0.001 (0.003)	Loss 2.4610 (2.6798)	Acc@1 47.656 (46.231)	Acc@5 82.812 (78.108)
Epoch: [14][100/391]	Time 0.014 (0.013)	Data 0.001 (0.003)	Loss 2.8107 (2.6783)	Acc@1 43.750 (46.303)	Acc@5 75.000 (78.125)
Epoch: [14][110/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.7346 (2.6713)	Acc@1 48.438 (46.551)	Acc@5 75.781 (78.308)
Epoch: [14][120/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6928 (2.6711)	Acc@1 46.094 (46.475)	Acc@5 76.562 (78.461)
Epoch: [14][130/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5482 (2.6733)	Acc@1 50.000 (46.362)	Acc@5 76.562 (78.447)
Epoch: [14][140/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8045 (2.6806)	Acc@1 43.750 (46.310)	Acc@5 75.781 (78.286)
Epoch: [14][150/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6488 (2.6846)	Acc@1 45.312 (46.213)	Acc@5 80.469 (78.291)
Epoch: [14][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5796 (2.6875)	Acc@1 45.312 (46.137)	Acc@5 80.469 (78.256)
Epoch: [14][170/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8138 (2.6905)	Acc@1 44.531 (46.194)	Acc@5 76.562 (78.162)
Epoch: [14][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5142 (2.6881)	Acc@1 50.000 (46.292)	Acc@5 83.594 (78.168)
Epoch: [14][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4908 (2.6843)	Acc@1 48.438 (46.417)	Acc@5 82.812 (78.231)
Epoch: [14][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6010 (2.6847)	Acc@1 54.688 (46.389)	Acc@5 78.906 (78.238)
Epoch: [14][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7632 (2.6881)	Acc@1 44.531 (46.275)	Acc@5 75.781 (78.225)
Epoch: [14][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6167 (2.6854)	Acc@1 50.000 (46.394)	Acc@5 74.219 (78.277)
Epoch: [14][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6477 (2.6855)	Acc@1 48.438 (46.449)	Acc@5 77.344 (78.281)
Epoch: [14][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6992 (2.6867)	Acc@1 46.094 (46.431)	Acc@5 78.906 (78.242)
Epoch: [14][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6996 (2.6867)	Acc@1 43.750 (46.495)	Acc@5 78.125 (78.256)
Epoch: [14][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5535 (2.6873)	Acc@1 48.438 (46.468)	Acc@5 82.031 (78.278)
Epoch: [14][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9900 (2.6877)	Acc@1 36.719 (46.477)	Acc@5 71.094 (78.278)
Epoch: [14][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9550 (2.6909)	Acc@1 42.969 (46.436)	Acc@5 73.438 (78.203)
Epoch: [14][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4624 (2.6910)	Acc@1 59.375 (46.470)	Acc@5 81.250 (78.187)
Epoch: [14][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4623 (2.6898)	Acc@1 52.344 (46.527)	Acc@5 83.594 (78.211)
Epoch: [14][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8731 (2.6897)	Acc@1 39.844 (46.518)	Acc@5 73.438 (78.205)
Epoch: [14][320/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5990 (2.6873)	Acc@1 49.219 (46.549)	Acc@5 76.562 (78.261)
Epoch: [14][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8435 (2.6886)	Acc@1 38.281 (46.467)	Acc@5 80.469 (78.248)
Epoch: [14][340/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.7874 (2.6903)	Acc@1 43.750 (46.419)	Acc@5 75.781 (78.198)
Epoch: [14][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4473 (2.6916)	Acc@1 50.781 (46.368)	Acc@5 81.250 (78.181)
Epoch: [14][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2344 (2.6900)	Acc@1 57.812 (46.423)	Acc@5 84.375 (78.181)
Epoch: [14][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7342 (2.6892)	Acc@1 46.875 (46.477)	Acc@5 76.562 (78.163)
Epoch: [14][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8147 (2.6877)	Acc@1 44.531 (46.526)	Acc@5 73.438 (78.162)
Epoch: [14][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.8982 (2.6880)	Acc@1 47.500 (46.492)	Acc@5 72.500 (78.156)
num momentum params: 26
[0.1, 2.6880412547302246, 2.5376097440719603, 46.492, 37.74, tensor(0.2645, device='cuda:0', grad_fn=<DivBackward0>), 5.179262638092041, 0.3717834949493408]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [15 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [15][0/391]	Time 0.032 (0.032)	Data 0.131 (0.131)	Loss 2.5625 (2.5625)	Acc@1 48.438 (48.438)	Acc@5 81.250 (81.250)
Epoch: [15][10/391]	Time 0.013 (0.015)	Data 0.001 (0.014)	Loss 2.5609 (2.6128)	Acc@1 51.562 (48.935)	Acc@5 84.375 (80.398)
Epoch: [15][20/391]	Time 0.014 (0.014)	Data 0.001 (0.008)	Loss 2.6894 (2.6526)	Acc@1 49.219 (47.954)	Acc@5 75.781 (79.688)
Epoch: [15][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.6939 (2.6639)	Acc@1 41.406 (47.329)	Acc@5 79.688 (79.612)
Epoch: [15][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.5931 (2.6521)	Acc@1 46.875 (47.104)	Acc@5 78.125 (79.859)
Epoch: [15][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.8315 (2.6468)	Acc@1 39.844 (47.335)	Acc@5 76.562 (79.642)
Epoch: [15][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4833 (2.6480)	Acc@1 50.000 (47.464)	Acc@5 81.250 (79.598)
Epoch: [15][70/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6659 (2.6446)	Acc@1 45.312 (47.304)	Acc@5 78.906 (79.555)
Epoch: [15][80/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.9009 (2.6462)	Acc@1 46.094 (47.319)	Acc@5 75.000 (79.475)
Epoch: [15][90/391]	Time 0.010 (0.013)	Data 0.011 (0.003)	Loss 2.7343 (2.6567)	Acc@1 46.094 (47.047)	Acc@5 75.781 (79.361)
Epoch: [15][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.8503 (2.6695)	Acc@1 39.062 (46.697)	Acc@5 77.344 (79.007)
Epoch: [15][110/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.7413 (2.6659)	Acc@1 40.625 (46.706)	Acc@5 82.812 (79.153)
Epoch: [15][120/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.5731 (2.6669)	Acc@1 47.656 (46.733)	Acc@5 82.031 (79.061)
Epoch: [15][130/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7973 (2.6653)	Acc@1 47.656 (46.797)	Acc@5 78.125 (79.091)
Epoch: [15][140/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.6535 (2.6616)	Acc@1 53.906 (46.964)	Acc@5 80.469 (79.150)
Epoch: [15][150/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6092 (2.6631)	Acc@1 46.094 (46.891)	Acc@5 79.688 (79.030)
Epoch: [15][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9034 (2.6634)	Acc@1 44.531 (46.817)	Acc@5 78.125 (79.125)
Epoch: [15][170/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5664 (2.6578)	Acc@1 53.125 (47.035)	Acc@5 81.250 (79.203)
Epoch: [15][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7370 (2.6614)	Acc@1 46.094 (46.992)	Acc@5 79.688 (79.174)
Epoch: [15][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6884 (2.6632)	Acc@1 44.531 (46.969)	Acc@5 78.906 (79.111)
Epoch: [15][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7647 (2.6652)	Acc@1 46.094 (46.898)	Acc@5 77.344 (79.066)
Epoch: [15][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8078 (2.6668)	Acc@1 41.406 (46.901)	Acc@5 75.000 (79.017)
Epoch: [15][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9783 (2.6647)	Acc@1 42.188 (46.935)	Acc@5 71.875 (78.998)
Epoch: [15][230/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5539 (2.6641)	Acc@1 51.562 (46.922)	Acc@5 82.812 (78.984)
Epoch: [15][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9729 (2.6641)	Acc@1 42.188 (46.823)	Acc@5 69.531 (79.026)
Epoch: [15][250/391]	Time 0.021 (0.013)	Data 0.001 (0.002)	Loss 2.7132 (2.6641)	Acc@1 48.438 (46.859)	Acc@5 78.125 (79.015)
Epoch: [15][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7104 (2.6657)	Acc@1 52.344 (46.887)	Acc@5 78.125 (78.963)
Epoch: [15][270/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.8313 (2.6686)	Acc@1 47.656 (46.838)	Acc@5 73.438 (78.898)
Epoch: [15][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5939 (2.6707)	Acc@1 52.344 (46.828)	Acc@5 78.125 (78.853)
Epoch: [15][290/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.6878 (2.6670)	Acc@1 46.094 (46.902)	Acc@5 78.906 (78.914)
Epoch: [15][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6508 (2.6674)	Acc@1 49.219 (46.885)	Acc@5 77.344 (78.932)
Epoch: [15][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6277 (2.6698)	Acc@1 47.656 (46.860)	Acc@5 79.688 (78.851)
Epoch: [15][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6120 (2.6730)	Acc@1 40.625 (46.785)	Acc@5 80.469 (78.777)
Epoch: [15][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9088 (2.6749)	Acc@1 41.406 (46.788)	Acc@5 75.000 (78.708)
Epoch: [15][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6306 (2.6736)	Acc@1 49.219 (46.827)	Acc@5 79.688 (78.760)
Epoch: [15][350/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.7406 (2.6724)	Acc@1 46.094 (46.855)	Acc@5 78.125 (78.768)
Epoch: [15][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5202 (2.6733)	Acc@1 53.125 (46.817)	Acc@5 82.031 (78.781)
Epoch: [15][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7070 (2.6729)	Acc@1 47.656 (46.877)	Acc@5 76.562 (78.769)
Epoch: [15][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7666 (2.6736)	Acc@1 44.531 (46.879)	Acc@5 78.125 (78.763)
Epoch: [15][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.9144 (2.6740)	Acc@1 41.250 (46.860)	Acc@5 75.000 (78.746)
num momentum params: 26
[0.1, 2.674002202911377, 2.3908822548389437, 46.86, 39.54, tensor(0.2700, device='cuda:0', grad_fn=<DivBackward0>), 5.227114915847778, 0.37330079078674316]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [16 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [16][0/391]	Time 0.030 (0.030)	Data 0.144 (0.144)	Loss 2.4955 (2.4955)	Acc@1 53.125 (53.125)	Acc@5 84.375 (84.375)
Epoch: [16][10/391]	Time 0.013 (0.015)	Data 0.001 (0.014)	Loss 2.8205 (2.6576)	Acc@1 42.969 (46.875)	Acc@5 74.219 (79.119)
Epoch: [16][20/391]	Time 0.013 (0.014)	Data 0.001 (0.008)	Loss 2.4941 (2.5880)	Acc@1 48.438 (48.847)	Acc@5 79.688 (79.948)
Epoch: [16][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.5004 (2.5713)	Acc@1 51.562 (49.496)	Acc@5 83.594 (80.544)
Epoch: [16][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.6318 (2.5635)	Acc@1 48.438 (49.638)	Acc@5 76.562 (80.659)
Epoch: [16][50/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.6792 (2.5899)	Acc@1 50.781 (48.775)	Acc@5 81.250 (80.162)
Epoch: [16][60/391]	Time 0.013 (0.013)	Data 0.001 (0.004)	Loss 2.5089 (2.6112)	Acc@1 48.438 (48.348)	Acc@5 82.031 (79.688)
Epoch: [16][70/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.6707 (2.6148)	Acc@1 42.969 (48.305)	Acc@5 82.812 (79.643)
Epoch: [16][80/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.2492 (2.6168)	Acc@1 58.594 (48.312)	Acc@5 89.062 (79.794)
Epoch: [16][90/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.6667 (2.6328)	Acc@1 52.344 (48.120)	Acc@5 77.344 (79.662)
Epoch: [16][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.5400 (2.6395)	Acc@1 49.219 (48.020)	Acc@5 85.938 (79.618)
Epoch: [16][110/391]	Time 0.014 (0.013)	Data 0.001 (0.003)	Loss 2.4851 (2.6404)	Acc@1 50.000 (47.825)	Acc@5 84.375 (79.624)
Epoch: [16][120/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.4979 (2.6459)	Acc@1 53.125 (47.559)	Acc@5 81.250 (79.552)
Epoch: [16][130/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.5465 (2.6443)	Acc@1 50.000 (47.597)	Acc@5 79.688 (79.532)
Epoch: [16][140/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7181 (2.6448)	Acc@1 45.312 (47.595)	Acc@5 78.906 (79.510)
Epoch: [16][150/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2714 (2.6462)	Acc@1 59.375 (47.734)	Acc@5 85.938 (79.393)
Epoch: [16][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8303 (2.6482)	Acc@1 42.188 (47.787)	Acc@5 73.438 (79.319)
Epoch: [16][170/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7637 (2.6461)	Acc@1 46.875 (47.944)	Acc@5 73.438 (79.331)
Epoch: [16][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5724 (2.6497)	Acc@1 50.781 (47.868)	Acc@5 79.688 (79.286)
Epoch: [16][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6891 (2.6518)	Acc@1 43.750 (47.840)	Acc@5 79.688 (79.319)
Epoch: [16][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8730 (2.6588)	Acc@1 36.719 (47.680)	Acc@5 76.562 (79.182)
Epoch: [16][210/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5348 (2.6598)	Acc@1 52.344 (47.701)	Acc@5 84.375 (79.173)
Epoch: [16][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5064 (2.6584)	Acc@1 47.656 (47.688)	Acc@5 82.031 (79.228)
Epoch: [16][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7302 (2.6584)	Acc@1 41.406 (47.683)	Acc@5 78.125 (79.228)
Epoch: [16][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7403 (2.6590)	Acc@1 44.531 (47.640)	Acc@5 78.125 (79.237)
Epoch: [16][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7099 (2.6572)	Acc@1 47.656 (47.634)	Acc@5 75.781 (79.246)
Epoch: [16][260/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.7150 (2.6564)	Acc@1 45.312 (47.638)	Acc@5 75.000 (79.203)
Epoch: [16][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6291 (2.6550)	Acc@1 48.438 (47.694)	Acc@5 81.250 (79.267)
Epoch: [16][280/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5937 (2.6531)	Acc@1 50.781 (47.767)	Acc@5 80.469 (79.307)
Epoch: [16][290/391]	Time 0.012 (0.013)	Data 0.002 (0.002)	Loss 2.9480 (2.6522)	Acc@1 40.625 (47.774)	Acc@5 75.000 (79.333)
Epoch: [16][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4796 (2.6556)	Acc@1 53.125 (47.693)	Acc@5 81.250 (79.290)
Epoch: [16][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.0374 (2.6568)	Acc@1 37.500 (47.674)	Acc@5 74.219 (79.253)
Epoch: [16][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4587 (2.6536)	Acc@1 52.344 (47.756)	Acc@5 86.719 (79.288)
Epoch: [16][330/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.5335 (2.6554)	Acc@1 55.469 (47.748)	Acc@5 81.250 (79.244)
Epoch: [16][340/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.7495 (2.6539)	Acc@1 42.969 (47.814)	Acc@5 81.250 (79.248)
Epoch: [16][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6935 (2.6539)	Acc@1 51.562 (47.796)	Acc@5 76.562 (79.251)
Epoch: [16][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6981 (2.6521)	Acc@1 47.656 (47.823)	Acc@5 82.812 (79.259)
Epoch: [16][370/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.5153 (2.6524)	Acc@1 45.312 (47.787)	Acc@5 81.250 (79.256)
Epoch: [16][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5550 (2.6539)	Acc@1 48.438 (47.753)	Acc@5 81.250 (79.216)
Epoch: [16][390/391]	Time 0.016 (0.013)	Data 0.000 (0.002)	Loss 2.8096 (2.6521)	Acc@1 50.000 (47.770)	Acc@5 76.250 (79.270)
num momentum params: 26
[0.1, 2.652089896850586, 2.012563730478287, 47.77, 46.64, tensor(0.2759, device='cuda:0', grad_fn=<DivBackward0>), 5.182563781738281, 0.37625932693481445]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [17 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [17][0/391]	Time 0.031 (0.031)	Data 0.133 (0.133)	Loss 2.6702 (2.6702)	Acc@1 50.000 (50.000)	Acc@5 75.781 (75.781)
Epoch: [17][10/391]	Time 0.013 (0.015)	Data 0.001 (0.014)	Loss 2.6637 (2.5207)	Acc@1 46.875 (50.994)	Acc@5 74.219 (80.327)
Epoch: [17][20/391]	Time 0.013 (0.014)	Data 0.001 (0.008)	Loss 2.3422 (2.5132)	Acc@1 58.594 (52.195)	Acc@5 82.812 (80.729)
Epoch: [17][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.6276 (2.5450)	Acc@1 50.781 (50.832)	Acc@5 81.250 (80.771)
Epoch: [17][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.6340 (2.5655)	Acc@1 44.531 (50.419)	Acc@5 79.688 (80.164)
Epoch: [17][50/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.8082 (2.5712)	Acc@1 49.219 (50.046)	Acc@5 74.219 (80.025)
Epoch: [17][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.8583 (2.5674)	Acc@1 44.531 (50.205)	Acc@5 77.344 (80.085)
Epoch: [17][70/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.5198 (2.5573)	Acc@1 48.438 (50.297)	Acc@5 82.031 (80.502)
Epoch: [17][80/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.7713 (2.5731)	Acc@1 46.094 (49.826)	Acc@5 73.438 (80.449)
Epoch: [17][90/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.2999 (2.5716)	Acc@1 60.156 (49.863)	Acc@5 85.156 (80.460)
Epoch: [17][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.5760 (2.5788)	Acc@1 50.781 (49.675)	Acc@5 78.125 (80.291)
Epoch: [17][110/391]	Time 0.013 (0.013)	Data 0.002 (0.003)	Loss 2.5860 (2.5890)	Acc@1 44.531 (49.352)	Acc@5 80.469 (80.117)
Epoch: [17][120/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.6787 (2.5922)	Acc@1 43.750 (49.277)	Acc@5 78.125 (80.017)
Epoch: [17][130/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6056 (2.5903)	Acc@1 44.531 (49.225)	Acc@5 82.031 (80.081)
Epoch: [17][140/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.7559 (2.5931)	Acc@1 46.094 (49.330)	Acc@5 75.781 (79.965)
Epoch: [17][150/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6867 (2.5922)	Acc@1 50.000 (49.364)	Acc@5 75.000 (80.008)
Epoch: [17][160/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5699 (2.5948)	Acc@1 49.219 (49.258)	Acc@5 79.688 (79.984)
Epoch: [17][170/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.6678 (2.5954)	Acc@1 50.000 (49.278)	Acc@5 75.000 (79.984)
Epoch: [17][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6040 (2.5988)	Acc@1 49.219 (49.197)	Acc@5 79.688 (79.946)
Epoch: [17][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7141 (2.5996)	Acc@1 49.219 (49.243)	Acc@5 76.562 (79.896)
Epoch: [17][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9837 (2.6059)	Acc@1 38.281 (49.137)	Acc@5 75.000 (79.765)
Epoch: [17][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5686 (2.6135)	Acc@1 55.469 (48.941)	Acc@5 79.688 (79.676)
Epoch: [17][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6051 (2.6133)	Acc@1 50.781 (48.932)	Acc@5 78.906 (79.684)
Epoch: [17][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9631 (2.6130)	Acc@1 41.406 (48.962)	Acc@5 76.562 (79.654)
Epoch: [17][240/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.8496 (2.6133)	Acc@1 40.625 (48.917)	Acc@5 75.000 (79.665)
Epoch: [17][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6891 (2.6158)	Acc@1 49.219 (48.820)	Acc@5 78.906 (79.653)
Epoch: [17][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6251 (2.6162)	Acc@1 47.656 (48.791)	Acc@5 78.125 (79.652)
Epoch: [17][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5333 (2.6164)	Acc@1 54.688 (48.861)	Acc@5 80.469 (79.702)
Epoch: [17][280/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.4929 (2.6178)	Acc@1 50.781 (48.857)	Acc@5 78.906 (79.685)
Epoch: [17][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5981 (2.6198)	Acc@1 48.438 (48.832)	Acc@5 82.812 (79.663)
Epoch: [17][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4790 (2.6212)	Acc@1 51.562 (48.783)	Acc@5 78.906 (79.638)
Epoch: [17][310/391]	Time 0.012 (0.013)	Data 0.001 (0.002)	Loss 2.6279 (2.6201)	Acc@1 50.781 (48.832)	Acc@5 80.469 (79.677)
Epoch: [17][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3216 (2.6207)	Acc@1 56.250 (48.815)	Acc@5 82.812 (79.685)
Epoch: [17][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3842 (2.6224)	Acc@1 53.906 (48.768)	Acc@5 85.156 (79.716)
Epoch: [17][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6852 (2.6217)	Acc@1 49.219 (48.806)	Acc@5 77.344 (79.713)
Epoch: [17][350/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.6629 (2.6222)	Acc@1 50.781 (48.754)	Acc@5 79.688 (79.721)
Epoch: [17][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7930 (2.6233)	Acc@1 46.875 (48.725)	Acc@5 75.781 (79.709)
Epoch: [17][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6574 (2.6282)	Acc@1 50.000 (48.633)	Acc@5 77.344 (79.584)
Epoch: [17][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7440 (2.6294)	Acc@1 52.344 (48.620)	Acc@5 77.344 (79.564)
Epoch: [17][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.4292 (2.6283)	Acc@1 46.250 (48.634)	Acc@5 83.750 (79.584)
num momentum params: 26
[0.1, 2.628324897766113, 2.3323001956939695, 48.634, 40.74, tensor(0.2814, device='cuda:0', grad_fn=<DivBackward0>), 5.188855409622192, 0.3782539367675781]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [18 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [18][0/391]	Time 0.031 (0.031)	Data 0.139 (0.139)	Loss 2.5520 (2.5520)	Acc@1 48.438 (48.438)	Acc@5 78.906 (78.906)
Epoch: [18][10/391]	Time 0.013 (0.015)	Data 0.001 (0.014)	Loss 2.3230 (2.4842)	Acc@1 51.562 (51.207)	Acc@5 84.375 (80.611)
Epoch: [18][20/391]	Time 0.013 (0.014)	Data 0.001 (0.008)	Loss 2.5982 (2.5347)	Acc@1 48.438 (49.554)	Acc@5 82.031 (81.101)
Epoch: [18][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.6702 (2.5341)	Acc@1 46.875 (50.428)	Acc@5 78.125 (81.225)
Epoch: [18][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.4318 (2.5367)	Acc@1 55.469 (50.171)	Acc@5 81.250 (81.136)
Epoch: [18][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4607 (2.5380)	Acc@1 51.562 (50.000)	Acc@5 82.031 (81.250)
Epoch: [18][60/391]	Time 0.013 (0.013)	Data 0.001 (0.004)	Loss 2.6458 (2.5506)	Acc@1 48.438 (49.821)	Acc@5 81.250 (80.943)
Epoch: [18][70/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.8615 (2.5537)	Acc@1 40.625 (49.670)	Acc@5 75.781 (80.843)
Epoch: [18][80/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.5641 (2.5572)	Acc@1 45.312 (49.508)	Acc@5 83.594 (80.768)
Epoch: [18][90/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.4684 (2.5685)	Acc@1 55.469 (49.511)	Acc@5 80.469 (80.503)
Epoch: [18][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.8932 (2.5796)	Acc@1 45.312 (49.350)	Acc@5 75.781 (80.391)
Epoch: [18][110/391]	Time 0.013 (0.013)	Data 0.002 (0.003)	Loss 2.7560 (2.5839)	Acc@1 39.844 (49.148)	Acc@5 78.906 (80.377)
Epoch: [18][120/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.7439 (2.5841)	Acc@1 50.781 (49.264)	Acc@5 77.344 (80.385)
Epoch: [18][130/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.5380 (2.5864)	Acc@1 50.000 (49.266)	Acc@5 82.031 (80.338)
Epoch: [18][140/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.0153 (2.5971)	Acc@1 43.750 (49.141)	Acc@5 71.094 (80.175)
Epoch: [18][150/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.6440 (2.6003)	Acc@1 46.094 (49.053)	Acc@5 78.125 (80.076)
Epoch: [18][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6464 (2.6003)	Acc@1 51.562 (49.020)	Acc@5 77.344 (80.119)
Epoch: [18][170/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.5197 (2.5977)	Acc@1 46.875 (49.082)	Acc@5 83.594 (80.181)
Epoch: [18][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3813 (2.5949)	Acc@1 57.031 (49.201)	Acc@5 80.469 (80.240)
Epoch: [18][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3589 (2.5935)	Acc@1 50.781 (49.206)	Acc@5 86.719 (80.256)
Epoch: [18][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6867 (2.5942)	Acc@1 46.094 (49.168)	Acc@5 75.000 (80.232)
Epoch: [18][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6909 (2.5930)	Acc@1 45.312 (49.160)	Acc@5 80.469 (80.324)
Epoch: [18][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6036 (2.5942)	Acc@1 53.125 (49.145)	Acc@5 82.812 (80.366)
Epoch: [18][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6926 (2.5968)	Acc@1 46.094 (49.104)	Acc@5 78.906 (80.300)
Epoch: [18][240/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.8175 (2.6036)	Acc@1 42.969 (48.969)	Acc@5 77.344 (80.187)
Epoch: [18][250/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.6831 (2.6059)	Acc@1 46.094 (48.932)	Acc@5 77.344 (80.111)
Epoch: [18][260/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4826 (2.6057)	Acc@1 51.562 (48.946)	Acc@5 77.344 (80.053)
Epoch: [18][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7394 (2.6045)	Acc@1 46.094 (48.945)	Acc@5 76.562 (80.074)
Epoch: [18][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6529 (2.6025)	Acc@1 47.656 (48.955)	Acc@5 81.250 (80.102)
Epoch: [18][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7923 (2.6010)	Acc@1 45.312 (49.039)	Acc@5 75.000 (80.112)
Epoch: [18][300/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.4603 (2.6039)	Acc@1 53.125 (48.980)	Acc@5 83.594 (80.092)
Epoch: [18][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8615 (2.6074)	Acc@1 45.312 (48.915)	Acc@5 74.219 (80.034)
Epoch: [18][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3848 (2.6069)	Acc@1 57.812 (48.961)	Acc@5 85.156 (80.033)
Epoch: [18][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5504 (2.6060)	Acc@1 50.000 (49.013)	Acc@5 85.156 (80.077)
Epoch: [18][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5607 (2.6055)	Acc@1 53.125 (49.047)	Acc@5 82.812 (80.068)
Epoch: [18][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7650 (2.6049)	Acc@1 48.438 (49.023)	Acc@5 78.125 (80.093)
Epoch: [18][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5284 (2.6053)	Acc@1 53.125 (49.048)	Acc@5 78.125 (80.051)
Epoch: [18][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6794 (2.6058)	Acc@1 42.969 (49.017)	Acc@5 81.250 (80.075)
Epoch: [18][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 3.0072 (2.6088)	Acc@1 43.750 (48.948)	Acc@5 71.875 (80.016)
Epoch: [18][390/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.3851 (2.6108)	Acc@1 51.250 (48.888)	Acc@5 85.000 (79.988)
num momentum params: 26
[0.1, 2.610758926086426, 2.2152679681777956, 48.888, 41.86, tensor(0.2856, device='cuda:0', grad_fn=<DivBackward0>), 5.220051527023315, 0.3787837028503418]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [19 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [19][0/391]	Time 0.033 (0.033)	Data 0.144 (0.144)	Loss 2.5901 (2.5901)	Acc@1 47.656 (47.656)	Acc@5 82.031 (82.031)
Epoch: [19][10/391]	Time 0.013 (0.015)	Data 0.001 (0.014)	Loss 2.5595 (2.5210)	Acc@1 52.344 (51.065)	Acc@5 84.375 (82.244)
Epoch: [19][20/391]	Time 0.013 (0.015)	Data 0.001 (0.008)	Loss 2.3812 (2.5477)	Acc@1 61.719 (50.372)	Acc@5 83.594 (81.510)
Epoch: [19][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.4805 (2.5595)	Acc@1 47.656 (50.101)	Acc@5 81.250 (80.973)
Epoch: [19][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.4113 (2.5703)	Acc@1 53.906 (49.657)	Acc@5 85.156 (80.926)
Epoch: [19][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.5773 (2.5644)	Acc@1 46.094 (49.586)	Acc@5 83.594 (81.020)
Epoch: [19][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.6742 (2.5564)	Acc@1 50.781 (50.115)	Acc@5 79.688 (81.007)
Epoch: [19][70/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4245 (2.5531)	Acc@1 57.031 (50.088)	Acc@5 85.938 (81.162)
Epoch: [19][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.7608 (2.5515)	Acc@1 42.969 (50.212)	Acc@5 81.250 (81.047)
Epoch: [19][90/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.6919 (2.5674)	Acc@1 46.094 (49.768)	Acc@5 82.031 (80.889)
Epoch: [19][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.4044 (2.5800)	Acc@1 51.562 (49.629)	Acc@5 84.375 (80.585)
Epoch: [19][110/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.8668 (2.5823)	Acc@1 46.094 (49.740)	Acc@5 72.656 (80.511)
Epoch: [19][120/391]	Time 0.012 (0.013)	Data 0.001 (0.003)	Loss 2.4401 (2.5727)	Acc@1 50.781 (49.948)	Acc@5 82.812 (80.727)
Epoch: [19][130/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.5077 (2.5712)	Acc@1 50.000 (49.970)	Acc@5 78.906 (80.809)
Epoch: [19][140/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6851 (2.5730)	Acc@1 45.312 (49.939)	Acc@5 73.438 (80.746)
Epoch: [19][150/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6705 (2.5787)	Acc@1 48.438 (49.860)	Acc@5 78.906 (80.614)
Epoch: [19][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5046 (2.5786)	Acc@1 51.562 (49.932)	Acc@5 84.375 (80.677)
Epoch: [19][170/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6338 (2.5820)	Acc@1 53.906 (49.858)	Acc@5 78.125 (80.624)
Epoch: [19][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3896 (2.5861)	Acc@1 57.812 (49.754)	Acc@5 85.938 (80.503)
Epoch: [19][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7703 (2.5891)	Acc@1 41.406 (49.616)	Acc@5 81.250 (80.510)
Epoch: [19][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4179 (2.5913)	Acc@1 57.031 (49.639)	Acc@5 83.594 (80.496)
Epoch: [19][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4078 (2.5914)	Acc@1 54.688 (49.633)	Acc@5 84.375 (80.509)
Epoch: [19][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5674 (2.5919)	Acc@1 47.656 (49.593)	Acc@5 84.375 (80.486)
Epoch: [19][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4462 (2.5910)	Acc@1 55.469 (49.716)	Acc@5 80.469 (80.509)
Epoch: [19][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7323 (2.5924)	Acc@1 41.406 (49.637)	Acc@5 80.469 (80.508)
Epoch: [19][250/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.6021 (2.5928)	Acc@1 50.781 (49.617)	Acc@5 83.594 (80.500)
Epoch: [19][260/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5156 (2.5895)	Acc@1 50.000 (49.674)	Acc@5 78.125 (80.547)
Epoch: [19][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7942 (2.5895)	Acc@1 47.656 (49.668)	Acc@5 71.875 (80.509)
Epoch: [19][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9482 (2.5937)	Acc@1 42.188 (49.572)	Acc@5 75.781 (80.405)
Epoch: [19][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7935 (2.5980)	Acc@1 48.438 (49.541)	Acc@5 77.344 (80.332)
Epoch: [19][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5298 (2.5992)	Acc@1 50.000 (49.496)	Acc@5 81.250 (80.300)
Epoch: [19][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6240 (2.5973)	Acc@1 48.438 (49.508)	Acc@5 83.594 (80.356)
Epoch: [19][320/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.5450 (2.5979)	Acc@1 52.344 (49.479)	Acc@5 79.688 (80.354)
Epoch: [19][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6286 (2.5987)	Acc@1 48.438 (49.488)	Acc@5 79.688 (80.322)
Epoch: [19][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6814 (2.5986)	Acc@1 48.438 (49.491)	Acc@5 79.688 (80.329)
Epoch: [19][350/391]	Time 0.012 (0.013)	Data 0.003 (0.002)	Loss 2.4949 (2.5993)	Acc@1 47.656 (49.490)	Acc@5 86.719 (80.300)
Epoch: [19][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4637 (2.6001)	Acc@1 52.344 (49.487)	Acc@5 81.250 (80.274)
Epoch: [19][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6709 (2.5997)	Acc@1 46.875 (49.495)	Acc@5 77.344 (80.260)
Epoch: [19][380/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.6068 (2.5997)	Acc@1 53.125 (49.508)	Acc@5 75.000 (80.264)
Epoch: [19][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.6445 (2.6006)	Acc@1 47.500 (49.510)	Acc@5 78.750 (80.252)
num momentum params: 26
[0.1, 2.6005681672668457, 2.2905621516704557, 49.51, 41.31, tensor(0.2890, device='cuda:0', grad_fn=<DivBackward0>), 5.203487873077393, 0.3690676689147949]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [20 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [20][0/391]	Time 0.037 (0.037)	Data 0.136 (0.136)	Loss 2.3298 (2.3298)	Acc@1 60.938 (60.938)	Acc@5 85.156 (85.156)
Epoch: [20][10/391]	Time 0.013 (0.015)	Data 0.001 (0.014)	Loss 2.2881 (2.4711)	Acc@1 57.031 (52.344)	Acc@5 85.156 (83.949)
Epoch: [20][20/391]	Time 0.013 (0.014)	Data 0.001 (0.008)	Loss 2.9605 (2.4737)	Acc@1 40.625 (52.604)	Acc@5 75.000 (83.185)
Epoch: [20][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.2571 (2.4774)	Acc@1 60.156 (52.646)	Acc@5 85.938 (82.812)
Epoch: [20][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.4898 (2.5050)	Acc@1 50.781 (51.715)	Acc@5 83.594 (82.508)
Epoch: [20][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.5554 (2.5330)	Acc@1 50.781 (51.180)	Acc@5 78.906 (81.710)
Epoch: [20][60/391]	Time 0.021 (0.014)	Data 0.002 (0.004)	Loss 2.5191 (2.5252)	Acc@1 53.125 (51.281)	Acc@5 79.688 (81.724)
Epoch: [20][70/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3673 (2.5279)	Acc@1 53.125 (51.133)	Acc@5 82.031 (81.734)
Epoch: [20][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4775 (2.5492)	Acc@1 50.781 (50.617)	Acc@5 83.594 (81.318)
Epoch: [20][90/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.4179 (2.5445)	Acc@1 52.344 (50.790)	Acc@5 80.469 (81.422)
Epoch: [20][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.7108 (2.5378)	Acc@1 49.219 (51.060)	Acc@5 81.250 (81.575)
Epoch: [20][110/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.6196 (2.5451)	Acc@1 52.344 (50.859)	Acc@5 83.594 (81.454)
Epoch: [20][120/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.9753 (2.5496)	Acc@1 39.844 (50.807)	Acc@5 75.781 (81.444)
Epoch: [20][130/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5683 (2.5544)	Acc@1 50.781 (50.698)	Acc@5 83.594 (81.363)
Epoch: [20][140/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5186 (2.5604)	Acc@1 50.000 (50.515)	Acc@5 75.781 (81.228)
Epoch: [20][150/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7510 (2.5629)	Acc@1 45.312 (50.388)	Acc@5 80.469 (81.224)
Epoch: [20][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5361 (2.5635)	Acc@1 51.562 (50.432)	Acc@5 79.688 (81.216)
Epoch: [20][170/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8471 (2.5662)	Acc@1 44.531 (50.443)	Acc@5 76.562 (81.154)
Epoch: [20][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5475 (2.5662)	Acc@1 48.438 (50.440)	Acc@5 86.719 (81.138)
Epoch: [20][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5115 (2.5677)	Acc@1 48.438 (50.397)	Acc@5 84.375 (81.074)
Epoch: [20][200/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.9876 (2.5673)	Acc@1 40.625 (50.400)	Acc@5 75.781 (81.106)
Epoch: [20][210/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.6535 (2.5699)	Acc@1 46.875 (50.344)	Acc@5 82.812 (80.983)
Epoch: [20][220/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.7239 (2.5726)	Acc@1 43.750 (50.290)	Acc@5 75.781 (80.879)
Epoch: [20][230/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.6579 (2.5740)	Acc@1 48.438 (50.281)	Acc@5 78.125 (80.892)
Epoch: [20][240/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.6804 (2.5802)	Acc@1 48.438 (50.123)	Acc@5 78.125 (80.816)
Epoch: [20][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6102 (2.5825)	Acc@1 42.969 (50.053)	Acc@5 82.031 (80.718)
Epoch: [20][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6142 (2.5830)	Acc@1 43.750 (49.988)	Acc@5 82.031 (80.744)
Epoch: [20][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7621 (2.5851)	Acc@1 45.312 (49.942)	Acc@5 78.906 (80.763)
Epoch: [20][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3946 (2.5832)	Acc@1 50.000 (49.947)	Acc@5 87.500 (80.800)
Epoch: [20][290/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.6836 (2.5843)	Acc@1 52.344 (49.946)	Acc@5 78.125 (80.794)
Epoch: [20][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6785 (2.5861)	Acc@1 50.781 (49.914)	Acc@5 78.906 (80.788)
Epoch: [20][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7138 (2.5879)	Acc@1 47.656 (49.879)	Acc@5 78.125 (80.743)
Epoch: [20][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6615 (2.5903)	Acc@1 50.781 (49.876)	Acc@5 78.125 (80.688)
Epoch: [20][330/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5772 (2.5905)	Acc@1 51.562 (49.899)	Acc@5 77.344 (80.728)
Epoch: [20][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6309 (2.5933)	Acc@1 43.750 (49.828)	Acc@5 84.375 (80.686)
Epoch: [20][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7002 (2.5939)	Acc@1 54.688 (49.822)	Acc@5 75.000 (80.662)
Epoch: [20][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7980 (2.5962)	Acc@1 46.875 (49.768)	Acc@5 74.219 (80.627)
Epoch: [20][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9045 (2.5965)	Acc@1 46.094 (49.806)	Acc@5 73.438 (80.641)
Epoch: [20][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6023 (2.5976)	Acc@1 51.562 (49.815)	Acc@5 81.250 (80.620)
Epoch: [20][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.8177 (2.5988)	Acc@1 37.500 (49.720)	Acc@5 80.000 (80.610)
num momentum params: 26
[0.1, 2.5987748990631103, 2.1488518500328064, 49.72, 43.07, tensor(0.2915, device='cuda:0', grad_fn=<DivBackward0>), 5.205995321273804, 0.37735652923583984]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [21 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [21][0/391]	Time 0.032 (0.032)	Data 0.139 (0.139)	Loss 2.7233 (2.7233)	Acc@1 46.875 (46.875)	Acc@5 82.031 (82.031)
Epoch: [21][10/391]	Time 0.013 (0.015)	Data 0.002 (0.014)	Loss 2.4392 (2.5426)	Acc@1 51.562 (49.929)	Acc@5 84.375 (82.031)
Epoch: [21][20/391]	Time 0.013 (0.014)	Data 0.001 (0.008)	Loss 2.4891 (2.5256)	Acc@1 57.031 (50.893)	Acc@5 81.250 (82.478)
Epoch: [21][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.6598 (2.4942)	Acc@1 45.312 (51.361)	Acc@5 81.250 (83.115)
Epoch: [21][40/391]	Time 0.014 (0.014)	Data 0.001 (0.005)	Loss 2.8522 (2.5103)	Acc@1 42.188 (51.677)	Acc@5 75.000 (82.965)
Epoch: [21][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.6062 (2.5142)	Acc@1 44.531 (51.654)	Acc@5 79.688 (82.613)
Epoch: [21][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.6254 (2.5192)	Acc@1 50.781 (51.460)	Acc@5 80.469 (82.377)
Epoch: [21][70/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.7530 (2.5107)	Acc@1 46.875 (51.585)	Acc@5 78.125 (82.405)
Epoch: [21][80/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.3764 (2.4998)	Acc@1 51.562 (51.659)	Acc@5 85.938 (82.735)
Epoch: [21][90/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.6312 (2.5084)	Acc@1 49.219 (51.631)	Acc@5 82.031 (82.512)
Epoch: [21][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.5140 (2.5112)	Acc@1 54.688 (51.555)	Acc@5 80.469 (82.557)
Epoch: [21][110/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.4948 (2.5136)	Acc@1 54.688 (51.541)	Acc@5 82.031 (82.601)
Epoch: [21][120/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.6327 (2.5172)	Acc@1 48.438 (51.369)	Acc@5 82.031 (82.464)
Epoch: [21][130/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.5231 (2.5190)	Acc@1 54.688 (51.348)	Acc@5 78.125 (82.395)
Epoch: [21][140/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6965 (2.5279)	Acc@1 49.219 (51.252)	Acc@5 75.000 (82.203)
Epoch: [21][150/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5019 (2.5330)	Acc@1 49.219 (51.133)	Acc@5 82.031 (82.124)
Epoch: [21][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3634 (2.5317)	Acc@1 54.688 (51.218)	Acc@5 83.594 (82.022)
Epoch: [21][170/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5941 (2.5337)	Acc@1 55.469 (51.156)	Acc@5 81.250 (82.068)
Epoch: [21][180/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.6774 (2.5339)	Acc@1 47.656 (51.135)	Acc@5 82.031 (82.100)
Epoch: [21][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4316 (2.5399)	Acc@1 51.562 (50.961)	Acc@5 83.594 (81.986)
Epoch: [21][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7805 (2.5487)	Acc@1 47.656 (50.801)	Acc@5 79.688 (81.775)
Epoch: [21][210/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.7119 (2.5511)	Acc@1 46.875 (50.755)	Acc@5 79.688 (81.739)
Epoch: [21][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5873 (2.5522)	Acc@1 51.562 (50.675)	Acc@5 78.906 (81.688)
Epoch: [21][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3639 (2.5542)	Acc@1 56.250 (50.619)	Acc@5 85.938 (81.636)
Epoch: [21][240/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.6722 (2.5546)	Acc@1 43.750 (50.606)	Acc@5 82.031 (81.645)
Epoch: [21][250/391]	Time 0.011 (0.013)	Data 0.001 (0.002)	Loss 2.6380 (2.5588)	Acc@1 47.656 (50.514)	Acc@5 81.250 (81.483)
Epoch: [21][260/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.6593 (2.5598)	Acc@1 44.531 (50.545)	Acc@5 79.688 (81.451)
Epoch: [21][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3372 (2.5613)	Acc@1 53.125 (50.502)	Acc@5 85.938 (81.406)
Epoch: [21][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8522 (2.5671)	Acc@1 44.531 (50.373)	Acc@5 76.562 (81.292)
Epoch: [21][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5114 (2.5699)	Acc@1 51.562 (50.298)	Acc@5 82.031 (81.183)
Epoch: [21][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3912 (2.5703)	Acc@1 53.125 (50.291)	Acc@5 85.938 (81.159)
Epoch: [21][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6157 (2.5694)	Acc@1 50.781 (50.319)	Acc@5 79.688 (81.190)
Epoch: [21][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6810 (2.5737)	Acc@1 46.094 (50.221)	Acc@5 78.906 (81.123)
Epoch: [21][330/391]	Time 0.010 (0.013)	Data 0.001 (0.002)	Loss 2.4151 (2.5742)	Acc@1 49.219 (50.229)	Acc@5 81.250 (81.073)
Epoch: [21][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3981 (2.5733)	Acc@1 52.344 (50.268)	Acc@5 84.375 (81.115)
Epoch: [21][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4634 (2.5721)	Acc@1 48.438 (50.329)	Acc@5 81.250 (81.112)
Epoch: [21][360/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.8415 (2.5719)	Acc@1 47.656 (50.366)	Acc@5 75.000 (81.094)
Epoch: [21][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6497 (2.5744)	Acc@1 53.906 (50.350)	Acc@5 78.125 (81.071)
Epoch: [21][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6361 (2.5767)	Acc@1 50.781 (50.312)	Acc@5 79.688 (81.014)
Epoch: [21][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 3.0839 (2.5809)	Acc@1 46.250 (50.214)	Acc@5 65.000 (80.950)
num momentum params: 26
[0.1, 2.580919047470093, 2.115352615118027, 50.214, 45.52, tensor(0.2953, device='cuda:0', grad_fn=<DivBackward0>), 5.1978440284729, 0.37512779235839844]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [22 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [22][0/391]	Time 0.033 (0.033)	Data 0.142 (0.142)	Loss 2.4486 (2.4486)	Acc@1 53.125 (53.125)	Acc@5 81.250 (81.250)
Epoch: [22][10/391]	Time 0.014 (0.015)	Data 0.001 (0.014)	Loss 2.3046 (2.5043)	Acc@1 54.688 (50.355)	Acc@5 86.719 (81.818)
Epoch: [22][20/391]	Time 0.014 (0.014)	Data 0.000 (0.008)	Loss 2.4685 (2.4928)	Acc@1 50.781 (50.856)	Acc@5 82.812 (82.329)
Epoch: [22][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.8401 (2.5183)	Acc@1 42.969 (51.109)	Acc@5 74.219 (81.704)
Epoch: [22][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.2906 (2.5148)	Acc@1 55.469 (51.010)	Acc@5 87.500 (81.841)
Epoch: [22][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3420 (2.5117)	Acc@1 53.125 (51.149)	Acc@5 86.719 (82.169)
Epoch: [22][60/391]	Time 0.013 (0.013)	Data 0.001 (0.004)	Loss 2.3481 (2.5064)	Acc@1 55.469 (51.678)	Acc@5 82.812 (82.300)
Epoch: [22][70/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.1036 (2.5023)	Acc@1 62.500 (51.926)	Acc@5 90.625 (82.416)
Epoch: [22][80/391]	Time 0.013 (0.013)	Data 0.002 (0.003)	Loss 2.5836 (2.5055)	Acc@1 51.562 (51.833)	Acc@5 78.906 (82.272)
Epoch: [22][90/391]	Time 0.014 (0.013)	Data 0.001 (0.003)	Loss 2.5027 (2.5015)	Acc@1 53.125 (51.932)	Acc@5 82.812 (82.357)
Epoch: [22][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.5248 (2.5029)	Acc@1 53.906 (51.841)	Acc@5 80.469 (82.263)
Epoch: [22][110/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.6564 (2.5128)	Acc@1 50.000 (51.654)	Acc@5 76.562 (82.179)
Epoch: [22][120/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.7332 (2.5206)	Acc@1 39.062 (51.408)	Acc@5 80.469 (82.193)
Epoch: [22][130/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4130 (2.5241)	Acc@1 56.250 (51.467)	Acc@5 79.688 (82.013)
Epoch: [22][140/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7972 (2.5315)	Acc@1 49.219 (51.280)	Acc@5 79.688 (81.859)
Epoch: [22][150/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8155 (2.5344)	Acc@1 48.438 (51.293)	Acc@5 76.562 (81.798)
Epoch: [22][160/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5191 (2.5384)	Acc@1 55.469 (51.252)	Acc@5 80.469 (81.662)
Epoch: [22][170/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5498 (2.5430)	Acc@1 52.344 (51.156)	Acc@5 78.125 (81.574)
Epoch: [22][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4232 (2.5401)	Acc@1 57.031 (51.191)	Acc@5 84.375 (81.677)
Epoch: [22][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5247 (2.5404)	Acc@1 54.688 (51.182)	Acc@5 78.125 (81.733)
Epoch: [22][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6518 (2.5431)	Acc@1 50.000 (51.108)	Acc@5 80.469 (81.662)
Epoch: [22][210/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5862 (2.5414)	Acc@1 46.875 (51.163)	Acc@5 82.812 (81.713)
Epoch: [22][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5375 (2.5409)	Acc@1 50.781 (51.188)	Acc@5 79.688 (81.695)
Epoch: [22][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8912 (2.5445)	Acc@1 46.875 (51.126)	Acc@5 77.344 (81.602)
Epoch: [22][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2244 (2.5429)	Acc@1 59.375 (51.203)	Acc@5 89.062 (81.613)
Epoch: [22][250/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.6660 (2.5438)	Acc@1 46.094 (51.152)	Acc@5 85.938 (81.661)
Epoch: [22][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6371 (2.5465)	Acc@1 44.531 (51.122)	Acc@5 79.688 (81.630)
Epoch: [22][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6939 (2.5499)	Acc@1 52.344 (51.058)	Acc@5 77.344 (81.587)
Epoch: [22][280/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.8874 (2.5539)	Acc@1 42.188 (51.048)	Acc@5 71.875 (81.486)
Epoch: [22][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5818 (2.5548)	Acc@1 47.656 (51.036)	Acc@5 82.031 (81.529)
Epoch: [22][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5799 (2.5579)	Acc@1 54.688 (50.989)	Acc@5 81.250 (81.455)
Epoch: [22][310/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.6142 (2.5630)	Acc@1 49.219 (50.902)	Acc@5 77.344 (81.361)
Epoch: [22][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5995 (2.5641)	Acc@1 50.000 (50.835)	Acc@5 78.906 (81.357)
Epoch: [22][330/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.6034 (2.5640)	Acc@1 46.875 (50.843)	Acc@5 83.594 (81.377)
Epoch: [22][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4579 (2.5631)	Acc@1 45.312 (50.873)	Acc@5 89.062 (81.406)
Epoch: [22][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7951 (2.5638)	Acc@1 46.094 (50.826)	Acc@5 75.000 (81.419)
Epoch: [22][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8251 (2.5636)	Acc@1 49.219 (50.831)	Acc@5 76.562 (81.406)
Epoch: [22][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7298 (2.5658)	Acc@1 46.875 (50.777)	Acc@5 80.469 (81.374)
Epoch: [22][380/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.2898 (2.5638)	Acc@1 60.156 (50.812)	Acc@5 84.375 (81.404)
Epoch: [22][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.4264 (2.5639)	Acc@1 52.500 (50.798)	Acc@5 85.000 (81.414)
num momentum params: 26
[0.1, 2.563889205856323, 2.311265025138855, 50.798, 40.95, tensor(0.2996, device='cuda:0', grad_fn=<DivBackward0>), 5.201801538467407, 0.3732876777648926]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [23 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [23][0/391]	Time 0.030 (0.030)	Data 0.137 (0.137)	Loss 2.4404 (2.4404)	Acc@1 53.906 (53.906)	Acc@5 82.812 (82.812)
Epoch: [23][10/391]	Time 0.013 (0.015)	Data 0.001 (0.014)	Loss 2.4914 (2.4327)	Acc@1 53.125 (55.043)	Acc@5 85.938 (84.091)
Epoch: [23][20/391]	Time 0.014 (0.014)	Data 0.001 (0.008)	Loss 2.4904 (2.4275)	Acc@1 54.688 (54.390)	Acc@5 77.344 (84.338)
Epoch: [23][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.6902 (2.4593)	Acc@1 45.312 (53.352)	Acc@5 81.250 (83.745)
Epoch: [23][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.6326 (2.4790)	Acc@1 45.312 (52.744)	Acc@5 79.688 (83.175)
Epoch: [23][50/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.6377 (2.4927)	Acc@1 53.906 (52.773)	Acc@5 76.562 (82.629)
Epoch: [23][60/391]	Time 0.013 (0.013)	Data 0.001 (0.004)	Loss 2.3438 (2.4929)	Acc@1 56.250 (52.651)	Acc@5 85.156 (82.582)
Epoch: [23][70/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.3815 (2.4861)	Acc@1 53.906 (52.795)	Acc@5 82.812 (82.801)
Epoch: [23][80/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.5861 (2.4860)	Acc@1 49.219 (52.826)	Acc@5 82.031 (82.697)
Epoch: [23][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3509 (2.4924)	Acc@1 53.906 (52.533)	Acc@5 85.938 (82.589)
Epoch: [23][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.8532 (2.4947)	Acc@1 43.750 (52.638)	Acc@5 74.219 (82.503)
Epoch: [23][110/391]	Time 0.011 (0.013)	Data 0.004 (0.003)	Loss 2.3728 (2.4939)	Acc@1 57.812 (52.696)	Acc@5 82.812 (82.559)
Epoch: [23][120/391]	Time 0.014 (0.013)	Data 0.001 (0.003)	Loss 2.8689 (2.4961)	Acc@1 45.312 (52.602)	Acc@5 74.219 (82.483)
Epoch: [23][130/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5026 (2.5044)	Acc@1 53.125 (52.362)	Acc@5 85.156 (82.329)
Epoch: [23][140/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6138 (2.5080)	Acc@1 49.219 (52.311)	Acc@5 82.812 (82.314)
Epoch: [23][150/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5586 (2.5124)	Acc@1 50.000 (52.256)	Acc@5 81.250 (82.161)
Epoch: [23][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5983 (2.5199)	Acc@1 51.562 (52.091)	Acc@5 78.125 (82.056)
Epoch: [23][170/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8060 (2.5188)	Acc@1 46.875 (52.097)	Acc@5 76.562 (82.136)
Epoch: [23][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5472 (2.5217)	Acc@1 52.344 (52.046)	Acc@5 80.469 (82.070)
Epoch: [23][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5986 (2.5274)	Acc@1 53.906 (51.963)	Acc@5 78.906 (81.917)
Epoch: [23][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7108 (2.5250)	Acc@1 46.094 (51.928)	Acc@5 78.906 (82.027)
Epoch: [23][210/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5380 (2.5264)	Acc@1 52.344 (51.833)	Acc@5 81.250 (82.057)
Epoch: [23][220/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5982 (2.5251)	Acc@1 48.438 (51.817)	Acc@5 82.812 (82.113)
Epoch: [23][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5048 (2.5275)	Acc@1 50.781 (51.772)	Acc@5 78.125 (82.079)
Epoch: [23][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8502 (2.5324)	Acc@1 43.750 (51.640)	Acc@5 71.875 (81.973)
Epoch: [23][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3946 (2.5352)	Acc@1 53.125 (51.578)	Acc@5 85.938 (81.907)
Epoch: [23][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5429 (2.5322)	Acc@1 47.656 (51.637)	Acc@5 79.688 (81.950)
Epoch: [23][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5314 (2.5335)	Acc@1 54.688 (51.583)	Acc@5 78.906 (81.925)
Epoch: [23][280/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.8161 (2.5350)	Acc@1 48.438 (51.562)	Acc@5 75.000 (81.892)
Epoch: [23][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4561 (2.5361)	Acc@1 51.562 (51.450)	Acc@5 84.375 (81.881)
Epoch: [23][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3549 (2.5359)	Acc@1 58.594 (51.433)	Acc@5 82.812 (81.891)
Epoch: [23][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4914 (2.5401)	Acc@1 55.469 (51.382)	Acc@5 84.375 (81.820)
Epoch: [23][320/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.6305 (2.5411)	Acc@1 47.656 (51.351)	Acc@5 78.125 (81.817)
Epoch: [23][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7183 (2.5437)	Acc@1 46.875 (51.324)	Acc@5 82.031 (81.765)
Epoch: [23][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6317 (2.5479)	Acc@1 49.219 (51.253)	Acc@5 78.906 (81.706)
Epoch: [23][350/391]	Time 0.012 (0.013)	Data 0.002 (0.002)	Loss 2.3703 (2.5492)	Acc@1 47.656 (51.171)	Acc@5 87.500 (81.726)
Epoch: [23][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8485 (2.5501)	Acc@1 49.219 (51.149)	Acc@5 78.125 (81.700)
Epoch: [23][370/391]	Time 0.011 (0.013)	Data 0.001 (0.002)	Loss 2.4552 (2.5502)	Acc@1 52.344 (51.131)	Acc@5 83.594 (81.711)
Epoch: [23][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6045 (2.5523)	Acc@1 52.344 (51.068)	Acc@5 78.125 (81.670)
Epoch: [23][390/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.4745 (2.5542)	Acc@1 47.500 (51.050)	Acc@5 85.000 (81.616)
num momentum params: 26
[0.1, 2.554173243789673, 2.1496351671218874, 51.05, 44.39, tensor(0.3015, device='cuda:0', grad_fn=<DivBackward0>), 5.195933818817139, 0.37317919731140137]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [24 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [24][0/391]	Time 0.035 (0.035)	Data 0.144 (0.144)	Loss 2.1601 (2.1601)	Acc@1 60.156 (60.156)	Acc@5 88.281 (88.281)
Epoch: [24][10/391]	Time 0.013 (0.015)	Data 0.001 (0.014)	Loss 2.5638 (2.4798)	Acc@1 47.656 (52.770)	Acc@5 81.250 (83.381)
Epoch: [24][20/391]	Time 0.013 (0.014)	Data 0.001 (0.008)	Loss 2.4577 (2.5140)	Acc@1 57.812 (52.381)	Acc@5 83.594 (82.626)
Epoch: [24][30/391]	Time 0.014 (0.014)	Data 0.002 (0.006)	Loss 2.3622 (2.5063)	Acc@1 52.344 (52.369)	Acc@5 84.375 (82.812)
Epoch: [24][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.5868 (2.5049)	Acc@1 54.688 (52.725)	Acc@5 81.250 (82.927)
Epoch: [24][50/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.5752 (2.5045)	Acc@1 55.469 (52.604)	Acc@5 77.344 (82.675)
Epoch: [24][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.7285 (2.5104)	Acc@1 50.000 (52.702)	Acc@5 74.219 (82.236)
Epoch: [24][70/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4683 (2.5051)	Acc@1 53.906 (52.850)	Acc@5 76.562 (82.130)
Epoch: [24][80/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.3905 (2.4934)	Acc@1 52.344 (53.048)	Acc@5 87.500 (82.359)
Epoch: [24][90/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.4051 (2.4886)	Acc@1 54.688 (53.262)	Acc@5 85.156 (82.589)
Epoch: [24][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.5298 (2.4889)	Acc@1 49.219 (53.055)	Acc@5 80.469 (82.642)
Epoch: [24][110/391]	Time 0.013 (0.013)	Data 0.002 (0.003)	Loss 2.6033 (2.4866)	Acc@1 51.562 (53.069)	Acc@5 82.812 (82.742)
Epoch: [24][120/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.7049 (2.4891)	Acc@1 45.312 (53.015)	Acc@5 79.688 (82.696)
Epoch: [24][130/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.3293 (2.4901)	Acc@1 57.812 (52.940)	Acc@5 83.594 (82.789)
Epoch: [24][140/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3806 (2.4909)	Acc@1 52.344 (52.787)	Acc@5 83.594 (82.790)
Epoch: [24][150/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3658 (2.4923)	Acc@1 54.688 (52.721)	Acc@5 86.719 (82.756)
Epoch: [24][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7016 (2.4989)	Acc@1 48.438 (52.606)	Acc@5 75.781 (82.662)
Epoch: [24][170/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4650 (2.5034)	Acc@1 50.000 (52.371)	Acc@5 85.938 (82.657)
Epoch: [24][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6169 (2.5085)	Acc@1 53.125 (52.262)	Acc@5 80.469 (82.588)
Epoch: [24][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6798 (2.5110)	Acc@1 47.656 (52.160)	Acc@5 82.812 (82.538)
Epoch: [24][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3701 (2.5100)	Acc@1 54.688 (52.161)	Acc@5 83.594 (82.575)
Epoch: [24][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5152 (2.5114)	Acc@1 55.469 (52.177)	Acc@5 80.469 (82.501)
Epoch: [24][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4938 (2.5129)	Acc@1 52.344 (52.139)	Acc@5 82.812 (82.441)
Epoch: [24][230/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.6816 (2.5152)	Acc@1 47.656 (52.080)	Acc@5 82.031 (82.403)
Epoch: [24][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8185 (2.5186)	Acc@1 50.000 (52.065)	Acc@5 76.562 (82.359)
Epoch: [24][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8102 (2.5259)	Acc@1 37.500 (51.892)	Acc@5 81.250 (82.174)
Epoch: [24][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7333 (2.5259)	Acc@1 51.562 (51.916)	Acc@5 78.906 (82.148)
Epoch: [24][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6560 (2.5290)	Acc@1 44.531 (51.836)	Acc@5 81.250 (82.115)
Epoch: [24][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6881 (2.5310)	Acc@1 41.406 (51.782)	Acc@5 79.688 (82.109)
Epoch: [24][290/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.3754 (2.5323)	Acc@1 57.812 (51.748)	Acc@5 85.156 (82.066)
Epoch: [24][300/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.8687 (2.5332)	Acc@1 46.875 (51.736)	Acc@5 77.344 (82.044)
Epoch: [24][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5520 (2.5359)	Acc@1 49.219 (51.645)	Acc@5 82.031 (81.976)
Epoch: [24][320/391]	Time 0.022 (0.013)	Data 0.001 (0.002)	Loss 2.6216 (2.5377)	Acc@1 53.125 (51.609)	Acc@5 81.250 (81.961)
Epoch: [24][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6072 (2.5383)	Acc@1 55.469 (51.610)	Acc@5 81.250 (81.982)
Epoch: [24][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5451 (2.5399)	Acc@1 53.125 (51.565)	Acc@5 75.781 (81.930)
Epoch: [24][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3464 (2.5400)	Acc@1 53.906 (51.534)	Acc@5 89.844 (81.969)
Epoch: [24][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4219 (2.5413)	Acc@1 53.125 (51.480)	Acc@5 82.812 (81.938)
Epoch: [24][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7292 (2.5464)	Acc@1 50.000 (51.392)	Acc@5 79.688 (81.840)
Epoch: [24][380/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.6962 (2.5504)	Acc@1 50.000 (51.347)	Acc@5 78.906 (81.756)
Epoch: [24][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.8164 (2.5533)	Acc@1 45.000 (51.266)	Acc@5 77.500 (81.710)
num momentum params: 26
[0.1, 2.553329016418457, 2.4718018901348113, 51.266, 39.15, tensor(0.3031, device='cuda:0', grad_fn=<DivBackward0>), 5.202894449234009, 0.37886762619018555]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [25 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [25][0/391]	Time 0.032 (0.032)	Data 0.135 (0.135)	Loss 2.3111 (2.3111)	Acc@1 60.938 (60.938)	Acc@5 88.281 (88.281)
Epoch: [25][10/391]	Time 0.015 (0.015)	Data 0.001 (0.014)	Loss 2.5467 (2.4503)	Acc@1 53.125 (53.622)	Acc@5 78.906 (83.097)
Epoch: [25][20/391]	Time 0.013 (0.014)	Data 0.001 (0.008)	Loss 2.4065 (2.4430)	Acc@1 53.906 (53.646)	Acc@5 85.156 (83.631)
Epoch: [25][30/391]	Time 0.015 (0.014)	Data 0.001 (0.006)	Loss 2.3672 (2.4524)	Acc@1 56.250 (53.024)	Acc@5 84.375 (84.047)
Epoch: [25][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.4098 (2.4613)	Acc@1 53.125 (52.706)	Acc@5 89.062 (84.108)
Epoch: [25][50/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.6132 (2.4851)	Acc@1 51.562 (52.451)	Acc@5 80.469 (83.609)
Epoch: [25][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4475 (2.4895)	Acc@1 56.250 (52.485)	Acc@5 82.031 (83.248)
Epoch: [25][70/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3948 (2.4950)	Acc@1 55.469 (52.256)	Acc@5 86.719 (83.308)
Epoch: [25][80/391]	Time 0.013 (0.013)	Data 0.002 (0.003)	Loss 2.5043 (2.4944)	Acc@1 54.688 (52.421)	Acc@5 81.250 (83.169)
Epoch: [25][90/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.5006 (2.4870)	Acc@1 47.656 (52.610)	Acc@5 83.594 (83.242)
Epoch: [25][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.3847 (2.4810)	Acc@1 52.344 (52.816)	Acc@5 87.500 (83.253)
Epoch: [25][110/391]	Time 0.014 (0.013)	Data 0.001 (0.003)	Loss 2.6719 (2.4822)	Acc@1 46.094 (52.808)	Acc@5 82.031 (83.214)
Epoch: [25][120/391]	Time 0.014 (0.013)	Data 0.001 (0.003)	Loss 2.4288 (2.4835)	Acc@1 52.344 (52.757)	Acc@5 81.250 (83.271)
Epoch: [25][130/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6306 (2.4914)	Acc@1 52.344 (52.451)	Acc@5 78.125 (83.135)
Epoch: [25][140/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4371 (2.4933)	Acc@1 58.594 (52.516)	Acc@5 83.594 (83.001)
Epoch: [25][150/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5840 (2.4925)	Acc@1 50.000 (52.628)	Acc@5 77.344 (82.983)
Epoch: [25][160/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.5497 (2.4929)	Acc@1 53.906 (52.620)	Acc@5 84.375 (82.934)
Epoch: [25][170/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7158 (2.4955)	Acc@1 46.094 (52.558)	Acc@5 81.250 (82.876)
Epoch: [25][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5923 (2.4996)	Acc@1 52.344 (52.426)	Acc@5 80.469 (82.808)
Epoch: [25][190/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.6783 (2.4984)	Acc@1 49.219 (52.491)	Acc@5 82.031 (82.857)
Epoch: [25][200/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.3528 (2.5036)	Acc@1 57.031 (52.363)	Acc@5 85.938 (82.746)
Epoch: [25][210/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.7233 (2.5025)	Acc@1 47.656 (52.340)	Acc@5 74.219 (82.768)
Epoch: [25][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5126 (2.5062)	Acc@1 51.562 (52.270)	Acc@5 79.688 (82.703)
Epoch: [25][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3897 (2.5082)	Acc@1 50.781 (52.151)	Acc@5 86.719 (82.670)
Epoch: [25][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5963 (2.5108)	Acc@1 50.000 (52.107)	Acc@5 80.469 (82.621)
Epoch: [25][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4726 (2.5123)	Acc@1 53.125 (52.067)	Acc@5 85.156 (82.626)
Epoch: [25][260/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4994 (2.5157)	Acc@1 52.344 (51.982)	Acc@5 81.250 (82.519)
Epoch: [25][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4922 (2.5178)	Acc@1 56.250 (51.903)	Acc@5 81.250 (82.533)
Epoch: [25][280/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5088 (2.5201)	Acc@1 58.594 (51.838)	Acc@5 79.688 (82.501)
Epoch: [25][290/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4807 (2.5238)	Acc@1 53.906 (51.809)	Acc@5 84.375 (82.429)
Epoch: [25][300/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.8267 (2.5284)	Acc@1 35.156 (51.672)	Acc@5 80.469 (82.361)
Epoch: [25][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6172 (2.5303)	Acc@1 49.219 (51.668)	Acc@5 80.469 (82.313)
Epoch: [25][320/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.8198 (2.5325)	Acc@1 48.438 (51.604)	Acc@5 78.906 (82.272)
Epoch: [25][330/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.5333 (2.5346)	Acc@1 49.219 (51.551)	Acc@5 85.938 (82.248)
Epoch: [25][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5115 (2.5374)	Acc@1 52.344 (51.524)	Acc@5 79.688 (82.148)
Epoch: [25][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3977 (2.5385)	Acc@1 51.562 (51.460)	Acc@5 86.719 (82.116)
Epoch: [25][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4121 (2.5388)	Acc@1 55.469 (51.476)	Acc@5 85.938 (82.098)
Epoch: [25][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5529 (2.5393)	Acc@1 53.125 (51.476)	Acc@5 80.469 (82.107)
Epoch: [25][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7668 (2.5428)	Acc@1 42.188 (51.384)	Acc@5 79.688 (82.031)
Epoch: [25][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.9867 (2.5447)	Acc@1 45.000 (51.306)	Acc@5 73.750 (82.022)
num momentum params: 26
[0.1, 2.5446574353027342, 2.234374886751175, 51.306, 41.52, tensor(0.3058, device='cuda:0', grad_fn=<DivBackward0>), 5.226191520690918, 0.37743544578552246]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [26 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [26][0/391]	Time 0.035 (0.035)	Data 0.146 (0.146)	Loss 2.6381 (2.6381)	Acc@1 45.312 (45.312)	Acc@5 82.031 (82.031)
Epoch: [26][10/391]	Time 0.014 (0.015)	Data 0.001 (0.015)	Loss 2.5294 (2.5631)	Acc@1 49.219 (51.420)	Acc@5 82.812 (81.392)
Epoch: [26][20/391]	Time 0.013 (0.014)	Data 0.001 (0.008)	Loss 2.4566 (2.5342)	Acc@1 51.562 (51.562)	Acc@5 82.812 (81.994)
Epoch: [26][30/391]	Time 0.014 (0.014)	Data 0.001 (0.006)	Loss 2.3606 (2.5442)	Acc@1 57.031 (51.260)	Acc@5 83.594 (82.258)
Epoch: [26][40/391]	Time 0.013 (0.014)	Data 0.002 (0.005)	Loss 2.3900 (2.5175)	Acc@1 54.688 (51.753)	Acc@5 88.281 (82.812)
Epoch: [26][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.6870 (2.5282)	Acc@1 48.438 (51.486)	Acc@5 75.000 (82.353)
Epoch: [26][60/391]	Time 0.013 (0.013)	Data 0.001 (0.004)	Loss 2.8162 (2.5194)	Acc@1 43.750 (51.716)	Acc@5 74.219 (82.300)
Epoch: [26][70/391]	Time 0.013 (0.013)	Data 0.002 (0.004)	Loss 2.6526 (2.5263)	Acc@1 50.781 (51.375)	Acc@5 82.031 (82.427)
Epoch: [26][80/391]	Time 0.013 (0.013)	Data 0.002 (0.003)	Loss 2.4794 (2.5219)	Acc@1 53.906 (51.534)	Acc@5 79.688 (82.407)
Epoch: [26][90/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.5076 (2.5137)	Acc@1 53.125 (51.863)	Acc@5 84.375 (82.658)
Epoch: [26][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.5474 (2.5179)	Acc@1 51.562 (51.849)	Acc@5 80.469 (82.503)
Epoch: [26][110/391]	Time 0.013 (0.013)	Data 0.002 (0.003)	Loss 2.7473 (2.5240)	Acc@1 45.312 (51.738)	Acc@5 75.781 (82.447)
Epoch: [26][120/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.2959 (2.5278)	Acc@1 58.594 (51.705)	Acc@5 87.500 (82.341)
Epoch: [26][130/391]	Time 0.014 (0.013)	Data 0.002 (0.003)	Loss 2.5194 (2.5300)	Acc@1 49.219 (51.712)	Acc@5 83.594 (82.228)
Epoch: [26][140/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.2980 (2.5343)	Acc@1 57.031 (51.618)	Acc@5 86.719 (82.142)
Epoch: [26][150/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.3766 (2.5340)	Acc@1 52.344 (51.609)	Acc@5 83.594 (82.104)
Epoch: [26][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7313 (2.5313)	Acc@1 45.312 (51.655)	Acc@5 75.781 (82.148)
Epoch: [26][170/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5869 (2.5296)	Acc@1 50.781 (51.690)	Acc@5 82.031 (82.187)
Epoch: [26][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4205 (2.5276)	Acc@1 53.125 (51.714)	Acc@5 81.250 (82.161)
Epoch: [26][190/391]	Time 0.012 (0.013)	Data 0.002 (0.002)	Loss 2.4528 (2.5263)	Acc@1 50.781 (51.804)	Acc@5 85.938 (82.174)
Epoch: [26][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4897 (2.5277)	Acc@1 53.125 (51.765)	Acc@5 84.375 (82.148)
Epoch: [26][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5284 (2.5247)	Acc@1 54.688 (51.840)	Acc@5 83.594 (82.265)
Epoch: [26][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5127 (2.5292)	Acc@1 50.781 (51.750)	Acc@5 83.594 (82.204)
Epoch: [26][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6575 (2.5289)	Acc@1 50.000 (51.782)	Acc@5 78.906 (82.238)
Epoch: [26][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3756 (2.5291)	Acc@1 57.812 (51.874)	Acc@5 89.844 (82.158)
Epoch: [26][250/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4932 (2.5323)	Acc@1 50.781 (51.790)	Acc@5 83.594 (82.118)
Epoch: [26][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4188 (2.5328)	Acc@1 58.594 (51.835)	Acc@5 82.812 (82.097)
Epoch: [26][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5857 (2.5326)	Acc@1 53.125 (51.906)	Acc@5 84.375 (82.118)
Epoch: [26][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8932 (2.5379)	Acc@1 46.094 (51.740)	Acc@5 71.094 (82.042)
Epoch: [26][290/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.3302 (2.5413)	Acc@1 59.375 (51.697)	Acc@5 86.719 (81.978)
Epoch: [26][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6890 (2.5421)	Acc@1 50.000 (51.682)	Acc@5 79.688 (82.005)
Epoch: [26][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5709 (2.5418)	Acc@1 54.688 (51.696)	Acc@5 79.688 (81.981)
Epoch: [26][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.1907 (2.5388)	Acc@1 61.719 (51.765)	Acc@5 84.375 (82.017)
Epoch: [26][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9132 (2.5414)	Acc@1 42.188 (51.730)	Acc@5 78.125 (81.949)
Epoch: [26][340/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.4570 (2.5409)	Acc@1 51.562 (51.718)	Acc@5 86.719 (81.969)
Epoch: [26][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5433 (2.5409)	Acc@1 53.125 (51.716)	Acc@5 80.469 (81.956)
Epoch: [26][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4000 (2.5438)	Acc@1 50.000 (51.617)	Acc@5 89.844 (81.930)
Epoch: [26][370/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.7797 (2.5452)	Acc@1 48.438 (51.603)	Acc@5 76.562 (81.941)
Epoch: [26][380/391]	Time 0.016 (0.013)	Data 0.002 (0.002)	Loss 2.6913 (2.5467)	Acc@1 50.000 (51.569)	Acc@5 75.000 (81.927)
Epoch: [26][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.8213 (2.5482)	Acc@1 48.750 (51.558)	Acc@5 77.500 (81.924)
num momentum params: 26
[0.1, 2.548187424621582, 2.30406462430954, 51.558, 41.64, tensor(0.3063, device='cuda:0', grad_fn=<DivBackward0>), 5.208998441696167, 0.3938906192779541]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [27 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [27][0/391]	Time 0.032 (0.032)	Data 0.149 (0.149)	Loss 2.4614 (2.4614)	Acc@1 56.250 (56.250)	Acc@5 79.688 (79.688)
Epoch: [27][10/391]	Time 0.013 (0.015)	Data 0.002 (0.015)	Loss 2.4061 (2.4314)	Acc@1 55.469 (54.332)	Acc@5 84.375 (84.588)
Epoch: [27][20/391]	Time 0.013 (0.014)	Data 0.002 (0.008)	Loss 2.5382 (2.4594)	Acc@1 50.000 (53.832)	Acc@5 85.938 (84.226)
Epoch: [27][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.5644 (2.4626)	Acc@1 52.344 (53.654)	Acc@5 84.375 (84.199)
Epoch: [27][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.6081 (2.4753)	Acc@1 50.781 (53.163)	Acc@5 80.469 (84.070)
Epoch: [27][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.2831 (2.4745)	Acc@1 61.719 (53.309)	Acc@5 86.719 (83.977)
Epoch: [27][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4964 (2.4779)	Acc@1 56.250 (53.074)	Acc@5 83.594 (83.952)
Epoch: [27][70/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5018 (2.4821)	Acc@1 50.781 (52.971)	Acc@5 81.250 (83.726)
Epoch: [27][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4461 (2.4875)	Acc@1 52.344 (52.855)	Acc@5 86.719 (83.594)
Epoch: [27][90/391]	Time 0.014 (0.013)	Data 0.001 (0.003)	Loss 2.6404 (2.4969)	Acc@1 50.000 (52.670)	Acc@5 77.344 (83.371)
Epoch: [27][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.7809 (2.5042)	Acc@1 48.438 (52.468)	Acc@5 74.219 (83.184)
Epoch: [27][110/391]	Time 0.013 (0.013)	Data 0.002 (0.003)	Loss 2.5583 (2.5027)	Acc@1 55.469 (52.541)	Acc@5 80.469 (83.094)
Epoch: [27][120/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.7379 (2.5008)	Acc@1 44.531 (52.518)	Acc@5 78.125 (83.090)
Epoch: [27][130/391]	Time 0.014 (0.013)	Data 0.001 (0.003)	Loss 2.4593 (2.5036)	Acc@1 55.469 (52.421)	Acc@5 86.719 (83.039)
Epoch: [27][140/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5798 (2.5019)	Acc@1 47.656 (52.493)	Acc@5 82.812 (82.973)
Epoch: [27][150/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.3021 (2.5021)	Acc@1 58.594 (52.561)	Acc@5 82.812 (82.931)
Epoch: [27][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4721 (2.5040)	Acc@1 52.344 (52.514)	Acc@5 83.594 (82.919)
Epoch: [27][170/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.5105 (2.5058)	Acc@1 53.125 (52.458)	Acc@5 82.031 (82.895)
Epoch: [27][180/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.3753 (2.5012)	Acc@1 53.906 (52.525)	Acc@5 87.500 (83.007)
Epoch: [27][190/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.6014 (2.5051)	Acc@1 50.000 (52.385)	Acc@5 80.469 (82.935)
Epoch: [27][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5735 (2.5095)	Acc@1 52.344 (52.320)	Acc@5 82.031 (82.855)
Epoch: [27][210/391]	Time 0.016 (0.013)	Data 0.002 (0.002)	Loss 2.4031 (2.5128)	Acc@1 53.125 (52.229)	Acc@5 87.500 (82.801)
Epoch: [27][220/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.7058 (2.5146)	Acc@1 50.781 (52.231)	Acc@5 77.344 (82.721)
Epoch: [27][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2542 (2.5147)	Acc@1 59.375 (52.192)	Acc@5 88.281 (82.691)
Epoch: [27][240/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.4957 (2.5137)	Acc@1 52.344 (52.217)	Acc@5 80.469 (82.686)
Epoch: [27][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4643 (2.5154)	Acc@1 55.469 (52.235)	Acc@5 82.031 (82.620)
Epoch: [27][260/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.7827 (2.5170)	Acc@1 48.438 (52.212)	Acc@5 78.906 (82.585)
Epoch: [27][270/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.6536 (2.5216)	Acc@1 43.750 (52.041)	Acc@5 79.688 (82.527)
Epoch: [27][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7934 (2.5251)	Acc@1 49.219 (51.971)	Acc@5 77.344 (82.476)
Epoch: [27][290/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5764 (2.5256)	Acc@1 51.562 (51.936)	Acc@5 83.594 (82.469)
Epoch: [27][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5350 (2.5249)	Acc@1 50.781 (51.967)	Acc@5 83.594 (82.480)
Epoch: [27][310/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.2593 (2.5271)	Acc@1 60.156 (51.962)	Acc@5 86.719 (82.476)
Epoch: [27][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4013 (2.5276)	Acc@1 53.125 (51.945)	Acc@5 87.500 (82.482)
Epoch: [27][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5972 (2.5305)	Acc@1 51.562 (51.862)	Acc@5 82.812 (82.456)
Epoch: [27][340/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.3221 (2.5334)	Acc@1 54.688 (51.833)	Acc@5 84.375 (82.382)
Epoch: [27][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7506 (2.5345)	Acc@1 50.000 (51.823)	Acc@5 78.906 (82.378)
Epoch: [27][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7933 (2.5374)	Acc@1 41.406 (51.740)	Acc@5 71.094 (82.323)
Epoch: [27][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8263 (2.5390)	Acc@1 41.406 (51.710)	Acc@5 76.562 (82.292)
Epoch: [27][380/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.4479 (2.5403)	Acc@1 53.125 (51.673)	Acc@5 79.688 (82.247)
Epoch: [27][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.5147 (2.5397)	Acc@1 51.250 (51.698)	Acc@5 80.000 (82.210)
num momentum params: 26
[0.1, 2.539728727340698, 2.1087784612178804, 51.698, 44.94, tensor(0.3082, device='cuda:0', grad_fn=<DivBackward0>), 5.232835054397583, 0.37487101554870605]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [28 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [28][0/391]	Time 0.036 (0.036)	Data 0.135 (0.135)	Loss 2.3622 (2.3622)	Acc@1 59.375 (59.375)	Acc@5 84.375 (84.375)
Epoch: [28][10/391]	Time 0.013 (0.015)	Data 0.001 (0.014)	Loss 2.4590 (2.4427)	Acc@1 46.094 (53.693)	Acc@5 86.719 (84.730)
Epoch: [28][20/391]	Time 0.013 (0.014)	Data 0.001 (0.008)	Loss 2.6436 (2.4489)	Acc@1 45.312 (53.757)	Acc@5 83.594 (84.747)
Epoch: [28][30/391]	Time 0.015 (0.014)	Data 0.001 (0.006)	Loss 2.4393 (2.4660)	Acc@1 51.562 (53.301)	Acc@5 86.719 (84.148)
Epoch: [28][40/391]	Time 0.013 (0.014)	Data 0.002 (0.005)	Loss 2.5540 (2.4750)	Acc@1 47.656 (53.125)	Acc@5 83.594 (83.632)
Epoch: [28][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.7233 (2.4798)	Acc@1 48.438 (53.370)	Acc@5 81.250 (83.532)
Epoch: [28][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.6006 (2.4768)	Acc@1 46.094 (53.471)	Acc@5 84.375 (83.619)
Epoch: [28][70/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4466 (2.4687)	Acc@1 53.906 (53.532)	Acc@5 81.250 (83.704)
Epoch: [28][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6206 (2.4625)	Acc@1 50.781 (53.463)	Acc@5 82.031 (83.931)
Epoch: [28][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2821 (2.4536)	Acc@1 56.250 (53.726)	Acc@5 85.938 (84.126)
Epoch: [28][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4996 (2.4626)	Acc@1 53.906 (53.581)	Acc@5 82.812 (83.888)
Epoch: [28][110/391]	Time 0.013 (0.013)	Data 0.002 (0.003)	Loss 2.7293 (2.4697)	Acc@1 49.219 (53.533)	Acc@5 80.469 (83.847)
Epoch: [28][120/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.4580 (2.4699)	Acc@1 54.688 (53.648)	Acc@5 83.594 (83.723)
Epoch: [28][130/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.8649 (2.4797)	Acc@1 48.438 (53.411)	Acc@5 78.125 (83.510)
Epoch: [28][140/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.6182 (2.4842)	Acc@1 50.000 (53.385)	Acc@5 82.031 (83.383)
Epoch: [28][150/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.4962 (2.4895)	Acc@1 47.656 (53.120)	Acc@5 82.812 (83.247)
Epoch: [28][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4346 (2.4882)	Acc@1 55.469 (53.198)	Acc@5 82.812 (83.269)
Epoch: [28][170/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5621 (2.4958)	Acc@1 53.125 (52.974)	Acc@5 81.250 (83.091)
Epoch: [28][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5163 (2.5010)	Acc@1 53.125 (52.836)	Acc@5 82.031 (83.063)
Epoch: [28][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4710 (2.5044)	Acc@1 57.031 (52.753)	Acc@5 79.688 (82.980)
Epoch: [28][200/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4864 (2.5088)	Acc@1 53.125 (52.705)	Acc@5 85.938 (82.894)
Epoch: [28][210/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5210 (2.5082)	Acc@1 48.438 (52.744)	Acc@5 81.250 (82.920)
Epoch: [28][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4449 (2.5103)	Acc@1 52.344 (52.715)	Acc@5 85.156 (82.851)
Epoch: [28][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5673 (2.5110)	Acc@1 55.469 (52.679)	Acc@5 79.688 (82.873)
Epoch: [28][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6802 (2.5128)	Acc@1 42.969 (52.632)	Acc@5 81.250 (82.855)
Epoch: [28][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7658 (2.5147)	Acc@1 43.750 (52.534)	Acc@5 76.562 (82.800)
Epoch: [28][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5594 (2.5162)	Acc@1 51.562 (52.529)	Acc@5 83.594 (82.753)
Epoch: [28][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5945 (2.5157)	Acc@1 52.344 (52.560)	Acc@5 78.906 (82.778)
Epoch: [28][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6109 (2.5197)	Acc@1 52.344 (52.505)	Acc@5 80.469 (82.707)
Epoch: [28][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9285 (2.5230)	Acc@1 39.062 (52.403)	Acc@5 76.562 (82.657)
Epoch: [28][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8041 (2.5261)	Acc@1 47.656 (52.305)	Acc@5 77.344 (82.574)
Epoch: [28][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5288 (2.5307)	Acc@1 53.125 (52.170)	Acc@5 84.375 (82.529)
Epoch: [28][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2339 (2.5323)	Acc@1 58.594 (52.120)	Acc@5 84.375 (82.520)
Epoch: [28][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3645 (2.5325)	Acc@1 58.594 (52.094)	Acc@5 86.719 (82.513)
Epoch: [28][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5336 (2.5338)	Acc@1 53.125 (52.060)	Acc@5 84.375 (82.480)
Epoch: [28][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5388 (2.5353)	Acc@1 50.781 (52.054)	Acc@5 81.250 (82.439)
Epoch: [28][360/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5213 (2.5368)	Acc@1 55.469 (52.032)	Acc@5 80.469 (82.432)
Epoch: [28][370/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.7312 (2.5387)	Acc@1 49.219 (52.026)	Acc@5 80.469 (82.379)
Epoch: [28][380/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.6616 (2.5407)	Acc@1 48.438 (52.003)	Acc@5 81.250 (82.349)
Epoch: [28][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.6494 (2.5426)	Acc@1 51.250 (52.002)	Acc@5 83.750 (82.326)
num momentum params: 26
[0.1, 2.5425666284179687, 2.210657920837402, 52.002, 43.07, tensor(0.3088, device='cuda:0', grad_fn=<DivBackward0>), 5.22097373008728, 0.38445591926574707]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [29 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [29][0/391]	Time 0.040 (0.040)	Data 0.153 (0.153)	Loss 2.5855 (2.5855)	Acc@1 54.688 (54.688)	Acc@5 83.594 (83.594)
Epoch: [29][10/391]	Time 0.014 (0.016)	Data 0.001 (0.015)	Loss 2.4234 (2.4934)	Acc@1 55.469 (53.622)	Acc@5 82.812 (83.097)
Epoch: [29][20/391]	Time 0.013 (0.015)	Data 0.001 (0.009)	Loss 2.2789 (2.4846)	Acc@1 57.031 (52.567)	Acc@5 86.719 (83.259)
Epoch: [29][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.3513 (2.4548)	Acc@1 51.562 (53.427)	Acc@5 89.844 (83.720)
Epoch: [29][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.1667 (2.4364)	Acc@1 64.844 (54.345)	Acc@5 88.281 (84.089)
Epoch: [29][50/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.3387 (2.4264)	Acc@1 61.719 (54.611)	Acc@5 86.719 (84.145)
Epoch: [29][60/391]	Time 0.012 (0.014)	Data 0.001 (0.004)	Loss 2.3450 (2.4196)	Acc@1 54.688 (54.739)	Acc@5 85.156 (84.298)
Epoch: [29][70/391]	Time 0.014 (0.014)	Data 0.002 (0.004)	Loss 2.5272 (2.4283)	Acc@1 53.125 (54.654)	Acc@5 80.469 (84.111)
Epoch: [29][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2507 (2.4445)	Acc@1 56.250 (54.253)	Acc@5 89.062 (83.681)
Epoch: [29][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3551 (2.4496)	Acc@1 54.688 (54.232)	Acc@5 83.594 (83.654)
Epoch: [29][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.5879 (2.4530)	Acc@1 50.781 (54.123)	Acc@5 79.688 (83.578)
Epoch: [29][110/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.8214 (2.4579)	Acc@1 43.750 (53.963)	Acc@5 78.125 (83.404)
Epoch: [29][120/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.5373 (2.4575)	Acc@1 50.000 (53.829)	Acc@5 78.906 (83.407)
Epoch: [29][130/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.3832 (2.4574)	Acc@1 57.031 (53.805)	Acc@5 84.375 (83.415)
Epoch: [29][140/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.1999 (2.4538)	Acc@1 57.031 (53.906)	Acc@5 87.500 (83.444)
Epoch: [29][150/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5956 (2.4585)	Acc@1 53.125 (53.746)	Acc@5 78.125 (83.376)
Epoch: [29][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4467 (2.4635)	Acc@1 53.906 (53.615)	Acc@5 82.812 (83.303)
Epoch: [29][170/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6751 (2.4646)	Acc@1 47.656 (53.632)	Acc@5 81.250 (83.292)
Epoch: [29][180/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.6180 (2.4683)	Acc@1 46.094 (53.518)	Acc@5 82.031 (83.300)
Epoch: [29][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8660 (2.4737)	Acc@1 41.406 (53.362)	Acc@5 77.344 (83.217)
Epoch: [29][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5234 (2.4768)	Acc@1 55.469 (53.296)	Acc@5 85.156 (83.151)
Epoch: [29][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6029 (2.4811)	Acc@1 48.438 (53.203)	Acc@5 82.812 (83.079)
Epoch: [29][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6281 (2.4881)	Acc@1 51.562 (53.058)	Acc@5 82.031 (82.968)
Epoch: [29][230/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.6119 (2.4920)	Acc@1 45.312 (52.919)	Acc@5 80.469 (82.887)
Epoch: [29][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2875 (2.4969)	Acc@1 60.156 (52.817)	Acc@5 85.938 (82.800)
Epoch: [29][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5823 (2.5008)	Acc@1 50.000 (52.699)	Acc@5 82.812 (82.750)
Epoch: [29][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4162 (2.5027)	Acc@1 47.656 (52.664)	Acc@5 83.594 (82.693)
Epoch: [29][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6133 (2.5017)	Acc@1 53.125 (52.707)	Acc@5 77.344 (82.703)
Epoch: [29][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5457 (2.5066)	Acc@1 53.906 (52.625)	Acc@5 82.031 (82.618)
Epoch: [29][290/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5713 (2.5086)	Acc@1 55.469 (52.534)	Acc@5 82.812 (82.590)
Epoch: [29][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3548 (2.5080)	Acc@1 55.469 (52.551)	Acc@5 84.375 (82.589)
Epoch: [29][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5028 (2.5100)	Acc@1 52.344 (52.497)	Acc@5 81.250 (82.564)
Epoch: [29][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4110 (2.5100)	Acc@1 56.250 (52.524)	Acc@5 86.719 (82.555)
Epoch: [29][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4133 (2.5107)	Acc@1 53.906 (52.469)	Acc@5 85.938 (82.553)
Epoch: [29][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4644 (2.5137)	Acc@1 54.688 (52.408)	Acc@5 83.594 (82.538)
Epoch: [29][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6671 (2.5161)	Acc@1 46.875 (52.422)	Acc@5 78.906 (82.465)
Epoch: [29][360/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.7086 (2.5187)	Acc@1 46.875 (52.283)	Acc@5 78.125 (82.382)
Epoch: [29][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7019 (2.5195)	Acc@1 46.094 (52.243)	Acc@5 77.344 (82.381)
Epoch: [29][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5172 (2.5214)	Acc@1 47.656 (52.229)	Acc@5 83.594 (82.365)
Epoch: [29][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.8478 (2.5240)	Acc@1 45.000 (52.138)	Acc@5 78.750 (82.370)
num momentum params: 26
[0.1, 2.5239953005981444, 1.9572116363048553, 52.138, 47.98, tensor(0.3115, device='cuda:0', grad_fn=<DivBackward0>), 5.237196207046509, 0.37638092041015625]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [30 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [30][0/391]	Time 0.037 (0.037)	Data 0.154 (0.154)	Loss 2.2472 (2.2472)	Acc@1 58.594 (58.594)	Acc@5 88.281 (88.281)
Epoch: [30][10/391]	Time 0.013 (0.015)	Data 0.001 (0.015)	Loss 2.3050 (2.3143)	Acc@1 58.594 (56.889)	Acc@5 82.031 (85.724)
Epoch: [30][20/391]	Time 0.013 (0.015)	Data 0.001 (0.009)	Loss 2.2954 (2.4055)	Acc@1 58.594 (55.320)	Acc@5 85.938 (84.673)
Epoch: [30][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.2896 (2.4013)	Acc@1 57.812 (55.368)	Acc@5 86.719 (85.030)
Epoch: [30][40/391]	Time 0.014 (0.014)	Data 0.002 (0.005)	Loss 2.3493 (2.4026)	Acc@1 57.031 (55.164)	Acc@5 82.031 (84.661)
Epoch: [30][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.5472 (2.4185)	Acc@1 50.000 (54.642)	Acc@5 82.031 (84.099)
Epoch: [30][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4383 (2.4248)	Acc@1 53.125 (54.316)	Acc@5 82.812 (84.144)
Epoch: [30][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.5840 (2.4211)	Acc@1 50.781 (54.445)	Acc@5 80.469 (84.221)
Epoch: [30][80/391]	Time 0.011 (0.014)	Data 0.003 (0.003)	Loss 2.4157 (2.4255)	Acc@1 50.781 (54.205)	Acc@5 85.938 (84.115)
Epoch: [30][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.7581 (2.4415)	Acc@1 45.312 (53.855)	Acc@5 78.906 (83.851)
Epoch: [30][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4071 (2.4459)	Acc@1 51.562 (53.697)	Acc@5 85.156 (83.718)
Epoch: [30][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6061 (2.4559)	Acc@1 46.875 (53.414)	Acc@5 82.812 (83.587)
Epoch: [30][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5103 (2.4619)	Acc@1 52.344 (53.396)	Acc@5 85.938 (83.471)
Epoch: [30][130/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.8300 (2.4686)	Acc@1 51.562 (53.370)	Acc@5 78.125 (83.373)
Epoch: [30][140/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2297 (2.4728)	Acc@1 58.594 (53.441)	Acc@5 87.500 (83.267)
Epoch: [30][150/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2208 (2.4700)	Acc@1 60.938 (53.637)	Acc@5 90.625 (83.330)
Epoch: [30][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5048 (2.4672)	Acc@1 56.250 (53.775)	Acc@5 80.469 (83.385)
Epoch: [30][170/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3585 (2.4695)	Acc@1 54.688 (53.701)	Acc@5 87.500 (83.438)
Epoch: [30][180/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4064 (2.4680)	Acc@1 55.469 (53.785)	Acc@5 85.938 (83.447)
Epoch: [30][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2954 (2.4720)	Acc@1 53.906 (53.587)	Acc@5 89.062 (83.365)
Epoch: [30][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7602 (2.4800)	Acc@1 44.531 (53.424)	Acc@5 76.562 (83.147)
Epoch: [30][210/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.3190 (2.4793)	Acc@1 54.688 (53.410)	Acc@5 85.938 (83.127)
Epoch: [30][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5415 (2.4801)	Acc@1 49.219 (53.401)	Acc@5 82.031 (83.099)
Epoch: [30][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6422 (2.4846)	Acc@1 48.438 (53.335)	Acc@5 79.688 (83.005)
Epoch: [30][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2906 (2.4828)	Acc@1 55.469 (53.339)	Acc@5 87.500 (83.065)
Epoch: [30][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5818 (2.4838)	Acc@1 50.000 (53.330)	Acc@5 80.469 (83.052)
Epoch: [30][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6412 (2.4847)	Acc@1 54.688 (53.400)	Acc@5 81.250 (82.992)
Epoch: [30][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7868 (2.4876)	Acc@1 48.438 (53.286)	Acc@5 76.562 (82.960)
Epoch: [30][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6551 (2.4927)	Acc@1 50.000 (53.217)	Acc@5 78.906 (82.860)
Epoch: [30][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2937 (2.4916)	Acc@1 60.156 (53.265)	Acc@5 92.188 (82.904)
Epoch: [30][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6771 (2.4925)	Acc@1 50.781 (53.234)	Acc@5 84.375 (82.937)
Epoch: [30][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4708 (2.4947)	Acc@1 58.594 (53.223)	Acc@5 80.469 (82.873)
Epoch: [30][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3500 (2.4998)	Acc@1 55.469 (53.040)	Acc@5 82.031 (82.788)
Epoch: [30][330/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.6009 (2.5027)	Acc@1 50.000 (52.969)	Acc@5 78.125 (82.744)
Epoch: [30][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6839 (2.5040)	Acc@1 50.000 (52.955)	Acc@5 78.125 (82.719)
Epoch: [30][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7679 (2.5049)	Acc@1 49.219 (52.942)	Acc@5 81.250 (82.706)
Epoch: [30][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5782 (2.5078)	Acc@1 49.219 (52.852)	Acc@5 82.812 (82.650)
Epoch: [30][370/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5896 (2.5110)	Acc@1 53.125 (52.788)	Acc@5 82.031 (82.606)
Epoch: [30][380/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5992 (2.5142)	Acc@1 54.688 (52.746)	Acc@5 81.250 (82.562)
Epoch: [30][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.5742 (2.5157)	Acc@1 48.750 (52.668)	Acc@5 78.750 (82.530)
num momentum params: 26
[0.1, 2.51570686340332, 1.9884207987785338, 52.668, 46.97, tensor(0.3131, device='cuda:0', grad_fn=<DivBackward0>), 5.253805160522461, 0.38223886489868164]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [31 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [31][0/391]	Time 0.039 (0.039)	Data 0.148 (0.148)	Loss 2.4721 (2.4721)	Acc@1 55.469 (55.469)	Acc@5 84.375 (84.375)
Epoch: [31][10/391]	Time 0.013 (0.016)	Data 0.001 (0.015)	Loss 2.2156 (2.3536)	Acc@1 59.375 (56.747)	Acc@5 86.719 (85.511)
Epoch: [31][20/391]	Time 0.014 (0.015)	Data 0.001 (0.008)	Loss 2.6902 (2.4342)	Acc@1 52.344 (55.394)	Acc@5 79.688 (83.743)
Epoch: [31][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.4464 (2.4476)	Acc@1 53.906 (54.234)	Acc@5 85.938 (83.745)
Epoch: [31][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.4893 (2.4627)	Acc@1 53.125 (53.944)	Acc@5 82.031 (83.346)
Epoch: [31][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.2748 (2.4674)	Acc@1 60.156 (53.799)	Acc@5 84.375 (83.487)
Epoch: [31][60/391]	Time 0.015 (0.014)	Data 0.002 (0.004)	Loss 2.4569 (2.4700)	Acc@1 55.469 (53.893)	Acc@5 84.375 (83.402)
Epoch: [31][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.6317 (2.4811)	Acc@1 52.344 (53.719)	Acc@5 79.688 (83.275)
Epoch: [31][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3892 (2.4816)	Acc@1 56.250 (53.655)	Acc@5 84.375 (83.285)
Epoch: [31][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4153 (2.4799)	Acc@1 57.812 (53.649)	Acc@5 85.938 (83.491)
Epoch: [31][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.8722 (2.4834)	Acc@1 42.969 (53.566)	Acc@5 74.219 (83.338)
Epoch: [31][110/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.5552 (2.4850)	Acc@1 57.031 (53.554)	Acc@5 82.812 (83.354)
Epoch: [31][120/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.5743 (2.4832)	Acc@1 58.594 (53.506)	Acc@5 82.812 (83.419)
Epoch: [31][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6922 (2.4839)	Acc@1 49.219 (53.548)	Acc@5 79.688 (83.361)
Epoch: [31][140/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6381 (2.4801)	Acc@1 49.219 (53.446)	Acc@5 83.594 (83.400)
Epoch: [31][150/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4213 (2.4750)	Acc@1 53.906 (53.534)	Acc@5 85.156 (83.459)
Epoch: [31][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5133 (2.4753)	Acc@1 51.562 (53.513)	Acc@5 84.375 (83.443)
Epoch: [31][170/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7001 (2.4798)	Acc@1 48.438 (53.299)	Acc@5 78.906 (83.361)
Epoch: [31][180/391]	Time 0.011 (0.013)	Data 0.001 (0.002)	Loss 2.4474 (2.4902)	Acc@1 56.250 (53.121)	Acc@5 81.250 (83.188)
Epoch: [31][190/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.3740 (2.4928)	Acc@1 56.250 (53.105)	Acc@5 87.500 (83.148)
Epoch: [31][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4197 (2.4955)	Acc@1 53.906 (53.113)	Acc@5 87.500 (83.034)
Epoch: [31][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2769 (2.4917)	Acc@1 61.719 (53.262)	Acc@5 87.500 (83.112)
Epoch: [31][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4474 (2.4911)	Acc@1 56.250 (53.259)	Acc@5 82.031 (83.127)
Epoch: [31][230/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.2863 (2.4923)	Acc@1 54.688 (53.169)	Acc@5 88.281 (83.127)
Epoch: [31][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7144 (2.4942)	Acc@1 46.875 (53.099)	Acc@5 77.344 (83.082)
Epoch: [31][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7824 (2.4976)	Acc@1 48.438 (53.041)	Acc@5 79.688 (83.052)
Epoch: [31][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3802 (2.5017)	Acc@1 54.688 (52.993)	Acc@5 84.375 (82.992)
Epoch: [31][270/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.5229 (2.5030)	Acc@1 47.656 (52.906)	Acc@5 84.375 (82.971)
Epoch: [31][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6408 (2.5021)	Acc@1 46.875 (52.891)	Acc@5 81.250 (82.990)
Epoch: [31][290/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4770 (2.5012)	Acc@1 55.469 (52.910)	Acc@5 79.688 (82.976)
Epoch: [31][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6284 (2.5019)	Acc@1 47.656 (52.941)	Acc@5 79.688 (82.929)
Epoch: [31][310/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.3512 (2.5013)	Acc@1 55.469 (52.889)	Acc@5 85.156 (82.978)
Epoch: [31][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5333 (2.5020)	Acc@1 53.906 (52.879)	Acc@5 82.031 (82.988)
Epoch: [31][330/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.8429 (2.5053)	Acc@1 47.656 (52.858)	Acc@5 75.000 (82.912)
Epoch: [31][340/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.5015 (2.5086)	Acc@1 52.344 (52.754)	Acc@5 83.594 (82.893)
Epoch: [31][350/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.7667 (2.5119)	Acc@1 46.875 (52.669)	Acc@5 82.812 (82.824)
Epoch: [31][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6427 (2.5126)	Acc@1 53.125 (52.694)	Acc@5 82.812 (82.774)
Epoch: [31][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6607 (2.5139)	Acc@1 50.781 (52.668)	Acc@5 79.688 (82.726)
Epoch: [31][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6421 (2.5141)	Acc@1 48.438 (52.666)	Acc@5 78.125 (82.710)
Epoch: [31][390/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.5546 (2.5173)	Acc@1 48.750 (52.554)	Acc@5 78.750 (82.634)
num momentum params: 26
[0.1, 2.5173175748443604, 2.1903391242027284, 52.554, 43.55, tensor(0.3128, device='cuda:0', grad_fn=<DivBackward0>), 5.232163429260254, 0.38328099250793457]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [32 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [32][0/391]	Time 0.040 (0.040)	Data 0.141 (0.141)	Loss 2.3848 (2.3848)	Acc@1 53.125 (53.125)	Acc@5 85.156 (85.156)
Epoch: [32][10/391]	Time 0.013 (0.016)	Data 0.001 (0.014)	Loss 2.5377 (2.4228)	Acc@1 51.562 (54.545)	Acc@5 83.594 (83.878)
Epoch: [32][20/391]	Time 0.013 (0.015)	Data 0.001 (0.008)	Loss 2.3370 (2.4215)	Acc@1 57.031 (54.353)	Acc@5 87.500 (84.226)
Epoch: [32][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.6100 (2.4095)	Acc@1 55.469 (55.217)	Acc@5 82.812 (84.652)
Epoch: [32][40/391]	Time 0.014 (0.014)	Data 0.001 (0.005)	Loss 2.6670 (2.4130)	Acc@1 49.219 (54.897)	Acc@5 79.688 (84.413)
Epoch: [32][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3987 (2.4089)	Acc@1 53.906 (55.025)	Acc@5 81.250 (84.252)
Epoch: [32][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.7360 (2.4135)	Acc@1 45.312 (54.700)	Acc@5 81.250 (84.375)
Epoch: [32][70/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3710 (2.4265)	Acc@1 57.031 (54.511)	Acc@5 89.062 (84.001)
Epoch: [32][80/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4481 (2.4242)	Acc@1 56.250 (54.688)	Acc@5 85.156 (83.931)
Epoch: [32][90/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.7717 (2.4278)	Acc@1 45.312 (54.645)	Acc@5 82.031 (83.920)
Epoch: [32][100/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.7321 (2.4506)	Acc@1 49.219 (54.216)	Acc@5 78.906 (83.493)
Epoch: [32][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3553 (2.4499)	Acc@1 58.594 (54.258)	Acc@5 84.375 (83.460)
Epoch: [32][120/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.3048 (2.4586)	Acc@1 53.125 (54.010)	Acc@5 88.281 (83.374)
Epoch: [32][130/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2961 (2.4608)	Acc@1 58.594 (53.823)	Acc@5 86.719 (83.379)
Epoch: [32][140/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2670 (2.4672)	Acc@1 60.156 (53.568)	Acc@5 87.500 (83.306)
Epoch: [32][150/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6447 (2.4741)	Acc@1 45.312 (53.347)	Acc@5 81.250 (83.320)
Epoch: [32][160/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.2858 (2.4727)	Acc@1 57.031 (53.319)	Acc@5 85.938 (83.395)
Epoch: [32][170/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3095 (2.4707)	Acc@1 53.125 (53.436)	Acc@5 85.156 (83.416)
Epoch: [32][180/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.4197 (2.4701)	Acc@1 55.469 (53.419)	Acc@5 84.375 (83.400)
Epoch: [32][190/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.3996 (2.4726)	Acc@1 51.562 (53.362)	Acc@5 88.281 (83.332)
Epoch: [32][200/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.6814 (2.4767)	Acc@1 49.219 (53.211)	Acc@5 79.688 (83.283)
Epoch: [32][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6831 (2.4780)	Acc@1 50.000 (53.206)	Acc@5 78.125 (83.253)
Epoch: [32][220/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.1109 (2.4780)	Acc@1 63.281 (53.189)	Acc@5 90.625 (83.276)
Epoch: [32][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8313 (2.4812)	Acc@1 49.219 (53.145)	Acc@5 75.000 (83.201)
Epoch: [32][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4002 (2.4800)	Acc@1 54.688 (53.216)	Acc@5 83.594 (83.211)
Epoch: [32][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4902 (2.4823)	Acc@1 56.250 (53.215)	Acc@5 81.250 (83.164)
Epoch: [32][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7616 (2.4824)	Acc@1 45.312 (53.227)	Acc@5 78.906 (83.214)
Epoch: [32][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5281 (2.4824)	Acc@1 53.906 (53.206)	Acc@5 82.812 (83.222)
Epoch: [32][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5260 (2.4831)	Acc@1 51.562 (53.122)	Acc@5 78.906 (83.210)
Epoch: [32][290/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4508 (2.4847)	Acc@1 58.594 (53.085)	Acc@5 83.594 (83.202)
Epoch: [32][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6556 (2.4876)	Acc@1 50.781 (53.070)	Acc@5 77.344 (83.147)
Epoch: [32][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5635 (2.4882)	Acc@1 47.656 (52.999)	Acc@5 80.469 (83.134)
Epoch: [32][320/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.7532 (2.4935)	Acc@1 47.656 (52.918)	Acc@5 78.125 (83.041)
Epoch: [32][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5486 (2.4962)	Acc@1 49.219 (52.813)	Acc@5 82.031 (82.999)
Epoch: [32][340/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.7076 (2.4969)	Acc@1 50.781 (52.834)	Acc@5 81.250 (83.003)
Epoch: [32][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6073 (2.4954)	Acc@1 53.125 (52.896)	Acc@5 79.688 (83.002)
Epoch: [32][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5875 (2.4964)	Acc@1 53.125 (52.893)	Acc@5 77.344 (82.964)
Epoch: [32][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5350 (2.4972)	Acc@1 50.781 (52.855)	Acc@5 80.469 (82.954)
Epoch: [32][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4741 (2.4988)	Acc@1 57.812 (52.852)	Acc@5 81.250 (82.882)
Epoch: [32][390/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.7290 (2.5023)	Acc@1 51.250 (52.804)	Acc@5 75.000 (82.782)
num momentum params: 26
[0.1, 2.5023168410491943, 2.3746041369438173, 52.804, 42.74, tensor(0.3151, device='cuda:0', grad_fn=<DivBackward0>), 5.225116729736328, 0.3829371929168701]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [33 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [33][0/391]	Time 0.037 (0.037)	Data 0.155 (0.155)	Loss 2.3600 (2.3600)	Acc@1 58.594 (58.594)	Acc@5 85.938 (85.938)
Epoch: [33][10/391]	Time 0.013 (0.016)	Data 0.001 (0.015)	Loss 2.4820 (2.4514)	Acc@1 57.031 (54.901)	Acc@5 84.375 (84.801)
Epoch: [33][20/391]	Time 0.013 (0.015)	Data 0.001 (0.009)	Loss 2.4845 (2.4396)	Acc@1 53.906 (53.906)	Acc@5 83.594 (84.673)
Epoch: [33][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.3234 (2.4441)	Acc@1 53.906 (54.032)	Acc@5 89.062 (84.703)
Epoch: [33][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.5634 (2.4349)	Acc@1 48.438 (53.963)	Acc@5 83.594 (84.966)
Epoch: [33][50/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.4668 (2.4477)	Acc@1 50.781 (53.631)	Acc@5 83.594 (84.513)
Epoch: [33][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3668 (2.4409)	Acc@1 53.125 (53.919)	Acc@5 88.281 (84.413)
Epoch: [33][70/391]	Time 0.012 (0.014)	Data 0.001 (0.004)	Loss 2.3735 (2.4370)	Acc@1 54.688 (53.807)	Acc@5 82.812 (84.408)
Epoch: [33][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5263 (2.4441)	Acc@1 49.219 (53.646)	Acc@5 82.031 (84.307)
Epoch: [33][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6543 (2.4502)	Acc@1 42.969 (53.640)	Acc@5 81.250 (84.083)
Epoch: [33][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3782 (2.4494)	Acc@1 55.469 (53.666)	Acc@5 86.719 (84.011)
Epoch: [33][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4800 (2.4515)	Acc@1 50.781 (53.604)	Acc@5 82.031 (83.854)
Epoch: [33][120/391]	Time 0.014 (0.013)	Data 0.001 (0.003)	Loss 2.4533 (2.4462)	Acc@1 56.250 (53.771)	Acc@5 85.156 (83.955)
Epoch: [33][130/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.6169 (2.4521)	Acc@1 50.781 (53.781)	Acc@5 82.812 (83.779)
Epoch: [33][140/391]	Time 0.014 (0.013)	Data 0.001 (0.003)	Loss 2.7105 (2.4574)	Acc@1 50.000 (53.685)	Acc@5 82.812 (83.749)
Epoch: [33][150/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3896 (2.4631)	Acc@1 51.562 (53.627)	Acc@5 84.375 (83.599)
Epoch: [33][160/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4769 (2.4691)	Acc@1 50.781 (53.455)	Acc@5 82.031 (83.463)
Epoch: [33][170/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7316 (2.4731)	Acc@1 46.875 (53.335)	Acc@5 79.688 (83.429)
Epoch: [33][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9162 (2.4804)	Acc@1 46.875 (53.185)	Acc@5 77.344 (83.283)
Epoch: [33][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7270 (2.4826)	Acc@1 46.094 (53.109)	Acc@5 75.781 (83.275)
Epoch: [33][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7282 (2.4833)	Acc@1 51.562 (53.094)	Acc@5 79.688 (83.240)
Epoch: [33][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5284 (2.4854)	Acc@1 53.125 (52.992)	Acc@5 80.469 (83.253)
Epoch: [33][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5994 (2.4852)	Acc@1 52.344 (52.945)	Acc@5 83.594 (83.318)
Epoch: [33][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6787 (2.4874)	Acc@1 48.438 (52.919)	Acc@5 75.781 (83.252)
Epoch: [33][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3713 (2.4876)	Acc@1 55.469 (52.892)	Acc@5 82.812 (83.270)
Epoch: [33][250/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.2727 (2.4867)	Acc@1 55.469 (52.879)	Acc@5 85.156 (83.273)
Epoch: [33][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4290 (2.4895)	Acc@1 51.562 (52.820)	Acc@5 85.156 (83.199)
Epoch: [33][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6070 (2.4915)	Acc@1 51.562 (52.765)	Acc@5 82.031 (83.144)
Epoch: [33][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3820 (2.4951)	Acc@1 57.031 (52.752)	Acc@5 88.281 (83.104)
Epoch: [33][290/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5310 (2.4974)	Acc@1 44.531 (52.682)	Acc@5 83.594 (83.062)
Epoch: [33][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5791 (2.4998)	Acc@1 48.438 (52.629)	Acc@5 83.594 (83.044)
Epoch: [33][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5909 (2.5006)	Acc@1 50.000 (52.663)	Acc@5 77.344 (82.991)
Epoch: [33][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6778 (2.5011)	Acc@1 51.562 (52.692)	Acc@5 78.125 (82.971)
Epoch: [33][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5275 (2.5016)	Acc@1 49.219 (52.679)	Acc@5 85.156 (82.952)
Epoch: [33][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5750 (2.5022)	Acc@1 47.656 (52.681)	Acc@5 82.031 (82.922)
Epoch: [33][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4602 (2.5016)	Acc@1 51.562 (52.664)	Acc@5 81.250 (82.922)
Epoch: [33][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9123 (2.5066)	Acc@1 48.438 (52.582)	Acc@5 75.781 (82.817)
Epoch: [33][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5231 (2.5087)	Acc@1 53.125 (52.552)	Acc@5 84.375 (82.783)
Epoch: [33][380/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4129 (2.5085)	Acc@1 60.156 (52.567)	Acc@5 81.250 (82.776)
Epoch: [33][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.5088 (2.5082)	Acc@1 53.750 (52.580)	Acc@5 83.750 (82.798)
num momentum params: 26
[0.1, 2.5082083728790283, 2.2073500084877016, 52.58, 44.4, tensor(0.3153, device='cuda:0', grad_fn=<DivBackward0>), 5.213999032974243, 0.38457560539245605]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [34 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [34][0/391]	Time 0.042 (0.042)	Data 0.161 (0.161)	Loss 2.4595 (2.4595)	Acc@1 51.562 (51.562)	Acc@5 86.719 (86.719)
Epoch: [34][10/391]	Time 0.014 (0.016)	Data 0.001 (0.016)	Loss 2.2500 (2.4213)	Acc@1 61.719 (55.469)	Acc@5 85.938 (84.091)
Epoch: [34][20/391]	Time 0.013 (0.015)	Data 0.001 (0.009)	Loss 2.3177 (2.4199)	Acc@1 53.906 (55.357)	Acc@5 86.719 (84.003)
Epoch: [34][30/391]	Time 0.013 (0.014)	Data 0.001 (0.007)	Loss 2.2585 (2.3997)	Acc@1 57.031 (55.242)	Acc@5 85.938 (84.955)
Epoch: [34][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.2604 (2.4020)	Acc@1 57.812 (55.373)	Acc@5 89.844 (84.832)
Epoch: [34][50/391]	Time 0.013 (0.014)	Data 0.002 (0.005)	Loss 2.3646 (2.4158)	Acc@1 54.688 (55.101)	Acc@5 81.250 (84.390)
Epoch: [34][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.5621 (2.4435)	Acc@1 50.781 (54.175)	Acc@5 81.250 (84.080)
Epoch: [34][70/391]	Time 0.014 (0.014)	Data 0.002 (0.004)	Loss 2.3417 (2.4448)	Acc@1 61.719 (54.060)	Acc@5 81.250 (83.924)
Epoch: [34][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4017 (2.4518)	Acc@1 51.562 (53.733)	Acc@5 86.719 (83.767)
Epoch: [34][90/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2579 (2.4547)	Acc@1 58.594 (53.657)	Acc@5 84.375 (83.817)
Epoch: [34][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5421 (2.4620)	Acc@1 48.438 (53.597)	Acc@5 80.469 (83.733)
Epoch: [34][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4026 (2.4629)	Acc@1 60.156 (53.611)	Acc@5 80.469 (83.678)
Epoch: [34][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5821 (2.4738)	Acc@1 50.000 (53.370)	Acc@5 82.812 (83.542)
Epoch: [34][130/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4533 (2.4720)	Acc@1 50.000 (53.393)	Acc@5 84.375 (83.540)
Epoch: [34][140/391]	Time 0.010 (0.014)	Data 0.004 (0.003)	Loss 2.4879 (2.4739)	Acc@1 52.344 (53.385)	Acc@5 82.031 (83.466)
Epoch: [34][150/391]	Time 0.016 (0.014)	Data 0.001 (0.003)	Loss 2.4530 (2.4771)	Acc@1 55.469 (53.389)	Acc@5 76.562 (83.366)
Epoch: [34][160/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4711 (2.4747)	Acc@1 50.781 (53.474)	Acc@5 82.031 (83.414)
Epoch: [34][170/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5339 (2.4724)	Acc@1 53.906 (53.550)	Acc@5 84.375 (83.438)
Epoch: [34][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5306 (2.4768)	Acc@1 56.250 (53.509)	Acc@5 83.594 (83.369)
Epoch: [34][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4543 (2.4804)	Acc@1 52.344 (53.424)	Acc@5 83.594 (83.258)
Epoch: [34][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3918 (2.4782)	Acc@1 60.156 (53.584)	Acc@5 83.594 (83.267)
Epoch: [34][210/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4243 (2.4803)	Acc@1 52.344 (53.547)	Acc@5 82.812 (83.227)
Epoch: [34][220/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4732 (2.4849)	Acc@1 53.125 (53.454)	Acc@5 82.031 (83.109)
Epoch: [34][230/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.3053 (2.4822)	Acc@1 60.156 (53.487)	Acc@5 86.719 (83.181)
Epoch: [34][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6833 (2.4860)	Acc@1 50.000 (53.443)	Acc@5 78.906 (83.078)
Epoch: [34][250/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.6763 (2.4853)	Acc@1 52.344 (53.427)	Acc@5 80.469 (83.136)
Epoch: [34][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4035 (2.4862)	Acc@1 54.688 (53.409)	Acc@5 85.156 (83.115)
Epoch: [34][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4098 (2.4882)	Acc@1 52.344 (53.393)	Acc@5 86.719 (83.063)
Epoch: [34][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5837 (2.4875)	Acc@1 48.438 (53.420)	Acc@5 82.812 (83.074)
Epoch: [34][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4874 (2.4864)	Acc@1 57.812 (53.498)	Acc@5 82.031 (83.068)
Epoch: [34][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5539 (2.4901)	Acc@1 51.562 (53.416)	Acc@5 82.812 (82.979)
Epoch: [34][310/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.5435 (2.4957)	Acc@1 54.688 (53.258)	Acc@5 81.250 (82.910)
Epoch: [34][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4108 (2.4955)	Acc@1 56.250 (53.227)	Acc@5 85.156 (82.927)
Epoch: [34][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4944 (2.4978)	Acc@1 55.469 (53.215)	Acc@5 82.031 (82.857)
Epoch: [34][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5258 (2.4999)	Acc@1 44.531 (53.162)	Acc@5 90.625 (82.858)
Epoch: [34][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7219 (2.5027)	Acc@1 48.438 (53.125)	Acc@5 80.469 (82.828)
Epoch: [34][360/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.6034 (2.5023)	Acc@1 46.094 (53.125)	Acc@5 80.469 (82.851)
Epoch: [34][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3781 (2.5052)	Acc@1 60.938 (53.039)	Acc@5 87.500 (82.791)
Epoch: [34][380/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5031 (2.5047)	Acc@1 57.812 (53.072)	Acc@5 84.375 (82.780)
Epoch: [34][390/391]	Time 0.015 (0.013)	Data 0.002 (0.002)	Loss 2.4782 (2.5064)	Acc@1 53.750 (53.030)	Acc@5 81.250 (82.760)
num momentum params: 26
[0.1, 2.506356047592163, 2.1144228160381315, 53.03, 44.34, tensor(0.3161, device='cuda:0', grad_fn=<DivBackward0>), 5.243644952774048, 0.3843238353729248]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [35 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [35][0/391]	Time 0.040 (0.040)	Data 0.145 (0.145)	Loss 2.3994 (2.3994)	Acc@1 54.688 (54.688)	Acc@5 84.375 (84.375)
Epoch: [35][10/391]	Time 0.013 (0.016)	Data 0.001 (0.014)	Loss 2.5213 (2.4237)	Acc@1 55.469 (55.611)	Acc@5 79.688 (83.452)
Epoch: [35][20/391]	Time 0.013 (0.015)	Data 0.002 (0.008)	Loss 2.4422 (2.4090)	Acc@1 49.219 (56.064)	Acc@5 82.031 (83.482)
Epoch: [35][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.4180 (2.4230)	Acc@1 52.344 (55.091)	Acc@5 90.625 (83.745)
Epoch: [35][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.3785 (2.4046)	Acc@1 55.469 (55.316)	Acc@5 84.375 (84.184)
Epoch: [35][50/391]	Time 0.012 (0.014)	Data 0.002 (0.004)	Loss 2.5216 (2.4022)	Acc@1 55.469 (55.591)	Acc@5 82.812 (84.252)
Epoch: [35][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.5252 (2.4127)	Acc@1 53.125 (55.085)	Acc@5 82.812 (84.119)
Epoch: [35][70/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2954 (2.4070)	Acc@1 56.250 (55.403)	Acc@5 89.844 (84.320)
Epoch: [35][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4788 (2.4122)	Acc@1 51.562 (55.285)	Acc@5 85.156 (84.279)
Epoch: [35][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3468 (2.4233)	Acc@1 54.688 (55.091)	Acc@5 85.156 (84.049)
Epoch: [35][100/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.6942 (2.4321)	Acc@1 49.219 (54.889)	Acc@5 75.000 (83.957)
Epoch: [35][110/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.2443 (2.4259)	Acc@1 60.938 (54.969)	Acc@5 89.062 (84.072)
Epoch: [35][120/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.4235 (2.4309)	Acc@1 59.375 (54.797)	Acc@5 85.938 (84.084)
Epoch: [35][130/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.3242 (2.4308)	Acc@1 61.719 (54.854)	Acc@5 81.250 (84.065)
Epoch: [35][140/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3808 (2.4348)	Acc@1 60.938 (54.832)	Acc@5 88.281 (84.031)
Epoch: [35][150/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.6739 (2.4431)	Acc@1 48.438 (54.672)	Acc@5 80.469 (83.873)
Epoch: [35][160/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5281 (2.4458)	Acc@1 52.344 (54.527)	Acc@5 84.375 (83.817)
Epoch: [35][170/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.7369 (2.4504)	Acc@1 53.125 (54.409)	Acc@5 79.688 (83.776)
Epoch: [35][180/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5906 (2.4533)	Acc@1 53.906 (54.390)	Acc@5 83.594 (83.732)
Epoch: [35][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5065 (2.4522)	Acc@1 52.344 (54.446)	Acc@5 82.812 (83.766)
Epoch: [35][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5603 (2.4534)	Acc@1 50.000 (54.400)	Acc@5 81.250 (83.683)
Epoch: [35][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5113 (2.4583)	Acc@1 56.250 (54.328)	Acc@5 81.250 (83.590)
Epoch: [35][220/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.4374 (2.4604)	Acc@1 51.562 (54.320)	Acc@5 82.031 (83.573)
Epoch: [35][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5002 (2.4624)	Acc@1 51.562 (54.322)	Acc@5 85.156 (83.543)
Epoch: [35][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5247 (2.4630)	Acc@1 53.125 (54.302)	Acc@5 80.469 (83.516)
Epoch: [35][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4498 (2.4630)	Acc@1 56.250 (54.255)	Acc@5 85.938 (83.510)
Epoch: [35][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4369 (2.4633)	Acc@1 50.781 (54.227)	Acc@5 85.938 (83.540)
Epoch: [35][270/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.4979 (2.4625)	Acc@1 50.781 (54.244)	Acc@5 82.031 (83.525)
Epoch: [35][280/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.2646 (2.4621)	Acc@1 56.250 (54.190)	Acc@5 89.062 (83.546)
Epoch: [35][290/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.7844 (2.4654)	Acc@1 47.656 (54.191)	Acc@5 80.469 (83.492)
Epoch: [35][300/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5178 (2.4665)	Acc@1 49.219 (54.109)	Acc@5 79.688 (83.487)
Epoch: [35][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5410 (2.4712)	Acc@1 54.688 (53.997)	Acc@5 80.469 (83.408)
Epoch: [35][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4927 (2.4716)	Acc@1 51.562 (53.974)	Acc@5 85.938 (83.450)
Epoch: [35][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5109 (2.4733)	Acc@1 51.562 (53.913)	Acc@5 80.469 (83.381)
Epoch: [35][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6102 (2.4752)	Acc@1 52.344 (53.920)	Acc@5 82.812 (83.333)
Epoch: [35][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4779 (2.4755)	Acc@1 53.125 (53.900)	Acc@5 82.031 (83.313)
Epoch: [35][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4011 (2.4778)	Acc@1 57.812 (53.831)	Acc@5 82.031 (83.282)
Epoch: [35][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6635 (2.4798)	Acc@1 50.000 (53.765)	Acc@5 78.906 (83.276)
Epoch: [35][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4309 (2.4819)	Acc@1 51.562 (53.722)	Acc@5 86.719 (83.249)
Epoch: [35][390/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.6562 (2.4838)	Acc@1 51.250 (53.634)	Acc@5 78.750 (83.230)
num momentum params: 26
[0.1, 2.4837547172546386, 2.1802875804901123, 53.634, 44.83, tensor(0.3192, device='cuda:0', grad_fn=<DivBackward0>), 5.2278077602386475, 0.3857419490814209]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [36 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [36][0/391]	Time 0.043 (0.043)	Data 0.146 (0.146)	Loss 2.7240 (2.7240)	Acc@1 46.875 (46.875)	Acc@5 78.906 (78.906)
Epoch: [36][10/391]	Time 0.013 (0.016)	Data 0.001 (0.014)	Loss 2.2968 (2.4680)	Acc@1 57.812 (53.622)	Acc@5 85.938 (82.599)
Epoch: [36][20/391]	Time 0.013 (0.015)	Data 0.001 (0.008)	Loss 2.4374 (2.4831)	Acc@1 54.688 (53.720)	Acc@5 85.938 (82.254)
Epoch: [36][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.1485 (2.4507)	Acc@1 64.062 (54.612)	Acc@5 89.062 (83.090)
Epoch: [36][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.5128 (2.4288)	Acc@1 53.125 (55.183)	Acc@5 84.375 (83.632)
Epoch: [36][50/391]	Time 0.011 (0.014)	Data 0.004 (0.004)	Loss 2.4898 (2.4283)	Acc@1 50.781 (54.902)	Acc@5 84.375 (83.900)
Epoch: [36][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3032 (2.4207)	Acc@1 63.281 (55.136)	Acc@5 85.156 (84.068)
Epoch: [36][70/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.5317 (2.4281)	Acc@1 47.656 (54.886)	Acc@5 81.250 (83.891)
Epoch: [36][80/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4813 (2.4317)	Acc@1 53.906 (54.880)	Acc@5 83.594 (83.661)
Epoch: [36][90/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3389 (2.4413)	Acc@1 58.594 (54.524)	Acc@5 85.938 (83.654)
Epoch: [36][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5822 (2.4546)	Acc@1 55.469 (54.169)	Acc@5 78.906 (83.408)
Epoch: [36][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3940 (2.4532)	Acc@1 53.125 (54.202)	Acc@5 85.156 (83.446)
Epoch: [36][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3883 (2.4613)	Acc@1 59.375 (53.990)	Acc@5 82.812 (83.374)
Epoch: [36][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6399 (2.4658)	Acc@1 51.562 (53.882)	Acc@5 77.344 (83.278)
Epoch: [36][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3925 (2.4705)	Acc@1 53.906 (53.685)	Acc@5 84.375 (83.234)
Epoch: [36][150/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5087 (2.4712)	Acc@1 57.812 (53.617)	Acc@5 81.250 (83.206)
Epoch: [36][160/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5739 (2.4769)	Acc@1 49.219 (53.445)	Acc@5 82.812 (83.089)
Epoch: [36][170/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4738 (2.4829)	Acc@1 53.906 (53.267)	Acc@5 83.594 (83.000)
Epoch: [36][180/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.5632 (2.4809)	Acc@1 53.125 (53.319)	Acc@5 81.250 (83.037)
Epoch: [36][190/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.3885 (2.4783)	Acc@1 51.562 (53.309)	Acc@5 86.719 (83.111)
Epoch: [36][200/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.3539 (2.4794)	Acc@1 57.031 (53.308)	Acc@5 89.062 (83.155)
Epoch: [36][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4751 (2.4828)	Acc@1 53.906 (53.258)	Acc@5 82.031 (83.090)
Epoch: [36][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4679 (2.4821)	Acc@1 53.125 (53.284)	Acc@5 85.156 (83.095)
Epoch: [36][230/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.3293 (2.4822)	Acc@1 61.719 (53.267)	Acc@5 85.938 (83.124)
Epoch: [36][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3846 (2.4808)	Acc@1 54.688 (53.287)	Acc@5 82.812 (83.124)
Epoch: [36][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4881 (2.4779)	Acc@1 52.344 (53.355)	Acc@5 84.375 (83.152)
Epoch: [36][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4743 (2.4791)	Acc@1 54.688 (53.418)	Acc@5 82.812 (83.115)
Epoch: [36][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5397 (2.4836)	Acc@1 53.906 (53.318)	Acc@5 83.594 (83.026)
Epoch: [36][280/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.3106 (2.4864)	Acc@1 54.688 (53.222)	Acc@5 85.156 (83.002)
Epoch: [36][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7342 (2.4902)	Acc@1 46.875 (53.200)	Acc@5 75.781 (82.933)
Epoch: [36][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4535 (2.4912)	Acc@1 51.562 (53.192)	Acc@5 83.594 (82.919)
Epoch: [36][310/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.3284 (2.4887)	Acc@1 57.031 (53.238)	Acc@5 88.281 (82.958)
Epoch: [36][320/391]	Time 0.011 (0.013)	Data 0.004 (0.002)	Loss 2.6906 (2.4876)	Acc@1 48.438 (53.269)	Acc@5 80.469 (82.963)
Epoch: [36][330/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.5379 (2.4876)	Acc@1 50.000 (53.248)	Acc@5 82.812 (82.966)
Epoch: [36][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7166 (2.4892)	Acc@1 48.438 (53.198)	Acc@5 77.344 (82.932)
Epoch: [36][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5319 (2.4900)	Acc@1 51.562 (53.174)	Acc@5 85.156 (82.906)
Epoch: [36][360/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.6595 (2.4912)	Acc@1 49.219 (53.168)	Acc@5 79.688 (82.893)
Epoch: [36][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5348 (2.4916)	Acc@1 51.562 (53.157)	Acc@5 81.250 (82.905)
Epoch: [36][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5051 (2.4926)	Acc@1 53.906 (53.146)	Acc@5 79.688 (82.868)
Epoch: [36][390/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5981 (2.4916)	Acc@1 56.250 (53.172)	Acc@5 80.000 (82.874)
num momentum params: 26
[0.1, 2.491614806289673, 2.3182496654987337, 53.172, 41.36, tensor(0.3180, device='cuda:0', grad_fn=<DivBackward0>), 5.210803031921387, 0.3833611011505127]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [37 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [37][0/391]	Time 0.043 (0.043)	Data 0.163 (0.163)	Loss 2.1939 (2.1939)	Acc@1 59.375 (59.375)	Acc@5 89.062 (89.062)
Epoch: [37][10/391]	Time 0.013 (0.016)	Data 0.001 (0.016)	Loss 2.3167 (2.3721)	Acc@1 54.688 (55.114)	Acc@5 88.281 (84.233)
Epoch: [37][20/391]	Time 0.011 (0.015)	Data 0.003 (0.009)	Loss 2.4185 (2.3738)	Acc@1 52.344 (55.283)	Acc@5 85.156 (84.747)
Epoch: [37][30/391]	Time 0.013 (0.014)	Data 0.002 (0.007)	Loss 2.1169 (2.3459)	Acc@1 64.844 (55.973)	Acc@5 89.062 (85.207)
Epoch: [37][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.3744 (2.3458)	Acc@1 59.375 (56.136)	Acc@5 83.594 (85.042)
Epoch: [37][50/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.3109 (2.3479)	Acc@1 59.375 (56.373)	Acc@5 85.938 (85.080)
Epoch: [37][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3920 (2.3646)	Acc@1 50.781 (55.699)	Acc@5 82.812 (84.823)
Epoch: [37][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.5910 (2.3773)	Acc@1 46.094 (55.282)	Acc@5 82.812 (84.936)
Epoch: [37][80/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3243 (2.3952)	Acc@1 55.469 (55.122)	Acc@5 83.594 (84.761)
Epoch: [37][90/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5107 (2.4131)	Acc@1 46.875 (54.773)	Acc@5 83.594 (84.461)
Epoch: [37][100/391]	Time 0.011 (0.014)	Data 0.003 (0.003)	Loss 2.6546 (2.4251)	Acc@1 45.312 (54.626)	Acc@5 85.156 (84.321)
Epoch: [37][110/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.6042 (2.4349)	Acc@1 53.125 (54.554)	Acc@5 80.469 (84.192)
Epoch: [37][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2647 (2.4410)	Acc@1 63.281 (54.442)	Acc@5 83.594 (84.046)
Epoch: [37][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5561 (2.4469)	Acc@1 51.562 (54.282)	Acc@5 82.812 (83.910)
Epoch: [37][140/391]	Time 0.014 (0.013)	Data 0.001 (0.003)	Loss 2.3940 (2.4475)	Acc@1 54.688 (54.255)	Acc@5 85.156 (83.865)
Epoch: [37][150/391]	Time 0.014 (0.013)	Data 0.002 (0.003)	Loss 2.4992 (2.4518)	Acc@1 50.781 (54.005)	Acc@5 85.156 (83.858)
Epoch: [37][160/391]	Time 0.013 (0.013)	Data 0.001 (0.003)	Loss 2.6401 (2.4599)	Acc@1 48.438 (53.829)	Acc@5 79.688 (83.701)
Epoch: [37][170/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4611 (2.4627)	Acc@1 57.031 (53.778)	Acc@5 83.594 (83.676)
Epoch: [37][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6876 (2.4666)	Acc@1 46.875 (53.643)	Acc@5 79.688 (83.620)
Epoch: [37][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5259 (2.4657)	Acc@1 53.125 (53.685)	Acc@5 82.812 (83.618)
Epoch: [37][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5584 (2.4681)	Acc@1 53.125 (53.638)	Acc@5 84.375 (83.555)
Epoch: [37][210/391]	Time 0.011 (0.013)	Data 0.001 (0.002)	Loss 2.5607 (2.4678)	Acc@1 47.656 (53.592)	Acc@5 85.156 (83.572)
Epoch: [37][220/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.4716 (2.4687)	Acc@1 50.781 (53.623)	Acc@5 85.156 (83.622)
Epoch: [37][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4896 (2.4699)	Acc@1 55.469 (53.636)	Acc@5 82.812 (83.597)
Epoch: [37][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8285 (2.4752)	Acc@1 43.750 (53.514)	Acc@5 76.562 (83.509)
Epoch: [37][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4252 (2.4762)	Acc@1 51.562 (53.424)	Acc@5 86.719 (83.528)
Epoch: [37][260/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5205 (2.4776)	Acc@1 56.250 (53.352)	Acc@5 81.250 (83.483)
Epoch: [37][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2060 (2.4774)	Acc@1 59.375 (53.327)	Acc@5 89.062 (83.484)
Epoch: [37][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6784 (2.4803)	Acc@1 48.438 (53.267)	Acc@5 79.688 (83.430)
Epoch: [37][290/391]	Time 0.011 (0.013)	Data 0.001 (0.002)	Loss 2.5866 (2.4828)	Acc@1 53.125 (53.273)	Acc@5 82.812 (83.363)
Epoch: [37][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6154 (2.4832)	Acc@1 49.219 (53.304)	Acc@5 82.812 (83.350)
Epoch: [37][310/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.6024 (2.4850)	Acc@1 54.688 (53.296)	Acc@5 79.688 (83.338)
Epoch: [37][320/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.4627 (2.4857)	Acc@1 51.562 (53.273)	Acc@5 86.719 (83.350)
Epoch: [37][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4591 (2.4862)	Acc@1 55.469 (53.271)	Acc@5 85.156 (83.341)
Epoch: [37][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5768 (2.4864)	Acc@1 53.906 (53.256)	Acc@5 82.031 (83.330)
Epoch: [37][350/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.3271 (2.4871)	Acc@1 57.812 (53.239)	Acc@5 83.594 (83.329)
Epoch: [37][360/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.6037 (2.4870)	Acc@1 47.656 (53.246)	Acc@5 78.906 (83.310)
Epoch: [37][370/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.7126 (2.4899)	Acc@1 52.344 (53.152)	Acc@5 76.562 (83.251)
Epoch: [37][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6550 (2.4914)	Acc@1 51.562 (53.135)	Acc@5 85.156 (83.241)
Epoch: [37][390/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.1786 (2.4925)	Acc@1 53.750 (53.132)	Acc@5 88.750 (83.208)
num momentum params: 26
[0.1, 2.4924849364471435, 1.9953716731071471, 53.132, 47.79, tensor(0.3180, device='cuda:0', grad_fn=<DivBackward0>), 5.262478351593018, 0.38214778900146484]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [38 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [38][0/391]	Time 0.042 (0.042)	Data 0.152 (0.152)	Loss 2.2158 (2.2158)	Acc@1 64.062 (64.062)	Acc@5 84.375 (84.375)
Epoch: [38][10/391]	Time 0.014 (0.016)	Data 0.001 (0.015)	Loss 2.3742 (2.4380)	Acc@1 55.469 (55.895)	Acc@5 80.469 (81.889)
Epoch: [38][20/391]	Time 0.013 (0.015)	Data 0.001 (0.009)	Loss 2.5886 (2.4044)	Acc@1 47.656 (56.213)	Acc@5 83.594 (83.222)
Epoch: [38][30/391]	Time 0.015 (0.015)	Data 0.001 (0.006)	Loss 2.3646 (2.3978)	Acc@1 55.469 (55.872)	Acc@5 85.938 (83.745)
Epoch: [38][40/391]	Time 0.014 (0.014)	Data 0.001 (0.005)	Loss 2.5611 (2.4084)	Acc@1 47.656 (55.697)	Acc@5 85.938 (84.146)
Epoch: [38][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4848 (2.3986)	Acc@1 59.375 (55.990)	Acc@5 81.250 (84.268)
Epoch: [38][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.5707 (2.4046)	Acc@1 52.344 (55.763)	Acc@5 79.688 (84.298)
Epoch: [38][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4789 (2.4144)	Acc@1 53.125 (55.216)	Acc@5 83.594 (84.034)
Epoch: [38][80/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3784 (2.4166)	Acc@1 53.906 (55.044)	Acc@5 85.938 (84.211)
Epoch: [38][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5063 (2.4196)	Acc@1 54.688 (54.988)	Acc@5 82.031 (84.263)
Epoch: [38][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.5374 (2.4223)	Acc@1 55.469 (55.059)	Acc@5 83.594 (84.182)
Epoch: [38][110/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.6509 (2.4241)	Acc@1 50.781 (55.068)	Acc@5 77.344 (84.227)
Epoch: [38][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3678 (2.4221)	Acc@1 52.344 (55.049)	Acc@5 88.281 (84.252)
Epoch: [38][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6224 (2.4214)	Acc@1 54.688 (55.105)	Acc@5 76.562 (84.274)
Epoch: [38][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.7929 (2.4351)	Acc@1 46.875 (54.760)	Acc@5 73.438 (83.987)
Epoch: [38][150/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.7456 (2.4420)	Acc@1 44.531 (54.698)	Acc@5 73.438 (83.889)
Epoch: [38][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5250 (2.4485)	Acc@1 53.125 (54.615)	Acc@5 82.812 (83.812)
Epoch: [38][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1938 (2.4506)	Acc@1 60.938 (54.541)	Acc@5 85.938 (83.717)
Epoch: [38][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3814 (2.4502)	Acc@1 52.344 (54.549)	Acc@5 88.281 (83.736)
Epoch: [38][190/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3278 (2.4478)	Acc@1 60.156 (54.606)	Acc@5 86.719 (83.806)
Epoch: [38][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3680 (2.4536)	Acc@1 56.250 (54.489)	Acc@5 86.719 (83.710)
Epoch: [38][210/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.1159 (2.4514)	Acc@1 60.938 (54.525)	Acc@5 91.406 (83.705)
Epoch: [38][220/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.7188 (2.4557)	Acc@1 45.312 (54.419)	Acc@5 85.938 (83.675)
Epoch: [38][230/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.7445 (2.4597)	Acc@1 47.656 (54.309)	Acc@5 76.562 (83.634)
Epoch: [38][240/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4127 (2.4615)	Acc@1 50.781 (54.217)	Acc@5 82.812 (83.626)
Epoch: [38][250/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3845 (2.4655)	Acc@1 57.031 (54.130)	Acc@5 87.500 (83.616)
Epoch: [38][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5234 (2.4683)	Acc@1 51.562 (54.029)	Acc@5 85.938 (83.600)
Epoch: [38][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6452 (2.4695)	Acc@1 54.688 (54.010)	Acc@5 76.562 (83.530)
Epoch: [38][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4258 (2.4713)	Acc@1 50.000 (53.915)	Acc@5 82.812 (83.499)
Epoch: [38][290/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4358 (2.4763)	Acc@1 53.125 (53.775)	Acc@5 83.594 (83.433)
Epoch: [38][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5615 (2.4824)	Acc@1 52.344 (53.696)	Acc@5 81.250 (83.342)
Epoch: [38][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5592 (2.4838)	Acc@1 48.438 (53.658)	Acc@5 82.031 (83.310)
Epoch: [38][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5223 (2.4857)	Acc@1 54.688 (53.604)	Acc@5 79.688 (83.265)
Epoch: [38][330/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.9280 (2.4870)	Acc@1 42.969 (53.564)	Acc@5 82.031 (83.282)
Epoch: [38][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.9036 (2.4882)	Acc@1 47.656 (53.526)	Acc@5 76.562 (83.259)
Epoch: [38][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5995 (2.4877)	Acc@1 51.562 (53.566)	Acc@5 78.906 (83.247)
Epoch: [38][360/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.3973 (2.4879)	Acc@1 54.688 (53.558)	Acc@5 83.594 (83.224)
Epoch: [38][370/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5065 (2.4895)	Acc@1 52.344 (53.538)	Acc@5 85.938 (83.173)
Epoch: [38][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5313 (2.4902)	Acc@1 47.656 (53.506)	Acc@5 77.344 (83.161)
Epoch: [38][390/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.4022 (2.4884)	Acc@1 62.500 (53.554)	Acc@5 83.750 (83.182)
num momentum params: 26
[0.1, 2.488386423110962, 2.017449851036072, 53.554, 47.25, tensor(0.3196, device='cuda:0', grad_fn=<DivBackward0>), 5.282650709152222, 0.39360165596008295]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [39 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [39][0/391]	Time 0.044 (0.044)	Data 0.162 (0.162)	Loss 2.6091 (2.6091)	Acc@1 47.656 (47.656)	Acc@5 80.469 (80.469)
Epoch: [39][10/391]	Time 0.015 (0.017)	Data 0.002 (0.016)	Loss 2.5799 (2.4097)	Acc@1 55.469 (55.540)	Acc@5 77.344 (84.304)
Epoch: [39][20/391]	Time 0.014 (0.015)	Data 0.002 (0.009)	Loss 2.1724 (2.3847)	Acc@1 60.156 (55.655)	Acc@5 89.062 (85.007)
Epoch: [39][30/391]	Time 0.014 (0.015)	Data 0.002 (0.007)	Loss 2.4931 (2.4040)	Acc@1 50.781 (55.645)	Acc@5 82.812 (84.627)
Epoch: [39][40/391]	Time 0.013 (0.014)	Data 0.002 (0.006)	Loss 2.3748 (2.4230)	Acc@1 55.469 (55.126)	Acc@5 86.719 (84.508)
Epoch: [39][50/391]	Time 0.013 (0.014)	Data 0.002 (0.005)	Loss 2.3921 (2.4224)	Acc@1 54.688 (55.025)	Acc@5 85.156 (84.528)
Epoch: [39][60/391]	Time 0.014 (0.014)	Data 0.002 (0.004)	Loss 2.4471 (2.4368)	Acc@1 50.781 (54.559)	Acc@5 83.594 (84.413)
Epoch: [39][70/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.2986 (2.4463)	Acc@1 52.344 (54.214)	Acc@5 88.281 (84.199)
Epoch: [39][80/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.5638 (2.4548)	Acc@1 50.781 (54.225)	Acc@5 77.344 (83.989)
Epoch: [39][90/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.1350 (2.4481)	Acc@1 63.281 (54.250)	Acc@5 87.500 (84.092)
Epoch: [39][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4689 (2.4465)	Acc@1 51.562 (54.316)	Acc@5 80.469 (83.965)
Epoch: [39][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2750 (2.4451)	Acc@1 57.812 (54.160)	Acc@5 85.938 (83.974)
Epoch: [39][120/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.6120 (2.4484)	Acc@1 51.562 (54.197)	Acc@5 82.031 (83.865)
Epoch: [39][130/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5416 (2.4491)	Acc@1 55.469 (54.163)	Acc@5 85.938 (83.958)
Epoch: [39][140/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.2444 (2.4401)	Acc@1 59.375 (54.444)	Acc@5 89.062 (84.070)
Epoch: [39][150/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.3761 (2.4447)	Acc@1 57.031 (54.372)	Acc@5 82.812 (83.982)
Epoch: [39][160/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.5017 (2.4483)	Acc@1 53.125 (54.260)	Acc@5 80.469 (83.880)
Epoch: [39][170/391]	Time 0.012 (0.014)	Data 0.003 (0.003)	Loss 2.6815 (2.4494)	Acc@1 49.219 (54.226)	Acc@5 82.031 (83.859)
Epoch: [39][180/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.5316 (2.4550)	Acc@1 53.906 (54.070)	Acc@5 82.031 (83.771)
Epoch: [39][190/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.7500 (2.4593)	Acc@1 45.312 (54.009)	Acc@5 82.031 (83.741)
Epoch: [39][200/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5690 (2.4641)	Acc@1 50.781 (53.832)	Acc@5 78.125 (83.613)
Epoch: [39][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6464 (2.4661)	Acc@1 52.344 (53.821)	Acc@5 82.031 (83.586)
Epoch: [39][220/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6318 (2.4695)	Acc@1 48.438 (53.765)	Acc@5 78.906 (83.537)
Epoch: [39][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3863 (2.4738)	Acc@1 56.250 (53.707)	Acc@5 82.031 (83.435)
Epoch: [39][240/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3417 (2.4731)	Acc@1 59.375 (53.699)	Acc@5 86.719 (83.441)
Epoch: [39][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5988 (2.4743)	Acc@1 51.562 (53.710)	Acc@5 83.594 (83.385)
Epoch: [39][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5370 (2.4733)	Acc@1 49.219 (53.745)	Acc@5 84.375 (83.414)
Epoch: [39][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5204 (2.4759)	Acc@1 53.125 (53.699)	Acc@5 80.469 (83.372)
Epoch: [39][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4476 (2.4753)	Acc@1 53.906 (53.734)	Acc@5 84.375 (83.355)
Epoch: [39][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5512 (2.4782)	Acc@1 54.688 (53.675)	Acc@5 83.594 (83.317)
Epoch: [39][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5527 (2.4795)	Acc@1 55.469 (53.673)	Acc@5 80.469 (83.259)
Epoch: [39][310/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4682 (2.4787)	Acc@1 55.469 (53.718)	Acc@5 83.594 (83.265)
Epoch: [39][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4776 (2.4808)	Acc@1 50.781 (53.707)	Acc@5 82.812 (83.199)
Epoch: [39][330/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4323 (2.4813)	Acc@1 60.156 (53.729)	Acc@5 82.031 (83.193)
Epoch: [39][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7070 (2.4820)	Acc@1 48.438 (53.702)	Acc@5 79.688 (83.165)
Epoch: [39][350/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4521 (2.4816)	Acc@1 51.562 (53.695)	Acc@5 82.812 (83.166)
Epoch: [39][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4372 (2.4821)	Acc@1 56.250 (53.694)	Acc@5 83.594 (83.178)
Epoch: [39][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3377 (2.4828)	Acc@1 60.156 (53.698)	Acc@5 85.156 (83.152)
Epoch: [39][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2518 (2.4837)	Acc@1 55.469 (53.658)	Acc@5 92.188 (83.159)
Epoch: [39][390/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.7488 (2.4853)	Acc@1 47.500 (53.642)	Acc@5 80.000 (83.150)
num momentum params: 26
[0.1, 2.485274677276611, 2.4108748233318327, 53.642, 41.13, tensor(0.3199, device='cuda:0', grad_fn=<DivBackward0>), 5.291500568389893, 0.38675904273986816]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [40 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [40][0/391]	Time 0.039 (0.039)	Data 0.159 (0.159)	Loss 2.3705 (2.3705)	Acc@1 54.688 (54.688)	Acc@5 87.500 (87.500)
Epoch: [40][10/391]	Time 0.014 (0.016)	Data 0.001 (0.016)	Loss 2.5593 (2.4347)	Acc@1 55.469 (55.540)	Acc@5 78.125 (82.955)
Epoch: [40][20/391]	Time 0.013 (0.015)	Data 0.001 (0.009)	Loss 2.4431 (2.3938)	Acc@1 53.906 (56.399)	Acc@5 83.594 (83.668)
Epoch: [40][30/391]	Time 0.013 (0.014)	Data 0.002 (0.007)	Loss 2.4822 (2.3739)	Acc@1 55.469 (56.653)	Acc@5 82.031 (84.577)
Epoch: [40][40/391]	Time 0.013 (0.014)	Data 0.002 (0.005)	Loss 2.3630 (2.3897)	Acc@1 57.812 (56.574)	Acc@5 85.938 (83.975)
Epoch: [40][50/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.4380 (2.3823)	Acc@1 55.469 (56.587)	Acc@5 84.375 (84.237)
Epoch: [40][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4329 (2.3896)	Acc@1 51.562 (56.596)	Acc@5 87.500 (84.234)
Epoch: [40][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.6401 (2.3956)	Acc@1 51.562 (56.140)	Acc@5 80.469 (84.122)
Epoch: [40][80/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.6450 (2.4109)	Acc@1 46.875 (55.816)	Acc@5 79.688 (83.767)
Epoch: [40][90/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.5515 (2.4153)	Acc@1 49.219 (55.649)	Acc@5 82.031 (83.680)
Epoch: [40][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.1399 (2.4199)	Acc@1 58.594 (55.252)	Acc@5 89.062 (83.733)
Epoch: [40][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4988 (2.4222)	Acc@1 50.781 (55.004)	Acc@5 83.594 (83.735)
Epoch: [40][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4021 (2.4261)	Acc@1 54.688 (54.862)	Acc@5 89.062 (83.684)
Epoch: [40][130/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3836 (2.4248)	Acc@1 57.812 (54.932)	Acc@5 82.031 (83.618)
Epoch: [40][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5943 (2.4297)	Acc@1 50.781 (54.859)	Acc@5 82.812 (83.599)
Epoch: [40][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2336 (2.4301)	Acc@1 65.625 (54.910)	Acc@5 85.156 (83.687)
Epoch: [40][160/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6342 (2.4335)	Acc@1 51.562 (54.785)	Acc@5 82.812 (83.647)
Epoch: [40][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2227 (2.4316)	Acc@1 64.062 (54.811)	Acc@5 89.844 (83.754)
Epoch: [40][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6849 (2.4370)	Acc@1 46.875 (54.631)	Acc@5 78.125 (83.741)
Epoch: [40][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2288 (2.4384)	Acc@1 56.250 (54.528)	Acc@5 86.719 (83.733)
Epoch: [40][200/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5706 (2.4414)	Acc@1 53.906 (54.478)	Acc@5 83.594 (83.710)
Epoch: [40][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.0892 (2.4387)	Acc@1 60.156 (54.551)	Acc@5 88.281 (83.760)
Epoch: [40][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7426 (2.4422)	Acc@1 50.781 (54.514)	Acc@5 79.688 (83.717)
Epoch: [40][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4288 (2.4468)	Acc@1 55.469 (54.498)	Acc@5 82.031 (83.621)
Epoch: [40][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3672 (2.4481)	Acc@1 60.156 (54.448)	Acc@5 82.031 (83.603)
Epoch: [40][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2981 (2.4499)	Acc@1 58.594 (54.442)	Acc@5 83.594 (83.572)
Epoch: [40][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6388 (2.4508)	Acc@1 46.094 (54.385)	Acc@5 80.469 (83.561)
Epoch: [40][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2753 (2.4511)	Acc@1 59.375 (54.399)	Acc@5 88.281 (83.571)
Epoch: [40][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3939 (2.4511)	Acc@1 54.688 (54.426)	Acc@5 83.594 (83.588)
Epoch: [40][290/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4136 (2.4533)	Acc@1 55.469 (54.395)	Acc@5 82.031 (83.532)
Epoch: [40][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4008 (2.4564)	Acc@1 55.469 (54.355)	Acc@5 88.281 (83.480)
Epoch: [40][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5422 (2.4587)	Acc@1 53.125 (54.328)	Acc@5 78.906 (83.413)
Epoch: [40][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2348 (2.4596)	Acc@1 57.812 (54.288)	Acc@5 89.062 (83.433)
Epoch: [40][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 3.1807 (2.4672)	Acc@1 30.469 (54.081)	Acc@5 71.094 (83.294)
Epoch: [40][340/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5582 (2.4673)	Acc@1 50.000 (54.032)	Acc@5 82.031 (83.280)
Epoch: [40][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2803 (2.4676)	Acc@1 58.594 (54.062)	Acc@5 85.156 (83.269)
Epoch: [40][360/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.7057 (2.4709)	Acc@1 51.562 (53.995)	Acc@5 79.688 (83.219)
Epoch: [40][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3102 (2.4729)	Acc@1 57.812 (53.957)	Acc@5 87.500 (83.189)
Epoch: [40][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5065 (2.4750)	Acc@1 49.219 (53.871)	Acc@5 83.594 (83.151)
Epoch: [40][390/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.4598 (2.4774)	Acc@1 57.500 (53.830)	Acc@5 83.750 (83.098)
num momentum params: 26
[0.1, 2.477384126815796, 1.9517346811294556, 53.83, 48.51, tensor(0.3214, device='cuda:0', grad_fn=<DivBackward0>), 5.283998250961304, 0.3831033706665039]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [41 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [41][0/391]	Time 0.043 (0.043)	Data 0.149 (0.149)	Loss 2.3481 (2.3481)	Acc@1 53.906 (53.906)	Acc@5 86.719 (86.719)
Epoch: [41][10/391]	Time 0.013 (0.016)	Data 0.001 (0.015)	Loss 2.0520 (2.3704)	Acc@1 61.719 (56.392)	Acc@5 90.625 (85.866)
Epoch: [41][20/391]	Time 0.013 (0.015)	Data 0.001 (0.008)	Loss 2.3768 (2.3464)	Acc@1 58.594 (56.882)	Acc@5 86.719 (86.347)
Epoch: [41][30/391]	Time 0.013 (0.014)	Data 0.001 (0.006)	Loss 2.6219 (2.3679)	Acc@1 50.000 (56.174)	Acc@5 82.812 (86.064)
Epoch: [41][40/391]	Time 0.014 (0.014)	Data 0.001 (0.005)	Loss 2.4624 (2.3828)	Acc@1 56.250 (55.945)	Acc@5 85.938 (85.499)
Epoch: [41][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.6126 (2.3865)	Acc@1 49.219 (55.790)	Acc@5 82.031 (85.447)
Epoch: [41][60/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.5748 (2.3907)	Acc@1 51.562 (55.853)	Acc@5 78.906 (85.323)
Epoch: [41][70/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.3135 (2.3947)	Acc@1 60.156 (55.755)	Acc@5 87.500 (85.068)
Epoch: [41][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6219 (2.4010)	Acc@1 53.125 (55.594)	Acc@5 81.250 (84.992)
Epoch: [41][90/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.6023 (2.4103)	Acc@1 53.906 (55.314)	Acc@5 82.031 (84.864)
Epoch: [41][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5379 (2.4170)	Acc@1 53.125 (55.113)	Acc@5 78.125 (84.677)
Epoch: [41][110/391]	Time 0.012 (0.014)	Data 0.004 (0.003)	Loss 2.6415 (2.4173)	Acc@1 48.438 (55.180)	Acc@5 80.469 (84.600)
Epoch: [41][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5916 (2.4255)	Acc@1 53.906 (54.985)	Acc@5 79.688 (84.478)
Epoch: [41][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4132 (2.4269)	Acc@1 60.938 (54.890)	Acc@5 85.156 (84.411)
Epoch: [41][140/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2858 (2.4271)	Acc@1 61.719 (54.848)	Acc@5 88.281 (84.403)
Epoch: [41][150/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4401 (2.4292)	Acc@1 58.594 (54.832)	Acc@5 83.594 (84.359)
Epoch: [41][160/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4497 (2.4330)	Acc@1 51.562 (54.678)	Acc@5 87.500 (84.278)
Epoch: [41][170/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2873 (2.4407)	Acc@1 59.375 (54.491)	Acc@5 89.844 (84.183)
Epoch: [41][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4139 (2.4446)	Acc@1 50.000 (54.385)	Acc@5 85.938 (84.116)
Epoch: [41][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2771 (2.4430)	Acc@1 62.500 (54.381)	Acc@5 82.812 (84.150)
Epoch: [41][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5254 (2.4462)	Acc@1 51.562 (54.248)	Acc@5 84.375 (84.080)
Epoch: [41][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3300 (2.4478)	Acc@1 59.375 (54.247)	Acc@5 87.500 (84.012)
Epoch: [41][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6370 (2.4530)	Acc@1 50.781 (54.157)	Acc@5 82.031 (83.979)
Epoch: [41][230/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.7643 (2.4575)	Acc@1 46.094 (54.069)	Acc@5 78.906 (83.874)
Epoch: [41][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5795 (2.4602)	Acc@1 46.875 (54.004)	Acc@5 82.031 (83.837)
Epoch: [41][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5616 (2.4588)	Acc@1 50.000 (54.056)	Acc@5 85.156 (83.914)
Epoch: [41][260/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.4816 (2.4617)	Acc@1 57.812 (54.023)	Acc@5 83.594 (83.833)
Epoch: [41][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5372 (2.4651)	Acc@1 52.344 (53.929)	Acc@5 84.375 (83.744)
Epoch: [41][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4981 (2.4655)	Acc@1 50.000 (53.942)	Acc@5 85.156 (83.713)
Epoch: [41][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5986 (2.4650)	Acc@1 56.250 (53.952)	Acc@5 81.250 (83.712)
Epoch: [41][300/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.4882 (2.4647)	Acc@1 53.125 (53.976)	Acc@5 82.031 (83.695)
Epoch: [41][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4135 (2.4655)	Acc@1 52.344 (53.982)	Acc@5 85.938 (83.707)
Epoch: [41][320/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.3937 (2.4675)	Acc@1 50.000 (53.899)	Acc@5 89.062 (83.674)
Epoch: [41][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5125 (2.4713)	Acc@1 54.688 (53.786)	Acc@5 82.031 (83.591)
Epoch: [41][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3727 (2.4691)	Acc@1 59.375 (53.851)	Acc@5 83.594 (83.621)
Epoch: [41][350/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5666 (2.4688)	Acc@1 54.688 (53.871)	Acc@5 78.906 (83.614)
Epoch: [41][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5099 (2.4699)	Acc@1 53.125 (53.865)	Acc@5 82.812 (83.576)
Epoch: [41][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8387 (2.4712)	Acc@1 50.000 (53.814)	Acc@5 75.781 (83.554)
Epoch: [41][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6053 (2.4730)	Acc@1 51.562 (53.775)	Acc@5 82.031 (83.528)
Epoch: [41][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.8974 (2.4741)	Acc@1 35.000 (53.750)	Acc@5 76.250 (83.508)
num momentum params: 26
[0.1, 2.4741363952636717, 2.0739794754981995, 53.75, 46.17, tensor(0.3221, device='cuda:0', grad_fn=<DivBackward0>), 5.217392206192017, 0.38469862937927246]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [42 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [42][0/391]	Time 0.043 (0.043)	Data 0.148 (0.148)	Loss 2.3481 (2.3481)	Acc@1 62.500 (62.500)	Acc@5 87.500 (87.500)
Epoch: [42][10/391]	Time 0.013 (0.016)	Data 0.001 (0.015)	Loss 2.4901 (2.4195)	Acc@1 53.906 (54.830)	Acc@5 82.031 (84.872)
Epoch: [42][20/391]	Time 0.013 (0.015)	Data 0.001 (0.009)	Loss 2.3649 (2.3844)	Acc@1 57.031 (55.580)	Acc@5 84.375 (85.565)
Epoch: [42][30/391]	Time 0.014 (0.014)	Data 0.001 (0.006)	Loss 2.3821 (2.3860)	Acc@1 53.125 (55.267)	Acc@5 85.156 (85.232)
Epoch: [42][40/391]	Time 0.013 (0.014)	Data 0.002 (0.005)	Loss 2.1528 (2.3924)	Acc@1 58.594 (55.145)	Acc@5 89.062 (85.118)
Epoch: [42][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.6056 (2.4117)	Acc@1 48.438 (54.856)	Acc@5 80.469 (84.681)
Epoch: [42][60/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.4798 (2.4114)	Acc@1 54.688 (54.931)	Acc@5 83.594 (84.798)
Epoch: [42][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3345 (2.4073)	Acc@1 53.125 (55.194)	Acc@5 85.156 (84.749)
Epoch: [42][80/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2418 (2.4056)	Acc@1 57.812 (55.257)	Acc@5 85.156 (84.732)
Epoch: [42][90/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3522 (2.4107)	Acc@1 54.688 (55.117)	Acc@5 90.625 (84.684)
Epoch: [42][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3555 (2.4101)	Acc@1 58.594 (55.051)	Acc@5 83.594 (84.692)
Epoch: [42][110/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.3317 (2.4096)	Acc@1 51.562 (54.983)	Acc@5 84.375 (84.635)
Epoch: [42][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5992 (2.4133)	Acc@1 44.531 (54.959)	Acc@5 88.281 (84.601)
Epoch: [42][130/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.1638 (2.4143)	Acc@1 60.156 (54.854)	Acc@5 88.281 (84.482)
Epoch: [42][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4218 (2.4201)	Acc@1 53.906 (54.776)	Acc@5 85.156 (84.392)
Epoch: [42][150/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6985 (2.4212)	Acc@1 50.781 (54.806)	Acc@5 81.250 (84.334)
Epoch: [42][160/391]	Time 0.018 (0.014)	Data 0.001 (0.002)	Loss 2.4142 (2.4285)	Acc@1 51.562 (54.610)	Acc@5 85.938 (84.239)
Epoch: [42][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4921 (2.4312)	Acc@1 49.219 (54.601)	Acc@5 83.594 (84.188)
Epoch: [42][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5700 (2.4393)	Acc@1 50.000 (54.485)	Acc@5 83.594 (84.073)
Epoch: [42][190/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4834 (2.4415)	Acc@1 52.344 (54.499)	Acc@5 83.594 (84.044)
Epoch: [42][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6543 (2.4450)	Acc@1 53.125 (54.400)	Acc@5 77.344 (84.006)
Epoch: [42][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6633 (2.4449)	Acc@1 50.781 (54.462)	Acc@5 83.594 (84.042)
Epoch: [42][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5790 (2.4474)	Acc@1 50.000 (54.376)	Acc@5 86.719 (84.032)
Epoch: [42][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5246 (2.4497)	Acc@1 53.125 (54.234)	Acc@5 82.031 (84.013)
Epoch: [42][240/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6931 (2.4541)	Acc@1 54.688 (54.169)	Acc@5 77.344 (83.924)
Epoch: [42][250/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.1744 (2.4543)	Acc@1 59.375 (54.149)	Acc@5 86.719 (83.874)
Epoch: [42][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4922 (2.4580)	Acc@1 49.219 (54.059)	Acc@5 86.719 (83.827)
Epoch: [42][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2966 (2.4576)	Acc@1 60.156 (54.068)	Acc@5 85.938 (83.796)
Epoch: [42][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4334 (2.4571)	Acc@1 57.812 (54.106)	Acc@5 81.250 (83.799)
Epoch: [42][290/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4695 (2.4586)	Acc@1 55.469 (54.083)	Acc@5 80.469 (83.736)
Epoch: [42][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4043 (2.4581)	Acc@1 52.344 (54.067)	Acc@5 89.062 (83.752)
Epoch: [42][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3304 (2.4607)	Acc@1 56.250 (54.022)	Acc@5 83.594 (83.652)
Epoch: [42][320/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.6609 (2.4641)	Acc@1 53.125 (53.948)	Acc@5 76.562 (83.589)
Epoch: [42][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5660 (2.4661)	Acc@1 50.000 (53.913)	Acc@5 82.031 (83.561)
Epoch: [42][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2866 (2.4651)	Acc@1 57.812 (53.957)	Acc@5 90.625 (83.607)
Epoch: [42][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6515 (2.4677)	Acc@1 50.000 (53.913)	Acc@5 80.469 (83.545)
Epoch: [42][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7670 (2.4687)	Acc@1 44.531 (53.863)	Acc@5 74.219 (83.518)
Epoch: [42][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3955 (2.4706)	Acc@1 57.812 (53.816)	Acc@5 85.938 (83.518)
Epoch: [42][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3537 (2.4706)	Acc@1 57.031 (53.837)	Acc@5 82.812 (83.528)
Epoch: [42][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.4461 (2.4724)	Acc@1 57.500 (53.790)	Acc@5 81.250 (83.480)
num momentum params: 26
[0.1, 2.4723764599609375, 2.30794309258461, 53.79, 41.56, tensor(0.3219, device='cuda:0', grad_fn=<DivBackward0>), 5.257478952407837, 0.38370180130004883]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [43 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [43][0/391]	Time 0.044 (0.044)	Data 0.140 (0.140)	Loss 2.3104 (2.3104)	Acc@1 59.375 (59.375)	Acc@5 84.375 (84.375)
Epoch: [43][10/391]	Time 0.013 (0.017)	Data 0.002 (0.014)	Loss 2.4523 (2.3740)	Acc@1 57.031 (56.747)	Acc@5 82.812 (85.369)
Epoch: [43][20/391]	Time 0.013 (0.016)	Data 0.001 (0.008)	Loss 2.6708 (2.4075)	Acc@1 46.875 (55.878)	Acc@5 78.125 (84.226)
Epoch: [43][30/391]	Time 0.013 (0.015)	Data 0.025 (0.007)	Loss 2.4738 (2.4212)	Acc@1 50.000 (55.040)	Acc@5 83.594 (84.249)
Epoch: [43][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.3405 (2.4356)	Acc@1 53.906 (54.287)	Acc@5 85.938 (84.146)
Epoch: [43][50/391]	Time 0.012 (0.014)	Data 0.002 (0.005)	Loss 2.5090 (2.4132)	Acc@1 54.688 (54.902)	Acc@5 82.031 (84.513)
Epoch: [43][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.7085 (2.4081)	Acc@1 44.531 (55.020)	Acc@5 82.031 (84.490)
Epoch: [43][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3565 (2.4127)	Acc@1 55.469 (54.798)	Acc@5 84.375 (84.518)
Epoch: [43][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2638 (2.4124)	Acc@1 58.594 (54.794)	Acc@5 87.500 (84.558)
Epoch: [43][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4368 (2.4129)	Acc@1 61.719 (54.988)	Acc@5 81.250 (84.538)
Epoch: [43][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2301 (2.4050)	Acc@1 60.156 (55.322)	Acc@5 86.719 (84.599)
Epoch: [43][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2079 (2.3996)	Acc@1 56.250 (55.328)	Acc@5 88.281 (84.692)
Epoch: [43][120/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3992 (2.4038)	Acc@1 60.938 (55.256)	Acc@5 82.812 (84.575)
Epoch: [43][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3826 (2.4100)	Acc@1 58.594 (55.075)	Acc@5 87.500 (84.500)
Epoch: [43][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6284 (2.4236)	Acc@1 49.219 (54.754)	Acc@5 80.469 (84.297)
Epoch: [43][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3187 (2.4234)	Acc@1 52.344 (54.889)	Acc@5 87.500 (84.318)
Epoch: [43][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 3.0156 (2.4332)	Acc@1 40.625 (54.663)	Acc@5 75.000 (84.186)
Epoch: [43][170/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6331 (2.4398)	Acc@1 50.781 (54.482)	Acc@5 79.688 (83.996)
Epoch: [43][180/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3311 (2.4432)	Acc@1 56.250 (54.420)	Acc@5 84.375 (83.935)
Epoch: [43][190/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3862 (2.4421)	Acc@1 55.469 (54.561)	Acc@5 87.500 (83.941)
Epoch: [43][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5186 (2.4429)	Acc@1 51.562 (54.555)	Acc@5 82.812 (83.928)
Epoch: [43][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5458 (2.4448)	Acc@1 51.562 (54.517)	Acc@5 80.469 (83.894)
Epoch: [43][220/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5832 (2.4486)	Acc@1 46.875 (54.440)	Acc@5 79.688 (83.827)
Epoch: [43][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4611 (2.4503)	Acc@1 53.125 (54.397)	Acc@5 88.281 (83.834)
Epoch: [43][240/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.8088 (2.4533)	Acc@1 49.219 (54.276)	Acc@5 72.656 (83.775)
Epoch: [43][250/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4944 (2.4574)	Acc@1 57.812 (54.252)	Acc@5 77.344 (83.640)
Epoch: [43][260/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4923 (2.4601)	Acc@1 50.781 (54.176)	Acc@5 85.156 (83.615)
Epoch: [43][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6355 (2.4597)	Acc@1 52.344 (54.143)	Acc@5 78.125 (83.611)
Epoch: [43][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4254 (2.4616)	Acc@1 58.594 (54.109)	Acc@5 82.031 (83.602)
Epoch: [43][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3522 (2.4628)	Acc@1 62.500 (54.032)	Acc@5 88.281 (83.613)
Epoch: [43][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2445 (2.4614)	Acc@1 59.375 (54.065)	Acc@5 87.500 (83.620)
Epoch: [43][310/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5135 (2.4637)	Acc@1 50.781 (53.999)	Acc@5 80.469 (83.554)
Epoch: [43][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5664 (2.4622)	Acc@1 55.469 (54.057)	Acc@5 82.031 (83.562)
Epoch: [43][330/391]	Time 0.012 (0.013)	Data 0.002 (0.002)	Loss 2.5067 (2.4638)	Acc@1 57.031 (54.069)	Acc@5 82.031 (83.530)
Epoch: [43][340/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.3430 (2.4649)	Acc@1 59.375 (54.030)	Acc@5 83.594 (83.532)
Epoch: [43][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4273 (2.4649)	Acc@1 57.812 (54.069)	Acc@5 87.500 (83.523)
Epoch: [43][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4942 (2.4641)	Acc@1 47.656 (54.058)	Acc@5 81.250 (83.563)
Epoch: [43][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5839 (2.4674)	Acc@1 55.469 (54.037)	Acc@5 78.906 (83.472)
Epoch: [43][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2923 (2.4662)	Acc@1 53.906 (54.015)	Acc@5 87.500 (83.530)
Epoch: [43][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.8456 (2.4681)	Acc@1 41.250 (53.916)	Acc@5 78.750 (83.512)
num momentum params: 26
[0.1, 2.4680703451538086, 1.9396759474277496, 53.916, 48.31, tensor(0.3220, device='cuda:0', grad_fn=<DivBackward0>), 5.2530882358551025, 0.39397192001342773]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [44 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [44][0/391]	Time 0.044 (0.044)	Data 0.159 (0.159)	Loss 2.1857 (2.1857)	Acc@1 59.375 (59.375)	Acc@5 90.625 (90.625)
Epoch: [44][10/391]	Time 0.013 (0.017)	Data 0.002 (0.016)	Loss 2.5005 (2.2959)	Acc@1 54.688 (58.026)	Acc@5 81.250 (85.866)
Epoch: [44][20/391]	Time 0.013 (0.015)	Data 0.002 (0.009)	Loss 2.1437 (2.3198)	Acc@1 62.500 (57.626)	Acc@5 86.719 (85.677)
Epoch: [44][30/391]	Time 0.013 (0.015)	Data 0.002 (0.007)	Loss 2.5498 (2.3368)	Acc@1 53.906 (57.107)	Acc@5 84.375 (85.307)
Epoch: [44][40/391]	Time 0.013 (0.014)	Data 0.002 (0.006)	Loss 2.5126 (2.3450)	Acc@1 53.125 (56.784)	Acc@5 82.812 (85.118)
Epoch: [44][50/391]	Time 0.014 (0.014)	Data 0.001 (0.005)	Loss 2.4360 (2.3532)	Acc@1 50.000 (56.296)	Acc@5 82.812 (85.018)
Epoch: [44][60/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.6459 (2.3635)	Acc@1 48.438 (56.084)	Acc@5 80.469 (85.015)
Epoch: [44][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.2753 (2.3771)	Acc@1 58.594 (55.821)	Acc@5 90.625 (84.914)
Epoch: [44][80/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.6252 (2.3955)	Acc@1 47.656 (55.392)	Acc@5 80.469 (84.722)
Epoch: [44][90/391]	Time 0.018 (0.014)	Data 0.001 (0.003)	Loss 2.3883 (2.3969)	Acc@1 56.250 (55.323)	Acc@5 82.031 (84.633)
Epoch: [44][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4308 (2.4057)	Acc@1 52.344 (55.128)	Acc@5 85.156 (84.522)
Epoch: [44][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4430 (2.4083)	Acc@1 57.031 (55.103)	Acc@5 82.031 (84.431)
Epoch: [44][120/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3123 (2.4135)	Acc@1 57.812 (54.836)	Acc@5 85.938 (84.330)
Epoch: [44][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2922 (2.4184)	Acc@1 57.031 (54.699)	Acc@5 89.844 (84.250)
Epoch: [44][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5240 (2.4262)	Acc@1 50.000 (54.516)	Acc@5 82.812 (84.031)
Epoch: [44][150/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.2540 (2.4275)	Acc@1 60.938 (54.444)	Acc@5 88.281 (83.909)
Epoch: [44][160/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3828 (2.4325)	Acc@1 58.594 (54.324)	Acc@5 85.938 (83.895)
Epoch: [44][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2907 (2.4305)	Acc@1 60.938 (54.349)	Acc@5 82.812 (83.859)
Epoch: [44][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6073 (2.4331)	Acc@1 50.000 (54.355)	Acc@5 79.688 (83.810)
Epoch: [44][190/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3672 (2.4346)	Acc@1 58.594 (54.389)	Acc@5 78.125 (83.716)
Epoch: [44][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5127 (2.4351)	Acc@1 49.219 (54.318)	Acc@5 80.469 (83.749)
Epoch: [44][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5949 (2.4357)	Acc@1 49.219 (54.310)	Acc@5 79.688 (83.816)
Epoch: [44][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3873 (2.4367)	Acc@1 51.562 (54.253)	Acc@5 86.719 (83.845)
Epoch: [44][230/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.5960 (2.4427)	Acc@1 46.875 (54.146)	Acc@5 82.812 (83.746)
Epoch: [44][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6459 (2.4442)	Acc@1 50.781 (54.143)	Acc@5 76.562 (83.672)
Epoch: [44][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5769 (2.4488)	Acc@1 53.125 (54.031)	Acc@5 75.781 (83.556)
Epoch: [44][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5314 (2.4507)	Acc@1 56.250 (54.056)	Acc@5 84.375 (83.531)
Epoch: [44][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7075 (2.4528)	Acc@1 47.656 (54.010)	Acc@5 77.344 (83.490)
Epoch: [44][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3557 (2.4530)	Acc@1 53.125 (53.992)	Acc@5 88.281 (83.499)
Epoch: [44][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4341 (2.4561)	Acc@1 53.125 (53.928)	Acc@5 88.281 (83.497)
Epoch: [44][300/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5151 (2.4592)	Acc@1 52.344 (53.888)	Acc@5 80.469 (83.435)
Epoch: [44][310/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.3887 (2.4633)	Acc@1 57.031 (53.786)	Acc@5 85.156 (83.388)
Epoch: [44][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5507 (2.4647)	Acc@1 55.469 (53.743)	Acc@5 78.906 (83.365)
Epoch: [44][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3375 (2.4628)	Acc@1 61.719 (53.809)	Acc@5 82.031 (83.377)
Epoch: [44][340/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.3656 (2.4676)	Acc@1 60.156 (53.702)	Acc@5 86.719 (83.294)
Epoch: [44][350/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5241 (2.4690)	Acc@1 55.469 (53.650)	Acc@5 81.250 (83.273)
Epoch: [44][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.1698 (2.4677)	Acc@1 56.250 (53.666)	Acc@5 89.844 (83.336)
Epoch: [44][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3564 (2.4679)	Acc@1 57.812 (53.689)	Acc@5 82.812 (83.301)
Epoch: [44][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6034 (2.4706)	Acc@1 48.438 (53.675)	Acc@5 79.688 (83.278)
Epoch: [44][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.4262 (2.4705)	Acc@1 52.500 (53.688)	Acc@5 82.500 (83.288)
num momentum params: 26
[0.1, 2.470452699661255, 1.945059666633606, 53.688, 48.89, tensor(0.3224, device='cuda:0', grad_fn=<DivBackward0>), 5.246274471282959, 0.3919003009796143]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [45 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [45][0/391]	Time 0.043 (0.043)	Data 0.145 (0.145)	Loss 2.2486 (2.2486)	Acc@1 60.156 (60.156)	Acc@5 88.281 (88.281)
Epoch: [45][10/391]	Time 0.014 (0.017)	Data 0.002 (0.015)	Loss 2.4255 (2.3016)	Acc@1 57.812 (58.736)	Acc@5 85.938 (85.582)
Epoch: [45][20/391]	Time 0.013 (0.015)	Data 0.001 (0.008)	Loss 2.3910 (2.3268)	Acc@1 55.469 (57.961)	Acc@5 87.500 (85.640)
Epoch: [45][30/391]	Time 0.013 (0.015)	Data 0.001 (0.006)	Loss 2.7151 (2.3634)	Acc@1 48.438 (56.603)	Acc@5 75.781 (84.652)
Epoch: [45][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.4391 (2.3672)	Acc@1 56.250 (56.174)	Acc@5 82.031 (84.585)
Epoch: [45][50/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.2921 (2.3591)	Acc@1 60.938 (56.327)	Acc@5 88.281 (85.018)
Epoch: [45][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3976 (2.3636)	Acc@1 53.125 (56.301)	Acc@5 89.844 (85.105)
Epoch: [45][70/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3389 (2.3781)	Acc@1 54.688 (55.843)	Acc@5 84.375 (84.837)
Epoch: [45][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3246 (2.3850)	Acc@1 59.375 (55.700)	Acc@5 80.469 (84.635)
Epoch: [45][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3991 (2.3821)	Acc@1 58.594 (55.735)	Acc@5 83.594 (84.693)
Epoch: [45][100/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.6455 (2.3996)	Acc@1 45.312 (55.206)	Acc@5 78.906 (84.414)
Epoch: [45][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.6182 (2.4021)	Acc@1 48.438 (55.258)	Acc@5 80.469 (84.389)
Epoch: [45][120/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.1984 (2.4066)	Acc@1 60.156 (55.178)	Acc@5 87.500 (84.304)
Epoch: [45][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4724 (2.4037)	Acc@1 51.562 (55.254)	Acc@5 82.812 (84.357)
Epoch: [45][140/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4736 (2.4120)	Acc@1 52.344 (55.147)	Acc@5 78.906 (84.142)
Epoch: [45][150/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4756 (2.4186)	Acc@1 53.906 (55.076)	Acc@5 84.375 (84.034)
Epoch: [45][160/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4536 (2.4224)	Acc@1 55.469 (54.969)	Acc@5 84.375 (83.987)
Epoch: [45][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7222 (2.4285)	Acc@1 45.312 (54.820)	Acc@5 84.375 (83.886)
Epoch: [45][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6571 (2.4368)	Acc@1 46.875 (54.580)	Acc@5 78.906 (83.745)
Epoch: [45][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5879 (2.4437)	Acc@1 54.688 (54.450)	Acc@5 84.375 (83.667)
Epoch: [45][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5949 (2.4457)	Acc@1 53.125 (54.365)	Acc@5 82.031 (83.637)
Epoch: [45][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4198 (2.4460)	Acc@1 63.281 (54.354)	Acc@5 87.500 (83.642)
Epoch: [45][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6456 (2.4452)	Acc@1 52.344 (54.458)	Acc@5 78.906 (83.633)
Epoch: [45][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5072 (2.4421)	Acc@1 52.344 (54.552)	Acc@5 84.375 (83.709)
Epoch: [45][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3755 (2.4441)	Acc@1 61.719 (54.568)	Acc@5 85.938 (83.675)
Epoch: [45][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5995 (2.4432)	Acc@1 53.906 (54.619)	Acc@5 82.031 (83.668)
Epoch: [45][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5204 (2.4470)	Acc@1 50.781 (54.526)	Acc@5 83.594 (83.558)
Epoch: [45][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4713 (2.4501)	Acc@1 51.562 (54.457)	Acc@5 81.250 (83.513)
Epoch: [45][280/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.4419 (2.4507)	Acc@1 58.594 (54.487)	Acc@5 79.688 (83.499)
Epoch: [45][290/391]	Time 0.012 (0.013)	Data 0.001 (0.002)	Loss 2.5585 (2.4520)	Acc@1 51.562 (54.486)	Acc@5 85.938 (83.548)
Epoch: [45][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5018 (2.4544)	Acc@1 56.250 (54.397)	Acc@5 83.594 (83.531)
Epoch: [45][310/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.4422 (2.4565)	Acc@1 51.562 (54.338)	Acc@5 88.281 (83.516)
Epoch: [45][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2533 (2.4580)	Acc@1 60.938 (54.310)	Acc@5 87.500 (83.487)
Epoch: [45][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2689 (2.4611)	Acc@1 55.469 (54.225)	Acc@5 87.500 (83.436)
Epoch: [45][340/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.8058 (2.4630)	Acc@1 42.969 (54.145)	Acc@5 79.688 (83.433)
Epoch: [45][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3141 (2.4634)	Acc@1 58.594 (54.169)	Acc@5 83.594 (83.413)
Epoch: [45][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4836 (2.4638)	Acc@1 47.656 (54.136)	Acc@5 84.375 (83.434)
Epoch: [45][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5111 (2.4661)	Acc@1 50.781 (54.062)	Acc@5 82.812 (83.375)
Epoch: [45][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3815 (2.4653)	Acc@1 53.906 (54.085)	Acc@5 83.594 (83.387)
Epoch: [45][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.5943 (2.4647)	Acc@1 50.000 (54.066)	Acc@5 78.750 (83.410)
num momentum params: 26
[0.1, 2.4647483796691896, 2.0279813599586487, 54.066, 47.65, tensor(0.3229, device='cuda:0', grad_fn=<DivBackward0>), 5.239361524581909, 0.3890562057495117]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [46 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [46][0/391]	Time 0.042 (0.042)	Data 0.152 (0.152)	Loss 2.0884 (2.0884)	Acc@1 62.500 (62.500)	Acc@5 92.188 (92.188)
Epoch: [46][10/391]	Time 0.013 (0.017)	Data 0.001 (0.015)	Loss 2.2965 (2.3705)	Acc@1 56.250 (55.824)	Acc@5 87.500 (84.304)
Epoch: [46][20/391]	Time 0.013 (0.015)	Data 0.001 (0.009)	Loss 2.1173 (2.3549)	Acc@1 66.406 (56.250)	Acc@5 90.625 (84.821)
Epoch: [46][30/391]	Time 0.014 (0.015)	Data 0.001 (0.006)	Loss 2.3988 (2.3653)	Acc@1 53.906 (56.149)	Acc@5 84.375 (84.778)
Epoch: [46][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.3483 (2.3874)	Acc@1 56.250 (55.431)	Acc@5 87.500 (84.546)
Epoch: [46][50/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.2288 (2.3921)	Acc@1 57.812 (55.346)	Acc@5 85.938 (84.421)
Epoch: [46][60/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.0861 (2.3843)	Acc@1 57.031 (55.699)	Acc@5 91.406 (84.477)
Epoch: [46][70/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.3173 (2.3817)	Acc@1 57.031 (55.678)	Acc@5 87.500 (84.650)
Epoch: [46][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5083 (2.3827)	Acc@1 50.000 (55.748)	Acc@5 85.938 (84.655)
Epoch: [46][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6215 (2.3883)	Acc@1 53.125 (55.486)	Acc@5 81.250 (84.701)
Epoch: [46][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.0213 (2.3932)	Acc@1 65.625 (55.438)	Acc@5 89.062 (84.700)
Epoch: [46][110/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4145 (2.3974)	Acc@1 55.469 (55.244)	Acc@5 82.812 (84.635)
Epoch: [46][120/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3513 (2.3956)	Acc@1 52.344 (55.230)	Acc@5 86.719 (84.827)
Epoch: [46][130/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5913 (2.4015)	Acc@1 47.656 (55.051)	Acc@5 88.281 (84.798)
Epoch: [46][140/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3556 (2.4082)	Acc@1 50.000 (54.848)	Acc@5 85.156 (84.658)
Epoch: [46][150/391]	Time 0.010 (0.014)	Data 0.001 (0.002)	Loss 2.5057 (2.4099)	Acc@1 57.031 (54.817)	Acc@5 84.375 (84.660)
Epoch: [46][160/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6515 (2.4128)	Acc@1 44.531 (54.765)	Acc@5 85.156 (84.661)
Epoch: [46][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5923 (2.4167)	Acc@1 50.000 (54.742)	Acc@5 78.906 (84.585)
Epoch: [46][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5357 (2.4192)	Acc@1 52.344 (54.735)	Acc@5 79.688 (84.492)
Epoch: [46][190/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.6572 (2.4207)	Acc@1 52.344 (54.683)	Acc@5 77.344 (84.449)
Epoch: [46][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6234 (2.4284)	Acc@1 50.781 (54.485)	Acc@5 82.812 (84.359)
Epoch: [46][210/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6208 (2.4292)	Acc@1 50.000 (54.539)	Acc@5 85.938 (84.360)
Epoch: [46][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2882 (2.4290)	Acc@1 58.594 (54.574)	Acc@5 84.375 (84.357)
Epoch: [46][230/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.3723 (2.4298)	Acc@1 52.344 (54.515)	Acc@5 84.375 (84.348)
Epoch: [46][240/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.7116 (2.4323)	Acc@1 49.219 (54.487)	Acc@5 74.219 (84.265)
Epoch: [46][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6117 (2.4337)	Acc@1 50.000 (54.482)	Acc@5 82.812 (84.213)
Epoch: [46][260/391]	Time 0.023 (0.013)	Data 0.001 (0.002)	Loss 2.4902 (2.4354)	Acc@1 50.000 (54.433)	Acc@5 82.812 (84.195)
Epoch: [46][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6136 (2.4379)	Acc@1 55.469 (54.388)	Acc@5 79.688 (84.162)
Epoch: [46][280/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5272 (2.4419)	Acc@1 57.031 (54.348)	Acc@5 82.031 (84.061)
Epoch: [46][290/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.5035 (2.4440)	Acc@1 51.562 (54.357)	Acc@5 82.031 (84.021)
Epoch: [46][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3159 (2.4439)	Acc@1 55.469 (54.384)	Acc@5 86.719 (84.030)
Epoch: [46][310/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.4066 (2.4443)	Acc@1 54.688 (54.366)	Acc@5 84.375 (84.036)
Epoch: [46][320/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.5566 (2.4453)	Acc@1 48.438 (54.332)	Acc@5 84.375 (84.007)
Epoch: [46][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3535 (2.4480)	Acc@1 58.594 (54.279)	Acc@5 85.156 (83.957)
Epoch: [46][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3847 (2.4490)	Acc@1 52.344 (54.264)	Acc@5 84.375 (83.917)
Epoch: [46][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7016 (2.4520)	Acc@1 50.781 (54.211)	Acc@5 77.344 (83.839)
Epoch: [46][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5674 (2.4531)	Acc@1 54.688 (54.172)	Acc@5 85.938 (83.843)
Epoch: [46][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4144 (2.4576)	Acc@1 52.344 (54.066)	Acc@5 84.375 (83.752)
Epoch: [46][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4179 (2.4566)	Acc@1 56.250 (54.134)	Acc@5 89.062 (83.778)
Epoch: [46][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.3837 (2.4598)	Acc@1 57.500 (54.106)	Acc@5 82.500 (83.720)
num momentum params: 26
[0.1, 2.4598393043518065, 1.9248270654678346, 54.106, 47.88, tensor(0.3239, device='cuda:0', grad_fn=<DivBackward0>), 5.245041608810425, 0.39756035804748535]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [47 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [47][0/391]	Time 0.046 (0.046)	Data 0.145 (0.145)	Loss 2.2649 (2.2649)	Acc@1 55.469 (55.469)	Acc@5 88.281 (88.281)
Epoch: [47][10/391]	Time 0.014 (0.017)	Data 0.001 (0.015)	Loss 2.4440 (2.3107)	Acc@1 55.469 (57.955)	Acc@5 80.469 (86.222)
Epoch: [47][20/391]	Time 0.013 (0.015)	Data 0.001 (0.008)	Loss 2.2259 (2.3583)	Acc@1 61.719 (56.957)	Acc@5 85.938 (85.975)
Epoch: [47][30/391]	Time 0.014 (0.015)	Data 0.001 (0.006)	Loss 2.2317 (2.3883)	Acc@1 61.719 (56.376)	Acc@5 87.500 (85.459)
Epoch: [47][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.6566 (2.3979)	Acc@1 51.562 (56.288)	Acc@5 82.812 (85.061)
Epoch: [47][50/391]	Time 0.014 (0.014)	Data 0.002 (0.004)	Loss 2.6847 (2.4082)	Acc@1 52.344 (56.081)	Acc@5 78.906 (84.513)
Epoch: [47][60/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.4900 (2.4030)	Acc@1 52.344 (56.032)	Acc@5 83.594 (84.695)
Epoch: [47][70/391]	Time 0.014 (0.014)	Data 0.002 (0.004)	Loss 2.4979 (2.4033)	Acc@1 56.250 (56.019)	Acc@5 82.812 (84.606)
Epoch: [47][80/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.2800 (2.4023)	Acc@1 57.031 (55.999)	Acc@5 89.062 (84.606)
Epoch: [47][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5565 (2.4034)	Acc@1 50.000 (55.889)	Acc@5 83.594 (84.538)
Epoch: [47][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3006 (2.4076)	Acc@1 61.719 (55.739)	Acc@5 86.719 (84.553)
Epoch: [47][110/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.3449 (2.4070)	Acc@1 53.125 (55.595)	Acc@5 85.156 (84.607)
Epoch: [47][120/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3124 (2.4141)	Acc@1 57.031 (55.411)	Acc@5 85.156 (84.440)
Epoch: [47][130/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.6039 (2.4255)	Acc@1 53.125 (55.236)	Acc@5 80.469 (84.208)
Epoch: [47][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6024 (2.4292)	Acc@1 53.125 (55.170)	Acc@5 79.688 (84.164)
Epoch: [47][150/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3872 (2.4326)	Acc@1 55.469 (54.988)	Acc@5 83.594 (84.096)
Epoch: [47][160/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5478 (2.4373)	Acc@1 53.125 (54.828)	Acc@5 76.562 (84.011)
Epoch: [47][170/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5660 (2.4419)	Acc@1 56.250 (54.751)	Acc@5 83.594 (83.886)
Epoch: [47][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5905 (2.4445)	Acc@1 46.094 (54.605)	Acc@5 82.031 (83.909)
Epoch: [47][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3918 (2.4464)	Acc@1 57.812 (54.561)	Acc@5 85.938 (83.851)
Epoch: [47][200/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4777 (2.4477)	Acc@1 52.344 (54.513)	Acc@5 86.719 (83.889)
Epoch: [47][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3793 (2.4484)	Acc@1 59.375 (54.580)	Acc@5 86.719 (83.890)
Epoch: [47][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4667 (2.4514)	Acc@1 56.250 (54.571)	Acc@5 81.250 (83.831)
Epoch: [47][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3304 (2.4497)	Acc@1 56.250 (54.616)	Acc@5 86.719 (83.847)
Epoch: [47][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5910 (2.4533)	Acc@1 51.562 (54.584)	Acc@5 84.375 (83.749)
Epoch: [47][250/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5321 (2.4545)	Acc@1 57.031 (54.566)	Acc@5 83.594 (83.693)
Epoch: [47][260/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6115 (2.4563)	Acc@1 45.312 (54.520)	Acc@5 81.250 (83.633)
Epoch: [47][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5746 (2.4576)	Acc@1 48.438 (54.454)	Acc@5 84.375 (83.634)
Epoch: [47][280/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2732 (2.4555)	Acc@1 58.594 (54.479)	Acc@5 85.938 (83.677)
Epoch: [47][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4876 (2.4591)	Acc@1 54.688 (54.438)	Acc@5 85.156 (83.626)
Epoch: [47][300/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.8813 (2.4577)	Acc@1 43.750 (54.503)	Acc@5 77.344 (83.677)
Epoch: [47][310/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2743 (2.4598)	Acc@1 60.938 (54.489)	Acc@5 83.594 (83.654)
Epoch: [47][320/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5646 (2.4632)	Acc@1 55.469 (54.391)	Acc@5 76.562 (83.565)
Epoch: [47][330/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4645 (2.4618)	Acc@1 49.219 (54.395)	Acc@5 82.812 (83.561)
Epoch: [47][340/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4139 (2.4629)	Acc@1 60.156 (54.339)	Acc@5 89.844 (83.550)
Epoch: [47][350/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6227 (2.4644)	Acc@1 50.000 (54.322)	Acc@5 84.375 (83.556)
Epoch: [47][360/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3440 (2.4637)	Acc@1 56.250 (54.363)	Acc@5 84.375 (83.535)
Epoch: [47][370/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4660 (2.4636)	Acc@1 53.125 (54.361)	Acc@5 80.469 (83.550)
Epoch: [47][380/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5580 (2.4645)	Acc@1 52.344 (54.325)	Acc@5 86.719 (83.559)
Epoch: [47][390/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.5530 (2.4677)	Acc@1 55.000 (54.246)	Acc@5 83.750 (83.518)
num momentum params: 26
[0.1, 2.4676770932769774, 2.007933021783829, 54.246, 47.11, tensor(0.3229, device='cuda:0', grad_fn=<DivBackward0>), 5.284919500350952, 0.39434313774108887]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [48 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [48][0/391]	Time 0.044 (0.044)	Data 0.176 (0.176)	Loss 2.3648 (2.3648)	Acc@1 57.031 (57.031)	Acc@5 84.375 (84.375)
Epoch: [48][10/391]	Time 0.014 (0.017)	Data 0.002 (0.017)	Loss 2.2455 (2.3744)	Acc@1 66.406 (56.250)	Acc@5 82.812 (85.582)
Epoch: [48][20/391]	Time 0.014 (0.016)	Data 0.002 (0.010)	Loss 2.8218 (2.4016)	Acc@1 50.000 (55.469)	Acc@5 80.469 (85.156)
Epoch: [48][30/391]	Time 0.013 (0.015)	Data 0.002 (0.007)	Loss 2.2486 (2.3920)	Acc@1 61.719 (55.796)	Acc@5 86.719 (85.005)
Epoch: [48][40/391]	Time 0.015 (0.015)	Data 0.001 (0.006)	Loss 2.4051 (2.3887)	Acc@1 53.906 (56.098)	Acc@5 88.281 (85.080)
Epoch: [48][50/391]	Time 0.013 (0.014)	Data 0.002 (0.005)	Loss 2.4780 (2.3965)	Acc@1 51.562 (55.867)	Acc@5 85.156 (84.881)
Epoch: [48][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3062 (2.3991)	Acc@1 60.156 (55.917)	Acc@5 86.719 (84.657)
Epoch: [48][70/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.2293 (2.4147)	Acc@1 59.375 (55.414)	Acc@5 85.938 (84.342)
Epoch: [48][80/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3345 (2.4023)	Acc@1 54.688 (55.305)	Acc@5 89.062 (84.703)
Epoch: [48][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3065 (2.3966)	Acc@1 57.031 (55.280)	Acc@5 86.719 (84.804)
Epoch: [48][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.6886 (2.4066)	Acc@1 52.344 (55.190)	Acc@5 76.562 (84.491)
Epoch: [48][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4989 (2.4034)	Acc@1 51.562 (55.208)	Acc@5 82.031 (84.530)
Epoch: [48][120/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3613 (2.4074)	Acc@1 53.906 (54.939)	Acc@5 87.500 (84.543)
Epoch: [48][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.7255 (2.4081)	Acc@1 52.344 (55.075)	Acc@5 76.562 (84.417)
Epoch: [48][140/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4663 (2.4155)	Acc@1 57.031 (54.920)	Acc@5 84.375 (84.358)
Epoch: [48][150/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.2819 (2.4126)	Acc@1 57.031 (54.957)	Acc@5 85.938 (84.391)
Epoch: [48][160/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6699 (2.4121)	Acc@1 49.219 (54.988)	Acc@5 80.469 (84.424)
Epoch: [48][170/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2915 (2.4106)	Acc@1 57.812 (55.094)	Acc@5 84.375 (84.412)
Epoch: [48][180/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2839 (2.4101)	Acc@1 57.031 (55.136)	Acc@5 84.375 (84.397)
Epoch: [48][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4666 (2.4157)	Acc@1 55.469 (55.047)	Acc@5 82.812 (84.265)
Epoch: [48][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4380 (2.4162)	Acc@1 54.688 (55.119)	Acc@5 83.594 (84.262)
Epoch: [48][210/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.5050 (2.4176)	Acc@1 49.219 (55.058)	Acc@5 82.031 (84.231)
Epoch: [48][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.9441 (2.4212)	Acc@1 43.750 (54.999)	Acc@5 78.906 (84.219)
Epoch: [48][230/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6145 (2.4277)	Acc@1 50.000 (54.799)	Acc@5 81.250 (84.131)
Epoch: [48][240/391]	Time 0.011 (0.014)	Data 0.011 (0.002)	Loss 2.6438 (2.4313)	Acc@1 52.344 (54.782)	Acc@5 81.250 (84.048)
Epoch: [48][250/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.7086 (2.4346)	Acc@1 50.781 (54.731)	Acc@5 78.125 (83.955)
Epoch: [48][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4770 (2.4378)	Acc@1 53.906 (54.649)	Acc@5 80.469 (83.905)
Epoch: [48][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5090 (2.4383)	Acc@1 51.562 (54.636)	Acc@5 81.250 (83.879)
Epoch: [48][280/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3073 (2.4379)	Acc@1 58.594 (54.657)	Acc@5 85.938 (83.911)
Epoch: [48][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3894 (2.4405)	Acc@1 60.156 (54.650)	Acc@5 85.938 (83.870)
Epoch: [48][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4859 (2.4419)	Acc@1 53.906 (54.628)	Acc@5 86.719 (83.903)
Epoch: [48][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4037 (2.4401)	Acc@1 54.688 (54.728)	Acc@5 83.594 (83.890)
Epoch: [48][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4539 (2.4417)	Acc@1 54.688 (54.656)	Acc@5 84.375 (83.864)
Epoch: [48][330/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3811 (2.4444)	Acc@1 50.781 (54.529)	Acc@5 85.938 (83.853)
Epoch: [48][340/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3878 (2.4451)	Acc@1 50.781 (54.523)	Acc@5 82.812 (83.860)
Epoch: [48][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5202 (2.4487)	Acc@1 51.562 (54.418)	Acc@5 83.594 (83.823)
Epoch: [48][360/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5786 (2.4497)	Acc@1 50.781 (54.352)	Acc@5 79.688 (83.784)
Epoch: [48][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6057 (2.4513)	Acc@1 46.875 (54.306)	Acc@5 78.906 (83.739)
Epoch: [48][380/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5331 (2.4530)	Acc@1 54.688 (54.292)	Acc@5 77.344 (83.696)
Epoch: [48][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.7959 (2.4543)	Acc@1 45.000 (54.262)	Acc@5 77.500 (83.688)
num momentum params: 26
[0.1, 2.4543114365386964, 2.1781287586688993, 54.262, 44.05, tensor(0.3247, device='cuda:0', grad_fn=<DivBackward0>), 5.277742147445679, 0.3869931697845459]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [49 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [49][0/391]	Time 0.044 (0.044)	Data 0.156 (0.156)	Loss 2.6304 (2.6304)	Acc@1 49.219 (49.219)	Acc@5 80.469 (80.469)
Epoch: [49][10/391]	Time 0.014 (0.017)	Data 0.001 (0.016)	Loss 2.2914 (2.3582)	Acc@1 56.250 (57.173)	Acc@5 89.062 (85.582)
Epoch: [49][20/391]	Time 0.013 (0.015)	Data 0.001 (0.009)	Loss 2.4960 (2.3707)	Acc@1 50.781 (56.213)	Acc@5 85.156 (85.082)
Epoch: [49][30/391]	Time 0.013 (0.015)	Data 0.001 (0.006)	Loss 2.2975 (2.3891)	Acc@1 53.125 (55.595)	Acc@5 85.156 (84.980)
Epoch: [49][40/391]	Time 0.013 (0.014)	Data 0.002 (0.005)	Loss 2.6926 (2.3857)	Acc@1 46.094 (55.736)	Acc@5 81.250 (84.985)
Epoch: [49][50/391]	Time 0.014 (0.014)	Data 0.001 (0.005)	Loss 2.7519 (2.3822)	Acc@1 47.656 (55.944)	Acc@5 76.562 (84.988)
Epoch: [49][60/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.5638 (2.3833)	Acc@1 53.906 (56.148)	Acc@5 81.250 (84.695)
Epoch: [49][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.1737 (2.3808)	Acc@1 59.375 (56.206)	Acc@5 85.938 (84.749)
Epoch: [49][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4158 (2.3784)	Acc@1 55.469 (56.163)	Acc@5 85.156 (84.819)
Epoch: [49][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4918 (2.3874)	Acc@1 49.219 (55.915)	Acc@5 83.594 (84.555)
Epoch: [49][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3967 (2.3974)	Acc@1 58.594 (55.701)	Acc@5 85.938 (84.445)
Epoch: [49][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5681 (2.4079)	Acc@1 55.469 (55.455)	Acc@5 80.469 (84.213)
Epoch: [49][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4402 (2.4093)	Acc@1 54.688 (55.488)	Acc@5 85.156 (84.175)
Epoch: [49][130/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4035 (2.4157)	Acc@1 55.469 (55.391)	Acc@5 86.719 (84.071)
Epoch: [49][140/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.5593 (2.4186)	Acc@1 50.000 (55.375)	Acc@5 82.031 (84.076)
Epoch: [49][150/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6491 (2.4245)	Acc@1 53.906 (55.339)	Acc@5 79.688 (83.889)
Epoch: [49][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2038 (2.4223)	Acc@1 64.844 (55.386)	Acc@5 84.375 (83.919)
Epoch: [49][170/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.4187 (2.4301)	Acc@1 53.125 (55.185)	Acc@5 85.938 (83.850)
Epoch: [49][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3440 (2.4299)	Acc@1 57.031 (55.141)	Acc@5 82.812 (83.848)
Epoch: [49][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6105 (2.4299)	Acc@1 53.125 (55.076)	Acc@5 75.781 (83.790)
Epoch: [49][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4072 (2.4345)	Acc@1 54.688 (54.998)	Acc@5 85.938 (83.757)
Epoch: [49][210/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6889 (2.4420)	Acc@1 51.562 (54.950)	Acc@5 75.781 (83.583)
Epoch: [49][220/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.1489 (2.4440)	Acc@1 64.062 (54.921)	Acc@5 90.625 (83.562)
Epoch: [49][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3634 (2.4476)	Acc@1 58.594 (54.921)	Acc@5 88.281 (83.492)
Epoch: [49][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5173 (2.4522)	Acc@1 54.688 (54.811)	Acc@5 81.250 (83.412)
Epoch: [49][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3537 (2.4539)	Acc@1 57.812 (54.765)	Acc@5 85.938 (83.398)
Epoch: [49][260/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5797 (2.4531)	Acc@1 53.125 (54.801)	Acc@5 85.156 (83.420)
Epoch: [49][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4492 (2.4537)	Acc@1 53.906 (54.762)	Acc@5 83.594 (83.484)
Epoch: [49][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5569 (2.4534)	Acc@1 51.562 (54.732)	Acc@5 82.812 (83.508)
Epoch: [49][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6088 (2.4560)	Acc@1 51.562 (54.671)	Acc@5 79.688 (83.470)
Epoch: [49][300/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5914 (2.4575)	Acc@1 55.469 (54.628)	Acc@5 77.344 (83.425)
Epoch: [49][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6166 (2.4588)	Acc@1 46.875 (54.574)	Acc@5 82.812 (83.420)
Epoch: [49][320/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.7640 (2.4597)	Acc@1 46.875 (54.556)	Acc@5 78.906 (83.406)
Epoch: [49][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4217 (2.4585)	Acc@1 57.031 (54.610)	Acc@5 85.156 (83.438)
Epoch: [49][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8204 (2.4594)	Acc@1 47.656 (54.561)	Acc@5 78.906 (83.427)
Epoch: [49][350/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.3460 (2.4598)	Acc@1 58.594 (54.550)	Acc@5 85.938 (83.433)
Epoch: [49][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4800 (2.4617)	Acc@1 52.344 (54.465)	Acc@5 82.812 (83.380)
Epoch: [49][370/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.7173 (2.4616)	Acc@1 49.219 (54.445)	Acc@5 77.344 (83.358)
Epoch: [49][380/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5104 (2.4613)	Acc@1 54.688 (54.470)	Acc@5 83.594 (83.362)
Epoch: [49][390/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.5926 (2.4605)	Acc@1 42.500 (54.468)	Acc@5 85.000 (83.386)
num momentum params: 26
[0.1, 2.460498171157837, 1.9367312216758727, 54.468, 49.63, tensor(0.3238, device='cuda:0', grad_fn=<DivBackward0>), 5.253875255584717, 0.38619256019592285]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [50 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [50][0/391]	Time 0.046 (0.046)	Data 0.163 (0.163)	Loss 2.4633 (2.4633)	Acc@1 51.562 (51.562)	Acc@5 83.594 (83.594)
Epoch: [50][10/391]	Time 0.014 (0.017)	Data 0.001 (0.016)	Loss 2.6660 (2.3972)	Acc@1 51.562 (55.540)	Acc@5 82.812 (85.369)
Epoch: [50][20/391]	Time 0.013 (0.015)	Data 0.001 (0.009)	Loss 2.4945 (2.4276)	Acc@1 56.250 (54.836)	Acc@5 83.594 (84.561)
Epoch: [50][30/391]	Time 0.014 (0.015)	Data 0.001 (0.007)	Loss 2.1232 (2.3924)	Acc@1 63.281 (55.494)	Acc@5 89.062 (84.980)
Epoch: [50][40/391]	Time 0.013 (0.014)	Data 0.002 (0.005)	Loss 2.3446 (2.3960)	Acc@1 56.250 (55.488)	Acc@5 84.375 (84.737)
Epoch: [50][50/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.3843 (2.4130)	Acc@1 59.375 (55.025)	Acc@5 81.250 (84.161)
Epoch: [50][60/391]	Time 0.014 (0.014)	Data 0.002 (0.004)	Loss 2.1451 (2.4114)	Acc@1 60.938 (55.200)	Acc@5 86.719 (84.209)
Epoch: [50][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.5899 (2.4273)	Acc@1 54.688 (54.776)	Acc@5 82.031 (83.858)
Epoch: [50][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4617 (2.4342)	Acc@1 54.688 (54.620)	Acc@5 81.250 (83.931)
Epoch: [50][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3018 (2.4371)	Acc@1 58.594 (54.447)	Acc@5 85.938 (83.980)
Epoch: [50][100/391]	Time 0.012 (0.014)	Data 0.003 (0.003)	Loss 2.4243 (2.4436)	Acc@1 53.906 (54.154)	Acc@5 83.594 (83.926)
Epoch: [50][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3523 (2.4368)	Acc@1 57.031 (54.371)	Acc@5 87.500 (84.072)
Epoch: [50][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3479 (2.4350)	Acc@1 55.469 (54.436)	Acc@5 84.375 (84.188)
Epoch: [50][130/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4543 (2.4335)	Acc@1 51.562 (54.437)	Acc@5 82.812 (84.214)
Epoch: [50][140/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.2792 (2.4349)	Acc@1 50.781 (54.388)	Acc@5 89.844 (84.198)
Epoch: [50][150/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4830 (2.4412)	Acc@1 53.906 (54.320)	Acc@5 82.031 (84.070)
Epoch: [50][160/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.4124 (2.4437)	Acc@1 60.938 (54.319)	Acc@5 80.469 (83.933)
Epoch: [50][170/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6256 (2.4454)	Acc@1 52.344 (54.281)	Acc@5 82.031 (83.914)
Epoch: [50][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4475 (2.4486)	Acc@1 53.125 (54.230)	Acc@5 82.812 (83.917)
Epoch: [50][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6065 (2.4507)	Acc@1 46.875 (54.172)	Acc@5 80.469 (83.847)
Epoch: [50][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2855 (2.4483)	Acc@1 60.156 (54.186)	Acc@5 86.719 (83.916)
Epoch: [50][210/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3305 (2.4486)	Acc@1 54.688 (54.173)	Acc@5 85.938 (83.916)
Epoch: [50][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3763 (2.4476)	Acc@1 57.031 (54.207)	Acc@5 84.375 (83.937)
Epoch: [50][230/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3557 (2.4504)	Acc@1 59.375 (54.177)	Acc@5 87.500 (83.912)
Epoch: [50][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6765 (2.4549)	Acc@1 47.656 (53.978)	Acc@5 82.031 (83.863)
Epoch: [50][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3437 (2.4565)	Acc@1 57.812 (53.984)	Acc@5 82.031 (83.793)
Epoch: [50][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4424 (2.4566)	Acc@1 54.688 (53.990)	Acc@5 79.688 (83.755)
Epoch: [50][270/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2773 (2.4562)	Acc@1 53.125 (54.004)	Acc@5 89.844 (83.798)
Epoch: [50][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2783 (2.4544)	Acc@1 57.031 (54.020)	Acc@5 88.281 (83.833)
Epoch: [50][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4527 (2.4571)	Acc@1 53.125 (53.912)	Acc@5 82.812 (83.758)
Epoch: [50][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3642 (2.4544)	Acc@1 52.344 (53.987)	Acc@5 85.156 (83.781)
Epoch: [50][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7368 (2.4545)	Acc@1 52.344 (54.024)	Acc@5 79.688 (83.770)
Epoch: [50][320/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4715 (2.4541)	Acc@1 55.469 (54.057)	Acc@5 81.250 (83.786)
Epoch: [50][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3127 (2.4577)	Acc@1 60.938 (54.048)	Acc@5 86.719 (83.688)
Epoch: [50][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2689 (2.4588)	Acc@1 58.594 (54.064)	Acc@5 84.375 (83.653)
Epoch: [50][350/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.3193 (2.4600)	Acc@1 59.375 (54.022)	Acc@5 86.719 (83.636)
Epoch: [50][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4737 (2.4608)	Acc@1 57.031 (54.034)	Acc@5 84.375 (83.624)
Epoch: [50][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5785 (2.4636)	Acc@1 52.344 (53.925)	Acc@5 84.375 (83.611)
Epoch: [50][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7069 (2.4658)	Acc@1 53.906 (53.882)	Acc@5 82.812 (83.594)
Epoch: [50][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.4690 (2.4670)	Acc@1 53.750 (53.826)	Acc@5 83.750 (83.564)
num momentum params: 26
[0.1, 2.4670436380767824, 2.0378607416152956, 53.826, 47.36, tensor(0.3236, device='cuda:0', grad_fn=<DivBackward0>), 5.267910003662109, 0.3890564441680908]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [51 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [51][0/391]	Time 0.046 (0.046)	Data 0.149 (0.149)	Loss 2.3082 (2.3082)	Acc@1 60.938 (60.938)	Acc@5 86.719 (86.719)
Epoch: [51][10/391]	Time 0.013 (0.017)	Data 0.001 (0.015)	Loss 2.2096 (2.3524)	Acc@1 56.250 (57.244)	Acc@5 89.062 (85.866)
Epoch: [51][20/391]	Time 0.013 (0.015)	Data 0.001 (0.008)	Loss 2.3392 (2.3483)	Acc@1 53.906 (55.841)	Acc@5 88.281 (85.677)
Epoch: [51][30/391]	Time 0.013 (0.015)	Data 0.002 (0.006)	Loss 2.5476 (2.3461)	Acc@1 53.125 (56.275)	Acc@5 80.469 (85.585)
Epoch: [51][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.4582 (2.3404)	Acc@1 46.875 (56.441)	Acc@5 82.812 (85.957)
Epoch: [51][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.5723 (2.3581)	Acc@1 51.562 (56.112)	Acc@5 83.594 (85.815)
Epoch: [51][60/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.4223 (2.3616)	Acc@1 52.344 (56.058)	Acc@5 85.938 (85.605)
Epoch: [51][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3847 (2.3569)	Acc@1 57.031 (56.140)	Acc@5 84.375 (85.717)
Epoch: [51][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5855 (2.3653)	Acc@1 51.562 (56.105)	Acc@5 78.906 (85.561)
Epoch: [51][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6015 (2.3664)	Acc@1 46.875 (56.190)	Acc@5 82.812 (85.500)
Epoch: [51][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.2646 (2.3707)	Acc@1 64.062 (56.165)	Acc@5 85.938 (85.435)
Epoch: [51][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4476 (2.3738)	Acc@1 50.781 (56.250)	Acc@5 86.719 (85.213)
Epoch: [51][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4398 (2.3831)	Acc@1 56.250 (55.940)	Acc@5 82.812 (85.105)
Epoch: [51][130/391]	Time 0.012 (0.014)	Data 0.002 (0.003)	Loss 2.5260 (2.3900)	Acc@1 53.125 (55.749)	Acc@5 83.594 (85.049)
Epoch: [51][140/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3700 (2.3980)	Acc@1 55.469 (55.641)	Acc@5 82.812 (84.957)
Epoch: [51][150/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4010 (2.4019)	Acc@1 60.938 (55.546)	Acc@5 81.250 (84.825)
Epoch: [51][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3574 (2.4024)	Acc@1 53.906 (55.551)	Acc@5 85.156 (84.763)
Epoch: [51][170/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2806 (2.4034)	Acc@1 57.812 (55.560)	Acc@5 87.500 (84.704)
Epoch: [51][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6495 (2.4081)	Acc@1 48.438 (55.400)	Acc@5 77.344 (84.621)
Epoch: [51][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3207 (2.4089)	Acc@1 59.375 (55.350)	Acc@5 84.375 (84.596)
Epoch: [51][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5264 (2.4106)	Acc@1 51.562 (55.329)	Acc@5 85.156 (84.600)
Epoch: [51][210/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4973 (2.4148)	Acc@1 49.219 (55.221)	Acc@5 87.500 (84.586)
Epoch: [51][220/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5001 (2.4174)	Acc@1 46.094 (55.175)	Acc@5 84.375 (84.502)
Epoch: [51][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6748 (2.4208)	Acc@1 54.688 (55.164)	Acc@5 78.125 (84.412)
Epoch: [51][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6361 (2.4267)	Acc@1 52.344 (55.002)	Acc@5 78.906 (84.336)
Epoch: [51][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7412 (2.4255)	Acc@1 50.000 (55.005)	Acc@5 79.688 (84.338)
Epoch: [51][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3081 (2.4255)	Acc@1 55.469 (55.059)	Acc@5 86.719 (84.363)
Epoch: [51][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6949 (2.4291)	Acc@1 50.000 (54.941)	Acc@5 82.031 (84.314)
Epoch: [51][280/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5364 (2.4309)	Acc@1 51.562 (54.915)	Acc@5 83.594 (84.275)
Epoch: [51][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6301 (2.4331)	Acc@1 47.656 (54.827)	Acc@5 81.250 (84.249)
Epoch: [51][300/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.4716 (2.4346)	Acc@1 50.000 (54.841)	Acc@5 84.375 (84.204)
Epoch: [51][310/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5502 (2.4370)	Acc@1 51.562 (54.748)	Acc@5 80.469 (84.156)
Epoch: [51][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6136 (2.4378)	Acc@1 56.250 (54.748)	Acc@5 78.906 (84.132)
Epoch: [51][330/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5574 (2.4383)	Acc@1 53.125 (54.765)	Acc@5 79.688 (84.096)
Epoch: [51][340/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5183 (2.4402)	Acc@1 53.906 (54.754)	Acc@5 84.375 (84.063)
Epoch: [51][350/391]	Time 0.015 (0.013)	Data 0.002 (0.002)	Loss 2.5657 (2.4411)	Acc@1 51.562 (54.765)	Acc@5 78.906 (84.017)
Epoch: [51][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4614 (2.4413)	Acc@1 57.031 (54.692)	Acc@5 78.906 (84.040)
Epoch: [51][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3405 (2.4438)	Acc@1 60.156 (54.639)	Acc@5 83.594 (84.009)
Epoch: [51][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7470 (2.4456)	Acc@1 50.000 (54.624)	Acc@5 81.250 (83.953)
Epoch: [51][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.9014 (2.4472)	Acc@1 55.000 (54.594)	Acc@5 75.000 (83.936)
num momentum params: 26
[0.1, 2.4471591104888915, 2.0533210790157317, 54.594, 47.25, tensor(0.3262, device='cuda:0', grad_fn=<DivBackward0>), 5.264946699142456, 0.39862489700317383]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [52 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [52][0/391]	Time 0.043 (0.043)	Data 0.152 (0.152)	Loss 2.5657 (2.5657)	Acc@1 53.125 (53.125)	Acc@5 83.594 (83.594)
Epoch: [52][10/391]	Time 0.013 (0.017)	Data 0.001 (0.015)	Loss 2.3326 (2.4104)	Acc@1 57.812 (55.540)	Acc@5 84.375 (84.375)
Epoch: [52][20/391]	Time 0.013 (0.015)	Data 0.001 (0.009)	Loss 2.2398 (2.3499)	Acc@1 59.375 (57.440)	Acc@5 87.500 (84.933)
Epoch: [52][30/391]	Time 0.014 (0.015)	Data 0.001 (0.006)	Loss 2.4387 (2.3916)	Acc@1 51.562 (56.452)	Acc@5 85.938 (84.476)
Epoch: [52][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.5902 (2.3729)	Acc@1 54.688 (56.784)	Acc@5 82.031 (84.870)
Epoch: [52][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3089 (2.3832)	Acc@1 60.156 (56.357)	Acc@5 82.031 (84.835)
Epoch: [52][60/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.1060 (2.3842)	Acc@1 62.500 (56.404)	Acc@5 87.500 (84.772)
Epoch: [52][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.2494 (2.3863)	Acc@1 57.031 (56.382)	Acc@5 89.062 (84.727)
Epoch: [52][80/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.6077 (2.4012)	Acc@1 52.344 (56.047)	Acc@5 82.031 (84.423)
Epoch: [52][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5351 (2.4166)	Acc@1 53.125 (55.761)	Acc@5 82.031 (84.109)
Epoch: [52][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4395 (2.4204)	Acc@1 53.906 (55.623)	Acc@5 84.375 (84.174)
Epoch: [52][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3714 (2.4312)	Acc@1 53.125 (55.293)	Acc@5 88.281 (84.030)
Epoch: [52][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3777 (2.4339)	Acc@1 53.906 (55.198)	Acc@5 83.594 (83.981)
Epoch: [52][130/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4210 (2.4357)	Acc@1 52.344 (55.075)	Acc@5 85.156 (84.053)
Epoch: [52][140/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3542 (2.4378)	Acc@1 53.125 (54.920)	Acc@5 90.625 (84.142)
Epoch: [52][150/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4479 (2.4389)	Acc@1 52.344 (54.910)	Acc@5 82.031 (84.173)
Epoch: [52][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3614 (2.4393)	Acc@1 57.031 (54.954)	Acc@5 83.594 (84.094)
Epoch: [52][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7508 (2.4484)	Acc@1 44.531 (54.783)	Acc@5 78.125 (83.914)
Epoch: [52][180/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4948 (2.4508)	Acc@1 50.781 (54.623)	Acc@5 87.500 (83.965)
Epoch: [52][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4660 (2.4531)	Acc@1 51.562 (54.532)	Acc@5 87.500 (83.966)
Epoch: [52][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1589 (2.4519)	Acc@1 59.375 (54.540)	Acc@5 89.062 (83.975)
Epoch: [52][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4583 (2.4525)	Acc@1 51.562 (54.543)	Acc@5 80.469 (83.979)
Epoch: [52][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5907 (2.4501)	Acc@1 51.562 (54.631)	Acc@5 80.469 (83.976)
Epoch: [52][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2157 (2.4476)	Acc@1 63.281 (54.674)	Acc@5 86.719 (84.040)
Epoch: [52][240/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.4856 (2.4464)	Acc@1 54.688 (54.730)	Acc@5 85.938 (84.018)
Epoch: [52][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5962 (2.4501)	Acc@1 51.562 (54.641)	Acc@5 82.812 (83.942)
Epoch: [52][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4709 (2.4505)	Acc@1 51.562 (54.667)	Acc@5 83.594 (83.935)
Epoch: [52][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5601 (2.4520)	Acc@1 52.344 (54.598)	Acc@5 81.250 (83.931)
Epoch: [52][280/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.5067 (2.4532)	Acc@1 52.344 (54.585)	Acc@5 82.031 (83.897)
Epoch: [52][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2294 (2.4526)	Acc@1 55.469 (54.553)	Acc@5 89.844 (83.913)
Epoch: [52][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5090 (2.4546)	Acc@1 53.906 (54.514)	Acc@5 82.031 (83.866)
Epoch: [52][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3192 (2.4554)	Acc@1 57.031 (54.514)	Acc@5 82.812 (83.845)
Epoch: [52][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.1758 (2.4563)	Acc@1 54.688 (54.483)	Acc@5 89.062 (83.801)
Epoch: [52][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4103 (2.4551)	Acc@1 54.688 (54.534)	Acc@5 85.156 (83.816)
Epoch: [52][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6548 (2.4555)	Acc@1 51.562 (54.516)	Acc@5 79.688 (83.827)
Epoch: [52][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3621 (2.4578)	Acc@1 58.594 (54.436)	Acc@5 87.500 (83.787)
Epoch: [52][360/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.6041 (2.4562)	Acc@1 46.875 (54.501)	Acc@5 79.688 (83.791)
Epoch: [52][370/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5427 (2.4556)	Acc@1 56.250 (54.540)	Acc@5 81.250 (83.802)
Epoch: [52][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3971 (2.4562)	Acc@1 52.344 (54.544)	Acc@5 82.031 (83.750)
Epoch: [52][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.5828 (2.4560)	Acc@1 51.250 (54.534)	Acc@5 76.250 (83.748)
num momentum params: 26
[0.1, 2.456015843505859, 1.8664218652248383, 54.534, 50.61, tensor(0.3254, device='cuda:0', grad_fn=<DivBackward0>), 5.2535693645477295, 0.38693737983703613]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [53 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [53][0/391]	Time 0.045 (0.045)	Data 0.145 (0.145)	Loss 2.6296 (2.6296)	Acc@1 51.562 (51.562)	Acc@5 82.031 (82.031)
Epoch: [53][10/391]	Time 0.016 (0.017)	Data 0.001 (0.015)	Loss 2.4890 (2.2720)	Acc@1 56.250 (59.020)	Acc@5 83.594 (86.719)
Epoch: [53][20/391]	Time 0.013 (0.016)	Data 0.002 (0.008)	Loss 2.3659 (2.2669)	Acc@1 57.812 (58.780)	Acc@5 88.281 (86.644)
Epoch: [53][30/391]	Time 0.013 (0.015)	Data 0.001 (0.006)	Loss 2.4774 (2.2862)	Acc@1 49.219 (57.989)	Acc@5 85.938 (86.542)
Epoch: [53][40/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.2959 (2.2827)	Acc@1 58.594 (58.079)	Acc@5 87.500 (86.376)
Epoch: [53][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.1932 (2.3020)	Acc@1 60.938 (57.659)	Acc@5 85.938 (86.137)
Epoch: [53][60/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.4136 (2.3302)	Acc@1 55.469 (57.018)	Acc@5 84.375 (85.605)
Epoch: [53][70/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.5197 (2.3541)	Acc@1 52.344 (56.701)	Acc@5 83.594 (85.255)
Epoch: [53][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4393 (2.3632)	Acc@1 57.812 (56.636)	Acc@5 78.906 (85.002)
Epoch: [53][90/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5469 (2.3727)	Acc@1 53.125 (56.353)	Acc@5 83.594 (84.933)
Epoch: [53][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2677 (2.3769)	Acc@1 57.812 (56.327)	Acc@5 85.156 (84.855)
Epoch: [53][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4920 (2.3925)	Acc@1 54.688 (56.018)	Acc@5 82.031 (84.544)
Epoch: [53][120/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4163 (2.3936)	Acc@1 55.469 (55.972)	Acc@5 82.031 (84.562)
Epoch: [53][130/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3565 (2.3934)	Acc@1 60.156 (56.035)	Acc@5 82.812 (84.470)
Epoch: [53][140/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.4592 (2.3992)	Acc@1 55.469 (55.873)	Acc@5 82.031 (84.425)
Epoch: [53][150/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4924 (2.4032)	Acc@1 52.344 (55.676)	Acc@5 82.031 (84.416)
Epoch: [53][160/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3898 (2.4070)	Acc@1 53.906 (55.580)	Acc@5 85.938 (84.428)
Epoch: [53][170/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.2515 (2.4121)	Acc@1 60.156 (55.387)	Acc@5 83.594 (84.384)
Epoch: [53][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5569 (2.4110)	Acc@1 48.438 (55.395)	Acc@5 82.812 (84.405)
Epoch: [53][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3571 (2.4152)	Acc@1 53.906 (55.354)	Acc@5 85.938 (84.285)
Epoch: [53][200/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5652 (2.4200)	Acc@1 54.688 (55.259)	Acc@5 81.250 (84.153)
Epoch: [53][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2847 (2.4215)	Acc@1 59.375 (55.210)	Acc@5 87.500 (84.175)
Epoch: [53][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5404 (2.4269)	Acc@1 53.125 (55.087)	Acc@5 84.375 (84.057)
Epoch: [53][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4066 (2.4301)	Acc@1 58.594 (55.019)	Acc@5 83.594 (84.020)
Epoch: [53][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3896 (2.4306)	Acc@1 55.469 (54.979)	Acc@5 85.156 (84.064)
Epoch: [53][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5165 (2.4344)	Acc@1 56.250 (54.877)	Acc@5 84.375 (84.039)
Epoch: [53][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7286 (2.4355)	Acc@1 44.531 (54.840)	Acc@5 78.906 (84.034)
Epoch: [53][270/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5681 (2.4377)	Acc@1 46.875 (54.774)	Acc@5 82.031 (84.023)
Epoch: [53][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3649 (2.4399)	Acc@1 52.344 (54.726)	Acc@5 86.719 (83.989)
Epoch: [53][290/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4249 (2.4404)	Acc@1 51.562 (54.661)	Acc@5 87.500 (83.988)
Epoch: [53][300/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5221 (2.4447)	Acc@1 53.125 (54.566)	Acc@5 82.812 (83.910)
Epoch: [53][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4626 (2.4440)	Acc@1 55.469 (54.610)	Acc@5 82.031 (83.925)
Epoch: [53][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3651 (2.4454)	Acc@1 57.812 (54.619)	Acc@5 83.594 (83.866)
Epoch: [53][330/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4359 (2.4470)	Acc@1 53.906 (54.586)	Acc@5 85.938 (83.818)
Epoch: [53][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6511 (2.4478)	Acc@1 50.781 (54.580)	Acc@5 79.688 (83.788)
Epoch: [53][350/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5491 (2.4514)	Acc@1 52.344 (54.492)	Acc@5 85.156 (83.734)
Epoch: [53][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4732 (2.4523)	Acc@1 53.125 (54.475)	Acc@5 83.594 (83.700)
Epoch: [53][370/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6761 (2.4540)	Acc@1 48.438 (54.460)	Acc@5 81.250 (83.678)
Epoch: [53][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4791 (2.4554)	Acc@1 50.781 (54.411)	Acc@5 82.031 (83.668)
Epoch: [53][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.5947 (2.4575)	Acc@1 46.250 (54.380)	Acc@5 82.500 (83.636)
num momentum params: 26
[0.1, 2.457472075881958, 2.166963632106781, 54.38, 45.07, tensor(0.3259, device='cuda:0', grad_fn=<DivBackward0>), 5.275417327880859, 0.38715028762817383]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [54 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [54][0/391]	Time 0.043 (0.043)	Data 0.152 (0.152)	Loss 2.2595 (2.2595)	Acc@1 63.281 (63.281)	Acc@5 85.938 (85.938)
Epoch: [54][10/391]	Time 0.015 (0.017)	Data 0.001 (0.015)	Loss 2.1747 (2.3509)	Acc@1 62.500 (56.960)	Acc@5 89.844 (85.653)
Epoch: [54][20/391]	Time 0.013 (0.015)	Data 0.002 (0.009)	Loss 2.3574 (2.3589)	Acc@1 58.594 (56.957)	Acc@5 82.031 (85.603)
Epoch: [54][30/391]	Time 0.014 (0.015)	Data 0.002 (0.006)	Loss 2.1851 (2.3496)	Acc@1 57.031 (56.930)	Acc@5 90.625 (85.635)
Epoch: [54][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.3533 (2.3555)	Acc@1 56.250 (56.993)	Acc@5 82.812 (85.271)
Epoch: [54][50/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.3238 (2.3607)	Acc@1 58.594 (57.108)	Acc@5 87.500 (85.263)
Epoch: [54][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4237 (2.3603)	Acc@1 57.031 (57.108)	Acc@5 85.938 (85.272)
Epoch: [54][70/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.4218 (2.3599)	Acc@1 56.250 (57.273)	Acc@5 81.250 (85.178)
Epoch: [54][80/391]	Time 0.015 (0.014)	Data 0.002 (0.003)	Loss 2.3258 (2.3628)	Acc@1 60.938 (57.272)	Acc@5 86.719 (85.147)
Epoch: [54][90/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.5990 (2.3672)	Acc@1 50.781 (57.083)	Acc@5 79.688 (84.890)
Epoch: [54][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3109 (2.3769)	Acc@1 50.781 (56.714)	Acc@5 89.844 (84.816)
Epoch: [54][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3373 (2.3886)	Acc@1 62.500 (56.377)	Acc@5 83.594 (84.657)
Epoch: [54][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4361 (2.4011)	Acc@1 56.250 (56.089)	Acc@5 84.375 (84.375)
Epoch: [54][130/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.6042 (2.4014)	Acc@1 47.656 (56.071)	Acc@5 84.375 (84.458)
Epoch: [54][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4348 (2.4084)	Acc@1 60.156 (55.890)	Acc@5 80.469 (84.331)
Epoch: [54][150/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4738 (2.4139)	Acc@1 53.906 (55.655)	Acc@5 82.031 (84.240)
Epoch: [54][160/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5640 (2.4178)	Acc@1 58.594 (55.527)	Acc@5 82.812 (84.186)
Epoch: [54][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4818 (2.4163)	Acc@1 48.438 (55.496)	Acc@5 82.812 (84.183)
Epoch: [54][180/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4729 (2.4177)	Acc@1 58.594 (55.546)	Acc@5 83.594 (84.176)
Epoch: [54][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2582 (2.4188)	Acc@1 57.031 (55.501)	Acc@5 88.281 (84.195)
Epoch: [54][200/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3378 (2.4202)	Acc@1 60.156 (55.422)	Acc@5 85.156 (84.227)
Epoch: [54][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6267 (2.4253)	Acc@1 51.562 (55.295)	Acc@5 78.906 (84.160)
Epoch: [54][220/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5833 (2.4253)	Acc@1 53.906 (55.359)	Acc@5 81.250 (84.170)
Epoch: [54][230/391]	Time 0.012 (0.014)	Data 0.003 (0.002)	Loss 2.3635 (2.4273)	Acc@1 56.250 (55.317)	Acc@5 83.594 (84.131)
Epoch: [54][240/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.2545 (2.4286)	Acc@1 57.031 (55.222)	Acc@5 85.156 (84.106)
Epoch: [54][250/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.7789 (2.4349)	Acc@1 49.219 (55.067)	Acc@5 76.562 (83.967)
Epoch: [54][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4369 (2.4387)	Acc@1 60.156 (54.975)	Acc@5 82.031 (83.875)
Epoch: [54][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3474 (2.4390)	Acc@1 56.250 (55.013)	Acc@5 87.500 (83.850)
Epoch: [54][280/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.6706 (2.4405)	Acc@1 46.094 (54.938)	Acc@5 78.125 (83.847)
Epoch: [54][290/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4640 (2.4404)	Acc@1 54.688 (54.929)	Acc@5 84.375 (83.857)
Epoch: [54][300/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.7277 (2.4412)	Acc@1 48.438 (54.913)	Acc@5 77.344 (83.840)
Epoch: [54][310/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.8532 (2.4435)	Acc@1 41.406 (54.843)	Acc@5 79.688 (83.817)
Epoch: [54][320/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.4742 (2.4457)	Acc@1 53.906 (54.758)	Acc@5 85.156 (83.796)
Epoch: [54][330/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.3064 (2.4444)	Acc@1 56.250 (54.751)	Acc@5 83.594 (83.820)
Epoch: [54][340/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.4861 (2.4462)	Acc@1 53.125 (54.701)	Acc@5 82.812 (83.805)
Epoch: [54][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7358 (2.4484)	Acc@1 48.438 (54.696)	Acc@5 79.688 (83.772)
Epoch: [54][360/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.7792 (2.4489)	Acc@1 40.625 (54.653)	Acc@5 79.688 (83.737)
Epoch: [54][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3278 (2.4499)	Acc@1 57.031 (54.631)	Acc@5 85.156 (83.750)
Epoch: [54][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6891 (2.4529)	Acc@1 46.875 (54.567)	Acc@5 77.344 (83.692)
Epoch: [54][390/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.4184 (2.4533)	Acc@1 53.750 (54.552)	Acc@5 85.000 (83.696)
num momentum params: 26
[0.1, 2.4532662980651856, 2.118378200531006, 54.552, 46.17, tensor(0.3261, device='cuda:0', grad_fn=<DivBackward0>), 5.2652928829193115, 0.38806724548339844]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [55 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [55][0/391]	Time 0.047 (0.047)	Data 0.157 (0.157)	Loss 2.3098 (2.3098)	Acc@1 57.812 (57.812)	Acc@5 88.281 (88.281)
Epoch: [55][10/391]	Time 0.013 (0.017)	Data 0.002 (0.015)	Loss 2.4011 (2.3709)	Acc@1 55.469 (56.463)	Acc@5 82.812 (85.227)
Epoch: [55][20/391]	Time 0.013 (0.015)	Data 0.001 (0.009)	Loss 2.4499 (2.3495)	Acc@1 53.906 (56.101)	Acc@5 83.594 (85.454)
Epoch: [55][30/391]	Time 0.013 (0.015)	Data 0.001 (0.006)	Loss 2.4409 (2.3354)	Acc@1 50.781 (56.401)	Acc@5 89.062 (85.711)
Epoch: [55][40/391]	Time 0.013 (0.014)	Data 0.002 (0.005)	Loss 2.3729 (2.3230)	Acc@1 58.594 (57.165)	Acc@5 79.688 (85.766)
Epoch: [55][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3456 (2.3262)	Acc@1 56.250 (57.292)	Acc@5 86.719 (85.708)
Epoch: [55][60/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.2305 (2.3255)	Acc@1 59.375 (57.364)	Acc@5 82.031 (85.733)
Epoch: [55][70/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.4413 (2.3372)	Acc@1 56.250 (57.042)	Acc@5 83.594 (85.519)
Epoch: [55][80/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3261 (2.3514)	Acc@1 57.812 (56.684)	Acc@5 85.938 (85.233)
Epoch: [55][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2756 (2.3556)	Acc@1 61.719 (56.662)	Acc@5 85.938 (85.294)
Epoch: [55][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3596 (2.3613)	Acc@1 54.688 (56.513)	Acc@5 84.375 (85.257)
Epoch: [55][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5181 (2.3652)	Acc@1 51.562 (56.412)	Acc@5 82.031 (85.177)
Epoch: [55][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5151 (2.3692)	Acc@1 53.906 (56.411)	Acc@5 82.031 (85.059)
Epoch: [55][130/391]	Time 0.015 (0.014)	Data 0.002 (0.003)	Loss 2.4945 (2.3752)	Acc@1 53.125 (56.357)	Acc@5 84.375 (84.948)
Epoch: [55][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2612 (2.3886)	Acc@1 55.469 (55.995)	Acc@5 91.406 (84.818)
Epoch: [55][150/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5412 (2.3943)	Acc@1 48.438 (55.955)	Acc@5 79.688 (84.851)
Epoch: [55][160/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5257 (2.4020)	Acc@1 46.094 (55.847)	Acc@5 84.375 (84.758)
Epoch: [55][170/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4447 (2.4073)	Acc@1 52.344 (55.697)	Acc@5 85.156 (84.640)
Epoch: [55][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5245 (2.4106)	Acc@1 53.906 (55.616)	Acc@5 84.375 (84.595)
Epoch: [55][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4135 (2.4079)	Acc@1 58.594 (55.641)	Acc@5 86.719 (84.657)
Epoch: [55][200/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4314 (2.4113)	Acc@1 59.375 (55.593)	Acc@5 83.594 (84.581)
Epoch: [55][210/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4891 (2.4166)	Acc@1 53.125 (55.476)	Acc@5 86.719 (84.575)
Epoch: [55][220/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4333 (2.4175)	Acc@1 64.062 (55.472)	Acc@5 82.812 (84.541)
Epoch: [55][230/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3737 (2.4185)	Acc@1 57.031 (55.377)	Acc@5 85.156 (84.490)
Epoch: [55][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5421 (2.4213)	Acc@1 49.219 (55.287)	Acc@5 81.250 (84.488)
Epoch: [55][250/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3278 (2.4255)	Acc@1 54.688 (55.192)	Acc@5 86.719 (84.456)
Epoch: [55][260/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5186 (2.4290)	Acc@1 57.031 (55.145)	Acc@5 82.812 (84.375)
Epoch: [55][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4956 (2.4312)	Acc@1 51.562 (55.080)	Acc@5 85.156 (84.381)
Epoch: [55][280/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6672 (2.4347)	Acc@1 49.219 (55.018)	Acc@5 76.562 (84.236)
Epoch: [55][290/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5283 (2.4376)	Acc@1 48.438 (54.956)	Acc@5 87.500 (84.198)
Epoch: [55][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5351 (2.4406)	Acc@1 54.688 (54.885)	Acc@5 82.031 (84.152)
Epoch: [55][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4890 (2.4428)	Acc@1 51.562 (54.811)	Acc@5 86.719 (84.141)
Epoch: [55][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6200 (2.4452)	Acc@1 51.562 (54.778)	Acc@5 79.688 (84.098)
Epoch: [55][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3742 (2.4456)	Acc@1 56.250 (54.784)	Acc@5 84.375 (84.092)
Epoch: [55][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2826 (2.4473)	Acc@1 62.500 (54.747)	Acc@5 89.062 (84.047)
Epoch: [55][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3996 (2.4465)	Acc@1 56.250 (54.788)	Acc@5 83.594 (84.017)
Epoch: [55][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8393 (2.4500)	Acc@1 44.531 (54.711)	Acc@5 79.688 (83.968)
Epoch: [55][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4336 (2.4520)	Acc@1 53.906 (54.658)	Acc@5 85.156 (83.922)
Epoch: [55][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6875 (2.4574)	Acc@1 53.906 (54.564)	Acc@5 80.469 (83.811)
Epoch: [55][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.4172 (2.4566)	Acc@1 53.750 (54.572)	Acc@5 81.250 (83.790)
num momentum params: 26
[0.1, 2.4565995754241943, 2.2219644057750703, 54.572, 43.93, tensor(0.3259, device='cuda:0', grad_fn=<DivBackward0>), 5.265410423278809, 0.39041852951049805]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [56 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [56][0/391]	Time 0.045 (0.045)	Data 0.155 (0.155)	Loss 2.5119 (2.5119)	Acc@1 50.781 (50.781)	Acc@5 78.125 (78.125)
Epoch: [56][10/391]	Time 0.013 (0.017)	Data 0.001 (0.016)	Loss 2.1823 (2.4116)	Acc@1 66.406 (55.540)	Acc@5 88.281 (83.736)
Epoch: [56][20/391]	Time 0.013 (0.015)	Data 0.001 (0.009)	Loss 2.1904 (2.3824)	Acc@1 63.281 (56.957)	Acc@5 83.594 (84.115)
Epoch: [56][30/391]	Time 0.014 (0.015)	Data 0.001 (0.006)	Loss 2.5368 (2.3954)	Acc@1 52.344 (56.250)	Acc@5 78.906 (83.947)
Epoch: [56][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.3388 (2.3989)	Acc@1 56.250 (56.117)	Acc@5 82.812 (83.841)
Epoch: [56][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.5036 (2.4145)	Acc@1 52.344 (55.576)	Acc@5 85.156 (84.130)
Epoch: [56][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.5448 (2.4150)	Acc@1 50.000 (55.482)	Acc@5 85.156 (84.170)
Epoch: [56][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4870 (2.4061)	Acc@1 53.906 (55.788)	Acc@5 79.688 (84.320)
Epoch: [56][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2627 (2.3964)	Acc@1 61.719 (56.105)	Acc@5 89.062 (84.500)
Epoch: [56][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5651 (2.3834)	Acc@1 52.344 (56.276)	Acc@5 81.250 (84.761)
Epoch: [56][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4133 (2.3864)	Acc@1 50.781 (56.165)	Acc@5 85.938 (84.762)
Epoch: [56][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4780 (2.3959)	Acc@1 51.562 (55.919)	Acc@5 85.938 (84.699)
Epoch: [56][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3382 (2.4011)	Acc@1 55.469 (55.792)	Acc@5 85.938 (84.614)
Epoch: [56][130/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.2823 (2.4096)	Acc@1 62.500 (55.582)	Acc@5 86.719 (84.524)
Epoch: [56][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4295 (2.4107)	Acc@1 52.344 (55.557)	Acc@5 82.812 (84.547)
Epoch: [56][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3854 (2.4163)	Acc@1 56.250 (55.422)	Acc@5 86.719 (84.499)
Epoch: [56][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3829 (2.4211)	Acc@1 52.344 (55.347)	Acc@5 87.500 (84.428)
Epoch: [56][170/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6699 (2.4252)	Acc@1 52.344 (55.185)	Acc@5 84.375 (84.375)
Epoch: [56][180/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2483 (2.4259)	Acc@1 56.250 (55.149)	Acc@5 88.281 (84.362)
Epoch: [56][190/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5505 (2.4310)	Acc@1 51.562 (55.015)	Acc@5 83.594 (84.310)
Epoch: [56][200/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3794 (2.4360)	Acc@1 59.375 (54.967)	Acc@5 82.812 (84.177)
Epoch: [56][210/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.3612 (2.4367)	Acc@1 56.250 (54.969)	Acc@5 85.156 (84.101)
Epoch: [56][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7057 (2.4392)	Acc@1 49.219 (54.896)	Acc@5 78.906 (83.990)
Epoch: [56][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5451 (2.4364)	Acc@1 50.781 (54.911)	Acc@5 85.156 (84.074)
Epoch: [56][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5050 (2.4351)	Acc@1 56.250 (54.908)	Acc@5 79.688 (84.086)
Epoch: [56][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3905 (2.4358)	Acc@1 57.031 (54.840)	Acc@5 85.938 (84.095)
Epoch: [56][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4623 (2.4366)	Acc@1 56.250 (54.840)	Acc@5 82.031 (84.085)
Epoch: [56][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7347 (2.4385)	Acc@1 47.656 (54.777)	Acc@5 80.469 (84.067)
Epoch: [56][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4876 (2.4407)	Acc@1 51.562 (54.671)	Acc@5 81.250 (84.072)
Epoch: [56][290/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.4446 (2.4414)	Acc@1 58.594 (54.717)	Acc@5 82.031 (84.072)
Epoch: [56][300/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.6733 (2.4441)	Acc@1 50.781 (54.654)	Acc@5 78.125 (84.038)
Epoch: [56][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4232 (2.4428)	Acc@1 54.688 (54.705)	Acc@5 82.031 (84.064)
Epoch: [56][320/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.4139 (2.4461)	Acc@1 55.469 (54.651)	Acc@5 84.375 (83.978)
Epoch: [56][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7809 (2.4465)	Acc@1 45.312 (54.647)	Acc@5 82.031 (83.938)
Epoch: [56][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.1795 (2.4443)	Acc@1 62.500 (54.715)	Acc@5 89.062 (83.969)
Epoch: [56][350/391]	Time 0.012 (0.013)	Data 0.001 (0.002)	Loss 2.6708 (2.4452)	Acc@1 50.781 (54.714)	Acc@5 82.031 (83.970)
Epoch: [56][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4377 (2.4483)	Acc@1 57.031 (54.688)	Acc@5 83.594 (83.921)
Epoch: [56][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6504 (2.4488)	Acc@1 48.438 (54.688)	Acc@5 84.375 (83.910)
Epoch: [56][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5152 (2.4506)	Acc@1 56.250 (54.616)	Acc@5 78.125 (83.893)
Epoch: [56][390/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.4385 (2.4513)	Acc@1 62.500 (54.640)	Acc@5 83.750 (83.866)
num momentum params: 26
[0.1, 2.4512949758148195, 2.014033213853836, 54.64, 47.4, tensor(0.3268, device='cuda:0', grad_fn=<DivBackward0>), 5.227777481079102, 0.3955233097076416]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [57 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [57][0/391]	Time 0.053 (0.053)	Data 0.149 (0.149)	Loss 2.4126 (2.4126)	Acc@1 56.250 (56.250)	Acc@5 81.250 (81.250)
Epoch: [57][10/391]	Time 0.013 (0.017)	Data 0.001 (0.015)	Loss 2.4076 (2.3065)	Acc@1 57.812 (57.244)	Acc@5 88.281 (86.435)
Epoch: [57][20/391]	Time 0.013 (0.016)	Data 0.001 (0.009)	Loss 2.1931 (2.3158)	Acc@1 63.281 (57.106)	Acc@5 87.500 (85.938)
Epoch: [57][30/391]	Time 0.013 (0.015)	Data 0.001 (0.006)	Loss 2.2338 (2.3298)	Acc@1 61.719 (57.233)	Acc@5 86.719 (85.736)
Epoch: [57][40/391]	Time 0.014 (0.015)	Data 0.002 (0.005)	Loss 2.6042 (2.3771)	Acc@1 52.344 (56.421)	Acc@5 79.688 (84.985)
Epoch: [57][50/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.4265 (2.3840)	Acc@1 53.125 (55.928)	Acc@5 83.594 (85.049)
Epoch: [57][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3026 (2.3805)	Acc@1 59.375 (56.045)	Acc@5 84.375 (85.015)
Epoch: [57][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4723 (2.3890)	Acc@1 55.469 (55.832)	Acc@5 85.156 (84.936)
Epoch: [57][80/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.4561 (2.3996)	Acc@1 52.344 (55.584)	Acc@5 83.594 (84.722)
Epoch: [57][90/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5196 (2.4103)	Acc@1 55.469 (55.306)	Acc@5 81.250 (84.538)
Epoch: [57][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2528 (2.4091)	Acc@1 60.156 (55.415)	Acc@5 88.281 (84.646)
Epoch: [57][110/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.3791 (2.4088)	Acc@1 58.594 (55.405)	Acc@5 79.688 (84.614)
Epoch: [57][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.0786 (2.4049)	Acc@1 65.625 (55.566)	Acc@5 90.625 (84.640)
Epoch: [57][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3579 (2.4106)	Acc@1 57.031 (55.349)	Acc@5 89.844 (84.608)
Epoch: [57][140/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.6109 (2.4198)	Acc@1 50.781 (55.142)	Acc@5 81.250 (84.408)
Epoch: [57][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3823 (2.4235)	Acc@1 58.594 (55.169)	Acc@5 87.500 (84.339)
Epoch: [57][160/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4040 (2.4284)	Acc@1 55.469 (55.071)	Acc@5 85.938 (84.326)
Epoch: [57][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5771 (2.4295)	Acc@1 53.125 (55.021)	Acc@5 79.688 (84.311)
Epoch: [57][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4048 (2.4311)	Acc@1 54.688 (54.994)	Acc@5 84.375 (84.228)
Epoch: [57][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2946 (2.4321)	Acc@1 58.594 (54.941)	Acc@5 89.062 (84.215)
Epoch: [57][200/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6577 (2.4306)	Acc@1 51.562 (54.991)	Acc@5 77.344 (84.204)
Epoch: [57][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3946 (2.4306)	Acc@1 57.031 (54.976)	Acc@5 85.938 (84.223)
Epoch: [57][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2506 (2.4288)	Acc@1 60.938 (55.083)	Acc@5 87.500 (84.241)
Epoch: [57][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3930 (2.4297)	Acc@1 54.688 (55.053)	Acc@5 86.719 (84.233)
Epoch: [57][240/391]	Time 0.012 (0.014)	Data 0.002 (0.002)	Loss 2.6462 (2.4311)	Acc@1 53.906 (55.083)	Acc@5 80.469 (84.245)
Epoch: [57][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6103 (2.4344)	Acc@1 50.000 (55.036)	Acc@5 82.812 (84.170)
Epoch: [57][260/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5214 (2.4339)	Acc@1 52.344 (55.026)	Acc@5 84.375 (84.168)
Epoch: [57][270/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5028 (2.4322)	Acc@1 48.438 (54.984)	Acc@5 84.375 (84.214)
Epoch: [57][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3540 (2.4307)	Acc@1 64.844 (55.082)	Acc@5 82.812 (84.269)
Epoch: [57][290/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4020 (2.4304)	Acc@1 58.594 (55.069)	Acc@5 81.250 (84.297)
Epoch: [57][300/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3940 (2.4326)	Acc@1 54.688 (55.025)	Acc@5 84.375 (84.248)
Epoch: [57][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4709 (2.4354)	Acc@1 55.469 (54.996)	Acc@5 82.031 (84.184)
Epoch: [57][320/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5194 (2.4368)	Acc@1 46.094 (54.948)	Acc@5 82.031 (84.163)
Epoch: [57][330/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6408 (2.4381)	Acc@1 48.438 (54.893)	Acc@5 82.812 (84.141)
Epoch: [57][340/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.5442 (2.4413)	Acc@1 50.781 (54.791)	Acc@5 78.906 (84.063)
Epoch: [57][350/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2311 (2.4430)	Acc@1 57.812 (54.785)	Acc@5 88.281 (84.021)
Epoch: [57][360/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3879 (2.4434)	Acc@1 60.156 (54.791)	Acc@5 84.375 (84.005)
Epoch: [57][370/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.7053 (2.4453)	Acc@1 48.438 (54.770)	Acc@5 84.375 (83.996)
Epoch: [57][380/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.8972 (2.4467)	Acc@1 46.094 (54.753)	Acc@5 76.562 (84.012)
Epoch: [57][390/391]	Time 0.016 (0.014)	Data 0.002 (0.002)	Loss 2.4211 (2.4481)	Acc@1 52.500 (54.736)	Acc@5 78.750 (83.974)
num momentum params: 26
[0.1, 2.4480750011444092, 2.100564029216766, 54.736, 46.29, tensor(0.3269, device='cuda:0', grad_fn=<DivBackward0>), 5.292889595031738, 0.3951504230499268]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [58 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [58][0/391]	Time 0.049 (0.049)	Data 0.154 (0.154)	Loss 2.3467 (2.3467)	Acc@1 56.250 (56.250)	Acc@5 83.594 (83.594)
Epoch: [58][10/391]	Time 0.013 (0.018)	Data 0.002 (0.016)	Loss 2.4590 (2.3756)	Acc@1 52.344 (55.540)	Acc@5 82.812 (84.659)
Epoch: [58][20/391]	Time 0.015 (0.016)	Data 0.002 (0.009)	Loss 2.2030 (2.3437)	Acc@1 60.156 (56.510)	Acc@5 91.406 (85.714)
Epoch: [58][30/391]	Time 0.013 (0.015)	Data 0.002 (0.007)	Loss 2.3418 (2.3338)	Acc@1 54.688 (56.603)	Acc@5 86.719 (85.811)
Epoch: [58][40/391]	Time 0.014 (0.015)	Data 0.002 (0.005)	Loss 2.2061 (2.3222)	Acc@1 62.500 (57.260)	Acc@5 87.500 (86.166)
Epoch: [58][50/391]	Time 0.014 (0.015)	Data 0.002 (0.005)	Loss 2.3557 (2.3327)	Acc@1 53.125 (56.756)	Acc@5 83.594 (85.677)
Epoch: [58][60/391]	Time 0.014 (0.014)	Data 0.002 (0.004)	Loss 2.3130 (2.3452)	Acc@1 57.031 (56.416)	Acc@5 86.719 (85.502)
Epoch: [58][70/391]	Time 0.014 (0.014)	Data 0.002 (0.004)	Loss 2.5026 (2.3594)	Acc@1 61.719 (56.349)	Acc@5 81.250 (85.112)
Epoch: [58][80/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.4306 (2.3677)	Acc@1 57.812 (56.163)	Acc@5 83.594 (85.069)
Epoch: [58][90/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.0893 (2.3697)	Acc@1 62.500 (55.975)	Acc@5 89.062 (85.148)
Epoch: [58][100/391]	Time 0.017 (0.014)	Data 0.002 (0.003)	Loss 2.4778 (2.3779)	Acc@1 57.812 (55.894)	Acc@5 87.500 (85.102)
Epoch: [58][110/391]	Time 0.011 (0.014)	Data 0.003 (0.003)	Loss 2.1953 (2.3920)	Acc@1 63.281 (55.638)	Acc@5 85.156 (84.832)
Epoch: [58][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5315 (2.3918)	Acc@1 52.344 (55.656)	Acc@5 82.812 (84.853)
Epoch: [58][130/391]	Time 0.016 (0.014)	Data 0.001 (0.003)	Loss 2.4410 (2.3956)	Acc@1 53.906 (55.624)	Acc@5 82.812 (84.798)
Epoch: [58][140/391]	Time 0.016 (0.014)	Data 0.001 (0.003)	Loss 2.4418 (2.3946)	Acc@1 54.688 (55.624)	Acc@5 83.594 (84.746)
Epoch: [58][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.0108 (2.3922)	Acc@1 64.844 (55.691)	Acc@5 92.188 (84.825)
Epoch: [58][160/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3360 (2.3910)	Acc@1 53.125 (55.634)	Acc@5 85.156 (84.855)
Epoch: [58][170/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.5474 (2.3955)	Acc@1 55.469 (55.656)	Acc@5 80.469 (84.795)
Epoch: [58][180/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3597 (2.3999)	Acc@1 58.594 (55.590)	Acc@5 83.594 (84.738)
Epoch: [58][190/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2981 (2.4043)	Acc@1 57.812 (55.489)	Acc@5 85.156 (84.694)
Epoch: [58][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6176 (2.4108)	Acc@1 53.125 (55.368)	Acc@5 80.469 (84.569)
Epoch: [58][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4324 (2.4175)	Acc@1 56.250 (55.191)	Acc@5 83.594 (84.486)
Epoch: [58][220/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4830 (2.4206)	Acc@1 50.781 (55.094)	Acc@5 84.375 (84.442)
Epoch: [58][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4581 (2.4248)	Acc@1 55.469 (55.032)	Acc@5 84.375 (84.368)
Epoch: [58][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3627 (2.4247)	Acc@1 54.688 (55.051)	Acc@5 84.375 (84.339)
Epoch: [58][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2781 (2.4232)	Acc@1 60.156 (55.058)	Acc@5 87.500 (84.387)
Epoch: [58][260/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.6806 (2.4261)	Acc@1 46.875 (54.990)	Acc@5 82.812 (84.366)
Epoch: [58][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3781 (2.4273)	Acc@1 59.375 (54.976)	Acc@5 83.594 (84.338)
Epoch: [58][280/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4383 (2.4299)	Acc@1 59.375 (54.932)	Acc@5 85.938 (84.303)
Epoch: [58][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4860 (2.4314)	Acc@1 50.781 (54.894)	Acc@5 81.250 (84.289)
Epoch: [58][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6258 (2.4344)	Acc@1 49.219 (54.833)	Acc@5 82.812 (84.271)
Epoch: [58][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3714 (2.4345)	Acc@1 51.562 (54.768)	Acc@5 85.938 (84.244)
Epoch: [58][320/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.7229 (2.4363)	Acc@1 50.000 (54.734)	Acc@5 76.562 (84.192)
Epoch: [58][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4401 (2.4377)	Acc@1 59.375 (54.706)	Acc@5 83.594 (84.170)
Epoch: [58][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4849 (2.4384)	Acc@1 53.125 (54.681)	Acc@5 84.375 (84.187)
Epoch: [58][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5365 (2.4396)	Acc@1 56.250 (54.681)	Acc@5 80.469 (84.148)
Epoch: [58][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4797 (2.4398)	Acc@1 52.344 (54.664)	Acc@5 85.156 (84.159)
Epoch: [58][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5766 (2.4429)	Acc@1 50.000 (54.601)	Acc@5 82.031 (84.105)
Epoch: [58][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4020 (2.4416)	Acc@1 58.594 (54.659)	Acc@5 81.250 (84.090)
Epoch: [58][390/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.9377 (2.4428)	Acc@1 50.000 (54.666)	Acc@5 72.500 (84.054)
num momentum params: 26
[0.1, 2.442755504837036, 2.070683102607727, 54.666, 46.44, tensor(0.3272, device='cuda:0', grad_fn=<DivBackward0>), 5.316895246505737, 0.39363312721252436]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [59 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [59][0/391]	Time 0.049 (0.049)	Data 0.159 (0.159)	Loss 2.4044 (2.4044)	Acc@1 54.688 (54.688)	Acc@5 82.031 (82.031)
Epoch: [59][10/391]	Time 0.014 (0.017)	Data 0.002 (0.016)	Loss 2.3755 (2.3834)	Acc@1 60.156 (56.818)	Acc@5 85.156 (85.511)
Epoch: [59][20/391]	Time 0.013 (0.015)	Data 0.001 (0.009)	Loss 2.3388 (2.3778)	Acc@1 57.812 (56.250)	Acc@5 82.812 (85.379)
Epoch: [59][30/391]	Time 0.013 (0.015)	Data 0.001 (0.007)	Loss 2.2192 (2.3772)	Acc@1 57.812 (56.074)	Acc@5 89.844 (85.484)
Epoch: [59][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.5720 (2.3835)	Acc@1 53.125 (55.736)	Acc@5 84.375 (85.556)
Epoch: [59][50/391]	Time 0.012 (0.014)	Data 0.002 (0.005)	Loss 2.2557 (2.3914)	Acc@1 57.031 (55.254)	Acc@5 88.281 (85.355)
Epoch: [59][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4912 (2.3917)	Acc@1 50.000 (55.251)	Acc@5 82.031 (85.207)
Epoch: [59][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.1549 (2.4055)	Acc@1 57.812 (54.853)	Acc@5 88.281 (84.892)
Epoch: [59][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3525 (2.4154)	Acc@1 59.375 (54.794)	Acc@5 85.156 (84.674)
Epoch: [59][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4431 (2.4085)	Acc@1 56.250 (55.057)	Acc@5 81.250 (84.701)
Epoch: [59][100/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3354 (2.4077)	Acc@1 55.469 (55.097)	Acc@5 85.156 (84.777)
Epoch: [59][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5614 (2.4099)	Acc@1 55.469 (55.061)	Acc@5 82.812 (84.769)
Epoch: [59][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2654 (2.4114)	Acc@1 64.844 (55.178)	Acc@5 88.281 (84.769)
Epoch: [59][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5294 (2.4100)	Acc@1 58.594 (55.361)	Acc@5 84.375 (84.715)
Epoch: [59][140/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.9955 (2.4172)	Acc@1 44.531 (55.186)	Acc@5 75.781 (84.641)
Epoch: [59][150/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2972 (2.4166)	Acc@1 53.125 (55.189)	Acc@5 88.281 (84.613)
Epoch: [59][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5038 (2.4189)	Acc@1 51.562 (55.129)	Acc@5 86.719 (84.618)
Epoch: [59][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2032 (2.4192)	Acc@1 63.281 (55.231)	Acc@5 89.062 (84.631)
Epoch: [59][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5248 (2.4195)	Acc@1 53.125 (55.184)	Acc@5 83.594 (84.643)
Epoch: [59][190/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.9534 (2.4256)	Acc@1 46.094 (55.080)	Acc@5 73.438 (84.551)
Epoch: [59][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4301 (2.4277)	Acc@1 56.250 (55.014)	Acc@5 85.156 (84.523)
Epoch: [59][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2515 (2.4287)	Acc@1 56.250 (54.980)	Acc@5 90.625 (84.534)
Epoch: [59][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6029 (2.4305)	Acc@1 53.906 (54.942)	Acc@5 83.594 (84.499)
Epoch: [59][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4619 (2.4312)	Acc@1 50.781 (54.924)	Acc@5 84.375 (84.453)
Epoch: [59][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5962 (2.4351)	Acc@1 55.469 (54.901)	Acc@5 80.469 (84.307)
Epoch: [59][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5790 (2.4365)	Acc@1 48.438 (54.874)	Acc@5 82.031 (84.294)
Epoch: [59][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4533 (2.4351)	Acc@1 54.688 (54.924)	Acc@5 84.375 (84.279)
Epoch: [59][270/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3456 (2.4325)	Acc@1 53.906 (54.964)	Acc@5 86.719 (84.303)
Epoch: [59][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3156 (2.4309)	Acc@1 58.594 (54.996)	Acc@5 85.938 (84.294)
Epoch: [59][290/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5317 (2.4347)	Acc@1 54.688 (54.889)	Acc@5 80.469 (84.238)
Epoch: [59][300/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4860 (2.4363)	Acc@1 54.688 (54.848)	Acc@5 84.375 (84.201)
Epoch: [59][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5148 (2.4397)	Acc@1 55.469 (54.728)	Acc@5 85.938 (84.151)
Epoch: [59][320/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5273 (2.4420)	Acc@1 50.781 (54.658)	Acc@5 79.688 (84.090)
Epoch: [59][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5082 (2.4398)	Acc@1 52.344 (54.704)	Acc@5 80.469 (84.125)
Epoch: [59][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4667 (2.4383)	Acc@1 52.344 (54.715)	Acc@5 85.156 (84.153)
Epoch: [59][350/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4117 (2.4374)	Acc@1 56.250 (54.777)	Acc@5 85.938 (84.164)
Epoch: [59][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5376 (2.4391)	Acc@1 55.469 (54.752)	Acc@5 79.688 (84.137)
Epoch: [59][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3545 (2.4408)	Acc@1 54.688 (54.717)	Acc@5 90.625 (84.105)
Epoch: [59][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.0747 (2.4426)	Acc@1 64.844 (54.706)	Acc@5 89.062 (84.100)
Epoch: [59][390/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.4949 (2.4446)	Acc@1 52.500 (54.652)	Acc@5 87.500 (84.078)
num momentum params: 26
[0.1, 2.4446096684265135, 2.0931245923042296, 54.652, 47.24, tensor(0.3270, device='cuda:0', grad_fn=<DivBackward0>), 5.269056797027588, 0.3894062042236328]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [60 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [60][0/391]	Time 0.052 (0.052)	Data 0.156 (0.156)	Loss 2.5782 (2.5782)	Acc@1 52.344 (52.344)	Acc@5 78.906 (78.906)
Epoch: [60][10/391]	Time 0.013 (0.018)	Data 0.001 (0.015)	Loss 2.2495 (2.3311)	Acc@1 57.812 (58.026)	Acc@5 88.281 (86.435)
Epoch: [60][20/391]	Time 0.013 (0.016)	Data 0.001 (0.009)	Loss 2.4975 (2.3541)	Acc@1 46.875 (57.031)	Acc@5 84.375 (85.640)
Epoch: [60][30/391]	Time 0.013 (0.015)	Data 0.001 (0.006)	Loss 2.3379 (2.3608)	Acc@1 54.688 (56.981)	Acc@5 87.500 (85.358)
Epoch: [60][40/391]	Time 0.038 (0.015)	Data 0.001 (0.005)	Loss 2.2640 (2.3521)	Acc@1 55.469 (57.031)	Acc@5 81.250 (85.404)
Epoch: [60][50/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.2686 (2.3577)	Acc@1 60.156 (57.001)	Acc@5 89.062 (85.371)
Epoch: [60][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.4103 (2.3519)	Acc@1 50.781 (56.814)	Acc@5 83.594 (85.515)
Epoch: [60][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.2429 (2.3587)	Acc@1 55.469 (56.602)	Acc@5 89.062 (85.409)
Epoch: [60][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4770 (2.3671)	Acc@1 52.344 (56.443)	Acc@5 82.031 (85.176)
Epoch: [60][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3630 (2.3842)	Acc@1 58.594 (56.284)	Acc@5 85.938 (84.916)
Epoch: [60][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4087 (2.3859)	Acc@1 56.250 (56.235)	Acc@5 85.938 (84.986)
Epoch: [60][110/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.3262 (2.3875)	Acc@1 62.500 (56.173)	Acc@5 85.156 (85.015)
Epoch: [60][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4527 (2.3946)	Acc@1 52.344 (56.011)	Acc@5 82.812 (84.833)
Epoch: [60][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.7411 (2.4041)	Acc@1 49.219 (55.761)	Acc@5 78.906 (84.697)
Epoch: [60][140/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5649 (2.4136)	Acc@1 51.562 (55.519)	Acc@5 78.906 (84.519)
Epoch: [60][150/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3406 (2.4168)	Acc@1 57.812 (55.500)	Acc@5 86.719 (84.468)
Epoch: [60][160/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4752 (2.4188)	Acc@1 52.344 (55.444)	Acc@5 78.906 (84.385)
Epoch: [60][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6520 (2.4218)	Acc@1 59.375 (55.464)	Acc@5 80.469 (84.357)
Epoch: [60][180/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3005 (2.4239)	Acc@1 59.375 (55.352)	Acc@5 86.719 (84.336)
Epoch: [60][190/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6626 (2.4272)	Acc@1 51.562 (55.305)	Acc@5 76.562 (84.289)
Epoch: [60][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3815 (2.4282)	Acc@1 57.031 (55.255)	Acc@5 85.156 (84.255)
Epoch: [60][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6160 (2.4301)	Acc@1 54.688 (55.269)	Acc@5 80.469 (84.223)
Epoch: [60][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4427 (2.4291)	Acc@1 56.250 (55.267)	Acc@5 83.594 (84.227)
Epoch: [60][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6034 (2.4309)	Acc@1 48.438 (55.161)	Acc@5 81.250 (84.216)
Epoch: [60][240/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4992 (2.4319)	Acc@1 53.125 (55.125)	Acc@5 78.906 (84.216)
Epoch: [60][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3673 (2.4340)	Acc@1 57.812 (55.017)	Acc@5 84.375 (84.170)
Epoch: [60][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4412 (2.4333)	Acc@1 54.688 (55.023)	Acc@5 83.594 (84.171)
Epoch: [60][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4652 (2.4336)	Acc@1 54.688 (55.007)	Acc@5 83.594 (84.144)
Epoch: [60][280/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.4889 (2.4355)	Acc@1 50.000 (54.952)	Acc@5 81.250 (84.108)
Epoch: [60][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2003 (2.4345)	Acc@1 60.156 (55.002)	Acc@5 89.062 (84.133)
Epoch: [60][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4704 (2.4373)	Acc@1 54.688 (54.939)	Acc@5 82.812 (84.095)
Epoch: [60][310/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.9344 (2.4401)	Acc@1 47.656 (54.893)	Acc@5 77.344 (84.079)
Epoch: [60][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6123 (2.4408)	Acc@1 52.344 (54.872)	Acc@5 82.031 (84.051)
Epoch: [60][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3991 (2.4406)	Acc@1 52.344 (54.817)	Acc@5 84.375 (84.056)
Epoch: [60][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4437 (2.4423)	Acc@1 47.656 (54.745)	Acc@5 85.156 (84.029)
Epoch: [60][350/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6058 (2.4452)	Acc@1 49.219 (54.670)	Acc@5 84.375 (83.965)
Epoch: [60][360/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4671 (2.4460)	Acc@1 51.562 (54.666)	Acc@5 84.375 (83.929)
Epoch: [60][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4140 (2.4449)	Acc@1 55.469 (54.721)	Acc@5 81.250 (83.918)
Epoch: [60][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3666 (2.4454)	Acc@1 53.906 (54.708)	Acc@5 86.719 (83.903)
Epoch: [60][390/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.3880 (2.4457)	Acc@1 58.750 (54.700)	Acc@5 82.500 (83.916)
num momentum params: 26
[0.1, 2.445682428894043, 2.439919722080231, 54.7, 40.49, tensor(0.3268, device='cuda:0', grad_fn=<DivBackward0>), 5.296356201171875, 0.3876357078552246]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [61 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [61][0/391]	Time 0.049 (0.049)	Data 0.148 (0.148)	Loss 2.5839 (2.5839)	Acc@1 57.031 (57.031)	Acc@5 77.344 (77.344)
Epoch: [61][10/391]	Time 0.013 (0.017)	Data 0.001 (0.015)	Loss 2.3530 (2.4445)	Acc@1 51.562 (55.256)	Acc@5 85.938 (83.239)
Epoch: [61][20/391]	Time 0.013 (0.016)	Data 0.001 (0.008)	Loss 2.1060 (2.3528)	Acc@1 64.844 (56.548)	Acc@5 89.844 (85.417)
Epoch: [61][30/391]	Time 0.014 (0.015)	Data 0.001 (0.006)	Loss 2.4688 (2.3518)	Acc@1 58.594 (56.603)	Acc@5 83.594 (85.509)
Epoch: [61][40/391]	Time 0.014 (0.014)	Data 0.001 (0.005)	Loss 2.1227 (2.3482)	Acc@1 61.719 (57.012)	Acc@5 89.062 (85.480)
Epoch: [61][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.2069 (2.3442)	Acc@1 64.844 (56.924)	Acc@5 86.719 (85.600)
Epoch: [61][60/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.4967 (2.3690)	Acc@1 51.562 (56.481)	Acc@5 82.031 (85.207)
Epoch: [61][70/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.1126 (2.3634)	Acc@1 62.500 (56.459)	Acc@5 86.719 (85.354)
Epoch: [61][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3879 (2.3560)	Acc@1 53.906 (56.645)	Acc@5 86.719 (85.552)
Epoch: [61][90/391]	Time 0.017 (0.014)	Data 0.001 (0.003)	Loss 2.2174 (2.3508)	Acc@1 59.375 (56.791)	Acc@5 89.062 (85.568)
Epoch: [61][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3136 (2.3567)	Acc@1 57.031 (56.745)	Acc@5 87.500 (85.535)
Epoch: [61][110/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3929 (2.3614)	Acc@1 57.031 (56.722)	Acc@5 84.375 (85.360)
Epoch: [61][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3781 (2.3624)	Acc@1 54.688 (56.734)	Acc@5 85.938 (85.318)
Epoch: [61][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4802 (2.3663)	Acc@1 52.344 (56.548)	Acc@5 83.594 (85.240)
Epoch: [61][140/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4241 (2.3704)	Acc@1 51.562 (56.461)	Acc@5 82.812 (85.129)
Epoch: [61][150/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1988 (2.3719)	Acc@1 61.719 (56.405)	Acc@5 89.844 (85.105)
Epoch: [61][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5991 (2.3792)	Acc@1 47.656 (56.235)	Acc@5 80.469 (85.020)
Epoch: [61][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4752 (2.3827)	Acc@1 49.219 (56.163)	Acc@5 84.375 (84.992)
Epoch: [61][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6678 (2.3908)	Acc@1 46.094 (55.879)	Acc@5 78.906 (84.828)
Epoch: [61][190/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2784 (2.3969)	Acc@1 58.594 (55.808)	Acc@5 88.281 (84.698)
Epoch: [61][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4756 (2.3975)	Acc@1 50.000 (55.795)	Acc@5 84.375 (84.713)
Epoch: [61][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2580 (2.4031)	Acc@1 55.469 (55.687)	Acc@5 84.375 (84.616)
Epoch: [61][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3150 (2.4056)	Acc@1 60.156 (55.642)	Acc@5 84.375 (84.630)
Epoch: [61][230/391]	Time 0.012 (0.013)	Data 0.001 (0.002)	Loss 2.3112 (2.4042)	Acc@1 60.156 (55.716)	Acc@5 88.281 (84.629)
Epoch: [61][240/391]	Time 0.015 (0.013)	Data 0.002 (0.002)	Loss 2.4144 (2.4045)	Acc@1 49.219 (55.696)	Acc@5 85.938 (84.573)
Epoch: [61][250/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.3055 (2.4068)	Acc@1 56.250 (55.631)	Acc@5 89.062 (84.537)
Epoch: [61][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7545 (2.4103)	Acc@1 42.969 (55.538)	Acc@5 78.906 (84.492)
Epoch: [61][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4081 (2.4105)	Acc@1 53.906 (55.518)	Acc@5 83.594 (84.522)
Epoch: [61][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5133 (2.4129)	Acc@1 53.906 (55.483)	Acc@5 85.156 (84.478)
Epoch: [61][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5260 (2.4166)	Acc@1 52.344 (55.386)	Acc@5 81.250 (84.456)
Epoch: [61][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5362 (2.4192)	Acc@1 52.344 (55.279)	Acc@5 82.031 (84.393)
Epoch: [61][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5304 (2.4216)	Acc@1 53.906 (55.233)	Acc@5 82.031 (84.372)
Epoch: [61][320/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5010 (2.4271)	Acc@1 54.688 (55.135)	Acc@5 82.031 (84.265)
Epoch: [61][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3879 (2.4271)	Acc@1 57.031 (55.091)	Acc@5 88.281 (84.269)
Epoch: [61][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7948 (2.4296)	Acc@1 52.344 (55.059)	Acc@5 76.562 (84.254)
Epoch: [61][350/391]	Time 0.012 (0.013)	Data 0.002 (0.002)	Loss 2.4579 (2.4326)	Acc@1 54.688 (54.986)	Acc@5 83.594 (84.226)
Epoch: [61][360/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4593 (2.4348)	Acc@1 50.781 (54.967)	Acc@5 81.250 (84.178)
Epoch: [61][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2798 (2.4347)	Acc@1 56.250 (54.959)	Acc@5 85.938 (84.171)
Epoch: [61][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6670 (2.4364)	Acc@1 52.344 (54.927)	Acc@5 77.344 (84.123)
Epoch: [61][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.3338 (2.4357)	Acc@1 63.750 (54.938)	Acc@5 83.750 (84.148)
num momentum params: 26
[0.1, 2.4356937321472167, 1.9879642951488494, 54.938, 47.17, tensor(0.3281, device='cuda:0', grad_fn=<DivBackward0>), 5.245048761367798, 0.3912503719329834]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [62 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [62][0/391]	Time 0.052 (0.052)	Data 0.153 (0.153)	Loss 2.2670 (2.2670)	Acc@1 52.344 (52.344)	Acc@5 89.062 (89.062)
Epoch: [62][10/391]	Time 0.013 (0.017)	Data 0.001 (0.016)	Loss 2.3126 (2.3373)	Acc@1 57.812 (55.895)	Acc@5 88.281 (85.582)
Epoch: [62][20/391]	Time 0.016 (0.015)	Data 0.001 (0.009)	Loss 2.5534 (2.3813)	Acc@1 53.125 (55.543)	Acc@5 82.031 (85.454)
Epoch: [62][30/391]	Time 0.013 (0.015)	Data 0.001 (0.006)	Loss 2.4108 (2.3707)	Acc@1 57.031 (55.620)	Acc@5 83.594 (85.484)
Epoch: [62][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.4186 (2.3586)	Acc@1 54.688 (56.059)	Acc@5 85.156 (85.499)
Epoch: [62][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3521 (2.3672)	Acc@1 57.031 (55.974)	Acc@5 83.594 (85.172)
Epoch: [62][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.6996 (2.3728)	Acc@1 49.219 (55.789)	Acc@5 81.250 (85.182)
Epoch: [62][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.8062 (2.3902)	Acc@1 42.969 (55.425)	Acc@5 81.250 (84.892)
Epoch: [62][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3547 (2.3909)	Acc@1 57.812 (55.613)	Acc@5 85.938 (84.867)
Epoch: [62][90/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2251 (2.3997)	Acc@1 61.719 (55.546)	Acc@5 88.281 (84.641)
Epoch: [62][100/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4397 (2.3962)	Acc@1 53.906 (55.639)	Acc@5 85.156 (84.700)
Epoch: [62][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3632 (2.3916)	Acc@1 52.344 (55.743)	Acc@5 86.719 (84.783)
Epoch: [62][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5508 (2.3991)	Acc@1 52.344 (55.572)	Acc@5 83.594 (84.685)
Epoch: [62][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3487 (2.4058)	Acc@1 57.031 (55.522)	Acc@5 85.156 (84.512)
Epoch: [62][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6300 (2.4105)	Acc@1 47.656 (55.341)	Acc@5 82.031 (84.414)
Epoch: [62][150/391]	Time 0.021 (0.014)	Data 0.001 (0.002)	Loss 2.4244 (2.4123)	Acc@1 50.000 (55.391)	Acc@5 82.031 (84.308)
Epoch: [62][160/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2871 (2.4182)	Acc@1 60.156 (55.202)	Acc@5 85.156 (84.278)
Epoch: [62][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6240 (2.4230)	Acc@1 47.656 (55.016)	Acc@5 82.812 (84.261)
Epoch: [62][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4372 (2.4273)	Acc@1 52.344 (54.882)	Acc@5 85.156 (84.233)
Epoch: [62][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1654 (2.4288)	Acc@1 55.469 (54.831)	Acc@5 89.844 (84.248)
Epoch: [62][200/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3598 (2.4294)	Acc@1 56.250 (54.754)	Acc@5 84.375 (84.231)
Epoch: [62][210/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3763 (2.4299)	Acc@1 53.125 (54.673)	Acc@5 79.688 (84.212)
Epoch: [62][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5268 (2.4309)	Acc@1 53.906 (54.652)	Acc@5 85.156 (84.223)
Epoch: [62][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4861 (2.4297)	Acc@1 52.344 (54.681)	Acc@5 86.719 (84.246)
Epoch: [62][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5109 (2.4294)	Acc@1 53.906 (54.762)	Acc@5 82.031 (84.193)
Epoch: [62][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3616 (2.4299)	Acc@1 57.031 (54.765)	Acc@5 82.812 (84.185)
Epoch: [62][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4742 (2.4325)	Acc@1 57.031 (54.688)	Acc@5 79.688 (84.139)
Epoch: [62][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3473 (2.4325)	Acc@1 55.469 (54.708)	Acc@5 87.500 (84.136)
Epoch: [62][280/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3494 (2.4312)	Acc@1 57.031 (54.713)	Acc@5 85.156 (84.194)
Epoch: [62][290/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6218 (2.4318)	Acc@1 50.000 (54.714)	Acc@5 77.344 (84.158)
Epoch: [62][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2933 (2.4345)	Acc@1 58.594 (54.625)	Acc@5 87.500 (84.110)
Epoch: [62][310/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4581 (2.4364)	Acc@1 58.594 (54.592)	Acc@5 82.812 (84.114)
Epoch: [62][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5791 (2.4384)	Acc@1 49.219 (54.537)	Acc@5 83.594 (84.124)
Epoch: [62][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6809 (2.4400)	Acc@1 50.781 (54.489)	Acc@5 78.906 (84.122)
Epoch: [62][340/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4205 (2.4432)	Acc@1 53.906 (54.419)	Acc@5 85.156 (84.057)
Epoch: [62][350/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6723 (2.4433)	Acc@1 50.781 (54.387)	Acc@5 80.469 (84.068)
Epoch: [62][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6139 (2.4435)	Acc@1 55.469 (54.404)	Acc@5 82.031 (84.096)
Epoch: [62][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4144 (2.4445)	Acc@1 56.250 (54.395)	Acc@5 82.812 (84.046)
Epoch: [62][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5137 (2.4470)	Acc@1 54.688 (54.320)	Acc@5 80.469 (83.985)
Epoch: [62][390/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.5377 (2.4453)	Acc@1 55.000 (54.398)	Acc@5 86.250 (84.014)
num momentum params: 26
[0.1, 2.4452965731048586, 1.8355159342288971, 54.398, 51.34, tensor(0.3278, device='cuda:0', grad_fn=<DivBackward0>), 5.2747838497161865, 0.3911101818084716]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [63 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [63][0/391]	Time 0.051 (0.051)	Data 0.152 (0.152)	Loss 2.4505 (2.4505)	Acc@1 57.031 (57.031)	Acc@5 82.812 (82.812)
Epoch: [63][10/391]	Time 0.017 (0.018)	Data 0.001 (0.016)	Loss 2.2279 (2.3337)	Acc@1 64.844 (57.244)	Acc@5 86.719 (86.009)
Epoch: [63][20/391]	Time 0.013 (0.016)	Data 0.001 (0.009)	Loss 2.4372 (2.3524)	Acc@1 57.031 (57.329)	Acc@5 87.500 (85.789)
Epoch: [63][30/391]	Time 0.013 (0.015)	Data 0.001 (0.007)	Loss 2.2124 (2.3590)	Acc@1 64.062 (57.535)	Acc@5 89.844 (85.761)
Epoch: [63][40/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.1540 (2.3552)	Acc@1 57.031 (57.317)	Acc@5 92.188 (85.918)
Epoch: [63][50/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.3824 (2.3632)	Acc@1 53.125 (56.648)	Acc@5 86.719 (85.677)
Epoch: [63][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.2832 (2.3694)	Acc@1 59.375 (56.468)	Acc@5 84.375 (85.489)
Epoch: [63][70/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.1986 (2.3680)	Acc@1 63.281 (56.657)	Acc@5 88.281 (85.343)
Epoch: [63][80/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.5453 (2.3719)	Acc@1 49.219 (56.453)	Acc@5 82.812 (85.436)
Epoch: [63][90/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.6756 (2.3729)	Acc@1 46.094 (56.387)	Acc@5 82.812 (85.371)
Epoch: [63][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4061 (2.3672)	Acc@1 57.031 (56.536)	Acc@5 87.500 (85.450)
Epoch: [63][110/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.5171 (2.3632)	Acc@1 55.469 (56.489)	Acc@5 80.469 (85.459)
Epoch: [63][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6947 (2.3649)	Acc@1 50.781 (56.508)	Acc@5 79.688 (85.453)
Epoch: [63][130/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.7009 (2.3680)	Acc@1 46.875 (56.357)	Acc@5 81.250 (85.466)
Epoch: [63][140/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4341 (2.3756)	Acc@1 57.812 (56.206)	Acc@5 81.250 (85.311)
Epoch: [63][150/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5221 (2.3806)	Acc@1 53.906 (56.028)	Acc@5 81.250 (85.239)
Epoch: [63][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3374 (2.3873)	Acc@1 55.469 (55.973)	Acc@5 85.938 (85.103)
Epoch: [63][170/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2923 (2.3920)	Acc@1 57.031 (55.880)	Acc@5 87.500 (85.024)
Epoch: [63][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6469 (2.3955)	Acc@1 54.688 (55.892)	Acc@5 80.469 (84.902)
Epoch: [63][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2849 (2.3994)	Acc@1 60.156 (55.825)	Acc@5 84.375 (84.845)
Epoch: [63][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4393 (2.4048)	Acc@1 53.125 (55.667)	Acc@5 85.938 (84.799)
Epoch: [63][210/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6766 (2.4057)	Acc@1 48.438 (55.624)	Acc@5 82.812 (84.786)
Epoch: [63][220/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6390 (2.4090)	Acc@1 50.000 (55.589)	Acc@5 79.688 (84.743)
Epoch: [63][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5650 (2.4102)	Acc@1 48.438 (55.489)	Acc@5 85.156 (84.737)
Epoch: [63][240/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.4784 (2.4141)	Acc@1 53.125 (55.430)	Acc@5 82.812 (84.628)
Epoch: [63][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3668 (2.4148)	Acc@1 60.938 (55.391)	Acc@5 85.938 (84.655)
Epoch: [63][260/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3163 (2.4179)	Acc@1 52.344 (55.295)	Acc@5 88.281 (84.632)
Epoch: [63][270/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3001 (2.4176)	Acc@1 54.688 (55.325)	Acc@5 85.156 (84.675)
Epoch: [63][280/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4530 (2.4203)	Acc@1 56.250 (55.282)	Acc@5 82.812 (84.595)
Epoch: [63][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4238 (2.4235)	Acc@1 57.812 (55.187)	Acc@5 83.594 (84.493)
Epoch: [63][300/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4832 (2.4213)	Acc@1 57.031 (55.284)	Acc@5 82.812 (84.515)
Epoch: [63][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1988 (2.4217)	Acc@1 60.938 (55.213)	Acc@5 86.719 (84.483)
Epoch: [63][320/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2719 (2.4216)	Acc@1 53.906 (55.186)	Acc@5 85.938 (84.458)
Epoch: [63][330/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4604 (2.4235)	Acc@1 55.469 (55.160)	Acc@5 82.812 (84.399)
Epoch: [63][340/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.7370 (2.4245)	Acc@1 45.312 (55.146)	Acc@5 78.906 (84.373)
Epoch: [63][350/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.1345 (2.4253)	Acc@1 65.625 (55.157)	Acc@5 86.719 (84.364)
Epoch: [63][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3068 (2.4283)	Acc@1 56.250 (55.038)	Acc@5 89.062 (84.332)
Epoch: [63][370/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.2995 (2.4298)	Acc@1 58.594 (55.005)	Acc@5 89.844 (84.324)
Epoch: [63][380/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6009 (2.4291)	Acc@1 50.000 (55.003)	Acc@5 81.250 (84.318)
Epoch: [63][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.5278 (2.4316)	Acc@1 52.500 (54.964)	Acc@5 83.750 (84.278)
num momentum params: 26
[0.1, 2.4315505616760253, 1.927900367975235, 54.964, 49.41, tensor(0.3295, device='cuda:0', grad_fn=<DivBackward0>), 5.282650709152222, 0.4051361083984375]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [64 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [64][0/391]	Time 0.049 (0.049)	Data 0.160 (0.160)	Loss 2.2869 (2.2869)	Acc@1 59.375 (59.375)	Acc@5 85.156 (85.156)
Epoch: [64][10/391]	Time 0.013 (0.018)	Data 0.001 (0.016)	Loss 2.2758 (2.3703)	Acc@1 62.500 (57.386)	Acc@5 85.156 (84.517)
Epoch: [64][20/391]	Time 0.013 (0.016)	Data 0.001 (0.009)	Loss 2.1196 (2.3355)	Acc@1 62.500 (56.585)	Acc@5 89.062 (85.603)
Epoch: [64][30/391]	Time 0.013 (0.015)	Data 0.001 (0.007)	Loss 2.2824 (2.3467)	Acc@1 55.469 (55.872)	Acc@5 85.156 (85.333)
Epoch: [64][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.5533 (2.3614)	Acc@1 50.781 (55.907)	Acc@5 84.375 (85.137)
Epoch: [64][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.5067 (2.3549)	Acc@1 49.219 (56.173)	Acc@5 89.062 (85.371)
Epoch: [64][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4035 (2.3503)	Acc@1 56.250 (56.545)	Acc@5 89.062 (85.592)
Epoch: [64][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3231 (2.3549)	Acc@1 57.812 (56.426)	Acc@5 84.375 (85.530)
Epoch: [64][80/391]	Time 0.012 (0.014)	Data 0.004 (0.003)	Loss 2.6045 (2.3594)	Acc@1 46.875 (56.125)	Acc@5 77.344 (85.503)
Epoch: [64][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2088 (2.3665)	Acc@1 60.938 (56.087)	Acc@5 86.719 (85.234)
Epoch: [64][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3148 (2.3739)	Acc@1 60.938 (56.018)	Acc@5 84.375 (85.087)
Epoch: [64][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6188 (2.3751)	Acc@1 50.000 (55.997)	Acc@5 82.031 (85.093)
Epoch: [64][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3737 (2.3861)	Acc@1 54.688 (55.727)	Acc@5 89.844 (84.917)
Epoch: [64][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5424 (2.3907)	Acc@1 53.125 (55.672)	Acc@5 83.594 (84.822)
Epoch: [64][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4838 (2.3902)	Acc@1 52.344 (55.707)	Acc@5 85.156 (84.796)
Epoch: [64][150/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4882 (2.3895)	Acc@1 48.438 (55.686)	Acc@5 86.719 (84.841)
Epoch: [64][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2917 (2.3944)	Acc@1 60.156 (55.682)	Acc@5 88.281 (84.720)
Epoch: [64][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3958 (2.3957)	Acc@1 57.031 (55.651)	Acc@5 85.156 (84.699)
Epoch: [64][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5275 (2.3976)	Acc@1 53.906 (55.659)	Acc@5 82.812 (84.716)
Epoch: [64][190/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2859 (2.3977)	Acc@1 60.938 (55.677)	Acc@5 89.062 (84.735)
Epoch: [64][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5281 (2.3998)	Acc@1 60.156 (55.675)	Acc@5 79.688 (84.659)
Epoch: [64][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2997 (2.4006)	Acc@1 59.375 (55.561)	Acc@5 86.719 (84.668)
Epoch: [64][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5154 (2.4006)	Acc@1 53.906 (55.554)	Acc@5 83.594 (84.697)
Epoch: [64][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5711 (2.4035)	Acc@1 50.781 (55.553)	Acc@5 82.031 (84.608)
Epoch: [64][240/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.2160 (2.4052)	Acc@1 65.625 (55.462)	Acc@5 89.062 (84.589)
Epoch: [64][250/391]	Time 0.015 (0.013)	Data 0.007 (0.002)	Loss 2.2157 (2.4039)	Acc@1 64.062 (55.509)	Acc@5 84.375 (84.602)
Epoch: [64][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3064 (2.4046)	Acc@1 57.812 (55.487)	Acc@5 86.719 (84.567)
Epoch: [64][270/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.4461 (2.4033)	Acc@1 53.906 (55.509)	Acc@5 82.812 (84.603)
Epoch: [64][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4874 (2.4049)	Acc@1 50.000 (55.488)	Acc@5 82.812 (84.584)
Epoch: [64][290/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.6678 (2.4086)	Acc@1 49.219 (55.369)	Acc@5 81.250 (84.512)
Epoch: [64][300/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4302 (2.4122)	Acc@1 57.031 (55.321)	Acc@5 82.031 (84.432)
Epoch: [64][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5293 (2.4141)	Acc@1 51.562 (55.308)	Acc@5 82.031 (84.385)
Epoch: [64][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7271 (2.4168)	Acc@1 54.688 (55.257)	Acc@5 81.250 (84.363)
Epoch: [64][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3057 (2.4177)	Acc@1 60.156 (55.211)	Acc@5 84.375 (84.363)
Epoch: [64][340/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.3014 (2.4183)	Acc@1 54.688 (55.150)	Acc@5 85.938 (84.359)
Epoch: [64][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3160 (2.4178)	Acc@1 58.594 (55.184)	Acc@5 85.156 (84.362)
Epoch: [64][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4685 (2.4229)	Acc@1 58.594 (55.058)	Acc@5 82.812 (84.297)
Epoch: [64][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6519 (2.4264)	Acc@1 50.000 (54.972)	Acc@5 84.375 (84.244)
Epoch: [64][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6332 (2.4292)	Acc@1 49.219 (54.932)	Acc@5 82.031 (84.223)
Epoch: [64][390/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.4985 (2.4298)	Acc@1 53.750 (54.908)	Acc@5 81.250 (84.202)
num momentum params: 26
[0.1, 2.4297838150024416, 1.9735291075706483, 54.908, 47.64, tensor(0.3291, device='cuda:0', grad_fn=<DivBackward0>), 5.254180431365967, 0.3883509635925293]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [65 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [65][0/391]	Time 0.049 (0.049)	Data 0.151 (0.151)	Loss 2.1944 (2.1944)	Acc@1 58.594 (58.594)	Acc@5 90.625 (90.625)
Epoch: [65][10/391]	Time 0.013 (0.017)	Data 0.002 (0.015)	Loss 2.3156 (2.3447)	Acc@1 59.375 (55.327)	Acc@5 85.938 (86.648)
Epoch: [65][20/391]	Time 0.013 (0.016)	Data 0.002 (0.009)	Loss 2.0457 (2.3311)	Acc@1 64.062 (56.808)	Acc@5 89.062 (86.086)
Epoch: [65][30/391]	Time 0.013 (0.015)	Data 0.002 (0.006)	Loss 2.3527 (2.3390)	Acc@1 59.375 (56.603)	Acc@5 85.156 (85.963)
Epoch: [65][40/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.3769 (2.3588)	Acc@1 57.031 (55.964)	Acc@5 84.375 (85.861)
Epoch: [65][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.1548 (2.3619)	Acc@1 62.500 (55.990)	Acc@5 90.625 (85.800)
Epoch: [65][60/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.2602 (2.3629)	Acc@1 55.469 (56.096)	Acc@5 85.938 (85.579)
Epoch: [65][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.2303 (2.3692)	Acc@1 56.250 (55.953)	Acc@5 88.281 (85.365)
Epoch: [65][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3419 (2.3817)	Acc@1 53.125 (55.739)	Acc@5 85.156 (85.156)
Epoch: [65][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3424 (2.3965)	Acc@1 48.438 (55.306)	Acc@5 87.500 (84.916)
Epoch: [65][100/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3194 (2.3991)	Acc@1 58.594 (55.252)	Acc@5 87.500 (84.769)
Epoch: [65][110/391]	Time 0.016 (0.014)	Data 0.002 (0.003)	Loss 2.5713 (2.4114)	Acc@1 49.219 (55.138)	Acc@5 78.906 (84.502)
Epoch: [65][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.1077 (2.4121)	Acc@1 67.969 (55.056)	Acc@5 88.281 (84.524)
Epoch: [65][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2844 (2.4126)	Acc@1 58.594 (55.087)	Acc@5 85.156 (84.482)
Epoch: [65][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2904 (2.4050)	Acc@1 56.250 (55.325)	Acc@5 88.281 (84.619)
Epoch: [65][150/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4710 (2.4076)	Acc@1 53.906 (55.360)	Acc@5 87.500 (84.670)
Epoch: [65][160/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6095 (2.4070)	Acc@1 47.656 (55.236)	Acc@5 82.031 (84.768)
Epoch: [65][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4555 (2.4082)	Acc@1 56.250 (55.263)	Acc@5 84.375 (84.731)
Epoch: [65][180/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6858 (2.4106)	Acc@1 46.094 (55.175)	Acc@5 80.469 (84.707)
Epoch: [65][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.9407 (2.4182)	Acc@1 46.875 (55.088)	Acc@5 77.344 (84.535)
Epoch: [65][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6281 (2.4214)	Acc@1 51.562 (55.002)	Acc@5 82.031 (84.507)
Epoch: [65][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5868 (2.4215)	Acc@1 46.875 (55.058)	Acc@5 80.469 (84.438)
Epoch: [65][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2442 (2.4193)	Acc@1 62.500 (55.090)	Acc@5 87.500 (84.516)
Epoch: [65][230/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5122 (2.4222)	Acc@1 53.125 (55.016)	Acc@5 85.156 (84.504)
Epoch: [65][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4750 (2.4248)	Acc@1 54.688 (54.970)	Acc@5 82.812 (84.459)
Epoch: [65][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5299 (2.4278)	Acc@1 50.781 (54.918)	Acc@5 81.250 (84.387)
Epoch: [65][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3664 (2.4276)	Acc@1 57.812 (54.948)	Acc@5 79.688 (84.333)
Epoch: [65][270/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3898 (2.4286)	Acc@1 57.812 (54.918)	Acc@5 87.500 (84.314)
Epoch: [65][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3931 (2.4318)	Acc@1 60.156 (54.893)	Acc@5 85.156 (84.264)
Epoch: [65][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3858 (2.4318)	Acc@1 53.906 (54.900)	Acc@5 85.938 (84.270)
Epoch: [65][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2987 (2.4309)	Acc@1 64.844 (54.952)	Acc@5 84.375 (84.261)
Epoch: [65][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3200 (2.4306)	Acc@1 57.031 (54.914)	Acc@5 85.156 (84.275)
Epoch: [65][320/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2881 (2.4323)	Acc@1 59.375 (54.926)	Acc@5 82.812 (84.210)
Epoch: [65][330/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3781 (2.4306)	Acc@1 56.250 (54.985)	Acc@5 88.281 (84.274)
Epoch: [65][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5419 (2.4335)	Acc@1 55.469 (54.983)	Acc@5 81.250 (84.215)
Epoch: [65][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4132 (2.4379)	Acc@1 50.781 (54.832)	Acc@5 85.938 (84.150)
Epoch: [65][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5030 (2.4378)	Acc@1 51.562 (54.800)	Acc@5 86.719 (84.182)
Epoch: [65][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4725 (2.4426)	Acc@1 51.562 (54.694)	Acc@5 82.812 (84.110)
Epoch: [65][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5713 (2.4443)	Acc@1 53.906 (54.681)	Acc@5 78.906 (84.078)
Epoch: [65][390/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.6620 (2.4456)	Acc@1 40.000 (54.660)	Acc@5 82.500 (84.018)
num momentum params: 26
[0.1, 2.445642171936035, 2.0638222169876097, 54.66, 46.43, tensor(0.3285, device='cuda:0', grad_fn=<DivBackward0>), 5.281100273132324, 0.39280223846435547]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [66 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [66][0/391]	Time 0.049 (0.049)	Data 0.147 (0.147)	Loss 2.4377 (2.4377)	Acc@1 53.906 (53.906)	Acc@5 86.719 (86.719)
Epoch: [66][10/391]	Time 0.014 (0.017)	Data 0.001 (0.015)	Loss 2.0610 (2.3719)	Acc@1 65.625 (56.108)	Acc@5 88.281 (84.943)
Epoch: [66][20/391]	Time 0.013 (0.015)	Data 0.001 (0.008)	Loss 2.1647 (2.3500)	Acc@1 58.594 (56.064)	Acc@5 87.500 (85.417)
Epoch: [66][30/391]	Time 0.013 (0.015)	Data 0.002 (0.006)	Loss 2.5222 (2.3395)	Acc@1 50.000 (56.779)	Acc@5 84.375 (85.559)
Epoch: [66][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 1.9252 (2.3386)	Acc@1 73.438 (57.165)	Acc@5 89.844 (85.537)
Epoch: [66][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4084 (2.3444)	Acc@1 56.250 (57.108)	Acc@5 87.500 (85.585)
Epoch: [66][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.2357 (2.3585)	Acc@1 57.031 (56.416)	Acc@5 88.281 (85.553)
Epoch: [66][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3629 (2.3674)	Acc@1 53.125 (56.382)	Acc@5 85.156 (85.431)
Epoch: [66][80/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3410 (2.3609)	Acc@1 56.250 (56.501)	Acc@5 85.938 (85.619)
Epoch: [66][90/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3469 (2.3685)	Acc@1 53.125 (56.344)	Acc@5 85.938 (85.379)
Epoch: [66][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.5915 (2.3766)	Acc@1 47.656 (56.103)	Acc@5 79.688 (85.218)
Epoch: [66][110/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.3739 (2.3818)	Acc@1 52.344 (56.004)	Acc@5 86.719 (85.114)
Epoch: [66][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4275 (2.3852)	Acc@1 62.500 (55.947)	Acc@5 85.938 (85.085)
Epoch: [66][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2814 (2.3869)	Acc@1 57.031 (55.844)	Acc@5 85.156 (85.109)
Epoch: [66][140/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4102 (2.3907)	Acc@1 51.562 (55.735)	Acc@5 88.281 (84.996)
Epoch: [66][150/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6784 (2.3945)	Acc@1 50.781 (55.660)	Acc@5 78.125 (84.923)
Epoch: [66][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7885 (2.4033)	Acc@1 46.875 (55.444)	Acc@5 75.781 (84.744)
Epoch: [66][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5627 (2.4100)	Acc@1 53.906 (55.323)	Acc@5 85.938 (84.626)
Epoch: [66][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2257 (2.4153)	Acc@1 58.594 (55.141)	Acc@5 87.500 (84.522)
Epoch: [66][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4576 (2.4184)	Acc@1 52.344 (55.101)	Acc@5 85.938 (84.469)
Epoch: [66][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5026 (2.4216)	Acc@1 56.250 (55.045)	Acc@5 81.250 (84.418)
Epoch: [66][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5152 (2.4247)	Acc@1 57.812 (55.050)	Acc@5 80.469 (84.371)
Epoch: [66][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3816 (2.4291)	Acc@1 61.719 (54.974)	Acc@5 89.062 (84.301)
Epoch: [66][230/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5628 (2.4297)	Acc@1 55.469 (55.005)	Acc@5 82.031 (84.243)
Epoch: [66][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3799 (2.4295)	Acc@1 56.250 (54.966)	Acc@5 86.719 (84.336)
Epoch: [66][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4883 (2.4322)	Acc@1 53.906 (54.905)	Acc@5 81.250 (84.303)
Epoch: [66][260/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5778 (2.4336)	Acc@1 47.656 (54.912)	Acc@5 82.031 (84.261)
Epoch: [66][270/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5025 (2.4344)	Acc@1 56.250 (54.933)	Acc@5 81.250 (84.257)
Epoch: [66][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3490 (2.4347)	Acc@1 53.125 (54.877)	Acc@5 86.719 (84.258)
Epoch: [66][290/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5910 (2.4373)	Acc@1 48.438 (54.873)	Acc@5 84.375 (84.211)
Epoch: [66][300/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5336 (2.4396)	Acc@1 57.812 (54.859)	Acc@5 81.250 (84.136)
Epoch: [66][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2891 (2.4391)	Acc@1 57.031 (54.853)	Acc@5 86.719 (84.144)
Epoch: [66][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5313 (2.4373)	Acc@1 50.781 (54.911)	Acc@5 80.469 (84.136)
Epoch: [66][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3830 (2.4373)	Acc@1 58.594 (54.947)	Acc@5 83.594 (84.127)
Epoch: [66][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2615 (2.4365)	Acc@1 57.812 (54.933)	Acc@5 84.375 (84.128)
Epoch: [66][350/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.3477 (2.4378)	Acc@1 58.594 (54.908)	Acc@5 83.594 (84.061)
Epoch: [66][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5100 (2.4368)	Acc@1 53.906 (54.913)	Acc@5 84.375 (84.107)
Epoch: [66][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4394 (2.4404)	Acc@1 54.688 (54.860)	Acc@5 83.594 (84.006)
Epoch: [66][380/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.5982 (2.4422)	Acc@1 54.688 (54.823)	Acc@5 82.031 (84.002)
Epoch: [66][390/391]	Time 0.016 (0.013)	Data 0.002 (0.002)	Loss 2.2550 (2.4415)	Acc@1 60.000 (54.876)	Acc@5 86.250 (83.990)
num momentum params: 26
[0.1, 2.441525964126587, 2.094812036752701, 54.876, 45.25, tensor(0.3283, device='cuda:0', grad_fn=<DivBackward0>), 5.269705295562744, 0.39104437828063965]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [67 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [67][0/391]	Time 0.050 (0.050)	Data 0.147 (0.147)	Loss 2.3579 (2.3579)	Acc@1 54.688 (54.688)	Acc@5 86.719 (86.719)
Epoch: [67][10/391]	Time 0.014 (0.018)	Data 0.001 (0.015)	Loss 2.2382 (2.3293)	Acc@1 58.594 (57.315)	Acc@5 87.500 (85.582)
Epoch: [67][20/391]	Time 0.014 (0.016)	Data 0.001 (0.009)	Loss 2.2113 (2.2931)	Acc@1 57.031 (58.185)	Acc@5 86.719 (86.198)
Epoch: [67][30/391]	Time 0.013 (0.015)	Data 0.002 (0.006)	Loss 2.2619 (2.2867)	Acc@1 60.156 (58.317)	Acc@5 87.500 (86.215)
Epoch: [67][40/391]	Time 0.014 (0.015)	Data 0.002 (0.005)	Loss 2.4673 (2.3132)	Acc@1 51.562 (57.889)	Acc@5 83.594 (85.804)
Epoch: [67][50/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.2813 (2.3427)	Acc@1 55.469 (56.847)	Acc@5 85.938 (85.493)
Epoch: [67][60/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.4834 (2.3535)	Acc@1 52.344 (56.545)	Acc@5 86.719 (85.553)
Epoch: [67][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.2358 (2.3616)	Acc@1 57.031 (56.107)	Acc@5 85.938 (85.420)
Epoch: [67][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3686 (2.3590)	Acc@1 54.688 (56.125)	Acc@5 86.719 (85.542)
Epoch: [67][90/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4303 (2.3528)	Acc@1 53.125 (56.173)	Acc@5 79.688 (85.586)
Epoch: [67][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.1506 (2.3560)	Acc@1 62.500 (56.103)	Acc@5 88.281 (85.504)
Epoch: [67][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2632 (2.3584)	Acc@1 58.594 (56.039)	Acc@5 89.844 (85.494)
Epoch: [67][120/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2360 (2.3562)	Acc@1 57.031 (56.198)	Acc@5 89.844 (85.621)
Epoch: [67][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2948 (2.3583)	Acc@1 62.500 (56.328)	Acc@5 85.938 (85.550)
Epoch: [67][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3382 (2.3614)	Acc@1 57.031 (56.250)	Acc@5 84.375 (85.422)
Epoch: [67][150/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.5882 (2.3686)	Acc@1 49.219 (56.059)	Acc@5 82.031 (85.291)
Epoch: [67][160/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3463 (2.3700)	Acc@1 57.812 (56.061)	Acc@5 86.719 (85.253)
Epoch: [67][170/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5862 (2.3740)	Acc@1 51.562 (55.912)	Acc@5 85.156 (85.293)
Epoch: [67][180/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6873 (2.3777)	Acc@1 50.781 (55.831)	Acc@5 82.031 (85.312)
Epoch: [67][190/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5241 (2.3833)	Acc@1 51.562 (55.759)	Acc@5 85.156 (85.193)
Epoch: [67][200/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6479 (2.3877)	Acc@1 51.562 (55.725)	Acc@5 82.031 (85.121)
Epoch: [67][210/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5179 (2.3924)	Acc@1 50.781 (55.628)	Acc@5 80.469 (85.001)
Epoch: [67][220/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6002 (2.3926)	Acc@1 50.781 (55.600)	Acc@5 78.906 (84.972)
Epoch: [67][230/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3387 (2.3947)	Acc@1 52.344 (55.580)	Acc@5 85.938 (84.872)
Epoch: [67][240/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6852 (2.3972)	Acc@1 50.781 (55.543)	Acc@5 82.031 (84.839)
Epoch: [67][250/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4643 (2.3991)	Acc@1 53.125 (55.547)	Acc@5 81.250 (84.761)
Epoch: [67][260/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.7332 (2.4013)	Acc@1 46.875 (55.502)	Acc@5 82.031 (84.767)
Epoch: [67][270/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6492 (2.4071)	Acc@1 49.219 (55.368)	Acc@5 77.344 (84.658)
Epoch: [67][280/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3528 (2.4089)	Acc@1 55.469 (55.344)	Acc@5 88.281 (84.642)
Epoch: [67][290/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.3329 (2.4104)	Acc@1 59.375 (55.329)	Acc@5 85.156 (84.574)
Epoch: [67][300/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5490 (2.4120)	Acc@1 52.344 (55.336)	Acc@5 78.906 (84.505)
Epoch: [67][310/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3140 (2.4120)	Acc@1 59.375 (55.361)	Acc@5 85.938 (84.475)
Epoch: [67][320/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4992 (2.4133)	Acc@1 54.688 (55.352)	Acc@5 83.594 (84.463)
Epoch: [67][330/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5156 (2.4150)	Acc@1 49.219 (55.315)	Acc@5 84.375 (84.443)
Epoch: [67][340/391]	Time 0.017 (0.014)	Data 0.002 (0.002)	Loss 2.5773 (2.4167)	Acc@1 51.562 (55.283)	Acc@5 80.469 (84.435)
Epoch: [67][350/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4780 (2.4178)	Acc@1 55.469 (55.193)	Acc@5 85.156 (84.431)
Epoch: [67][360/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5498 (2.4187)	Acc@1 53.125 (55.168)	Acc@5 84.375 (84.405)
Epoch: [67][370/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6053 (2.4197)	Acc@1 53.906 (55.184)	Acc@5 79.688 (84.367)
Epoch: [67][380/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3245 (2.4215)	Acc@1 56.250 (55.110)	Acc@5 85.938 (84.324)
Epoch: [67][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.3053 (2.4227)	Acc@1 55.000 (55.114)	Acc@5 87.500 (84.310)
num momentum params: 26
[0.1, 2.4227435485839846, 1.9833104693889618, 55.114, 48.02, tensor(0.3307, device='cuda:0', grad_fn=<DivBackward0>), 5.343638896942139, 0.3955113887786865]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [68 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [68][0/391]	Time 0.053 (0.053)	Data 0.156 (0.156)	Loss 2.3413 (2.3413)	Acc@1 57.812 (57.812)	Acc@5 85.156 (85.156)
Epoch: [68][10/391]	Time 0.013 (0.018)	Data 0.001 (0.015)	Loss 2.2970 (2.3718)	Acc@1 57.031 (56.818)	Acc@5 87.500 (84.943)
Epoch: [68][20/391]	Time 0.013 (0.016)	Data 0.001 (0.009)	Loss 2.4940 (2.3761)	Acc@1 54.688 (56.436)	Acc@5 82.812 (84.003)
Epoch: [68][30/391]	Time 0.013 (0.015)	Data 0.002 (0.006)	Loss 2.1294 (2.3677)	Acc@1 64.062 (57.082)	Acc@5 86.719 (84.451)
Epoch: [68][40/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.2576 (2.3473)	Acc@1 59.375 (57.355)	Acc@5 85.938 (84.889)
Epoch: [68][50/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.2575 (2.3447)	Acc@1 57.812 (57.184)	Acc@5 86.719 (85.187)
Epoch: [68][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.2635 (2.3559)	Acc@1 60.156 (56.878)	Acc@5 82.812 (85.156)
Epoch: [68][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.6662 (2.3733)	Acc@1 49.219 (56.503)	Acc@5 82.031 (85.112)
Epoch: [68][80/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4934 (2.3838)	Acc@1 55.469 (56.192)	Acc@5 84.375 (84.992)
Epoch: [68][90/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4726 (2.3917)	Acc@1 52.344 (55.846)	Acc@5 82.812 (84.916)
Epoch: [68][100/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.1889 (2.3955)	Acc@1 62.500 (55.809)	Acc@5 89.062 (84.893)
Epoch: [68][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4672 (2.3967)	Acc@1 57.031 (55.905)	Acc@5 83.594 (84.832)
Epoch: [68][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4546 (2.4015)	Acc@1 57.031 (55.856)	Acc@5 83.594 (84.672)
Epoch: [68][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3990 (2.4025)	Acc@1 55.469 (55.839)	Acc@5 85.156 (84.625)
Epoch: [68][140/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.6102 (2.4069)	Acc@1 50.781 (55.740)	Acc@5 81.250 (84.519)
Epoch: [68][150/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4439 (2.4144)	Acc@1 53.125 (55.510)	Acc@5 85.938 (84.453)
Epoch: [68][160/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3444 (2.4194)	Acc@1 60.938 (55.488)	Acc@5 86.719 (84.380)
Epoch: [68][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4423 (2.4231)	Acc@1 52.344 (55.355)	Acc@5 83.594 (84.297)
Epoch: [68][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5522 (2.4253)	Acc@1 53.906 (55.331)	Acc@5 81.250 (84.276)
Epoch: [68][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4297 (2.4234)	Acc@1 55.469 (55.366)	Acc@5 82.812 (84.240)
Epoch: [68][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3835 (2.4254)	Acc@1 56.250 (55.360)	Acc@5 85.156 (84.177)
Epoch: [68][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5224 (2.4277)	Acc@1 50.781 (55.269)	Acc@5 83.594 (84.120)
Epoch: [68][220/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5307 (2.4250)	Acc@1 52.344 (55.324)	Acc@5 82.031 (84.152)
Epoch: [68][230/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6449 (2.4285)	Acc@1 51.562 (55.178)	Acc@5 78.906 (84.084)
Epoch: [68][240/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4346 (2.4314)	Acc@1 54.688 (55.083)	Acc@5 85.156 (84.041)
Epoch: [68][250/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4535 (2.4344)	Acc@1 54.688 (54.993)	Acc@5 84.375 (83.989)
Epoch: [68][260/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3639 (2.4355)	Acc@1 59.375 (54.912)	Acc@5 88.281 (84.010)
Epoch: [68][270/391]	Time 0.018 (0.014)	Data 0.001 (0.002)	Loss 2.3690 (2.4384)	Acc@1 57.812 (54.860)	Acc@5 83.594 (83.974)
Epoch: [68][280/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 2.2738 (2.4353)	Acc@1 61.719 (54.957)	Acc@5 83.594 (84.002)
Epoch: [68][290/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 2.6029 (2.4363)	Acc@1 45.312 (54.913)	Acc@5 82.031 (83.978)
Epoch: [68][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2687 (2.4379)	Acc@1 53.906 (54.817)	Acc@5 86.719 (83.947)
Epoch: [68][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2870 (2.4386)	Acc@1 62.500 (54.828)	Acc@5 86.719 (83.935)
Epoch: [68][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3475 (2.4378)	Acc@1 53.906 (54.863)	Acc@5 85.938 (83.942)
Epoch: [68][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2248 (2.4377)	Acc@1 54.688 (54.886)	Acc@5 86.719 (83.931)
Epoch: [68][340/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2181 (2.4360)	Acc@1 60.156 (54.907)	Acc@5 85.938 (83.944)
Epoch: [68][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4489 (2.4366)	Acc@1 51.562 (54.888)	Acc@5 78.125 (83.899)
Epoch: [68][360/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4383 (2.4382)	Acc@1 57.812 (54.908)	Acc@5 85.938 (83.858)
Epoch: [68][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6904 (2.4415)	Acc@1 50.781 (54.831)	Acc@5 80.469 (83.804)
Epoch: [68][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4778 (2.4430)	Acc@1 50.000 (54.778)	Acc@5 84.375 (83.799)
Epoch: [68][390/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.5179 (2.4454)	Acc@1 50.000 (54.740)	Acc@5 85.000 (83.776)
num momentum params: 26
[0.1, 2.445416231689453, 2.096989187002182, 54.74, 46.15, tensor(0.3279, device='cuda:0', grad_fn=<DivBackward0>), 5.306531667709351, 0.39928507804870605]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [69 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [69][0/391]	Time 0.050 (0.050)	Data 0.175 (0.175)	Loss 2.2605 (2.2605)	Acc@1 58.594 (58.594)	Acc@5 87.500 (87.500)
Epoch: [69][10/391]	Time 0.013 (0.018)	Data 0.001 (0.017)	Loss 2.3769 (2.3439)	Acc@1 53.906 (56.321)	Acc@5 84.375 (85.938)
Epoch: [69][20/391]	Time 0.013 (0.016)	Data 0.001 (0.010)	Loss 2.2754 (2.3031)	Acc@1 59.375 (57.329)	Acc@5 87.500 (86.719)
Epoch: [69][30/391]	Time 0.014 (0.015)	Data 0.002 (0.007)	Loss 2.3469 (2.3214)	Acc@1 59.375 (57.132)	Acc@5 83.594 (85.761)
Epoch: [69][40/391]	Time 0.014 (0.015)	Data 0.001 (0.006)	Loss 2.2519 (2.3305)	Acc@1 59.375 (56.707)	Acc@5 86.719 (85.938)
Epoch: [69][50/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.2940 (2.3283)	Acc@1 59.375 (57.001)	Acc@5 86.719 (86.060)
Epoch: [69][60/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.2697 (2.3403)	Acc@1 60.156 (56.890)	Acc@5 85.156 (85.720)
Epoch: [69][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.1457 (2.3399)	Acc@1 60.938 (56.833)	Acc@5 87.500 (85.750)
Epoch: [69][80/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3988 (2.3427)	Acc@1 57.031 (56.809)	Acc@5 85.156 (85.600)
Epoch: [69][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2183 (2.3513)	Acc@1 61.719 (56.645)	Acc@5 87.500 (85.440)
Epoch: [69][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3225 (2.3499)	Acc@1 57.031 (56.753)	Acc@5 84.375 (85.520)
Epoch: [69][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2895 (2.3551)	Acc@1 57.031 (56.623)	Acc@5 86.719 (85.452)
Epoch: [69][120/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.5371 (2.3588)	Acc@1 53.906 (56.599)	Acc@5 82.031 (85.434)
Epoch: [69][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6434 (2.3788)	Acc@1 51.562 (56.167)	Acc@5 79.688 (85.109)
Epoch: [69][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4314 (2.3842)	Acc@1 53.906 (56.006)	Acc@5 80.469 (85.012)
Epoch: [69][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4419 (2.3924)	Acc@1 53.125 (55.831)	Acc@5 85.938 (84.784)
Epoch: [69][160/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4156 (2.3927)	Acc@1 53.125 (55.828)	Acc@5 83.594 (84.792)
Epoch: [69][170/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3455 (2.3932)	Acc@1 56.250 (55.871)	Acc@5 83.594 (84.745)
Epoch: [69][180/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3093 (2.3970)	Acc@1 57.031 (55.741)	Acc@5 85.938 (84.664)
Epoch: [69][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1111 (2.3968)	Acc@1 64.062 (55.780)	Acc@5 92.188 (84.698)
Epoch: [69][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2061 (2.3940)	Acc@1 63.281 (55.873)	Acc@5 85.938 (84.740)
Epoch: [69][210/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.6899 (2.3988)	Acc@1 50.000 (55.809)	Acc@5 76.562 (84.671)
Epoch: [69][220/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5542 (2.3997)	Acc@1 52.344 (55.819)	Acc@5 79.688 (84.591)
Epoch: [69][230/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4551 (2.4012)	Acc@1 56.250 (55.814)	Acc@5 82.812 (84.558)
Epoch: [69][240/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.3826 (2.4005)	Acc@1 55.469 (55.851)	Acc@5 78.125 (84.586)
Epoch: [69][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2446 (2.4012)	Acc@1 62.500 (55.876)	Acc@5 85.156 (84.515)
Epoch: [69][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4392 (2.4013)	Acc@1 55.469 (55.891)	Acc@5 84.375 (84.546)
Epoch: [69][270/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.3997 (2.4031)	Acc@1 55.469 (55.838)	Acc@5 85.938 (84.519)
Epoch: [69][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3182 (2.4044)	Acc@1 59.375 (55.816)	Acc@5 82.031 (84.533)
Epoch: [69][290/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4318 (2.4090)	Acc@1 57.031 (55.684)	Acc@5 83.594 (84.485)
Epoch: [69][300/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.5654 (2.4101)	Acc@1 50.781 (55.627)	Acc@5 79.688 (84.468)
Epoch: [69][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4613 (2.4128)	Acc@1 55.469 (55.599)	Acc@5 85.156 (84.415)
Epoch: [69][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6037 (2.4161)	Acc@1 50.781 (55.554)	Acc@5 82.031 (84.387)
Epoch: [69][330/391]	Time 0.017 (0.013)	Data 0.001 (0.002)	Loss 2.4280 (2.4183)	Acc@1 53.125 (55.481)	Acc@5 81.250 (84.361)
Epoch: [69][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4385 (2.4211)	Acc@1 54.688 (55.434)	Acc@5 86.719 (84.297)
Epoch: [69][350/391]	Time 0.012 (0.013)	Data 0.001 (0.002)	Loss 2.5506 (2.4226)	Acc@1 51.562 (55.366)	Acc@5 81.250 (84.299)
Epoch: [69][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.1540 (2.4238)	Acc@1 62.500 (55.322)	Acc@5 85.156 (84.284)
Epoch: [69][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5706 (2.4272)	Acc@1 50.000 (55.254)	Acc@5 79.688 (84.247)
Epoch: [69][380/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.4562 (2.4304)	Acc@1 46.094 (55.180)	Acc@5 88.281 (84.231)
Epoch: [69][390/391]	Time 0.015 (0.013)	Data 0.002 (0.002)	Loss 2.4863 (2.4327)	Acc@1 55.000 (55.174)	Acc@5 81.250 (84.186)
num momentum params: 26
[0.1, 2.4327027165985107, 2.1671354842185973, 55.174, 44.19, tensor(0.3302, device='cuda:0', grad_fn=<DivBackward0>), 5.270773649215698, 0.3882787227630615]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [70 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [70][0/391]	Time 0.049 (0.049)	Data 0.148 (0.148)	Loss 2.3776 (2.3776)	Acc@1 54.688 (54.688)	Acc@5 89.062 (89.062)
Epoch: [70][10/391]	Time 0.013 (0.017)	Data 0.001 (0.015)	Loss 2.0543 (2.3425)	Acc@1 64.844 (56.321)	Acc@5 94.531 (87.074)
Epoch: [70][20/391]	Time 0.014 (0.016)	Data 0.002 (0.009)	Loss 2.3078 (2.3404)	Acc@1 57.031 (56.436)	Acc@5 84.375 (86.942)
Epoch: [70][30/391]	Time 0.013 (0.015)	Data 0.001 (0.006)	Loss 2.5279 (2.3429)	Acc@1 52.344 (56.502)	Acc@5 85.938 (86.668)
Epoch: [70][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.4545 (2.3609)	Acc@1 57.031 (55.983)	Acc@5 81.250 (86.014)
Epoch: [70][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4579 (2.3816)	Acc@1 53.125 (55.484)	Acc@5 84.375 (85.493)
Epoch: [70][60/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.4983 (2.3882)	Acc@1 58.594 (55.648)	Acc@5 84.375 (85.374)
Epoch: [70][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.5430 (2.3951)	Acc@1 53.125 (55.491)	Acc@5 81.250 (85.299)
Epoch: [70][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3319 (2.4076)	Acc@1 58.594 (55.237)	Acc@5 84.375 (84.857)
Epoch: [70][90/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.7017 (2.4183)	Acc@1 50.000 (55.031)	Acc@5 78.125 (84.633)
Epoch: [70][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2923 (2.4114)	Acc@1 58.594 (55.167)	Acc@5 85.938 (84.777)
Epoch: [70][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3176 (2.4059)	Acc@1 54.688 (55.391)	Acc@5 88.281 (84.847)
Epoch: [70][120/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5985 (2.4096)	Acc@1 50.781 (55.436)	Acc@5 80.469 (84.814)
Epoch: [70][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4332 (2.4107)	Acc@1 51.562 (55.445)	Acc@5 85.938 (84.781)
Epoch: [70][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5722 (2.4160)	Acc@1 51.562 (55.280)	Acc@5 84.375 (84.752)
Epoch: [70][150/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5848 (2.4195)	Acc@1 50.000 (55.189)	Acc@5 82.812 (84.753)
Epoch: [70][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5510 (2.4231)	Acc@1 52.344 (55.003)	Acc@5 83.594 (84.729)
Epoch: [70][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3461 (2.4249)	Acc@1 56.250 (54.989)	Acc@5 85.156 (84.667)
Epoch: [70][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6205 (2.4247)	Acc@1 46.875 (55.016)	Acc@5 84.375 (84.690)
Epoch: [70][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3973 (2.4205)	Acc@1 57.031 (55.174)	Acc@5 86.719 (84.690)
Epoch: [70][200/391]	Time 0.017 (0.014)	Data 0.002 (0.002)	Loss 2.7210 (2.4260)	Acc@1 50.000 (55.037)	Acc@5 78.906 (84.608)
Epoch: [70][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5614 (2.4268)	Acc@1 54.688 (55.047)	Acc@5 80.469 (84.586)
Epoch: [70][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4904 (2.4298)	Acc@1 51.562 (55.016)	Acc@5 85.156 (84.499)
Epoch: [70][230/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 2.4027 (2.4328)	Acc@1 55.469 (54.948)	Acc@5 84.375 (84.436)
Epoch: [70][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3641 (2.4325)	Acc@1 58.594 (54.999)	Acc@5 86.719 (84.433)
Epoch: [70][250/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4799 (2.4291)	Acc@1 53.125 (55.030)	Acc@5 78.906 (84.493)
Epoch: [70][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2163 (2.4263)	Acc@1 54.688 (55.136)	Acc@5 88.281 (84.462)
Epoch: [70][270/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.4524 (2.4251)	Acc@1 55.469 (55.166)	Acc@5 82.812 (84.476)
Epoch: [70][280/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.7870 (2.4265)	Acc@1 48.438 (55.152)	Acc@5 79.688 (84.447)
Epoch: [70][290/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5496 (2.4267)	Acc@1 53.125 (55.163)	Acc@5 82.812 (84.405)
Epoch: [70][300/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.8065 (2.4277)	Acc@1 50.000 (55.170)	Acc@5 79.688 (84.393)
Epoch: [70][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5446 (2.4292)	Acc@1 50.781 (55.145)	Acc@5 84.375 (84.350)
Epoch: [70][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4822 (2.4310)	Acc@1 53.125 (55.130)	Acc@5 84.375 (84.319)
Epoch: [70][330/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.2726 (2.4314)	Acc@1 60.156 (55.136)	Acc@5 86.719 (84.307)
Epoch: [70][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6362 (2.4328)	Acc@1 50.781 (55.084)	Acc@5 82.812 (84.309)
Epoch: [70][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4534 (2.4331)	Acc@1 51.562 (55.077)	Acc@5 82.812 (84.286)
Epoch: [70][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3027 (2.4322)	Acc@1 62.500 (55.090)	Acc@5 85.156 (84.286)
Epoch: [70][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5907 (2.4311)	Acc@1 54.688 (55.130)	Acc@5 84.375 (84.282)
Epoch: [70][380/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.4203 (2.4315)	Acc@1 52.344 (55.114)	Acc@5 83.594 (84.281)
Epoch: [70][390/391]	Time 0.017 (0.013)	Data 0.001 (0.002)	Loss 2.8094 (2.4325)	Acc@1 51.250 (55.082)	Acc@5 75.000 (84.270)
num momentum params: 26
[0.1, 2.4325054444122314, 1.7943499195575714, 55.082, 51.99, tensor(0.3300, device='cuda:0', grad_fn=<DivBackward0>), 5.2596213817596436, 0.39490795135498047]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [71 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [71][0/391]	Time 0.045 (0.045)	Data 0.158 (0.158)	Loss 2.6719 (2.6719)	Acc@1 47.656 (47.656)	Acc@5 81.250 (81.250)
Epoch: [71][10/391]	Time 0.013 (0.018)	Data 0.002 (0.016)	Loss 2.2177 (2.3204)	Acc@1 61.719 (57.386)	Acc@5 86.719 (85.156)
Epoch: [71][20/391]	Time 0.013 (0.016)	Data 0.002 (0.009)	Loss 2.3476 (2.3204)	Acc@1 53.125 (57.329)	Acc@5 86.719 (85.342)
Epoch: [71][30/391]	Time 0.013 (0.015)	Data 0.002 (0.007)	Loss 2.4945 (2.3314)	Acc@1 53.125 (57.913)	Acc@5 86.719 (85.232)
Epoch: [71][40/391]	Time 0.014 (0.015)	Data 0.001 (0.005)	Loss 2.0498 (2.3266)	Acc@1 67.188 (57.641)	Acc@5 90.625 (85.976)
Epoch: [71][50/391]	Time 0.014 (0.014)	Data 0.001 (0.005)	Loss 2.4284 (2.3309)	Acc@1 53.125 (57.537)	Acc@5 85.938 (85.861)
Epoch: [71][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4988 (2.3396)	Acc@1 51.562 (57.364)	Acc@5 83.594 (85.797)
Epoch: [71][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3674 (2.3476)	Acc@1 57.812 (57.251)	Acc@5 86.719 (85.464)
Epoch: [71][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4678 (2.3498)	Acc@1 55.469 (57.128)	Acc@5 84.375 (85.426)
Epoch: [71][90/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.1885 (2.3550)	Acc@1 62.500 (56.937)	Acc@5 87.500 (85.371)
Epoch: [71][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4157 (2.3670)	Acc@1 58.594 (56.567)	Acc@5 86.719 (85.149)
Epoch: [71][110/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4801 (2.3766)	Acc@1 53.125 (56.306)	Acc@5 82.812 (85.023)
Epoch: [71][120/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4447 (2.3807)	Acc@1 56.250 (56.276)	Acc@5 82.812 (84.879)
Epoch: [71][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3494 (2.3768)	Acc@1 54.688 (56.328)	Acc@5 86.719 (84.924)
Epoch: [71][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5979 (2.3799)	Acc@1 56.250 (56.311)	Acc@5 79.688 (84.918)
Epoch: [71][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5688 (2.3883)	Acc@1 47.656 (56.167)	Acc@5 85.156 (84.794)
Epoch: [71][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1839 (2.3875)	Acc@1 57.812 (56.143)	Acc@5 88.281 (84.817)
Epoch: [71][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3154 (2.3875)	Acc@1 54.688 (56.154)	Acc@5 84.375 (84.768)
Epoch: [71][180/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.1890 (2.3877)	Acc@1 58.594 (56.138)	Acc@5 89.844 (84.746)
Epoch: [71][190/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5407 (2.3908)	Acc@1 52.344 (56.058)	Acc@5 81.250 (84.682)
Epoch: [71][200/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4660 (2.3931)	Acc@1 50.781 (55.939)	Acc@5 85.938 (84.663)
Epoch: [71][210/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.7048 (2.3950)	Acc@1 45.312 (55.957)	Acc@5 78.906 (84.649)
Epoch: [71][220/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5373 (2.3992)	Acc@1 50.781 (55.935)	Acc@5 82.812 (84.594)
Epoch: [71][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3298 (2.4023)	Acc@1 57.812 (55.878)	Acc@5 88.281 (84.541)
Epoch: [71][240/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2700 (2.4051)	Acc@1 60.938 (55.874)	Acc@5 85.938 (84.479)
Epoch: [71][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7046 (2.4097)	Acc@1 46.094 (55.764)	Acc@5 75.781 (84.384)
Epoch: [71][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3201 (2.4078)	Acc@1 53.125 (55.771)	Acc@5 88.281 (84.420)
Epoch: [71][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2104 (2.4083)	Acc@1 60.156 (55.720)	Acc@5 85.938 (84.421)
Epoch: [71][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4486 (2.4131)	Acc@1 53.906 (55.588)	Acc@5 84.375 (84.319)
Epoch: [71][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2612 (2.4142)	Acc@1 59.375 (55.624)	Acc@5 87.500 (84.297)
Epoch: [71][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2310 (2.4142)	Acc@1 56.250 (55.635)	Acc@5 88.281 (84.323)
Epoch: [71][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6714 (2.4166)	Acc@1 51.562 (55.574)	Acc@5 76.562 (84.262)
Epoch: [71][320/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5768 (2.4173)	Acc@1 53.125 (55.561)	Acc@5 81.250 (84.224)
Epoch: [71][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4408 (2.4205)	Acc@1 54.688 (55.483)	Acc@5 82.031 (84.196)
Epoch: [71][340/391]	Time 0.012 (0.013)	Data 0.002 (0.002)	Loss 2.4161 (2.4182)	Acc@1 57.812 (55.526)	Acc@5 85.156 (84.249)
Epoch: [71][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3918 (2.4215)	Acc@1 55.469 (55.446)	Acc@5 89.844 (84.219)
Epoch: [71][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6330 (2.4238)	Acc@1 51.562 (55.371)	Acc@5 80.469 (84.195)
Epoch: [71][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2861 (2.4237)	Acc@1 59.375 (55.349)	Acc@5 86.719 (84.190)
Epoch: [71][380/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.4236 (2.4238)	Acc@1 57.812 (55.360)	Acc@5 85.938 (84.190)
Epoch: [71][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.7803 (2.4240)	Acc@1 48.750 (55.376)	Acc@5 78.750 (84.184)
num momentum params: 26
[0.1, 2.4240178243255617, 2.2939349246025085, 55.376, 43.55, tensor(0.3308, device='cuda:0', grad_fn=<DivBackward0>), 5.258768796920776, 0.39400529861450195]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [72 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [72][0/391]	Time 0.053 (0.053)	Data 0.161 (0.161)	Loss 2.3084 (2.3084)	Acc@1 59.375 (59.375)	Acc@5 87.500 (87.500)
Epoch: [72][10/391]	Time 0.016 (0.018)	Data 0.001 (0.016)	Loss 2.3363 (2.3344)	Acc@1 49.219 (56.818)	Acc@5 86.719 (85.938)
Epoch: [72][20/391]	Time 0.014 (0.016)	Data 0.001 (0.009)	Loss 2.4021 (2.3241)	Acc@1 56.250 (57.589)	Acc@5 85.938 (85.863)
Epoch: [72][30/391]	Time 0.014 (0.015)	Data 0.001 (0.007)	Loss 2.2824 (2.3440)	Acc@1 57.031 (56.779)	Acc@5 87.500 (85.585)
Epoch: [72][40/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.4682 (2.3581)	Acc@1 55.469 (56.326)	Acc@5 80.469 (85.461)
Epoch: [72][50/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.3905 (2.3698)	Acc@1 57.031 (56.097)	Acc@5 89.844 (85.294)
Epoch: [72][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.2917 (2.3685)	Acc@1 63.281 (56.327)	Acc@5 85.156 (85.284)
Epoch: [72][70/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.3957 (2.3735)	Acc@1 55.469 (56.261)	Acc@5 81.250 (84.925)
Epoch: [72][80/391]	Time 0.014 (0.014)	Data 0.000 (0.003)	Loss 2.4692 (2.3825)	Acc@1 49.219 (55.951)	Acc@5 85.156 (84.915)
Epoch: [72][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3088 (2.3712)	Acc@1 61.719 (56.181)	Acc@5 85.156 (85.148)
Epoch: [72][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5955 (2.3790)	Acc@1 53.906 (56.010)	Acc@5 80.469 (85.079)
Epoch: [72][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4881 (2.3917)	Acc@1 55.469 (55.680)	Acc@5 85.156 (84.903)
Epoch: [72][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5152 (2.3910)	Acc@1 55.469 (55.637)	Acc@5 78.906 (84.853)
Epoch: [72][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.7195 (2.3988)	Acc@1 48.438 (55.493)	Acc@5 77.344 (84.846)
Epoch: [72][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6031 (2.4011)	Acc@1 48.438 (55.563)	Acc@5 84.375 (84.857)
Epoch: [72][150/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 2.8724 (2.4058)	Acc@1 44.531 (55.515)	Acc@5 76.562 (84.732)
Epoch: [72][160/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4527 (2.4035)	Acc@1 56.250 (55.648)	Acc@5 84.375 (84.749)
Epoch: [72][170/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3201 (2.4016)	Acc@1 55.469 (55.757)	Acc@5 83.594 (84.745)
Epoch: [72][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3658 (2.4020)	Acc@1 62.500 (55.805)	Acc@5 84.375 (84.690)
Epoch: [72][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5082 (2.3993)	Acc@1 50.781 (55.857)	Acc@5 85.156 (84.747)
Epoch: [72][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.8218 (2.4030)	Acc@1 46.094 (55.784)	Acc@5 79.688 (84.701)
Epoch: [72][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5761 (2.4098)	Acc@1 51.562 (55.598)	Acc@5 81.250 (84.612)
Epoch: [72][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6119 (2.4149)	Acc@1 52.344 (55.437)	Acc@5 81.250 (84.552)
Epoch: [72][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2532 (2.4180)	Acc@1 61.719 (55.445)	Acc@5 89.844 (84.507)
Epoch: [72][240/391]	Time 0.010 (0.014)	Data 0.005 (0.002)	Loss 2.4430 (2.4196)	Acc@1 56.250 (55.446)	Acc@5 82.812 (84.459)
Epoch: [72][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5911 (2.4210)	Acc@1 49.219 (55.438)	Acc@5 82.031 (84.425)
Epoch: [72][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6201 (2.4224)	Acc@1 48.438 (55.319)	Acc@5 83.594 (84.426)
Epoch: [72][270/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 2.6246 (2.4246)	Acc@1 45.312 (55.264)	Acc@5 82.812 (84.438)
Epoch: [72][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3321 (2.4279)	Acc@1 58.594 (55.180)	Acc@5 85.156 (84.367)
Epoch: [72][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3946 (2.4311)	Acc@1 57.031 (55.106)	Acc@5 85.156 (84.303)
Epoch: [72][300/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3581 (2.4310)	Acc@1 53.906 (55.129)	Acc@5 83.594 (84.240)
Epoch: [72][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2718 (2.4311)	Acc@1 55.469 (55.125)	Acc@5 89.062 (84.239)
Epoch: [72][320/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3901 (2.4312)	Acc@1 57.031 (55.128)	Acc@5 82.812 (84.217)
Epoch: [72][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3981 (2.4315)	Acc@1 59.375 (55.101)	Acc@5 82.031 (84.252)
Epoch: [72][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3693 (2.4323)	Acc@1 55.469 (55.086)	Acc@5 82.812 (84.254)
Epoch: [72][350/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.3398 (2.4314)	Acc@1 60.156 (55.126)	Acc@5 82.812 (84.233)
Epoch: [72][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4394 (2.4305)	Acc@1 54.688 (55.120)	Acc@5 83.594 (84.278)
Epoch: [72][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4554 (2.4330)	Acc@1 51.562 (55.033)	Acc@5 85.156 (84.242)
Epoch: [72][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4671 (2.4354)	Acc@1 58.594 (55.024)	Acc@5 82.031 (84.151)
Epoch: [72][390/391]	Time 0.017 (0.013)	Data 0.001 (0.002)	Loss 2.7843 (2.4376)	Acc@1 51.250 (54.974)	Acc@5 78.750 (84.130)
num momentum params: 26
[0.1, 2.4375909564971923, 2.1016518545150755, 54.974, 46.49, tensor(0.3286, device='cuda:0', grad_fn=<DivBackward0>), 5.267454147338867, 0.3959839344024658]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [73 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [73][0/391]	Time 0.054 (0.054)	Data 0.154 (0.154)	Loss 2.3201 (2.3201)	Acc@1 59.375 (59.375)	Acc@5 86.719 (86.719)
Epoch: [73][10/391]	Time 0.014 (0.018)	Data 0.002 (0.015)	Loss 2.1807 (2.3178)	Acc@1 60.938 (58.381)	Acc@5 89.844 (85.511)
Epoch: [73][20/391]	Time 0.014 (0.016)	Data 0.001 (0.009)	Loss 2.5233 (2.3212)	Acc@1 49.219 (58.222)	Acc@5 78.906 (85.454)
Epoch: [73][30/391]	Time 0.014 (0.015)	Data 0.001 (0.006)	Loss 2.6632 (2.3427)	Acc@1 49.219 (57.485)	Acc@5 82.812 (85.207)
Epoch: [73][40/391]	Time 0.014 (0.015)	Data 0.001 (0.005)	Loss 2.3964 (2.3513)	Acc@1 52.344 (57.031)	Acc@5 82.812 (85.252)
Epoch: [73][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3209 (2.3521)	Acc@1 59.375 (57.047)	Acc@5 89.062 (85.524)
Epoch: [73][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.5215 (2.3508)	Acc@1 53.906 (56.980)	Acc@5 82.812 (85.681)
Epoch: [73][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3431 (2.3536)	Acc@1 53.906 (56.888)	Acc@5 85.156 (85.772)
Epoch: [73][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5718 (2.3626)	Acc@1 53.125 (56.559)	Acc@5 82.031 (85.494)
Epoch: [73][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3891 (2.3662)	Acc@1 59.375 (56.576)	Acc@5 84.375 (85.362)
Epoch: [73][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5833 (2.3659)	Acc@1 50.000 (56.436)	Acc@5 82.031 (85.365)
Epoch: [73][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4694 (2.3762)	Acc@1 56.250 (56.299)	Acc@5 86.719 (85.100)
Epoch: [73][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.1650 (2.3796)	Acc@1 64.062 (56.231)	Acc@5 87.500 (85.021)
Epoch: [73][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4931 (2.3894)	Acc@1 51.562 (56.071)	Acc@5 80.469 (84.828)
Epoch: [73][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3406 (2.3933)	Acc@1 55.469 (55.962)	Acc@5 85.156 (84.840)
Epoch: [73][150/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4312 (2.3956)	Acc@1 53.125 (55.991)	Acc@5 82.031 (84.742)
Epoch: [73][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3720 (2.3983)	Acc@1 56.250 (55.935)	Acc@5 83.594 (84.656)
Epoch: [73][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2336 (2.4007)	Acc@1 53.906 (55.811)	Acc@5 87.500 (84.699)
Epoch: [73][180/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4601 (2.4034)	Acc@1 52.344 (55.646)	Acc@5 83.594 (84.703)
Epoch: [73][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5216 (2.4069)	Acc@1 50.781 (55.542)	Acc@5 80.469 (84.592)
Epoch: [73][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6571 (2.4126)	Acc@1 47.656 (55.379)	Acc@5 81.250 (84.472)
Epoch: [73][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4175 (2.4108)	Acc@1 58.594 (55.417)	Acc@5 82.031 (84.486)
Epoch: [73][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1838 (2.4079)	Acc@1 61.719 (55.508)	Acc@5 88.281 (84.541)
Epoch: [73][230/391]	Time 0.012 (0.014)	Data 0.002 (0.002)	Loss 2.2674 (2.4113)	Acc@1 60.156 (55.469)	Acc@5 88.281 (84.510)
Epoch: [73][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.0597 (2.4086)	Acc@1 60.938 (55.576)	Acc@5 90.625 (84.501)
Epoch: [73][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4124 (2.4110)	Acc@1 57.031 (55.500)	Acc@5 85.156 (84.475)
Epoch: [73][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3466 (2.4144)	Acc@1 60.938 (55.451)	Acc@5 85.938 (84.408)
Epoch: [73][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5023 (2.4165)	Acc@1 55.469 (55.402)	Acc@5 82.031 (84.355)
Epoch: [73][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2990 (2.4137)	Acc@1 56.250 (55.458)	Acc@5 88.281 (84.442)
Epoch: [73][290/391]	Time 0.012 (0.013)	Data 0.004 (0.002)	Loss 2.3750 (2.4150)	Acc@1 55.469 (55.386)	Acc@5 88.281 (84.509)
Epoch: [73][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6209 (2.4172)	Acc@1 50.000 (55.326)	Acc@5 80.469 (84.476)
Epoch: [73][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3484 (2.4181)	Acc@1 52.344 (55.290)	Acc@5 90.625 (84.465)
Epoch: [73][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7541 (2.4197)	Acc@1 50.781 (55.233)	Acc@5 82.031 (84.480)
Epoch: [73][330/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.3872 (2.4223)	Acc@1 57.812 (55.228)	Acc@5 86.719 (84.410)
Epoch: [73][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3553 (2.4227)	Acc@1 56.250 (55.226)	Acc@5 85.938 (84.412)
Epoch: [73][350/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4384 (2.4228)	Acc@1 58.594 (55.264)	Acc@5 83.594 (84.379)
Epoch: [73][360/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.6027 (2.4232)	Acc@1 54.688 (55.237)	Acc@5 78.906 (84.362)
Epoch: [73][370/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.4606 (2.4258)	Acc@1 52.344 (55.166)	Acc@5 82.031 (84.297)
Epoch: [73][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6235 (2.4284)	Acc@1 53.906 (55.046)	Acc@5 81.250 (84.246)
Epoch: [73][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.8842 (2.4337)	Acc@1 52.500 (54.972)	Acc@5 75.000 (84.130)
num momentum params: 26
[0.1, 2.433675945739746, 2.016441913843155, 54.972, 47.12, tensor(0.3288, device='cuda:0', grad_fn=<DivBackward0>), 5.261603832244873, 0.3943822383880615]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [74 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [74][0/391]	Time 0.053 (0.053)	Data 0.157 (0.157)	Loss 2.3175 (2.3175)	Acc@1 57.031 (57.031)	Acc@5 88.281 (88.281)
Epoch: [74][10/391]	Time 0.014 (0.018)	Data 0.001 (0.016)	Loss 2.3699 (2.3576)	Acc@1 54.688 (55.966)	Acc@5 85.938 (86.364)
Epoch: [74][20/391]	Time 0.013 (0.016)	Data 0.001 (0.009)	Loss 2.1254 (2.3735)	Acc@1 60.156 (56.287)	Acc@5 87.500 (85.938)
Epoch: [74][30/391]	Time 0.013 (0.015)	Data 0.001 (0.007)	Loss 2.2488 (2.3943)	Acc@1 59.375 (55.570)	Acc@5 89.844 (85.786)
Epoch: [74][40/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.5019 (2.3908)	Acc@1 50.781 (55.678)	Acc@5 84.375 (85.690)
Epoch: [74][50/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.4443 (2.3844)	Acc@1 51.562 (55.852)	Acc@5 89.062 (85.738)
Epoch: [74][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.6812 (2.3730)	Acc@1 50.781 (56.019)	Acc@5 79.688 (85.707)
Epoch: [74][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.2397 (2.3682)	Acc@1 56.250 (56.151)	Acc@5 86.719 (85.574)
Epoch: [74][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2858 (2.3740)	Acc@1 57.031 (56.337)	Acc@5 88.281 (85.272)
Epoch: [74][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3831 (2.3809)	Acc@1 56.250 (56.147)	Acc@5 85.156 (85.234)
Epoch: [74][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4593 (2.3859)	Acc@1 58.594 (56.103)	Acc@5 78.125 (85.048)
Epoch: [74][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3326 (2.3797)	Acc@1 53.906 (56.229)	Acc@5 83.594 (85.121)
Epoch: [74][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5290 (2.3821)	Acc@1 51.562 (56.018)	Acc@5 80.469 (85.066)
Epoch: [74][130/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3676 (2.3870)	Acc@1 58.594 (55.904)	Acc@5 85.156 (85.007)
Epoch: [74][140/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2018 (2.3905)	Acc@1 59.375 (55.879)	Acc@5 85.938 (84.990)
Epoch: [74][150/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.0884 (2.3881)	Acc@1 66.406 (55.976)	Acc@5 88.281 (84.986)
Epoch: [74][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5966 (2.3858)	Acc@1 50.781 (56.012)	Acc@5 82.031 (85.064)
Epoch: [74][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3239 (2.3904)	Acc@1 57.031 (55.866)	Acc@5 89.062 (84.978)
Epoch: [74][180/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4573 (2.3903)	Acc@1 56.250 (55.857)	Acc@5 85.156 (84.988)
Epoch: [74][190/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.3987 (2.3933)	Acc@1 56.250 (55.861)	Acc@5 86.719 (84.935)
Epoch: [74][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4873 (2.3977)	Acc@1 57.812 (55.850)	Acc@5 82.031 (84.830)
Epoch: [74][210/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 2.5633 (2.4002)	Acc@1 53.906 (55.780)	Acc@5 83.594 (84.797)
Epoch: [74][220/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4496 (2.4026)	Acc@1 54.688 (55.755)	Acc@5 82.812 (84.714)
Epoch: [74][230/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4885 (2.4055)	Acc@1 52.344 (55.624)	Acc@5 85.156 (84.632)
Epoch: [74][240/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4576 (2.4016)	Acc@1 57.812 (55.790)	Acc@5 85.156 (84.699)
Epoch: [74][250/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5715 (2.4017)	Acc@1 50.000 (55.814)	Acc@5 82.031 (84.668)
Epoch: [74][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2073 (2.4028)	Acc@1 60.156 (55.825)	Acc@5 89.062 (84.620)
Epoch: [74][270/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3806 (2.4053)	Acc@1 55.469 (55.835)	Acc@5 88.281 (84.580)
Epoch: [74][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3580 (2.4045)	Acc@1 56.250 (55.877)	Acc@5 85.938 (84.561)
Epoch: [74][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3698 (2.4050)	Acc@1 59.375 (55.847)	Acc@5 79.688 (84.584)
Epoch: [74][300/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 2.5441 (2.4090)	Acc@1 58.594 (55.780)	Acc@5 82.031 (84.494)
Epoch: [74][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5719 (2.4123)	Acc@1 49.219 (55.720)	Acc@5 85.938 (84.425)
Epoch: [74][320/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5223 (2.4136)	Acc@1 53.125 (55.671)	Acc@5 81.250 (84.409)
Epoch: [74][330/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.6558 (2.4159)	Acc@1 54.688 (55.610)	Acc@5 87.500 (84.422)
Epoch: [74][340/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5052 (2.4149)	Acc@1 52.344 (55.618)	Acc@5 83.594 (84.444)
Epoch: [74][350/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.5010 (2.4159)	Acc@1 52.344 (55.578)	Acc@5 80.469 (84.440)
Epoch: [74][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8467 (2.4190)	Acc@1 46.094 (55.503)	Acc@5 71.875 (84.362)
Epoch: [74][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7368 (2.4208)	Acc@1 48.438 (55.427)	Acc@5 75.000 (84.320)
Epoch: [74][380/391]	Time 0.012 (0.013)	Data 0.001 (0.002)	Loss 2.6060 (2.4207)	Acc@1 49.219 (55.415)	Acc@5 78.125 (84.305)
Epoch: [74][390/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.4264 (2.4213)	Acc@1 52.500 (55.372)	Acc@5 87.500 (84.316)
num momentum params: 26
[0.1, 2.421335177154541, 2.0298533630371094, 55.372, 47.29, tensor(0.3305, device='cuda:0', grad_fn=<DivBackward0>), 5.261188983917236, 0.393381118774414]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [75 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [75][0/391]	Time 0.054 (0.054)	Data 0.163 (0.163)	Loss 2.3253 (2.3253)	Acc@1 56.250 (56.250)	Acc@5 87.500 (87.500)
Epoch: [75][10/391]	Time 0.013 (0.018)	Data 0.002 (0.016)	Loss 2.3281 (2.3314)	Acc@1 57.812 (57.741)	Acc@5 85.938 (85.866)
Epoch: [75][20/391]	Time 0.015 (0.016)	Data 0.002 (0.009)	Loss 2.3286 (2.3481)	Acc@1 60.938 (57.664)	Acc@5 82.812 (85.640)
Epoch: [75][30/391]	Time 0.014 (0.015)	Data 0.001 (0.007)	Loss 2.0329 (2.3359)	Acc@1 64.844 (57.787)	Acc@5 91.406 (85.887)
Epoch: [75][40/391]	Time 0.013 (0.015)	Data 0.002 (0.005)	Loss 2.1749 (2.3066)	Acc@1 61.719 (58.498)	Acc@5 87.500 (86.090)
Epoch: [75][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.2572 (2.3143)	Acc@1 61.719 (58.058)	Acc@5 87.500 (85.876)
Epoch: [75][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4449 (2.3136)	Acc@1 52.344 (58.005)	Acc@5 82.812 (85.694)
Epoch: [75][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.0841 (2.3250)	Acc@1 61.719 (57.746)	Acc@5 91.406 (85.530)
Epoch: [75][80/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.1853 (2.3196)	Acc@1 60.938 (57.784)	Acc@5 90.625 (85.667)
Epoch: [75][90/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.5042 (2.3334)	Acc@1 53.906 (57.598)	Acc@5 85.156 (85.440)
Epoch: [75][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.7355 (2.3503)	Acc@1 48.438 (57.248)	Acc@5 76.562 (85.079)
Epoch: [75][110/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.3476 (2.3620)	Acc@1 57.812 (56.841)	Acc@5 82.031 (84.945)
Epoch: [75][120/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5257 (2.3698)	Acc@1 47.656 (56.696)	Acc@5 81.250 (84.775)
Epoch: [75][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4965 (2.3726)	Acc@1 57.812 (56.650)	Acc@5 82.812 (84.757)
Epoch: [75][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3038 (2.3738)	Acc@1 57.031 (56.566)	Acc@5 88.281 (84.785)
Epoch: [75][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5272 (2.3757)	Acc@1 48.438 (56.457)	Acc@5 82.031 (84.804)
Epoch: [75][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2506 (2.3780)	Acc@1 63.281 (56.454)	Acc@5 87.500 (84.778)
Epoch: [75][170/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4981 (2.3841)	Acc@1 50.000 (56.309)	Acc@5 85.156 (84.763)
Epoch: [75][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5495 (2.3822)	Acc@1 51.562 (56.332)	Acc@5 85.156 (84.850)
Epoch: [75][190/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3327 (2.3843)	Acc@1 56.250 (56.315)	Acc@5 86.719 (84.862)
Epoch: [75][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4913 (2.3869)	Acc@1 54.688 (56.223)	Acc@5 85.156 (84.904)
Epoch: [75][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4914 (2.3897)	Acc@1 52.344 (56.146)	Acc@5 84.375 (84.856)
Epoch: [75][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6518 (2.3941)	Acc@1 48.438 (56.024)	Acc@5 82.812 (84.806)
Epoch: [75][230/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.5579 (2.3960)	Acc@1 52.344 (55.973)	Acc@5 80.469 (84.798)
Epoch: [75][240/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5878 (2.3991)	Acc@1 53.906 (55.877)	Acc@5 78.906 (84.699)
Epoch: [75][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1674 (2.3961)	Acc@1 60.156 (55.933)	Acc@5 86.719 (84.783)
Epoch: [75][260/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3433 (2.3984)	Acc@1 56.250 (55.861)	Acc@5 85.156 (84.803)
Epoch: [75][270/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5139 (2.4047)	Acc@1 47.656 (55.734)	Acc@5 85.938 (84.721)
Epoch: [75][280/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5550 (2.4073)	Acc@1 54.688 (55.674)	Acc@5 78.125 (84.686)
Epoch: [75][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4235 (2.4112)	Acc@1 54.688 (55.522)	Acc@5 83.594 (84.619)
Epoch: [75][300/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2897 (2.4135)	Acc@1 59.375 (55.443)	Acc@5 84.375 (84.562)
Epoch: [75][310/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6611 (2.4128)	Acc@1 54.688 (55.444)	Acc@5 84.375 (84.621)
Epoch: [75][320/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 2.3803 (2.4117)	Acc@1 57.031 (55.449)	Acc@5 83.594 (84.655)
Epoch: [75][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5391 (2.4118)	Acc@1 55.469 (55.414)	Acc@5 80.469 (84.649)
Epoch: [75][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1263 (2.4124)	Acc@1 64.844 (55.432)	Acc@5 89.844 (84.655)
Epoch: [75][350/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6974 (2.4150)	Acc@1 50.781 (55.438)	Acc@5 81.250 (84.584)
Epoch: [75][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2805 (2.4155)	Acc@1 56.250 (55.412)	Acc@5 85.156 (84.561)
Epoch: [75][370/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3817 (2.4177)	Acc@1 58.594 (55.313)	Acc@5 85.156 (84.535)
Epoch: [75][380/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2934 (2.4182)	Acc@1 60.156 (55.342)	Acc@5 84.375 (84.547)
Epoch: [75][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.7859 (2.4198)	Acc@1 42.500 (55.318)	Acc@5 82.500 (84.522)
num momentum params: 26
[0.1, 2.4198153108978273, 2.1060605013370512, 55.318, 45.25, tensor(0.3313, device='cuda:0', grad_fn=<DivBackward0>), 5.309685945510864, 0.39576220512390137]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [76 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [76][0/391]	Time 0.050 (0.050)	Data 0.166 (0.166)	Loss 2.2412 (2.2412)	Acc@1 59.375 (59.375)	Acc@5 88.281 (88.281)
Epoch: [76][10/391]	Time 0.014 (0.018)	Data 0.002 (0.016)	Loss 2.2797 (2.3130)	Acc@1 58.594 (57.102)	Acc@5 88.281 (86.932)
Epoch: [76][20/391]	Time 0.013 (0.016)	Data 0.001 (0.009)	Loss 2.2471 (2.2955)	Acc@1 57.812 (58.222)	Acc@5 86.719 (86.421)
Epoch: [76][30/391]	Time 0.013 (0.015)	Data 0.001 (0.007)	Loss 2.1804 (2.3029)	Acc@1 64.062 (58.266)	Acc@5 89.062 (86.240)
Epoch: [76][40/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.3231 (2.3082)	Acc@1 59.375 (58.041)	Acc@5 90.625 (86.433)
Epoch: [76][50/391]	Time 0.013 (0.014)	Data 0.002 (0.005)	Loss 2.4721 (2.3252)	Acc@1 55.469 (57.583)	Acc@5 85.156 (86.229)
Epoch: [76][60/391]	Time 0.012 (0.014)	Data 0.001 (0.004)	Loss 2.3239 (2.3395)	Acc@1 56.250 (57.108)	Acc@5 88.281 (86.194)
Epoch: [76][70/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.2585 (2.3465)	Acc@1 57.812 (56.844)	Acc@5 81.250 (85.993)
Epoch: [76][80/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.9291 (2.3583)	Acc@1 46.094 (56.539)	Acc@5 75.000 (85.831)
Epoch: [76][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3774 (2.3745)	Acc@1 62.500 (56.156)	Acc@5 83.594 (85.637)
Epoch: [76][100/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3098 (2.3857)	Acc@1 57.031 (55.809)	Acc@5 87.500 (85.458)
Epoch: [76][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2067 (2.3819)	Acc@1 59.375 (55.947)	Acc@5 88.281 (85.522)
Epoch: [76][120/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4578 (2.3866)	Acc@1 50.781 (55.779)	Acc@5 82.812 (85.318)
Epoch: [76][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3935 (2.3983)	Acc@1 57.031 (55.499)	Acc@5 83.594 (85.091)
Epoch: [76][140/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4883 (2.4008)	Acc@1 57.031 (55.508)	Acc@5 82.031 (84.984)
Epoch: [76][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2750 (2.4021)	Acc@1 57.031 (55.479)	Acc@5 85.156 (84.923)
Epoch: [76][160/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.5869 (2.4050)	Acc@1 42.188 (55.318)	Acc@5 87.500 (84.933)
Epoch: [76][170/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3225 (2.4083)	Acc@1 59.375 (55.249)	Acc@5 82.812 (84.900)
Epoch: [76][180/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3405 (2.4125)	Acc@1 58.594 (55.145)	Acc@5 86.719 (84.845)
Epoch: [76][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5456 (2.4145)	Acc@1 52.344 (55.150)	Acc@5 82.812 (84.845)
Epoch: [76][200/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4925 (2.4144)	Acc@1 57.812 (55.177)	Acc@5 81.250 (84.849)
Epoch: [76][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3768 (2.4136)	Acc@1 57.031 (55.191)	Acc@5 86.719 (84.838)
Epoch: [76][220/391]	Time 0.012 (0.014)	Data 0.002 (0.002)	Loss 2.9077 (2.4166)	Acc@1 42.188 (55.126)	Acc@5 79.688 (84.736)
Epoch: [76][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4001 (2.4172)	Acc@1 57.031 (55.161)	Acc@5 86.719 (84.696)
Epoch: [76][240/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3077 (2.4185)	Acc@1 52.344 (55.109)	Acc@5 86.719 (84.625)
Epoch: [76][250/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5649 (2.4186)	Acc@1 53.906 (55.123)	Acc@5 85.156 (84.636)
Epoch: [76][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4038 (2.4172)	Acc@1 53.125 (55.119)	Acc@5 85.156 (84.659)
Epoch: [76][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4302 (2.4186)	Acc@1 47.656 (55.042)	Acc@5 85.938 (84.652)
Epoch: [76][280/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3511 (2.4201)	Acc@1 60.156 (55.016)	Acc@5 83.594 (84.659)
Epoch: [76][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3804 (2.4194)	Acc@1 55.469 (55.079)	Acc@5 85.938 (84.660)
Epoch: [76][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4171 (2.4198)	Acc@1 52.344 (55.059)	Acc@5 86.719 (84.640)
Epoch: [76][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4228 (2.4200)	Acc@1 57.031 (55.097)	Acc@5 87.500 (84.641)
Epoch: [76][320/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5006 (2.4185)	Acc@1 51.562 (55.118)	Acc@5 85.156 (84.672)
Epoch: [76][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5244 (2.4195)	Acc@1 55.469 (55.162)	Acc@5 80.469 (84.651)
Epoch: [76][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4824 (2.4240)	Acc@1 53.906 (55.049)	Acc@5 78.125 (84.556)
Epoch: [76][350/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.6248 (2.4281)	Acc@1 49.219 (54.943)	Acc@5 81.250 (84.504)
Epoch: [76][360/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5016 (2.4292)	Acc@1 50.781 (54.897)	Acc@5 85.156 (84.481)
Epoch: [76][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5130 (2.4339)	Acc@1 52.344 (54.829)	Acc@5 80.469 (84.386)
Epoch: [76][380/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5686 (2.4336)	Acc@1 55.469 (54.837)	Acc@5 82.031 (84.361)
Epoch: [76][390/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.4828 (2.4358)	Acc@1 48.750 (54.780)	Acc@5 81.250 (84.304)
num momentum params: 26
[0.1, 2.4358265798187255, 2.1908863615989684, 54.78, 44.3, tensor(0.3291, device='cuda:0', grad_fn=<DivBackward0>), 5.2765960693359375, 0.389188289642334]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [77 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [77][0/391]	Time 0.048 (0.048)	Data 0.157 (0.157)	Loss 2.4911 (2.4911)	Acc@1 49.219 (49.219)	Acc@5 85.938 (85.938)
Epoch: [77][10/391]	Time 0.016 (0.018)	Data 0.001 (0.016)	Loss 2.3807 (2.3941)	Acc@1 57.812 (56.250)	Acc@5 85.156 (85.369)
Epoch: [77][20/391]	Time 0.013 (0.016)	Data 0.001 (0.009)	Loss 2.2289 (2.3538)	Acc@1 57.812 (56.957)	Acc@5 92.188 (86.049)
Epoch: [77][30/391]	Time 0.013 (0.015)	Data 0.002 (0.007)	Loss 2.3121 (2.3588)	Acc@1 57.812 (56.552)	Acc@5 85.156 (85.509)
Epoch: [77][40/391]	Time 0.013 (0.015)	Data 0.002 (0.005)	Loss 2.1287 (2.3525)	Acc@1 60.938 (56.421)	Acc@5 89.844 (85.671)
Epoch: [77][50/391]	Time 0.014 (0.015)	Data 0.002 (0.005)	Loss 2.4156 (2.3488)	Acc@1 54.688 (56.801)	Acc@5 82.812 (85.631)
Epoch: [77][60/391]	Time 0.014 (0.015)	Data 0.002 (0.004)	Loss 2.2815 (2.3554)	Acc@1 58.594 (56.634)	Acc@5 88.281 (85.553)
Epoch: [77][70/391]	Time 0.014 (0.014)	Data 0.002 (0.004)	Loss 2.1339 (2.3710)	Acc@1 60.156 (56.129)	Acc@5 92.188 (85.266)
Epoch: [77][80/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.3564 (2.3874)	Acc@1 53.125 (55.575)	Acc@5 84.375 (84.925)
Epoch: [77][90/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5036 (2.3929)	Acc@1 53.125 (55.391)	Acc@5 86.719 (84.967)
Epoch: [77][100/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.4477 (2.3953)	Acc@1 55.469 (55.616)	Acc@5 84.375 (84.831)
Epoch: [77][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3651 (2.3996)	Acc@1 56.250 (55.441)	Acc@5 84.375 (84.783)
Epoch: [77][120/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2305 (2.3993)	Acc@1 59.375 (55.540)	Acc@5 87.500 (84.911)
Epoch: [77][130/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.2252 (2.3966)	Acc@1 61.719 (55.594)	Acc@5 83.594 (84.936)
Epoch: [77][140/391]	Time 0.012 (0.014)	Data 0.001 (0.003)	Loss 2.2113 (2.3988)	Acc@1 61.719 (55.508)	Acc@5 92.969 (84.951)
Epoch: [77][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3035 (2.3978)	Acc@1 48.438 (55.500)	Acc@5 89.062 (84.934)
Epoch: [77][160/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5394 (2.3979)	Acc@1 52.344 (55.517)	Acc@5 82.812 (84.943)
Epoch: [77][170/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2289 (2.3983)	Acc@1 63.281 (55.578)	Acc@5 88.281 (84.873)
Epoch: [77][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2155 (2.4047)	Acc@1 61.719 (55.499)	Acc@5 85.156 (84.763)
Epoch: [77][190/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2526 (2.4084)	Acc@1 54.688 (55.411)	Acc@5 89.062 (84.702)
Epoch: [77][200/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4768 (2.4133)	Acc@1 57.812 (55.309)	Acc@5 80.469 (84.628)
Epoch: [77][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3585 (2.4144)	Acc@1 55.469 (55.310)	Acc@5 85.938 (84.575)
Epoch: [77][220/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.4313 (2.4156)	Acc@1 57.031 (55.271)	Acc@5 85.938 (84.566)
Epoch: [77][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3957 (2.4146)	Acc@1 50.781 (55.252)	Acc@5 92.188 (84.588)
Epoch: [77][240/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3096 (2.4162)	Acc@1 59.375 (55.154)	Acc@5 85.156 (84.540)
Epoch: [77][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6662 (2.4165)	Acc@1 50.781 (55.176)	Acc@5 78.125 (84.512)
Epoch: [77][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3599 (2.4170)	Acc@1 57.812 (55.160)	Acc@5 86.719 (84.513)
Epoch: [77][270/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2729 (2.4182)	Acc@1 61.719 (55.183)	Acc@5 85.938 (84.496)
Epoch: [77][280/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4030 (2.4200)	Acc@1 60.156 (55.157)	Acc@5 85.156 (84.467)
Epoch: [77][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4253 (2.4197)	Acc@1 53.125 (55.093)	Acc@5 82.812 (84.474)
Epoch: [77][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4763 (2.4209)	Acc@1 52.344 (55.053)	Acc@5 85.156 (84.453)
Epoch: [77][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3735 (2.4228)	Acc@1 60.938 (55.039)	Acc@5 80.469 (84.388)
Epoch: [77][320/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.7527 (2.4255)	Acc@1 49.219 (54.972)	Acc@5 77.344 (84.368)
Epoch: [77][330/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.7770 (2.4275)	Acc@1 44.531 (54.947)	Acc@5 79.688 (84.351)
Epoch: [77][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3240 (2.4274)	Acc@1 57.812 (54.958)	Acc@5 85.938 (84.366)
Epoch: [77][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2893 (2.4256)	Acc@1 65.625 (55.037)	Acc@5 84.375 (84.357)
Epoch: [77][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4341 (2.4270)	Acc@1 50.000 (55.032)	Acc@5 88.281 (84.356)
Epoch: [77][370/391]	Time 0.019 (0.014)	Data 0.001 (0.002)	Loss 2.2759 (2.4264)	Acc@1 58.594 (55.048)	Acc@5 88.281 (84.375)
Epoch: [77][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.0958 (2.4254)	Acc@1 66.406 (55.081)	Acc@5 89.062 (84.375)
Epoch: [77][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.7069 (2.4291)	Acc@1 50.000 (54.970)	Acc@5 75.000 (84.272)
num momentum params: 26
[0.1, 2.429061543960571, 2.1147389030456543, 54.97, 46.23, tensor(0.3301, device='cuda:0', grad_fn=<DivBackward0>), 5.329623460769653, 0.40047502517700195]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [78 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [78][0/391]	Time 0.051 (0.051)	Data 0.167 (0.167)	Loss 2.2293 (2.2293)	Acc@1 60.938 (60.938)	Acc@5 86.719 (86.719)
Epoch: [78][10/391]	Time 0.013 (0.017)	Data 0.001 (0.016)	Loss 2.2446 (2.3918)	Acc@1 60.938 (54.830)	Acc@5 88.281 (84.801)
Epoch: [78][20/391]	Time 0.013 (0.015)	Data 0.001 (0.009)	Loss 2.5344 (2.3813)	Acc@1 52.344 (55.804)	Acc@5 80.469 (85.007)
Epoch: [78][30/391]	Time 0.013 (0.015)	Data 0.001 (0.007)	Loss 2.2557 (2.3734)	Acc@1 53.125 (55.343)	Acc@5 89.062 (85.610)
Epoch: [78][40/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.2493 (2.3576)	Acc@1 61.719 (55.583)	Acc@5 87.500 (85.747)
Epoch: [78][50/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.2420 (2.3444)	Acc@1 59.375 (55.913)	Acc@5 86.719 (86.014)
Epoch: [78][60/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.3427 (2.3438)	Acc@1 58.594 (56.032)	Acc@5 85.938 (85.963)
Epoch: [78][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.6115 (2.3581)	Acc@1 52.344 (55.854)	Acc@5 81.250 (85.728)
Epoch: [78][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4736 (2.3658)	Acc@1 53.125 (55.855)	Acc@5 83.594 (85.561)
Epoch: [78][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3723 (2.3657)	Acc@1 57.812 (56.035)	Acc@5 85.156 (85.663)
Epoch: [78][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6612 (2.3801)	Acc@1 49.219 (55.647)	Acc@5 80.469 (85.473)
Epoch: [78][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3858 (2.3854)	Acc@1 54.688 (55.518)	Acc@5 85.938 (85.374)
Epoch: [78][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2087 (2.3907)	Acc@1 61.719 (55.540)	Acc@5 89.844 (85.247)
Epoch: [78][130/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.4475 (2.3968)	Acc@1 52.344 (55.391)	Acc@5 82.812 (85.174)
Epoch: [78][140/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5075 (2.4009)	Acc@1 50.781 (55.386)	Acc@5 85.938 (85.095)
Epoch: [78][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6159 (2.4027)	Acc@1 51.562 (55.308)	Acc@5 80.469 (85.084)
Epoch: [78][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.8188 (2.4062)	Acc@1 48.438 (55.362)	Acc@5 76.562 (84.986)
Epoch: [78][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4352 (2.4084)	Acc@1 53.125 (55.359)	Acc@5 82.031 (84.900)
Epoch: [78][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6602 (2.4080)	Acc@1 53.125 (55.400)	Acc@5 81.250 (84.910)
Epoch: [78][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3321 (2.4053)	Acc@1 56.250 (55.424)	Acc@5 89.062 (84.976)
Epoch: [78][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6843 (2.4095)	Acc@1 51.562 (55.418)	Acc@5 76.562 (84.841)
Epoch: [78][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4564 (2.4085)	Acc@1 55.469 (55.454)	Acc@5 83.594 (84.834)
Epoch: [78][220/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3690 (2.4064)	Acc@1 57.812 (55.589)	Acc@5 84.375 (84.817)
Epoch: [78][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5228 (2.4077)	Acc@1 57.812 (55.594)	Acc@5 87.500 (84.794)
Epoch: [78][240/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.8413 (2.4108)	Acc@1 49.219 (55.534)	Acc@5 76.562 (84.725)
Epoch: [78][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5227 (2.4092)	Acc@1 53.125 (55.547)	Acc@5 82.031 (84.733)
Epoch: [78][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3881 (2.4098)	Acc@1 54.688 (55.481)	Acc@5 86.719 (84.752)
Epoch: [78][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3343 (2.4108)	Acc@1 55.469 (55.451)	Acc@5 89.062 (84.758)
Epoch: [78][280/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4341 (2.4128)	Acc@1 53.906 (55.452)	Acc@5 81.250 (84.667)
Epoch: [78][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6207 (2.4154)	Acc@1 49.219 (55.372)	Acc@5 81.250 (84.590)
Epoch: [78][300/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.3764 (2.4178)	Acc@1 58.594 (55.310)	Acc@5 83.594 (84.536)
Epoch: [78][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3495 (2.4187)	Acc@1 57.812 (55.253)	Acc@5 86.719 (84.521)
Epoch: [78][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4580 (2.4184)	Acc@1 58.594 (55.308)	Acc@5 82.812 (84.531)
Epoch: [78][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3980 (2.4215)	Acc@1 54.688 (55.259)	Acc@5 82.031 (84.469)
Epoch: [78][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3917 (2.4193)	Acc@1 53.125 (55.299)	Acc@5 86.719 (84.503)
Epoch: [78][350/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4964 (2.4196)	Acc@1 53.906 (55.293)	Acc@5 84.375 (84.513)
Epoch: [78][360/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.3838 (2.4185)	Acc@1 52.344 (55.300)	Acc@5 82.812 (84.518)
Epoch: [78][370/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5402 (2.4193)	Acc@1 54.688 (55.304)	Acc@5 82.812 (84.512)
Epoch: [78][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.0940 (2.4202)	Acc@1 64.062 (55.297)	Acc@5 88.281 (84.496)
Epoch: [78][390/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.3855 (2.4219)	Acc@1 56.250 (55.242)	Acc@5 86.250 (84.418)
num momentum params: 26
[0.1, 2.4219113760375977, 2.308981969356537, 55.242, 43.12, tensor(0.3308, device='cuda:0', grad_fn=<DivBackward0>), 5.250607013702393, 0.3986170291900635]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [79 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [79][0/391]	Time 0.054 (0.054)	Data 0.176 (0.176)	Loss 2.0798 (2.0798)	Acc@1 64.844 (64.844)	Acc@5 89.844 (89.844)
Epoch: [79][10/391]	Time 0.015 (0.018)	Data 0.002 (0.017)	Loss 2.4827 (2.3745)	Acc@1 56.250 (57.031)	Acc@5 87.500 (85.440)
Epoch: [79][20/391]	Time 0.014 (0.016)	Data 0.001 (0.010)	Loss 2.1178 (2.3180)	Acc@1 69.531 (58.445)	Acc@5 89.844 (86.570)
Epoch: [79][30/391]	Time 0.014 (0.015)	Data 0.001 (0.007)	Loss 2.4052 (2.3454)	Acc@1 57.031 (57.409)	Acc@5 87.500 (86.064)
Epoch: [79][40/391]	Time 0.013 (0.015)	Data 0.001 (0.006)	Loss 2.5156 (2.3650)	Acc@1 53.125 (56.612)	Acc@5 82.031 (85.442)
Epoch: [79][50/391]	Time 0.010 (0.014)	Data 0.001 (0.005)	Loss 2.4117 (2.3728)	Acc@1 53.906 (56.066)	Acc@5 85.156 (85.432)
Epoch: [79][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3977 (2.3703)	Acc@1 51.562 (56.084)	Acc@5 85.938 (85.579)
Epoch: [79][70/391]	Time 0.012 (0.014)	Data 0.002 (0.004)	Loss 2.6365 (2.3698)	Acc@1 51.562 (56.151)	Acc@5 78.125 (85.629)
Epoch: [79][80/391]	Time 0.014 (0.014)	Data 0.002 (0.004)	Loss 2.3140 (2.3619)	Acc@1 53.906 (56.144)	Acc@5 86.719 (85.841)
Epoch: [79][90/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.5375 (2.3740)	Acc@1 46.875 (55.812)	Acc@5 84.375 (85.551)
Epoch: [79][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4571 (2.3781)	Acc@1 55.469 (55.809)	Acc@5 85.938 (85.450)
Epoch: [79][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5806 (2.3773)	Acc@1 46.094 (55.793)	Acc@5 87.500 (85.353)
Epoch: [79][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3659 (2.3748)	Acc@1 57.031 (55.863)	Acc@5 85.156 (85.331)
Epoch: [79][130/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.7149 (2.3808)	Acc@1 44.531 (55.773)	Acc@5 77.344 (85.240)
Epoch: [79][140/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2991 (2.3817)	Acc@1 59.375 (55.890)	Acc@5 85.938 (85.223)
Epoch: [79][150/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5613 (2.3844)	Acc@1 48.438 (55.800)	Acc@5 82.812 (85.172)
Epoch: [79][160/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.1234 (2.3828)	Acc@1 64.844 (55.770)	Acc@5 89.062 (85.181)
Epoch: [79][170/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5064 (2.3816)	Acc@1 49.219 (55.793)	Acc@5 85.156 (85.165)
Epoch: [79][180/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.7224 (2.3827)	Acc@1 50.000 (55.853)	Acc@5 76.562 (85.109)
Epoch: [79][190/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4143 (2.3815)	Acc@1 55.469 (55.841)	Acc@5 84.375 (85.111)
Epoch: [79][200/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5282 (2.3859)	Acc@1 49.219 (55.760)	Acc@5 81.250 (84.966)
Epoch: [79][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.0747 (2.3836)	Acc@1 63.281 (55.809)	Acc@5 92.188 (85.004)
Epoch: [79][220/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6439 (2.3902)	Acc@1 52.344 (55.723)	Acc@5 76.562 (84.877)
Epoch: [79][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3799 (2.3941)	Acc@1 52.344 (55.678)	Acc@5 85.938 (84.808)
Epoch: [79][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2390 (2.3986)	Acc@1 60.156 (55.644)	Acc@5 85.156 (84.738)
Epoch: [79][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1865 (2.3997)	Acc@1 60.938 (55.562)	Acc@5 89.844 (84.777)
Epoch: [79][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3354 (2.4030)	Acc@1 60.156 (55.535)	Acc@5 83.594 (84.689)
Epoch: [79][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2776 (2.4050)	Acc@1 60.938 (55.521)	Acc@5 86.719 (84.704)
Epoch: [79][280/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6382 (2.4078)	Acc@1 51.562 (55.455)	Acc@5 78.906 (84.681)
Epoch: [79][290/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2938 (2.4112)	Acc@1 53.125 (55.367)	Acc@5 88.281 (84.635)
Epoch: [79][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1635 (2.4115)	Acc@1 59.375 (55.355)	Acc@5 89.062 (84.627)
Epoch: [79][310/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3196 (2.4098)	Acc@1 64.062 (55.459)	Acc@5 84.375 (84.684)
Epoch: [79][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6174 (2.4123)	Acc@1 46.094 (55.432)	Acc@5 80.469 (84.635)
Epoch: [79][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4485 (2.4115)	Acc@1 50.000 (55.414)	Acc@5 87.500 (84.670)
Epoch: [79][340/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.7098 (2.4147)	Acc@1 53.125 (55.416)	Acc@5 80.469 (84.600)
Epoch: [79][350/391]	Time 0.012 (0.014)	Data 0.002 (0.002)	Loss 2.4556 (2.4159)	Acc@1 57.031 (55.411)	Acc@5 86.719 (84.578)
Epoch: [79][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3417 (2.4191)	Acc@1 57.031 (55.369)	Acc@5 83.594 (84.514)
Epoch: [79][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4530 (2.4183)	Acc@1 57.812 (55.418)	Acc@5 85.156 (84.535)
Epoch: [79][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7901 (2.4202)	Acc@1 44.531 (55.352)	Acc@5 81.250 (84.512)
Epoch: [79][390/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 2.6309 (2.4220)	Acc@1 56.250 (55.314)	Acc@5 77.500 (84.456)
num momentum params: 26
[0.1, 2.422003391418457, 2.080430943965912, 55.314, 45.63, tensor(0.3310, device='cuda:0', grad_fn=<DivBackward0>), 5.305671691894531, 0.4007179737091065]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [80 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [80][0/391]	Time 0.048 (0.048)	Data 0.157 (0.157)	Loss 2.2453 (2.2453)	Acc@1 64.062 (64.062)	Acc@5 83.594 (83.594)
Epoch: [80][10/391]	Time 0.013 (0.018)	Data 0.001 (0.016)	Loss 2.4888 (2.4579)	Acc@1 53.906 (55.043)	Acc@5 84.375 (82.457)
Epoch: [80][20/391]	Time 0.014 (0.016)	Data 0.001 (0.009)	Loss 2.3473 (2.4159)	Acc@1 55.469 (56.101)	Acc@5 87.500 (83.891)
Epoch: [80][30/391]	Time 0.013 (0.015)	Data 0.002 (0.007)	Loss 2.3029 (2.3872)	Acc@1 53.906 (56.804)	Acc@5 87.500 (84.677)
Epoch: [80][40/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.3594 (2.3864)	Acc@1 55.469 (56.764)	Acc@5 87.500 (84.642)
Epoch: [80][50/391]	Time 0.013 (0.015)	Data 0.002 (0.005)	Loss 2.3117 (2.4053)	Acc@1 53.906 (56.250)	Acc@5 85.156 (84.589)
Epoch: [80][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.2780 (2.4049)	Acc@1 57.812 (56.135)	Acc@5 85.156 (84.721)
Epoch: [80][70/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.1206 (2.4016)	Acc@1 64.844 (56.349)	Acc@5 88.281 (84.694)
Epoch: [80][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3240 (2.3984)	Acc@1 59.375 (56.346)	Acc@5 85.938 (84.722)
Epoch: [80][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3256 (2.3871)	Acc@1 58.594 (56.636)	Acc@5 80.469 (84.864)
Epoch: [80][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2869 (2.3856)	Acc@1 60.156 (56.644)	Acc@5 85.938 (84.909)
Epoch: [80][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5109 (2.3828)	Acc@1 53.906 (56.736)	Acc@5 80.469 (84.917)
Epoch: [80][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5725 (2.3863)	Acc@1 57.031 (56.696)	Acc@5 80.469 (84.833)
Epoch: [80][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3733 (2.3944)	Acc@1 50.781 (56.393)	Acc@5 86.719 (84.709)
Epoch: [80][140/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.1741 (2.3933)	Acc@1 62.500 (56.322)	Acc@5 87.500 (84.696)
Epoch: [80][150/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3920 (2.3892)	Acc@1 56.250 (56.462)	Acc@5 82.812 (84.846)
Epoch: [80][160/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3465 (2.3954)	Acc@1 53.906 (56.371)	Acc@5 84.375 (84.758)
Epoch: [80][170/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4021 (2.3958)	Acc@1 59.375 (56.328)	Acc@5 84.375 (84.686)
Epoch: [80][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4598 (2.3947)	Acc@1 50.781 (56.285)	Acc@5 85.938 (84.755)
Epoch: [80][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3944 (2.3907)	Acc@1 58.594 (56.381)	Acc@5 82.812 (84.854)
Epoch: [80][200/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3980 (2.3887)	Acc@1 55.469 (56.390)	Acc@5 91.406 (84.884)
Epoch: [80][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6031 (2.3960)	Acc@1 45.312 (56.139)	Acc@5 85.156 (84.797)
Epoch: [80][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6333 (2.4048)	Acc@1 49.219 (55.900)	Acc@5 78.125 (84.619)
Epoch: [80][230/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.6140 (2.4079)	Acc@1 51.562 (55.814)	Acc@5 83.594 (84.547)
Epoch: [80][240/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.7098 (2.4148)	Acc@1 48.438 (55.563)	Acc@5 76.562 (84.463)
Epoch: [80][250/391]	Time 0.014 (0.014)	Data 0.000 (0.002)	Loss 2.3892 (2.4161)	Acc@1 53.125 (55.491)	Acc@5 85.938 (84.512)
Epoch: [80][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7005 (2.4187)	Acc@1 46.094 (55.433)	Acc@5 80.469 (84.492)
Epoch: [80][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3339 (2.4187)	Acc@1 55.469 (55.446)	Acc@5 88.281 (84.482)
Epoch: [80][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3143 (2.4187)	Acc@1 63.281 (55.402)	Acc@5 85.938 (84.478)
Epoch: [80][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5601 (2.4216)	Acc@1 55.469 (55.316)	Acc@5 82.031 (84.442)
Epoch: [80][300/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5539 (2.4264)	Acc@1 53.906 (55.186)	Acc@5 79.688 (84.367)
Epoch: [80][310/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3690 (2.4298)	Acc@1 53.125 (55.105)	Acc@5 89.062 (84.388)
Epoch: [80][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2961 (2.4293)	Acc@1 55.469 (55.113)	Acc@5 85.156 (84.397)
Epoch: [80][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4837 (2.4298)	Acc@1 50.781 (55.086)	Acc@5 85.938 (84.392)
Epoch: [80][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4442 (2.4274)	Acc@1 58.594 (55.157)	Acc@5 82.812 (84.412)
Epoch: [80][350/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3504 (2.4261)	Acc@1 60.156 (55.170)	Acc@5 87.500 (84.453)
Epoch: [80][360/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3834 (2.4266)	Acc@1 55.469 (55.110)	Acc@5 85.156 (84.459)
Epoch: [80][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4657 (2.4278)	Acc@1 51.562 (55.102)	Acc@5 80.469 (84.411)
Epoch: [80][380/391]	Time 0.012 (0.014)	Data 0.002 (0.002)	Loss 2.2156 (2.4277)	Acc@1 62.500 (55.126)	Acc@5 88.281 (84.412)
Epoch: [80][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.3408 (2.4283)	Acc@1 53.750 (55.090)	Acc@5 90.000 (84.414)
num momentum params: 26
[0.1, 2.428266747207642, 2.0520272421836854, 55.09, 46.99, tensor(0.3304, device='cuda:0', grad_fn=<DivBackward0>), 5.295313119888306, 0.3990089893341065]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [81 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [81][0/391]	Time 0.049 (0.049)	Data 0.162 (0.162)	Loss 2.1660 (2.1660)	Acc@1 60.938 (60.938)	Acc@5 87.500 (87.500)
Epoch: [81][10/391]	Time 0.013 (0.017)	Data 0.001 (0.016)	Loss 2.3639 (2.3815)	Acc@1 48.438 (53.835)	Acc@5 86.719 (85.014)
Epoch: [81][20/391]	Time 0.014 (0.016)	Data 0.002 (0.009)	Loss 2.3452 (2.3563)	Acc@1 54.688 (55.134)	Acc@5 85.938 (85.640)
Epoch: [81][30/391]	Time 0.014 (0.015)	Data 0.002 (0.007)	Loss 2.1243 (2.3553)	Acc@1 63.281 (55.595)	Acc@5 87.500 (85.761)
Epoch: [81][40/391]	Time 0.014 (0.015)	Data 0.002 (0.005)	Loss 2.1287 (2.3287)	Acc@1 65.625 (56.669)	Acc@5 83.594 (85.938)
Epoch: [81][50/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.6019 (2.3333)	Acc@1 50.781 (56.541)	Acc@5 79.688 (86.029)
Epoch: [81][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.0866 (2.3346)	Acc@1 63.281 (56.890)	Acc@5 90.625 (86.104)
Epoch: [81][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3029 (2.3384)	Acc@1 57.031 (56.844)	Acc@5 84.375 (85.949)
Epoch: [81][80/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.1596 (2.3396)	Acc@1 64.062 (57.051)	Acc@5 89.844 (85.841)
Epoch: [81][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2947 (2.3408)	Acc@1 59.375 (57.066)	Acc@5 85.938 (85.680)
Epoch: [81][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.6295 (2.3506)	Acc@1 51.562 (56.846)	Acc@5 80.469 (85.566)
Epoch: [81][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5834 (2.3550)	Acc@1 55.469 (56.637)	Acc@5 82.031 (85.466)
Epoch: [81][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6633 (2.3603)	Acc@1 46.875 (56.386)	Acc@5 80.469 (85.395)
Epoch: [81][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6633 (2.3643)	Acc@1 48.438 (56.262)	Acc@5 77.344 (85.347)
Epoch: [81][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3196 (2.3643)	Acc@1 59.375 (56.311)	Acc@5 85.938 (85.383)
Epoch: [81][150/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3988 (2.3669)	Acc@1 54.688 (56.198)	Acc@5 82.031 (85.343)
Epoch: [81][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3457 (2.3739)	Acc@1 53.125 (56.051)	Acc@5 85.938 (85.190)
Epoch: [81][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3172 (2.3762)	Acc@1 54.688 (56.026)	Acc@5 86.719 (85.143)
Epoch: [81][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2886 (2.3787)	Acc@1 53.125 (55.926)	Acc@5 83.594 (85.100)
Epoch: [81][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2466 (2.3841)	Acc@1 60.156 (55.788)	Acc@5 87.500 (85.066)
Epoch: [81][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3543 (2.3835)	Acc@1 55.469 (55.830)	Acc@5 86.719 (85.113)
Epoch: [81][210/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5538 (2.3840)	Acc@1 53.906 (55.832)	Acc@5 83.594 (85.134)
Epoch: [81][220/391]	Time 0.013 (0.014)	Data 0.003 (0.002)	Loss 2.3105 (2.3861)	Acc@1 57.031 (55.819)	Acc@5 85.938 (85.054)
Epoch: [81][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1023 (2.3919)	Acc@1 59.375 (55.692)	Acc@5 91.406 (84.953)
Epoch: [81][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4655 (2.3949)	Acc@1 47.656 (55.566)	Acc@5 85.156 (84.926)
Epoch: [81][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5998 (2.4005)	Acc@1 52.344 (55.453)	Acc@5 78.125 (84.845)
Epoch: [81][260/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5786 (2.4063)	Acc@1 51.562 (55.364)	Acc@5 81.250 (84.713)
Epoch: [81][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4806 (2.4056)	Acc@1 57.031 (55.428)	Acc@5 81.250 (84.712)
Epoch: [81][280/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2696 (2.4073)	Acc@1 58.594 (55.383)	Acc@5 86.719 (84.672)
Epoch: [81][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2558 (2.4079)	Acc@1 57.812 (55.388)	Acc@5 85.156 (84.619)
Epoch: [81][300/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5094 (2.4098)	Acc@1 50.781 (55.386)	Acc@5 79.688 (84.557)
Epoch: [81][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.0924 (2.4107)	Acc@1 64.062 (55.403)	Acc@5 89.062 (84.538)
Epoch: [81][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5267 (2.4125)	Acc@1 52.344 (55.393)	Acc@5 79.688 (84.487)
Epoch: [81][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5138 (2.4114)	Acc@1 48.438 (55.422)	Acc@5 84.375 (84.495)
Epoch: [81][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4291 (2.4119)	Acc@1 55.469 (55.402)	Acc@5 83.594 (84.490)
Epoch: [81][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5740 (2.4136)	Acc@1 47.656 (55.340)	Acc@5 82.031 (84.440)
Epoch: [81][360/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.7315 (2.4174)	Acc@1 53.906 (55.272)	Acc@5 78.125 (84.390)
Epoch: [81][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.1304 (2.4164)	Acc@1 62.500 (55.288)	Acc@5 85.938 (84.377)
Epoch: [81][380/391]	Time 0.012 (0.013)	Data 0.003 (0.002)	Loss 2.3998 (2.4187)	Acc@1 53.906 (55.233)	Acc@5 83.594 (84.316)
Epoch: [81][390/391]	Time 0.017 (0.013)	Data 0.001 (0.002)	Loss 2.3985 (2.4192)	Acc@1 58.750 (55.240)	Acc@5 80.000 (84.272)
num momentum params: 26
[0.1, 2.419217278594971, 2.0602511310577394, 55.24, 47.12, tensor(0.3311, device='cuda:0', grad_fn=<DivBackward0>), 5.270803213119507, 0.39524006843566895]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [82 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [82][0/391]	Time 0.049 (0.049)	Data 0.161 (0.161)	Loss 2.3579 (2.3579)	Acc@1 57.812 (57.812)	Acc@5 83.594 (83.594)
Epoch: [82][10/391]	Time 0.013 (0.018)	Data 0.001 (0.016)	Loss 2.2457 (2.2975)	Acc@1 60.938 (58.381)	Acc@5 88.281 (87.003)
Epoch: [82][20/391]	Time 0.014 (0.016)	Data 0.001 (0.009)	Loss 2.1046 (2.2382)	Acc@1 60.938 (59.449)	Acc@5 89.844 (87.686)
Epoch: [82][30/391]	Time 0.013 (0.015)	Data 0.001 (0.007)	Loss 2.4322 (2.2734)	Acc@1 51.562 (58.191)	Acc@5 87.500 (87.046)
Epoch: [82][40/391]	Time 0.013 (0.015)	Data 0.002 (0.005)	Loss 2.4204 (2.2988)	Acc@1 51.562 (57.641)	Acc@5 83.594 (86.528)
Epoch: [82][50/391]	Time 0.013 (0.014)	Data 0.002 (0.005)	Loss 2.5459 (2.3277)	Acc@1 54.688 (57.108)	Acc@5 81.250 (85.830)
Epoch: [82][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.5511 (2.3397)	Acc@1 52.344 (56.814)	Acc@5 85.938 (85.707)
Epoch: [82][70/391]	Time 0.014 (0.014)	Data 0.002 (0.004)	Loss 2.3129 (2.3494)	Acc@1 57.031 (56.547)	Acc@5 87.500 (85.717)
Epoch: [82][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4550 (2.3562)	Acc@1 53.906 (56.375)	Acc@5 85.938 (85.590)
Epoch: [82][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3893 (2.3585)	Acc@1 57.031 (56.181)	Acc@5 83.594 (85.586)
Epoch: [82][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6290 (2.3629)	Acc@1 50.781 (56.188)	Acc@5 82.812 (85.473)
Epoch: [82][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.1613 (2.3639)	Acc@1 62.500 (56.243)	Acc@5 90.625 (85.543)
Epoch: [82][120/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 1.9835 (2.3628)	Acc@1 67.188 (56.198)	Acc@5 90.625 (85.518)
Epoch: [82][130/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.6609 (2.3686)	Acc@1 53.906 (56.178)	Acc@5 78.906 (85.377)
Epoch: [82][140/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.4622 (2.3670)	Acc@1 53.125 (56.211)	Acc@5 82.812 (85.356)
Epoch: [82][150/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3402 (2.3696)	Acc@1 51.562 (56.229)	Acc@5 89.062 (85.280)
Epoch: [82][160/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3933 (2.3775)	Acc@1 53.906 (55.993)	Acc@5 82.812 (85.142)
Epoch: [82][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3829 (2.3764)	Acc@1 56.250 (56.008)	Acc@5 85.938 (85.229)
Epoch: [82][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4179 (2.3824)	Acc@1 52.344 (55.879)	Acc@5 83.594 (85.104)
Epoch: [82][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5092 (2.3864)	Acc@1 53.125 (55.837)	Acc@5 83.594 (85.046)
Epoch: [82][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3239 (2.3854)	Acc@1 60.156 (55.822)	Acc@5 88.281 (85.059)
Epoch: [82][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3526 (2.3870)	Acc@1 64.062 (55.858)	Acc@5 82.812 (85.030)
Epoch: [82][220/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2942 (2.3879)	Acc@1 53.906 (55.812)	Acc@5 89.062 (85.011)
Epoch: [82][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2531 (2.3904)	Acc@1 57.031 (55.705)	Acc@5 87.500 (84.960)
Epoch: [82][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4897 (2.3922)	Acc@1 51.562 (55.676)	Acc@5 85.156 (84.962)
Epoch: [82][250/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5211 (2.3934)	Acc@1 55.469 (55.724)	Acc@5 81.250 (84.907)
Epoch: [82][260/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3297 (2.3936)	Acc@1 56.250 (55.744)	Acc@5 83.594 (84.926)
Epoch: [82][270/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3021 (2.3940)	Acc@1 60.938 (55.717)	Acc@5 85.156 (84.905)
Epoch: [82][280/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4407 (2.3949)	Acc@1 50.781 (55.694)	Acc@5 83.594 (84.898)
Epoch: [82][290/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3558 (2.3979)	Acc@1 53.125 (55.614)	Acc@5 86.719 (84.823)
Epoch: [82][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5651 (2.3990)	Acc@1 51.562 (55.612)	Acc@5 81.250 (84.806)
Epoch: [82][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4402 (2.4013)	Acc@1 54.688 (55.622)	Acc@5 85.156 (84.772)
Epoch: [82][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2683 (2.4000)	Acc@1 61.719 (55.676)	Acc@5 85.938 (84.791)
Epoch: [82][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5305 (2.4033)	Acc@1 58.594 (55.540)	Acc@5 82.812 (84.764)
Epoch: [82][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5628 (2.4080)	Acc@1 50.781 (55.423)	Acc@5 80.469 (84.700)
Epoch: [82][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4958 (2.4104)	Acc@1 53.125 (55.389)	Acc@5 79.688 (84.653)
Epoch: [82][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5071 (2.4136)	Acc@1 53.906 (55.319)	Acc@5 77.344 (84.598)
Epoch: [82][370/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.2883 (2.4145)	Acc@1 62.500 (55.288)	Acc@5 86.719 (84.581)
Epoch: [82][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6905 (2.4170)	Acc@1 50.000 (55.231)	Acc@5 83.594 (84.527)
Epoch: [82][390/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.2815 (2.4179)	Acc@1 62.500 (55.222)	Acc@5 86.250 (84.514)
num momentum params: 26
[0.1, 2.417875305480957, 2.022198315858841, 55.222, 47.58, tensor(0.3314, device='cuda:0', grad_fn=<DivBackward0>), 5.268120050430298, 0.39591479301452637]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [83 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [83][0/391]	Time 0.046 (0.046)	Data 0.156 (0.156)	Loss 2.5695 (2.5695)	Acc@1 53.906 (53.906)	Acc@5 82.031 (82.031)
Epoch: [83][10/391]	Time 0.014 (0.018)	Data 0.001 (0.015)	Loss 2.4688 (2.3295)	Acc@1 57.812 (58.665)	Acc@5 86.719 (86.719)
Epoch: [83][20/391]	Time 0.014 (0.016)	Data 0.002 (0.009)	Loss 2.4732 (2.3233)	Acc@1 56.250 (58.445)	Acc@5 82.031 (86.421)
Epoch: [83][30/391]	Time 0.013 (0.015)	Data 0.001 (0.006)	Loss 2.5203 (2.3174)	Acc@1 53.125 (58.140)	Acc@5 83.594 (86.265)
Epoch: [83][40/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.4338 (2.3292)	Acc@1 53.906 (58.003)	Acc@5 82.812 (85.861)
Epoch: [83][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3653 (2.3201)	Acc@1 57.812 (57.797)	Acc@5 85.156 (86.029)
Epoch: [83][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3612 (2.3344)	Acc@1 57.031 (57.556)	Acc@5 87.500 (85.886)
Epoch: [83][70/391]	Time 0.012 (0.014)	Data 0.002 (0.004)	Loss 2.4096 (2.3454)	Acc@1 57.812 (57.152)	Acc@5 84.375 (85.827)
Epoch: [83][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5160 (2.3591)	Acc@1 54.688 (56.674)	Acc@5 79.688 (85.455)
Epoch: [83][90/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.4962 (2.3671)	Acc@1 54.688 (56.508)	Acc@5 84.375 (85.302)
Epoch: [83][100/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4106 (2.3759)	Acc@1 55.469 (56.180)	Acc@5 82.031 (85.187)
Epoch: [83][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4613 (2.3814)	Acc@1 53.125 (56.285)	Acc@5 87.500 (85.100)
Epoch: [83][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4456 (2.3840)	Acc@1 54.688 (56.185)	Acc@5 83.594 (85.046)
Epoch: [83][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2241 (2.3892)	Acc@1 57.812 (56.065)	Acc@5 87.500 (84.894)
Epoch: [83][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2955 (2.3913)	Acc@1 57.812 (56.012)	Acc@5 85.938 (84.840)
Epoch: [83][150/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4402 (2.3860)	Acc@1 53.906 (56.069)	Acc@5 85.938 (84.975)
Epoch: [83][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4085 (2.3893)	Acc@1 54.688 (55.920)	Acc@5 82.812 (84.914)
Epoch: [83][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5044 (2.3937)	Acc@1 46.875 (55.821)	Acc@5 82.031 (84.782)
Epoch: [83][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3982 (2.3927)	Acc@1 56.250 (55.870)	Acc@5 87.500 (84.858)
Epoch: [83][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2809 (2.3947)	Acc@1 62.500 (55.935)	Acc@5 83.594 (84.833)
Epoch: [83][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4151 (2.3909)	Acc@1 53.125 (55.982)	Acc@5 85.156 (84.962)
Epoch: [83][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4218 (2.3954)	Acc@1 59.375 (55.902)	Acc@5 83.594 (84.827)
Epoch: [83][220/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3756 (2.3964)	Acc@1 53.906 (55.829)	Acc@5 85.156 (84.764)
Epoch: [83][230/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.2169 (2.4000)	Acc@1 57.031 (55.699)	Acc@5 90.625 (84.723)
Epoch: [83][240/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4518 (2.4023)	Acc@1 54.688 (55.666)	Acc@5 84.375 (84.689)
Epoch: [83][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6221 (2.4051)	Acc@1 51.562 (55.631)	Acc@5 83.594 (84.655)
Epoch: [83][260/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.2805 (2.4034)	Acc@1 55.469 (55.696)	Acc@5 89.844 (84.671)
Epoch: [83][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4193 (2.4031)	Acc@1 54.688 (55.671)	Acc@5 84.375 (84.701)
Epoch: [83][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4457 (2.4040)	Acc@1 56.250 (55.616)	Acc@5 85.156 (84.723)
Epoch: [83][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2533 (2.4047)	Acc@1 61.719 (55.659)	Acc@5 85.938 (84.703)
Epoch: [83][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6067 (2.4066)	Acc@1 52.344 (55.624)	Acc@5 81.250 (84.673)
Epoch: [83][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2954 (2.4066)	Acc@1 59.375 (55.640)	Acc@5 86.719 (84.661)
Epoch: [83][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6290 (2.4099)	Acc@1 42.188 (55.542)	Acc@5 84.375 (84.587)
Epoch: [83][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3834 (2.4092)	Acc@1 53.125 (55.563)	Acc@5 85.156 (84.576)
Epoch: [83][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3527 (2.4106)	Acc@1 58.594 (55.567)	Acc@5 85.938 (84.556)
Epoch: [83][350/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.8311 (2.4135)	Acc@1 50.781 (55.469)	Acc@5 75.000 (84.500)
Epoch: [83][360/391]	Time 0.014 (0.013)	Data 0.002 (0.002)	Loss 2.3507 (2.4128)	Acc@1 56.250 (55.480)	Acc@5 84.375 (84.535)
Epoch: [83][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3088 (2.4120)	Acc@1 57.031 (55.496)	Acc@5 85.156 (84.541)
Epoch: [83][380/391]	Time 0.012 (0.013)	Data 0.001 (0.002)	Loss 2.6877 (2.4157)	Acc@1 47.656 (55.417)	Acc@5 78.125 (84.473)
Epoch: [83][390/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.8322 (2.4181)	Acc@1 43.750 (55.360)	Acc@5 81.250 (84.442)
num momentum params: 26
[0.1, 2.4180836711120604, 2.0743083500862123, 55.36, 46.46, tensor(0.3315, device='cuda:0', grad_fn=<DivBackward0>), 5.234687566757202, 0.3906328678131104]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [84 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [84][0/391]	Time 0.047 (0.047)	Data 0.158 (0.158)	Loss 2.2661 (2.2661)	Acc@1 55.469 (55.469)	Acc@5 88.281 (88.281)
Epoch: [84][10/391]	Time 0.014 (0.018)	Data 0.001 (0.016)	Loss 2.3047 (2.3431)	Acc@1 60.938 (56.321)	Acc@5 88.281 (86.009)
Epoch: [84][20/391]	Time 0.013 (0.016)	Data 0.001 (0.009)	Loss 2.3516 (2.3336)	Acc@1 53.125 (56.436)	Acc@5 86.719 (85.826)
Epoch: [84][30/391]	Time 0.013 (0.015)	Data 0.001 (0.007)	Loss 2.0106 (2.3125)	Acc@1 66.406 (57.132)	Acc@5 89.062 (86.089)
Epoch: [84][40/391]	Time 0.013 (0.015)	Data 0.002 (0.005)	Loss 2.1567 (2.2984)	Acc@1 58.594 (57.755)	Acc@5 85.938 (86.204)
Epoch: [84][50/391]	Time 0.014 (0.015)	Data 0.002 (0.005)	Loss 2.5807 (2.2929)	Acc@1 54.688 (57.812)	Acc@5 83.594 (86.351)
Epoch: [84][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4484 (2.3130)	Acc@1 54.688 (57.185)	Acc@5 83.594 (86.155)
Epoch: [84][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.1300 (2.3117)	Acc@1 64.062 (57.427)	Acc@5 86.719 (86.147)
Epoch: [84][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5025 (2.3212)	Acc@1 55.469 (57.340)	Acc@5 81.250 (85.976)
Epoch: [84][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4469 (2.3280)	Acc@1 53.906 (57.143)	Acc@5 83.594 (85.826)
Epoch: [84][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4835 (2.3454)	Acc@1 51.562 (56.846)	Acc@5 78.906 (85.458)
Epoch: [84][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4210 (2.3472)	Acc@1 49.219 (56.736)	Acc@5 90.625 (85.494)
Epoch: [84][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4318 (2.3528)	Acc@1 54.688 (56.553)	Acc@5 80.469 (85.498)
Epoch: [84][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6351 (2.3525)	Acc@1 53.125 (56.644)	Acc@5 78.125 (85.574)
Epoch: [84][140/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.4471 (2.3597)	Acc@1 57.031 (56.527)	Acc@5 83.594 (85.439)
Epoch: [84][150/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4475 (2.3662)	Acc@1 53.906 (56.369)	Acc@5 81.250 (85.332)
Epoch: [84][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3903 (2.3711)	Acc@1 56.250 (56.332)	Acc@5 85.938 (85.312)
Epoch: [84][170/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4110 (2.3751)	Acc@1 53.125 (56.191)	Acc@5 81.250 (85.261)
Epoch: [84][180/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.5436 (2.3770)	Acc@1 58.594 (56.259)	Acc@5 79.688 (85.234)
Epoch: [84][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5633 (2.3812)	Acc@1 44.531 (56.213)	Acc@5 82.812 (85.115)
Epoch: [84][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5480 (2.3846)	Acc@1 50.000 (56.044)	Acc@5 82.031 (85.113)
Epoch: [84][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5637 (2.3936)	Acc@1 47.656 (55.891)	Acc@5 82.031 (84.953)
Epoch: [84][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4611 (2.3968)	Acc@1 57.812 (55.773)	Acc@5 83.594 (84.866)
Epoch: [84][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4770 (2.3985)	Acc@1 50.781 (55.756)	Acc@5 87.500 (84.828)
Epoch: [84][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3108 (2.3990)	Acc@1 52.344 (55.722)	Acc@5 87.500 (84.819)
Epoch: [84][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3285 (2.4040)	Acc@1 59.375 (55.634)	Acc@5 85.156 (84.720)
Epoch: [84][260/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4334 (2.4040)	Acc@1 60.156 (55.672)	Acc@5 82.031 (84.662)
Epoch: [84][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5562 (2.4038)	Acc@1 52.344 (55.673)	Acc@5 81.250 (84.681)
Epoch: [84][280/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.4445 (2.4042)	Acc@1 57.812 (55.649)	Acc@5 85.938 (84.678)
Epoch: [84][290/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2397 (2.4064)	Acc@1 57.031 (55.635)	Acc@5 88.281 (84.630)
Epoch: [84][300/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3244 (2.4103)	Acc@1 56.250 (55.547)	Acc@5 87.500 (84.596)
Epoch: [84][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5887 (2.4152)	Acc@1 55.469 (55.456)	Acc@5 79.688 (84.511)
Epoch: [84][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4275 (2.4192)	Acc@1 54.688 (55.362)	Acc@5 82.031 (84.438)
Epoch: [84][330/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4921 (2.4201)	Acc@1 54.688 (55.353)	Acc@5 82.031 (84.420)
Epoch: [84][340/391]	Time 0.012 (0.014)	Data 0.002 (0.002)	Loss 2.4645 (2.4213)	Acc@1 58.594 (55.359)	Acc@5 85.938 (84.391)
Epoch: [84][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3515 (2.4215)	Acc@1 58.594 (55.384)	Acc@5 83.594 (84.357)
Epoch: [84][360/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3609 (2.4216)	Acc@1 53.125 (55.339)	Acc@5 85.938 (84.360)
Epoch: [84][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2881 (2.4209)	Acc@1 54.688 (55.363)	Acc@5 83.594 (84.369)
Epoch: [84][380/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3125 (2.4223)	Acc@1 59.375 (55.325)	Acc@5 86.719 (84.359)
Epoch: [84][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.2168 (2.4237)	Acc@1 60.000 (55.322)	Acc@5 86.250 (84.308)
num momentum params: 26
[0.1, 2.4236887550354003, 2.013071482181549, 55.322, 47.27, tensor(0.3302, device='cuda:0', grad_fn=<DivBackward0>), 5.284506320953369, 0.4026644229888916]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [85 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [85][0/391]	Time 0.052 (0.052)	Data 0.169 (0.169)	Loss 2.4849 (2.4849)	Acc@1 52.344 (52.344)	Acc@5 83.594 (83.594)
Epoch: [85][10/391]	Time 0.014 (0.018)	Data 0.002 (0.016)	Loss 2.4818 (2.3334)	Acc@1 46.875 (57.031)	Acc@5 85.156 (86.222)
Epoch: [85][20/391]	Time 0.013 (0.016)	Data 0.001 (0.009)	Loss 2.3539 (2.3198)	Acc@1 54.688 (57.924)	Acc@5 86.719 (86.310)
Epoch: [85][30/391]	Time 0.014 (0.015)	Data 0.001 (0.007)	Loss 2.2507 (2.3063)	Acc@1 56.250 (58.216)	Acc@5 88.281 (86.366)
Epoch: [85][40/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.3566 (2.3230)	Acc@1 57.031 (58.041)	Acc@5 85.938 (85.766)
Epoch: [85][50/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.2301 (2.3300)	Acc@1 53.906 (57.659)	Acc@5 85.156 (85.953)
Epoch: [85][60/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.3006 (2.3441)	Acc@1 56.250 (57.185)	Acc@5 86.719 (85.605)
Epoch: [85][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4955 (2.3471)	Acc@1 53.906 (57.020)	Acc@5 79.688 (85.343)
Epoch: [85][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3272 (2.3563)	Acc@1 54.688 (56.636)	Acc@5 82.812 (85.108)
Epoch: [85][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5517 (2.3555)	Acc@1 53.125 (56.688)	Acc@5 79.688 (85.113)
Epoch: [85][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3637 (2.3623)	Acc@1 57.812 (56.513)	Acc@5 81.250 (84.994)
Epoch: [85][110/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.3961 (2.3636)	Acc@1 53.125 (56.349)	Acc@5 85.938 (85.086)
Epoch: [85][120/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2742 (2.3615)	Acc@1 58.594 (56.379)	Acc@5 89.844 (85.143)
Epoch: [85][130/391]	Time 0.016 (0.014)	Data 0.001 (0.003)	Loss 2.3386 (2.3609)	Acc@1 57.812 (56.441)	Acc@5 82.812 (85.120)
Epoch: [85][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4365 (2.3659)	Acc@1 50.781 (56.328)	Acc@5 81.250 (84.984)
Epoch: [85][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4199 (2.3675)	Acc@1 53.125 (56.302)	Acc@5 83.594 (84.929)
Epoch: [85][160/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3993 (2.3737)	Acc@1 57.031 (56.187)	Acc@5 84.375 (84.841)
Epoch: [85][170/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 2.6371 (2.3824)	Acc@1 50.781 (56.044)	Acc@5 79.688 (84.727)
Epoch: [85][180/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5399 (2.3843)	Acc@1 52.344 (56.013)	Acc@5 85.156 (84.729)
Epoch: [85][190/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5374 (2.3876)	Acc@1 51.562 (55.992)	Acc@5 85.938 (84.743)
Epoch: [85][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3111 (2.3937)	Acc@1 61.719 (55.958)	Acc@5 86.719 (84.616)
Epoch: [85][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4639 (2.3981)	Acc@1 50.781 (55.820)	Acc@5 85.156 (84.560)
Epoch: [85][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5278 (2.4005)	Acc@1 54.688 (55.766)	Acc@5 85.156 (84.523)
Epoch: [85][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5979 (2.4051)	Acc@1 50.000 (55.655)	Acc@5 82.812 (84.480)
Epoch: [85][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6189 (2.4049)	Acc@1 53.906 (55.692)	Acc@5 81.250 (84.492)
Epoch: [85][250/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.8587 (2.4058)	Acc@1 47.656 (55.643)	Acc@5 78.125 (84.500)
Epoch: [85][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5906 (2.4076)	Acc@1 53.125 (55.612)	Acc@5 83.594 (84.504)
Epoch: [85][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7046 (2.4081)	Acc@1 52.344 (55.642)	Acc@5 78.906 (84.487)
Epoch: [85][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4556 (2.4123)	Acc@1 57.031 (55.488)	Acc@5 86.719 (84.472)
Epoch: [85][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2951 (2.4136)	Acc@1 61.719 (55.466)	Acc@5 88.281 (84.450)
Epoch: [85][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4985 (2.4153)	Acc@1 55.469 (55.427)	Acc@5 84.375 (84.411)
Epoch: [85][310/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2085 (2.4158)	Acc@1 60.156 (55.424)	Acc@5 89.844 (84.398)
Epoch: [85][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4879 (2.4207)	Acc@1 60.938 (55.371)	Acc@5 81.250 (84.295)
Epoch: [85][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5799 (2.4251)	Acc@1 51.562 (55.247)	Acc@5 81.250 (84.238)
Epoch: [85][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4532 (2.4270)	Acc@1 50.781 (55.217)	Acc@5 83.594 (84.221)
Epoch: [85][350/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3759 (2.4262)	Acc@1 59.375 (55.268)	Acc@5 85.938 (84.248)
Epoch: [85][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6923 (2.4258)	Acc@1 51.562 (55.298)	Acc@5 79.688 (84.271)
Epoch: [85][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5718 (2.4292)	Acc@1 48.438 (55.229)	Acc@5 83.594 (84.225)
Epoch: [85][380/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4108 (2.4303)	Acc@1 54.688 (55.204)	Acc@5 83.594 (84.176)
Epoch: [85][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.3180 (2.4317)	Acc@1 56.250 (55.152)	Acc@5 86.250 (84.136)
num momentum params: 26
[0.1, 2.431678642578125, 1.9776786649227143, 55.152, 48.71, tensor(0.3302, device='cuda:0', grad_fn=<DivBackward0>), 5.291780233383179, 0.3902881145477295]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [86 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [86][0/391]	Time 0.045 (0.045)	Data 0.156 (0.156)	Loss 2.4599 (2.4599)	Acc@1 55.469 (55.469)	Acc@5 82.812 (82.812)
Epoch: [86][10/391]	Time 0.013 (0.018)	Data 0.001 (0.016)	Loss 2.1061 (2.3690)	Acc@1 60.938 (56.392)	Acc@5 92.188 (84.801)
Epoch: [86][20/391]	Time 0.013 (0.016)	Data 0.001 (0.009)	Loss 2.1962 (2.3446)	Acc@1 59.375 (56.920)	Acc@5 85.156 (85.528)
Epoch: [86][30/391]	Time 0.015 (0.015)	Data 0.001 (0.006)	Loss 2.2139 (2.2939)	Acc@1 60.156 (57.863)	Acc@5 90.625 (86.542)
Epoch: [86][40/391]	Time 0.015 (0.015)	Data 0.002 (0.005)	Loss 2.4888 (2.3051)	Acc@1 58.594 (57.489)	Acc@5 84.375 (86.319)
Epoch: [86][50/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.2389 (2.3089)	Acc@1 58.594 (57.138)	Acc@5 87.500 (86.244)
Epoch: [86][60/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.3145 (2.3208)	Acc@1 50.000 (56.865)	Acc@5 88.281 (86.117)
Epoch: [86][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3902 (2.3263)	Acc@1 58.594 (57.031)	Acc@5 82.812 (85.938)
Epoch: [86][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3065 (2.3393)	Acc@1 55.469 (56.713)	Acc@5 85.938 (85.899)
Epoch: [86][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.1961 (2.3357)	Acc@1 60.938 (56.731)	Acc@5 86.719 (85.920)
Epoch: [86][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4369 (2.3536)	Acc@1 57.031 (56.443)	Acc@5 84.375 (85.543)
Epoch: [86][110/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.6595 (2.3643)	Acc@1 53.906 (56.180)	Acc@5 77.344 (85.396)
Epoch: [86][120/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.5342 (2.3715)	Acc@1 60.156 (56.127)	Acc@5 78.125 (85.298)
Epoch: [86][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2419 (2.3810)	Acc@1 56.250 (55.809)	Acc@5 89.844 (85.168)
Epoch: [86][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2916 (2.3801)	Acc@1 56.250 (55.890)	Acc@5 88.281 (85.206)
Epoch: [86][150/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1039 (2.3789)	Acc@1 60.938 (56.038)	Acc@5 90.625 (85.208)
Epoch: [86][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2444 (2.3774)	Acc@1 60.156 (56.061)	Acc@5 87.500 (85.224)
Epoch: [86][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3014 (2.3790)	Acc@1 58.594 (56.076)	Acc@5 88.281 (85.220)
Epoch: [86][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4373 (2.3778)	Acc@1 56.250 (56.138)	Acc@5 83.594 (85.212)
Epoch: [86][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5987 (2.3769)	Acc@1 50.781 (56.176)	Acc@5 82.031 (85.173)
Epoch: [86][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6825 (2.3796)	Acc@1 47.656 (56.091)	Acc@5 78.125 (85.090)
Epoch: [86][210/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2654 (2.3825)	Acc@1 55.469 (56.024)	Acc@5 85.938 (85.041)
Epoch: [86][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4427 (2.3877)	Acc@1 55.469 (55.896)	Acc@5 86.719 (85.015)
Epoch: [86][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2756 (2.3898)	Acc@1 57.812 (55.915)	Acc@5 85.938 (84.984)
Epoch: [86][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2355 (2.3916)	Acc@1 63.281 (55.926)	Acc@5 86.719 (84.916)
Epoch: [86][250/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 2.2926 (2.3965)	Acc@1 59.375 (55.864)	Acc@5 85.938 (84.801)
Epoch: [86][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2899 (2.3997)	Acc@1 57.031 (55.771)	Acc@5 89.062 (84.779)
Epoch: [86][270/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6587 (2.4015)	Acc@1 48.438 (55.702)	Acc@5 75.781 (84.741)
Epoch: [86][280/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.5118 (2.4029)	Acc@1 52.344 (55.686)	Acc@5 81.250 (84.706)
Epoch: [86][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2667 (2.4038)	Acc@1 57.031 (55.630)	Acc@5 87.500 (84.705)
Epoch: [86][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2770 (2.4004)	Acc@1 57.031 (55.746)	Acc@5 90.625 (84.757)
Epoch: [86][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1932 (2.3983)	Acc@1 60.938 (55.765)	Acc@5 88.281 (84.820)
Epoch: [86][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3705 (2.3997)	Acc@1 54.688 (55.751)	Acc@5 84.375 (84.796)
Epoch: [86][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5031 (2.4004)	Acc@1 51.562 (55.776)	Acc@5 86.719 (84.788)
Epoch: [86][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3379 (2.3991)	Acc@1 54.688 (55.785)	Acc@5 85.938 (84.797)
Epoch: [86][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4639 (2.4011)	Acc@1 49.219 (55.729)	Acc@5 82.812 (84.767)
Epoch: [86][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5349 (2.4042)	Acc@1 52.344 (55.653)	Acc@5 79.688 (84.719)
Epoch: [86][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3434 (2.4069)	Acc@1 54.688 (55.595)	Acc@5 88.281 (84.657)
Epoch: [86][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5191 (2.4104)	Acc@1 50.781 (55.518)	Acc@5 83.594 (84.621)
Epoch: [86][390/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.5438 (2.4123)	Acc@1 48.750 (55.462)	Acc@5 83.750 (84.608)
num momentum params: 26
[0.1, 2.4123327951812743, 1.9840056526660919, 55.462, 47.52, tensor(0.3324, device='cuda:0', grad_fn=<DivBackward0>), 5.267201662063599, 0.3912057876586914]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [87 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [87][0/391]	Time 0.050 (0.050)	Data 0.158 (0.158)	Loss 2.3762 (2.3762)	Acc@1 59.375 (59.375)	Acc@5 85.938 (85.938)
Epoch: [87][10/391]	Time 0.014 (0.018)	Data 0.001 (0.016)	Loss 2.4003 (2.3087)	Acc@1 56.250 (57.244)	Acc@5 86.719 (86.719)
Epoch: [87][20/391]	Time 0.014 (0.016)	Data 0.001 (0.009)	Loss 2.4635 (2.3162)	Acc@1 53.125 (57.403)	Acc@5 79.688 (86.272)
Epoch: [87][30/391]	Time 0.013 (0.015)	Data 0.001 (0.007)	Loss 2.2477 (2.3115)	Acc@1 63.281 (57.686)	Acc@5 86.719 (86.341)
Epoch: [87][40/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.6151 (2.3379)	Acc@1 50.781 (57.279)	Acc@5 82.031 (86.014)
Epoch: [87][50/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3823 (2.3419)	Acc@1 54.688 (56.847)	Acc@5 82.812 (85.983)
Epoch: [87][60/391]	Time 0.012 (0.014)	Data 0.001 (0.004)	Loss 2.4806 (2.3635)	Acc@1 57.812 (56.493)	Acc@5 83.594 (85.656)
Epoch: [87][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.1433 (2.3630)	Acc@1 64.844 (56.613)	Acc@5 88.281 (85.453)
Epoch: [87][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3475 (2.3629)	Acc@1 59.375 (56.549)	Acc@5 89.844 (85.542)
Epoch: [87][90/391]	Time 0.011 (0.014)	Data 0.001 (0.003)	Loss 2.4634 (2.3783)	Acc@1 53.906 (56.241)	Acc@5 81.250 (85.225)
Epoch: [87][100/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2416 (2.3772)	Acc@1 63.281 (56.304)	Acc@5 88.281 (85.311)
Epoch: [87][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4688 (2.3821)	Acc@1 54.688 (56.123)	Acc@5 85.156 (85.248)
Epoch: [87][120/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3579 (2.3818)	Acc@1 57.812 (56.050)	Acc@5 83.594 (85.227)
Epoch: [87][130/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.6306 (2.3903)	Acc@1 50.781 (55.892)	Acc@5 83.594 (85.001)
Epoch: [87][140/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4514 (2.3936)	Acc@1 50.000 (55.773)	Acc@5 85.156 (84.924)
Epoch: [87][150/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.1915 (2.3949)	Acc@1 57.812 (55.702)	Acc@5 89.062 (85.006)
Epoch: [87][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4965 (2.3930)	Acc@1 57.812 (55.740)	Acc@5 84.375 (85.064)
Epoch: [87][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3161 (2.3960)	Acc@1 50.781 (55.615)	Acc@5 89.844 (85.028)
Epoch: [87][180/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.3012 (2.3954)	Acc@1 56.250 (55.521)	Acc@5 85.156 (85.061)
Epoch: [87][190/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4090 (2.3944)	Acc@1 53.906 (55.591)	Acc@5 86.719 (85.054)
Epoch: [87][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2494 (2.3947)	Acc@1 60.938 (55.624)	Acc@5 83.594 (84.993)
Epoch: [87][210/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3568 (2.3938)	Acc@1 56.250 (55.654)	Acc@5 85.156 (85.012)
Epoch: [87][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7249 (2.3965)	Acc@1 47.656 (55.497)	Acc@5 78.125 (84.969)
Epoch: [87][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4545 (2.3990)	Acc@1 46.875 (55.330)	Acc@5 80.469 (84.967)
Epoch: [87][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8457 (2.4003)	Acc@1 47.656 (55.290)	Acc@5 78.125 (84.910)
Epoch: [87][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4413 (2.4046)	Acc@1 55.469 (55.173)	Acc@5 85.156 (84.861)
Epoch: [87][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4540 (2.4067)	Acc@1 55.469 (55.134)	Acc@5 84.375 (84.830)
Epoch: [87][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.8293 (2.4077)	Acc@1 48.438 (55.155)	Acc@5 82.031 (84.830)
Epoch: [87][280/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5191 (2.4098)	Acc@1 55.469 (55.138)	Acc@5 84.375 (84.789)
Epoch: [87][290/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5356 (2.4129)	Acc@1 56.250 (55.136)	Acc@5 82.812 (84.711)
Epoch: [87][300/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.1707 (2.4115)	Acc@1 60.938 (55.217)	Acc@5 85.938 (84.702)
Epoch: [87][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5118 (2.4134)	Acc@1 48.438 (55.177)	Acc@5 83.594 (84.644)
Epoch: [87][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3424 (2.4141)	Acc@1 58.594 (55.128)	Acc@5 83.594 (84.640)
Epoch: [87][330/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4995 (2.4157)	Acc@1 55.469 (55.101)	Acc@5 81.250 (84.616)
Epoch: [87][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6567 (2.4163)	Acc@1 51.562 (55.088)	Acc@5 82.031 (84.586)
Epoch: [87][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3302 (2.4185)	Acc@1 53.906 (55.032)	Acc@5 85.156 (84.555)
Epoch: [87][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2519 (2.4188)	Acc@1 60.938 (55.034)	Acc@5 83.594 (84.544)
Epoch: [87][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4573 (2.4186)	Acc@1 54.688 (55.039)	Acc@5 82.812 (84.525)
Epoch: [87][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3860 (2.4198)	Acc@1 54.688 (54.966)	Acc@5 83.594 (84.506)
Epoch: [87][390/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.4230 (2.4203)	Acc@1 58.750 (54.976)	Acc@5 85.000 (84.484)
num momentum params: 26
[0.1, 2.420334707946777, 1.9530906391143799, 54.976, 49.15, tensor(0.3310, device='cuda:0', grad_fn=<DivBackward0>), 5.250075817108154, 0.4034426212310791]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [88 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [88][0/391]	Time 0.053 (0.053)	Data 0.165 (0.165)	Loss 2.1524 (2.1524)	Acc@1 57.812 (57.812)	Acc@5 91.406 (91.406)
Epoch: [88][10/391]	Time 0.015 (0.019)	Data 0.001 (0.016)	Loss 2.2247 (2.3154)	Acc@1 61.719 (55.753)	Acc@5 86.719 (87.003)
Epoch: [88][20/391]	Time 0.014 (0.016)	Data 0.001 (0.009)	Loss 2.3131 (2.3353)	Acc@1 57.031 (56.176)	Acc@5 85.156 (86.458)
Epoch: [88][30/391]	Time 0.013 (0.015)	Data 0.001 (0.007)	Loss 2.2329 (2.3527)	Acc@1 57.031 (55.897)	Acc@5 85.156 (85.610)
Epoch: [88][40/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.8406 (2.3775)	Acc@1 46.875 (55.697)	Acc@5 78.125 (85.099)
Epoch: [88][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.1301 (2.3927)	Acc@1 60.938 (55.561)	Acc@5 88.281 (84.972)
Epoch: [88][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.2980 (2.3874)	Acc@1 57.031 (55.763)	Acc@5 85.938 (84.887)
Epoch: [88][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.1913 (2.3919)	Acc@1 60.156 (55.700)	Acc@5 88.281 (84.859)
Epoch: [88][80/391]	Time 0.012 (0.014)	Data 0.002 (0.003)	Loss 2.2908 (2.3879)	Acc@1 57.031 (55.951)	Acc@5 83.594 (84.925)
Epoch: [88][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4035 (2.3829)	Acc@1 52.344 (56.104)	Acc@5 82.812 (84.942)
Epoch: [88][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.1937 (2.3790)	Acc@1 62.500 (56.134)	Acc@5 89.844 (85.009)
Epoch: [88][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5158 (2.3850)	Acc@1 51.562 (55.926)	Acc@5 83.594 (84.931)
Epoch: [88][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4825 (2.3862)	Acc@1 51.562 (55.869)	Acc@5 85.156 (84.930)
Epoch: [88][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2778 (2.3825)	Acc@1 55.469 (55.952)	Acc@5 87.500 (85.043)
Epoch: [88][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4581 (2.3809)	Acc@1 54.688 (55.984)	Acc@5 83.594 (85.062)
Epoch: [88][150/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5574 (2.3782)	Acc@1 51.562 (56.090)	Acc@5 83.594 (85.094)
Epoch: [88][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3534 (2.3797)	Acc@1 55.469 (56.061)	Acc@5 87.500 (85.108)
Epoch: [88][170/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3701 (2.3819)	Acc@1 58.594 (55.967)	Acc@5 84.375 (85.037)
Epoch: [88][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4677 (2.3828)	Acc@1 50.000 (55.913)	Acc@5 83.594 (84.971)
Epoch: [88][190/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5750 (2.3865)	Acc@1 56.250 (55.898)	Acc@5 82.812 (84.948)
Epoch: [88][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5044 (2.3899)	Acc@1 54.688 (55.815)	Acc@5 82.031 (84.884)
Epoch: [88][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5744 (2.3928)	Acc@1 50.781 (55.746)	Acc@5 80.469 (84.830)
Epoch: [88][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5264 (2.3919)	Acc@1 50.781 (55.790)	Acc@5 81.250 (84.831)
Epoch: [88][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3822 (2.3918)	Acc@1 51.562 (55.766)	Acc@5 84.375 (84.865)
Epoch: [88][240/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5653 (2.3965)	Acc@1 57.031 (55.718)	Acc@5 82.812 (84.774)
Epoch: [88][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3502 (2.3978)	Acc@1 57.812 (55.677)	Acc@5 83.594 (84.724)
Epoch: [88][260/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6365 (2.4011)	Acc@1 51.562 (55.612)	Acc@5 79.688 (84.650)
Epoch: [88][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4918 (2.4062)	Acc@1 57.812 (55.489)	Acc@5 82.812 (84.617)
Epoch: [88][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5270 (2.4073)	Acc@1 42.969 (55.444)	Acc@5 82.812 (84.581)
Epoch: [88][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3949 (2.4068)	Acc@1 54.688 (55.428)	Acc@5 87.500 (84.587)
Epoch: [88][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3501 (2.4072)	Acc@1 58.594 (55.456)	Acc@5 85.156 (84.551)
Epoch: [88][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4853 (2.4112)	Acc@1 53.906 (55.371)	Acc@5 83.594 (84.483)
Epoch: [88][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4698 (2.4133)	Acc@1 50.781 (55.308)	Acc@5 84.375 (84.426)
Epoch: [88][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6316 (2.4141)	Acc@1 47.656 (55.294)	Acc@5 82.812 (84.401)
Epoch: [88][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5091 (2.4179)	Acc@1 51.562 (55.219)	Acc@5 85.938 (84.325)
Epoch: [88][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7510 (2.4189)	Acc@1 50.000 (55.173)	Acc@5 82.031 (84.315)
Epoch: [88][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2365 (2.4176)	Acc@1 60.938 (55.248)	Acc@5 86.719 (84.323)
Epoch: [88][370/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.0793 (2.4157)	Acc@1 61.719 (55.353)	Acc@5 92.188 (84.348)
Epoch: [88][380/391]	Time 0.012 (0.013)	Data 0.001 (0.002)	Loss 2.5030 (2.4183)	Acc@1 55.469 (55.333)	Acc@5 78.906 (84.318)
Epoch: [88][390/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.4320 (2.4210)	Acc@1 52.500 (55.282)	Acc@5 83.750 (84.270)
num momentum params: 26
[0.1, 2.421018279571533, 2.2980098474025725, 55.282, 43.1, tensor(0.3309, device='cuda:0', grad_fn=<DivBackward0>), 5.269742250442505, 0.3988842964172363]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [89 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [89][0/391]	Time 0.054 (0.054)	Data 0.165 (0.165)	Loss 2.4494 (2.4494)	Acc@1 50.781 (50.781)	Acc@5 81.250 (81.250)
Epoch: [89][10/391]	Time 0.013 (0.018)	Data 0.001 (0.016)	Loss 2.2753 (2.3781)	Acc@1 56.250 (55.256)	Acc@5 84.375 (85.156)
Epoch: [89][20/391]	Time 0.013 (0.016)	Data 0.001 (0.009)	Loss 2.1810 (2.3054)	Acc@1 54.688 (56.696)	Acc@5 87.500 (86.161)
Epoch: [89][30/391]	Time 0.013 (0.015)	Data 0.001 (0.007)	Loss 2.4414 (2.3128)	Acc@1 53.125 (57.006)	Acc@5 85.156 (85.811)
Epoch: [89][40/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.2550 (2.3033)	Acc@1 63.281 (57.679)	Acc@5 85.938 (85.995)
Epoch: [89][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.1583 (2.3092)	Acc@1 67.188 (57.812)	Acc@5 86.719 (85.723)
Epoch: [89][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.2114 (2.3138)	Acc@1 62.500 (57.787)	Acc@5 85.938 (85.656)
Epoch: [89][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4848 (2.3300)	Acc@1 52.344 (57.317)	Acc@5 83.594 (85.442)
Epoch: [89][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3916 (2.3305)	Acc@1 57.031 (57.388)	Acc@5 84.375 (85.475)
Epoch: [89][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5016 (2.3507)	Acc@1 53.906 (57.057)	Acc@5 84.375 (85.208)
Epoch: [89][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3513 (2.3502)	Acc@1 56.250 (57.016)	Acc@5 86.719 (85.280)
Epoch: [89][110/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.2944 (2.3554)	Acc@1 58.594 (56.919)	Acc@5 85.938 (85.156)
Epoch: [89][120/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.3521 (2.3608)	Acc@1 59.375 (56.728)	Acc@5 82.031 (85.085)
Epoch: [89][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4678 (2.3572)	Acc@1 52.344 (56.745)	Acc@5 82.812 (85.132)
Epoch: [89][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4594 (2.3615)	Acc@1 53.906 (56.627)	Acc@5 82.812 (85.167)
Epoch: [89][150/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.8013 (2.3698)	Acc@1 44.531 (56.504)	Acc@5 75.000 (84.980)
Epoch: [89][160/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.5893 (2.3800)	Acc@1 50.000 (56.226)	Acc@5 80.469 (84.831)
Epoch: [89][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4649 (2.3807)	Acc@1 59.375 (56.245)	Acc@5 84.375 (84.777)
Epoch: [89][180/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2835 (2.3874)	Acc@1 57.031 (56.090)	Acc@5 89.062 (84.725)
Epoch: [89][190/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4262 (2.3892)	Acc@1 59.375 (56.123)	Acc@5 83.594 (84.674)
Epoch: [89][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3897 (2.3897)	Acc@1 60.156 (56.145)	Acc@5 82.812 (84.682)
Epoch: [89][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3597 (2.3867)	Acc@1 57.031 (56.265)	Acc@5 85.156 (84.734)
Epoch: [89][220/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5607 (2.3895)	Acc@1 58.594 (56.201)	Acc@5 82.031 (84.711)
Epoch: [89][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3264 (2.3909)	Acc@1 58.594 (56.162)	Acc@5 87.500 (84.656)
Epoch: [89][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6119 (2.3931)	Acc@1 53.906 (56.117)	Acc@5 78.906 (84.576)
Epoch: [89][250/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2290 (2.3956)	Acc@1 61.719 (56.045)	Acc@5 87.500 (84.552)
Epoch: [89][260/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.3419 (2.3961)	Acc@1 57.812 (56.067)	Acc@5 85.938 (84.591)
Epoch: [89][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5100 (2.4004)	Acc@1 51.562 (55.918)	Acc@5 80.469 (84.522)
Epoch: [89][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2383 (2.4014)	Acc@1 57.812 (55.825)	Acc@5 87.500 (84.525)
Epoch: [89][290/391]	Time 0.012 (0.013)	Data 0.003 (0.002)	Loss 2.3022 (2.4014)	Acc@1 57.812 (55.796)	Acc@5 88.281 (84.555)
Epoch: [89][300/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.2839 (2.4030)	Acc@1 55.469 (55.741)	Acc@5 86.719 (84.570)
Epoch: [89][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3598 (2.4023)	Acc@1 59.375 (55.758)	Acc@5 87.500 (84.578)
Epoch: [89][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5942 (2.4058)	Acc@1 44.531 (55.683)	Acc@5 78.906 (84.497)
Epoch: [89][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5737 (2.4108)	Acc@1 53.906 (55.570)	Acc@5 80.469 (84.425)
Epoch: [89][340/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5466 (2.4141)	Acc@1 50.781 (55.471)	Acc@5 83.594 (84.373)
Epoch: [89][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.1351 (2.4165)	Acc@1 65.625 (55.464)	Acc@5 90.625 (84.373)
Epoch: [89][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6397 (2.4193)	Acc@1 52.344 (55.395)	Acc@5 78.906 (84.345)
Epoch: [89][370/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4515 (2.4188)	Acc@1 53.125 (55.395)	Acc@5 79.688 (84.352)
Epoch: [89][380/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4656 (2.4191)	Acc@1 56.250 (55.397)	Acc@5 85.938 (84.346)
Epoch: [89][390/391]	Time 0.015 (0.013)	Data 0.002 (0.002)	Loss 2.4025 (2.4175)	Acc@1 55.000 (55.422)	Acc@5 82.500 (84.398)
num momentum params: 26
[0.1, 2.4175073922729493, 1.9555397307872773, 55.422, 48.77, tensor(0.3310, device='cuda:0', grad_fn=<DivBackward0>), 5.236035108566284, 0.38889217376708984]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [90 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [90][0/391]	Time 0.053 (0.053)	Data 0.169 (0.169)	Loss 2.1634 (2.1634)	Acc@1 64.062 (64.062)	Acc@5 89.062 (89.062)
Epoch: [90][10/391]	Time 0.013 (0.019)	Data 0.001 (0.017)	Loss 2.2258 (2.3885)	Acc@1 58.594 (55.469)	Acc@5 88.281 (85.582)
Epoch: [90][20/391]	Time 0.013 (0.016)	Data 0.001 (0.009)	Loss 2.2004 (2.3345)	Acc@1 58.594 (57.106)	Acc@5 92.188 (85.863)
Epoch: [90][30/391]	Time 0.013 (0.015)	Data 0.001 (0.007)	Loss 2.5345 (2.3216)	Acc@1 50.781 (57.535)	Acc@5 83.594 (86.190)
Epoch: [90][40/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.3761 (2.3189)	Acc@1 52.344 (57.546)	Acc@5 82.031 (86.490)
Epoch: [90][50/391]	Time 0.013 (0.014)	Data 0.001 (0.005)	Loss 2.4538 (2.3516)	Acc@1 56.250 (56.801)	Acc@5 84.375 (85.784)
Epoch: [90][60/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.2689 (2.3546)	Acc@1 59.375 (56.634)	Acc@5 85.156 (85.605)
Epoch: [90][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.2042 (2.3558)	Acc@1 61.719 (56.668)	Acc@5 92.188 (85.497)
Epoch: [90][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4448 (2.3533)	Acc@1 56.250 (56.848)	Acc@5 85.156 (85.513)
Epoch: [90][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2973 (2.3579)	Acc@1 55.469 (56.920)	Acc@5 89.062 (85.405)
Epoch: [90][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4203 (2.3581)	Acc@1 60.156 (56.946)	Acc@5 79.688 (85.280)
Epoch: [90][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.7370 (2.3628)	Acc@1 50.781 (56.806)	Acc@5 78.906 (85.142)
Epoch: [90][120/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3966 (2.3645)	Acc@1 57.812 (56.799)	Acc@5 80.469 (85.098)
Epoch: [90][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4996 (2.3767)	Acc@1 49.219 (56.405)	Acc@5 84.375 (84.912)
Epoch: [90][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5115 (2.3839)	Acc@1 50.781 (56.123)	Acc@5 84.375 (84.846)
Epoch: [90][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5497 (2.3932)	Acc@1 54.688 (55.945)	Acc@5 82.031 (84.727)
Epoch: [90][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4674 (2.3908)	Acc@1 51.562 (55.925)	Acc@5 85.156 (84.836)
Epoch: [90][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2416 (2.3912)	Acc@1 57.812 (55.843)	Acc@5 85.938 (84.818)
Epoch: [90][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6922 (2.3924)	Acc@1 48.438 (55.827)	Acc@5 79.688 (84.841)
Epoch: [90][190/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3414 (2.3952)	Acc@1 58.594 (55.853)	Acc@5 82.031 (84.727)
Epoch: [90][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3459 (2.4009)	Acc@1 57.031 (55.694)	Acc@5 85.156 (84.608)
Epoch: [90][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1846 (2.4049)	Acc@1 59.375 (55.598)	Acc@5 89.844 (84.553)
Epoch: [90][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.9180 (2.4064)	Acc@1 49.219 (55.564)	Acc@5 77.344 (84.506)
Epoch: [90][230/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3897 (2.4079)	Acc@1 53.125 (55.455)	Acc@5 83.594 (84.514)
Epoch: [90][240/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.2430 (2.4072)	Acc@1 56.250 (55.436)	Acc@5 86.719 (84.540)
Epoch: [90][250/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5680 (2.4116)	Acc@1 54.688 (55.341)	Acc@5 82.812 (84.415)
Epoch: [90][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4726 (2.4138)	Acc@1 56.250 (55.274)	Acc@5 84.375 (84.423)
Epoch: [90][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5078 (2.4132)	Acc@1 44.531 (55.304)	Acc@5 85.938 (84.438)
Epoch: [90][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.1498 (2.4117)	Acc@1 57.031 (55.346)	Acc@5 89.062 (84.461)
Epoch: [90][290/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5967 (2.4139)	Acc@1 50.781 (55.294)	Acc@5 80.469 (84.418)
Epoch: [90][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5453 (2.4152)	Acc@1 53.125 (55.331)	Acc@5 79.688 (84.411)
Epoch: [90][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3887 (2.4162)	Acc@1 56.250 (55.258)	Acc@5 82.812 (84.400)
Epoch: [90][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6758 (2.4180)	Acc@1 46.875 (55.238)	Acc@5 81.250 (84.365)
Epoch: [90][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6308 (2.4196)	Acc@1 48.438 (55.230)	Acc@5 79.688 (84.337)
Epoch: [90][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4138 (2.4220)	Acc@1 58.594 (55.226)	Acc@5 80.469 (84.219)
Epoch: [90][350/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.7927 (2.4232)	Acc@1 47.656 (55.166)	Acc@5 82.031 (84.204)
Epoch: [90][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6467 (2.4255)	Acc@1 51.562 (55.110)	Acc@5 78.125 (84.159)
Epoch: [90][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6348 (2.4268)	Acc@1 47.656 (55.094)	Acc@5 81.250 (84.129)
Epoch: [90][380/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4763 (2.4256)	Acc@1 52.344 (55.132)	Acc@5 84.375 (84.162)
Epoch: [90][390/391]	Time 0.017 (0.013)	Data 0.001 (0.002)	Loss 2.4762 (2.4276)	Acc@1 52.500 (55.074)	Acc@5 82.500 (84.128)
num momentum params: 26
[0.1, 2.4275500678253175, 2.0536502611637117, 55.074, 46.79, tensor(0.3300, device='cuda:0', grad_fn=<DivBackward0>), 5.252899646759033, 0.39269232749938965]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [91 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [91][0/391]	Time 0.056 (0.056)	Data 0.161 (0.161)	Loss 2.2035 (2.2035)	Acc@1 60.156 (60.156)	Acc@5 87.500 (87.500)
Epoch: [91][10/391]	Time 0.026 (0.020)	Data 0.001 (0.016)	Loss 2.2467 (2.3063)	Acc@1 55.469 (57.955)	Acc@5 87.500 (85.795)
Epoch: [91][20/391]	Time 0.013 (0.017)	Data 0.001 (0.009)	Loss 2.1885 (2.3046)	Acc@1 62.500 (57.738)	Acc@5 88.281 (86.049)
Epoch: [91][30/391]	Time 0.013 (0.016)	Data 0.001 (0.007)	Loss 2.1888 (2.3121)	Acc@1 60.156 (57.787)	Acc@5 86.719 (86.316)
Epoch: [91][40/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.4019 (2.3141)	Acc@1 55.469 (57.793)	Acc@5 80.469 (86.223)
Epoch: [91][50/391]	Time 0.013 (0.015)	Data 0.002 (0.005)	Loss 2.6851 (2.3459)	Acc@1 51.562 (57.001)	Acc@5 78.906 (85.723)
Epoch: [91][60/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.1403 (2.3328)	Acc@1 63.281 (57.339)	Acc@5 87.500 (85.745)
Epoch: [91][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.2879 (2.3352)	Acc@1 55.469 (57.185)	Acc@5 89.844 (85.838)
Epoch: [91][80/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4092 (2.3405)	Acc@1 52.344 (57.012)	Acc@5 86.719 (85.754)
Epoch: [91][90/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2256 (2.3528)	Acc@1 61.719 (56.739)	Acc@5 84.375 (85.508)
Epoch: [91][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4359 (2.3649)	Acc@1 57.812 (56.505)	Acc@5 88.281 (85.388)
Epoch: [91][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2333 (2.3717)	Acc@1 60.156 (56.398)	Acc@5 88.281 (85.262)
Epoch: [91][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3053 (2.3702)	Acc@1 59.375 (56.482)	Acc@5 83.594 (85.253)
Epoch: [91][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.7316 (2.3757)	Acc@1 51.562 (56.298)	Acc@5 74.219 (85.126)
Epoch: [91][140/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3275 (2.3843)	Acc@1 54.688 (56.062)	Acc@5 87.500 (85.023)
Epoch: [91][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6072 (2.3886)	Acc@1 53.906 (56.079)	Acc@5 85.156 (84.918)
Epoch: [91][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4735 (2.3899)	Acc@1 50.781 (56.041)	Acc@5 82.812 (84.870)
Epoch: [91][170/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3731 (2.3905)	Acc@1 58.594 (56.054)	Acc@5 82.812 (84.850)
Epoch: [91][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2892 (2.3901)	Acc@1 59.375 (56.073)	Acc@5 84.375 (84.893)
Epoch: [91][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5389 (2.3924)	Acc@1 50.000 (56.005)	Acc@5 82.812 (84.792)
Epoch: [91][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4612 (2.3933)	Acc@1 53.906 (55.986)	Acc@5 85.938 (84.787)
Epoch: [91][210/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3134 (2.3914)	Acc@1 56.250 (56.020)	Acc@5 85.938 (84.797)
Epoch: [91][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5473 (2.3911)	Acc@1 53.906 (55.942)	Acc@5 80.469 (84.817)
Epoch: [91][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4226 (2.3939)	Acc@1 49.219 (55.837)	Acc@5 82.812 (84.737)
Epoch: [91][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4030 (2.3938)	Acc@1 51.562 (55.855)	Acc@5 82.812 (84.706)
Epoch: [91][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6509 (2.3960)	Acc@1 51.562 (55.858)	Acc@5 81.250 (84.674)
Epoch: [91][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6902 (2.3972)	Acc@1 50.781 (55.819)	Acc@5 85.938 (84.683)
Epoch: [91][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6470 (2.3965)	Acc@1 50.000 (55.861)	Acc@5 81.250 (84.689)
Epoch: [91][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4306 (2.3943)	Acc@1 54.688 (55.950)	Acc@5 82.812 (84.703)
Epoch: [91][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3046 (2.3933)	Acc@1 60.938 (55.979)	Acc@5 83.594 (84.719)
Epoch: [91][300/391]	Time 0.026 (0.014)	Data 0.001 (0.002)	Loss 2.3222 (2.3955)	Acc@1 59.375 (55.915)	Acc@5 83.594 (84.666)
Epoch: [91][310/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3263 (2.3981)	Acc@1 57.031 (55.868)	Acc@5 87.500 (84.626)
Epoch: [91][320/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5134 (2.4013)	Acc@1 50.781 (55.763)	Acc@5 82.031 (84.577)
Epoch: [91][330/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6742 (2.4051)	Acc@1 51.562 (55.658)	Acc@5 81.250 (84.517)
Epoch: [91][340/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4214 (2.4064)	Acc@1 57.812 (55.641)	Acc@5 78.906 (84.515)
Epoch: [91][350/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.2650 (2.4085)	Acc@1 60.938 (55.544)	Acc@5 86.719 (84.495)
Epoch: [91][360/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3212 (2.4083)	Acc@1 60.156 (55.583)	Acc@5 85.156 (84.472)
Epoch: [91][370/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3863 (2.4111)	Acc@1 53.125 (55.492)	Acc@5 84.375 (84.419)
Epoch: [91][380/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3942 (2.4134)	Acc@1 53.906 (55.428)	Acc@5 85.938 (84.383)
Epoch: [91][390/391]	Time 0.017 (0.014)	Data 0.002 (0.002)	Loss 2.7324 (2.4143)	Acc@1 52.500 (55.422)	Acc@5 76.250 (84.372)
num momentum params: 26
[0.1, 2.414325821685791, 1.9993865430355071, 55.422, 47.41, tensor(0.3317, device='cuda:0', grad_fn=<DivBackward0>), 5.341598033905029, 0.42363905906677246]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [92 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [92][0/391]	Time 0.051 (0.051)	Data 0.190 (0.190)	Loss 2.4151 (2.4151)	Acc@1 51.562 (51.562)	Acc@5 83.594 (83.594)
Epoch: [92][10/391]	Time 0.014 (0.020)	Data 0.001 (0.019)	Loss 2.2623 (2.3116)	Acc@1 60.938 (58.452)	Acc@5 88.281 (85.653)
Epoch: [92][20/391]	Time 0.013 (0.017)	Data 0.001 (0.010)	Loss 2.3766 (2.2865)	Acc@1 58.594 (58.705)	Acc@5 81.250 (85.826)
Epoch: [92][30/391]	Time 0.013 (0.016)	Data 0.001 (0.007)	Loss 2.4353 (2.3311)	Acc@1 51.562 (57.334)	Acc@5 88.281 (85.761)
Epoch: [92][40/391]	Time 0.014 (0.015)	Data 0.001 (0.006)	Loss 2.3707 (2.3423)	Acc@1 53.906 (57.050)	Acc@5 87.500 (85.709)
Epoch: [92][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.6588 (2.3449)	Acc@1 51.562 (56.939)	Acc@5 81.250 (85.815)
Epoch: [92][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.3540 (2.3479)	Acc@1 54.688 (56.954)	Acc@5 85.156 (85.758)
Epoch: [92][70/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.3170 (2.3487)	Acc@1 51.562 (56.811)	Acc@5 87.500 (85.629)
Epoch: [92][80/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4083 (2.3584)	Acc@1 57.031 (56.713)	Acc@5 83.594 (85.658)
Epoch: [92][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.1761 (2.3643)	Acc@1 65.625 (56.739)	Acc@5 87.500 (85.491)
Epoch: [92][100/391]	Time 0.018 (0.014)	Data 0.001 (0.003)	Loss 2.3133 (2.3687)	Acc@1 57.812 (56.567)	Acc@5 90.625 (85.473)
Epoch: [92][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4947 (2.3753)	Acc@1 54.688 (56.370)	Acc@5 81.250 (85.304)
Epoch: [92][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4790 (2.3810)	Acc@1 56.250 (56.295)	Acc@5 84.375 (85.118)
Epoch: [92][130/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4478 (2.3807)	Acc@1 50.781 (56.268)	Acc@5 85.938 (85.079)
Epoch: [92][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6069 (2.3922)	Acc@1 55.469 (56.073)	Acc@5 82.812 (84.924)
Epoch: [92][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3467 (2.3921)	Acc@1 64.844 (56.152)	Acc@5 84.375 (84.913)
Epoch: [92][160/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.1742 (2.3912)	Acc@1 57.031 (56.036)	Acc@5 88.281 (84.962)
Epoch: [92][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4196 (2.3892)	Acc@1 53.906 (56.136)	Acc@5 85.938 (84.987)
Epoch: [92][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3853 (2.3856)	Acc@1 54.688 (56.185)	Acc@5 85.938 (85.053)
Epoch: [92][190/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.2203 (2.3833)	Acc@1 63.281 (56.295)	Acc@5 88.281 (85.087)
Epoch: [92][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5112 (2.3893)	Acc@1 53.906 (56.219)	Acc@5 79.688 (84.958)
Epoch: [92][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4515 (2.3919)	Acc@1 52.344 (56.146)	Acc@5 82.812 (84.927)
Epoch: [92][220/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4769 (2.3928)	Acc@1 54.688 (56.066)	Acc@5 83.594 (84.902)
Epoch: [92][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3950 (2.3945)	Acc@1 55.469 (56.034)	Acc@5 85.156 (84.879)
Epoch: [92][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3383 (2.3981)	Acc@1 57.031 (55.991)	Acc@5 83.594 (84.835)
Epoch: [92][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5909 (2.4026)	Acc@1 52.344 (55.889)	Acc@5 82.031 (84.724)
Epoch: [92][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4901 (2.4023)	Acc@1 52.344 (55.906)	Acc@5 85.156 (84.722)
Epoch: [92][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4003 (2.4048)	Acc@1 53.906 (55.887)	Acc@5 86.719 (84.686)
Epoch: [92][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4621 (2.4075)	Acc@1 53.906 (55.844)	Acc@5 84.375 (84.647)
Epoch: [92][290/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3422 (2.4070)	Acc@1 56.250 (55.799)	Acc@5 86.719 (84.681)
Epoch: [92][300/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4438 (2.4083)	Acc@1 50.781 (55.739)	Acc@5 83.594 (84.648)
Epoch: [92][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6974 (2.4117)	Acc@1 51.562 (55.665)	Acc@5 78.906 (84.584)
Epoch: [92][320/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5966 (2.4112)	Acc@1 48.438 (55.625)	Acc@5 85.156 (84.631)
Epoch: [92][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7064 (2.4129)	Acc@1 48.438 (55.577)	Acc@5 81.250 (84.595)
Epoch: [92][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2584 (2.4121)	Acc@1 64.844 (55.576)	Acc@5 82.812 (84.583)
Epoch: [92][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5859 (2.4153)	Acc@1 51.562 (55.495)	Acc@5 82.031 (84.580)
Epoch: [92][360/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.7274 (2.4177)	Acc@1 52.344 (55.447)	Acc@5 78.906 (84.533)
Epoch: [92][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5008 (2.4172)	Acc@1 50.781 (55.473)	Acc@5 84.375 (84.529)
Epoch: [92][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4578 (2.4161)	Acc@1 56.250 (55.497)	Acc@5 80.469 (84.521)
Epoch: [92][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.4664 (2.4173)	Acc@1 60.000 (55.454)	Acc@5 76.250 (84.492)
num momentum params: 26
[0.1, 2.4173409118652343, 1.952717686891556, 55.454, 48.43, tensor(0.3316, device='cuda:0', grad_fn=<DivBackward0>), 5.285885572433472, 0.39291524887084966]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [93 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [93][0/391]	Time 0.051 (0.051)	Data 0.160 (0.160)	Loss 2.3817 (2.3817)	Acc@1 57.031 (57.031)	Acc@5 85.156 (85.156)
Epoch: [93][10/391]	Time 0.014 (0.018)	Data 0.001 (0.016)	Loss 2.5019 (2.4018)	Acc@1 55.469 (56.179)	Acc@5 82.031 (84.730)
Epoch: [93][20/391]	Time 0.013 (0.016)	Data 0.001 (0.009)	Loss 2.4902 (2.3836)	Acc@1 51.562 (56.585)	Acc@5 84.375 (85.045)
Epoch: [93][30/391]	Time 0.014 (0.015)	Data 0.001 (0.006)	Loss 2.3358 (2.3474)	Acc@1 59.375 (57.989)	Acc@5 85.156 (85.559)
Epoch: [93][40/391]	Time 0.012 (0.015)	Data 0.001 (0.005)	Loss 2.3507 (2.3359)	Acc@1 55.469 (57.908)	Acc@5 86.719 (85.899)
Epoch: [93][50/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.3677 (2.3277)	Acc@1 54.688 (57.889)	Acc@5 85.156 (85.830)
Epoch: [93][60/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.2639 (2.3235)	Acc@1 60.156 (57.838)	Acc@5 88.281 (85.989)
Epoch: [93][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.6061 (2.3368)	Acc@1 53.906 (57.361)	Acc@5 85.156 (85.960)
Epoch: [93][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3967 (2.3467)	Acc@1 51.562 (56.896)	Acc@5 84.375 (85.706)
Epoch: [93][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3065 (2.3477)	Acc@1 51.562 (56.748)	Acc@5 83.594 (85.560)
Epoch: [93][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3774 (2.3456)	Acc@1 53.125 (56.962)	Acc@5 83.594 (85.520)
Epoch: [93][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2490 (2.3504)	Acc@1 56.250 (56.848)	Acc@5 85.938 (85.374)
Epoch: [93][120/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3281 (2.3557)	Acc@1 57.812 (56.721)	Acc@5 85.156 (85.356)
Epoch: [93][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6005 (2.3590)	Acc@1 53.906 (56.548)	Acc@5 82.812 (85.252)
Epoch: [93][140/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3314 (2.3607)	Acc@1 54.688 (56.505)	Acc@5 84.375 (85.195)
Epoch: [93][150/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1872 (2.3614)	Acc@1 62.500 (56.514)	Acc@5 89.844 (85.301)
Epoch: [93][160/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5177 (2.3621)	Acc@1 50.000 (56.386)	Acc@5 82.812 (85.321)
Epoch: [93][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5494 (2.3594)	Acc@1 52.344 (56.529)	Acc@5 79.688 (85.289)
Epoch: [93][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4464 (2.3640)	Acc@1 53.906 (56.405)	Acc@5 86.719 (85.225)
Epoch: [93][190/391]	Time 0.011 (0.014)	Data 0.004 (0.002)	Loss 2.3498 (2.3672)	Acc@1 60.938 (56.344)	Acc@5 83.594 (85.185)
Epoch: [93][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5614 (2.3711)	Acc@1 52.344 (56.277)	Acc@5 82.031 (85.090)
Epoch: [93][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3087 (2.3754)	Acc@1 53.906 (56.198)	Acc@5 88.281 (84.993)
Epoch: [93][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6289 (2.3792)	Acc@1 50.000 (55.988)	Acc@5 78.906 (84.937)
Epoch: [93][230/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4843 (2.3816)	Acc@1 50.781 (55.919)	Acc@5 82.812 (84.933)
Epoch: [93][240/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2593 (2.3843)	Acc@1 64.062 (55.893)	Acc@5 87.500 (84.868)
Epoch: [93][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6312 (2.3881)	Acc@1 50.781 (55.858)	Acc@5 83.594 (84.783)
Epoch: [93][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4963 (2.3906)	Acc@1 56.250 (55.813)	Acc@5 81.250 (84.785)
Epoch: [93][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3764 (2.3901)	Acc@1 57.031 (55.858)	Acc@5 82.031 (84.787)
Epoch: [93][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3865 (2.3904)	Acc@1 52.344 (55.811)	Acc@5 85.156 (84.792)
Epoch: [93][290/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4604 (2.3918)	Acc@1 57.812 (55.850)	Acc@5 81.250 (84.705)
Epoch: [93][300/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.4566 (2.3934)	Acc@1 52.344 (55.843)	Acc@5 82.812 (84.668)
Epoch: [93][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3761 (2.3944)	Acc@1 57.031 (55.836)	Acc@5 83.594 (84.659)
Epoch: [93][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7908 (2.3983)	Acc@1 44.531 (55.749)	Acc@5 82.031 (84.623)
Epoch: [93][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5166 (2.4009)	Acc@1 53.125 (55.693)	Acc@5 80.469 (84.595)
Epoch: [93][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5805 (2.4031)	Acc@1 51.562 (55.622)	Acc@5 85.156 (84.606)
Epoch: [93][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4775 (2.4074)	Acc@1 46.094 (55.493)	Acc@5 85.938 (84.553)
Epoch: [93][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4673 (2.4068)	Acc@1 55.469 (55.501)	Acc@5 83.594 (84.544)
Epoch: [93][370/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5123 (2.4057)	Acc@1 50.781 (55.530)	Acc@5 83.594 (84.571)
Epoch: [93][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.0847 (2.4060)	Acc@1 63.281 (55.538)	Acc@5 91.406 (84.562)
Epoch: [93][390/391]	Time 0.017 (0.013)	Data 0.001 (0.002)	Loss 2.7752 (2.4066)	Acc@1 50.000 (55.518)	Acc@5 82.500 (84.550)
num momentum params: 26
[0.1, 2.4066304776000975, 1.9429900181293487, 55.518, 49.96, tensor(0.3327, device='cuda:0', grad_fn=<DivBackward0>), 5.250947952270508, 0.3909575939178467]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [94 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [94][0/391]	Time 0.056 (0.056)	Data 0.159 (0.159)	Loss 2.0425 (2.0425)	Acc@1 67.188 (67.188)	Acc@5 90.625 (90.625)
Epoch: [94][10/391]	Time 0.014 (0.019)	Data 0.001 (0.015)	Loss 2.4205 (2.3316)	Acc@1 58.594 (58.594)	Acc@5 85.156 (86.719)
Epoch: [94][20/391]	Time 0.014 (0.016)	Data 0.001 (0.009)	Loss 2.6862 (2.3290)	Acc@1 51.562 (58.110)	Acc@5 82.031 (86.049)
Epoch: [94][30/391]	Time 0.015 (0.015)	Data 0.001 (0.006)	Loss 2.4147 (2.3374)	Acc@1 59.375 (57.762)	Acc@5 85.938 (85.610)
Epoch: [94][40/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.4045 (2.3389)	Acc@1 57.812 (57.832)	Acc@5 85.156 (85.556)
Epoch: [94][50/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.3001 (2.3416)	Acc@1 56.250 (57.414)	Acc@5 86.719 (85.692)
Epoch: [94][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3886 (2.3507)	Acc@1 57.031 (57.275)	Acc@5 84.375 (85.451)
Epoch: [94][70/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.2571 (2.3502)	Acc@1 58.594 (57.163)	Acc@5 88.281 (85.354)
Epoch: [94][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5904 (2.3697)	Acc@1 46.875 (56.462)	Acc@5 84.375 (85.185)
Epoch: [94][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3765 (2.3699)	Acc@1 50.000 (56.559)	Acc@5 88.281 (85.208)
Epoch: [94][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3454 (2.3705)	Acc@1 60.938 (56.521)	Acc@5 84.375 (85.172)
Epoch: [94][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.1870 (2.3746)	Acc@1 60.156 (56.334)	Acc@5 86.719 (85.177)
Epoch: [94][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3089 (2.3783)	Acc@1 59.375 (56.276)	Acc@5 85.938 (85.111)
Epoch: [94][130/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4847 (2.3820)	Acc@1 53.125 (56.119)	Acc@5 82.812 (85.132)
Epoch: [94][140/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6305 (2.3920)	Acc@1 50.781 (55.840)	Acc@5 79.688 (84.901)
Epoch: [94][150/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5500 (2.3934)	Acc@1 50.781 (55.779)	Acc@5 83.594 (84.882)
Epoch: [94][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3009 (2.3980)	Acc@1 61.719 (55.716)	Acc@5 86.719 (84.744)
Epoch: [94][170/391]	Time 0.022 (0.014)	Data 0.001 (0.002)	Loss 2.2528 (2.3983)	Acc@1 58.594 (55.706)	Acc@5 86.719 (84.745)
Epoch: [94][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1274 (2.3964)	Acc@1 60.156 (55.767)	Acc@5 89.844 (84.733)
Epoch: [94][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4949 (2.3939)	Acc@1 54.688 (55.939)	Acc@5 84.375 (84.772)
Epoch: [94][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2563 (2.3964)	Acc@1 57.812 (55.885)	Acc@5 88.281 (84.725)
Epoch: [94][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6224 (2.4016)	Acc@1 48.438 (55.721)	Acc@5 82.031 (84.597)
Epoch: [94][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4462 (2.4001)	Acc@1 59.375 (55.787)	Acc@5 80.469 (84.665)
Epoch: [94][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6419 (2.4006)	Acc@1 47.656 (55.793)	Acc@5 78.125 (84.656)
Epoch: [94][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6421 (2.4030)	Acc@1 52.344 (55.822)	Acc@5 79.688 (84.576)
Epoch: [94][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6512 (2.4040)	Acc@1 48.438 (55.814)	Acc@5 83.594 (84.615)
Epoch: [94][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2720 (2.4035)	Acc@1 59.375 (55.882)	Acc@5 86.719 (84.632)
Epoch: [94][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4722 (2.4049)	Acc@1 53.125 (55.795)	Acc@5 81.250 (84.606)
Epoch: [94][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3489 (2.4057)	Acc@1 60.156 (55.777)	Acc@5 87.500 (84.567)
Epoch: [94][290/391]	Time 0.012 (0.013)	Data 0.002 (0.002)	Loss 2.6092 (2.4099)	Acc@1 53.906 (55.651)	Acc@5 75.000 (84.523)
Epoch: [94][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4701 (2.4114)	Acc@1 51.562 (55.617)	Acc@5 85.156 (84.513)
Epoch: [94][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2896 (2.4136)	Acc@1 52.344 (55.574)	Acc@5 87.500 (84.443)
Epoch: [94][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5498 (2.4153)	Acc@1 52.344 (55.493)	Acc@5 79.688 (84.407)
Epoch: [94][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3240 (2.4124)	Acc@1 52.344 (55.563)	Acc@5 84.375 (84.451)
Epoch: [94][340/391]	Time 0.015 (0.013)	Data 0.001 (0.002)	Loss 2.5398 (2.4106)	Acc@1 50.781 (55.634)	Acc@5 82.031 (84.499)
Epoch: [94][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3505 (2.4082)	Acc@1 58.594 (55.671)	Acc@5 82.031 (84.531)
Epoch: [94][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5121 (2.4089)	Acc@1 56.250 (55.659)	Acc@5 82.031 (84.555)
Epoch: [94][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5121 (2.4096)	Acc@1 49.219 (55.627)	Acc@5 80.469 (84.541)
Epoch: [94][380/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.6525 (2.4119)	Acc@1 54.688 (55.565)	Acc@5 79.688 (84.473)
Epoch: [94][390/391]	Time 0.017 (0.013)	Data 0.001 (0.002)	Loss 2.4791 (2.4139)	Acc@1 53.750 (55.500)	Acc@5 80.000 (84.478)
num momentum params: 26
[0.1, 2.413868247451782, 2.1302432763576507, 55.5, 46.1, tensor(0.3325, device='cuda:0', grad_fn=<DivBackward0>), 5.255956172943115, 0.4010791778564453]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [95 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [95][0/391]	Time 0.054 (0.054)	Data 0.164 (0.164)	Loss 2.3629 (2.3629)	Acc@1 56.250 (56.250)	Acc@5 85.938 (85.938)
Epoch: [95][10/391]	Time 0.013 (0.019)	Data 0.001 (0.016)	Loss 2.3291 (2.3913)	Acc@1 64.844 (54.830)	Acc@5 83.594 (84.801)
Epoch: [95][20/391]	Time 0.013 (0.016)	Data 0.001 (0.009)	Loss 2.4879 (2.3508)	Acc@1 53.906 (56.696)	Acc@5 82.812 (85.603)
Epoch: [95][30/391]	Time 0.013 (0.015)	Data 0.001 (0.007)	Loss 2.2671 (2.3072)	Acc@1 57.812 (58.140)	Acc@5 85.156 (86.240)
Epoch: [95][40/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.2951 (2.2876)	Acc@1 56.250 (58.460)	Acc@5 85.156 (86.509)
Epoch: [95][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.3646 (2.3027)	Acc@1 59.375 (58.410)	Acc@5 84.375 (86.244)
Epoch: [95][60/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.4434 (2.3264)	Acc@1 57.031 (57.877)	Acc@5 85.156 (86.053)
Epoch: [95][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4247 (2.3337)	Acc@1 54.688 (57.879)	Acc@5 84.375 (85.949)
Epoch: [95][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5183 (2.3411)	Acc@1 52.344 (57.562)	Acc@5 80.469 (85.812)
Epoch: [95][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3953 (2.3448)	Acc@1 56.250 (57.366)	Acc@5 84.375 (85.731)
Epoch: [95][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6019 (2.3524)	Acc@1 54.688 (57.155)	Acc@5 82.031 (85.667)
Epoch: [95][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4796 (2.3630)	Acc@1 55.469 (56.820)	Acc@5 82.031 (85.529)
Epoch: [95][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5060 (2.3718)	Acc@1 57.812 (56.747)	Acc@5 80.469 (85.408)
Epoch: [95][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3533 (2.3737)	Acc@1 57.031 (56.697)	Acc@5 85.938 (85.371)
Epoch: [95][140/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3997 (2.3778)	Acc@1 53.906 (56.605)	Acc@5 86.719 (85.295)
Epoch: [95][150/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3980 (2.3816)	Acc@1 50.781 (56.462)	Acc@5 86.719 (85.167)
Epoch: [95][160/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6171 (2.3857)	Acc@1 53.125 (56.410)	Acc@5 80.469 (85.069)
Epoch: [95][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6113 (2.3891)	Acc@1 48.438 (56.364)	Acc@5 78.906 (85.028)
Epoch: [95][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2461 (2.3925)	Acc@1 55.469 (56.328)	Acc@5 89.844 (84.997)
Epoch: [95][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6182 (2.3937)	Acc@1 50.000 (56.283)	Acc@5 78.906 (84.911)
Epoch: [95][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3023 (2.3905)	Acc@1 56.250 (56.343)	Acc@5 87.500 (84.954)
Epoch: [95][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3659 (2.3905)	Acc@1 57.031 (56.283)	Acc@5 86.719 (84.964)
Epoch: [95][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3699 (2.3877)	Acc@1 60.938 (56.384)	Acc@5 82.031 (84.965)
Epoch: [95][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3605 (2.3870)	Acc@1 57.812 (56.429)	Acc@5 85.156 (85.034)
Epoch: [95][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6566 (2.3916)	Acc@1 53.906 (56.334)	Acc@5 79.688 (84.949)
Epoch: [95][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5415 (2.3948)	Acc@1 51.562 (56.213)	Acc@5 89.062 (84.954)
Epoch: [95][260/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6425 (2.3968)	Acc@1 47.656 (56.136)	Acc@5 84.375 (84.899)
Epoch: [95][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2905 (2.3961)	Acc@1 58.594 (56.115)	Acc@5 88.281 (84.931)
Epoch: [95][280/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6916 (2.3992)	Acc@1 55.469 (55.986)	Acc@5 78.906 (84.875)
Epoch: [95][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2629 (2.4012)	Acc@1 57.031 (55.893)	Acc@5 87.500 (84.853)
Epoch: [95][300/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2884 (2.3993)	Acc@1 58.594 (55.939)	Acc@5 87.500 (84.879)
Epoch: [95][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2470 (2.4005)	Acc@1 62.500 (55.908)	Acc@5 84.375 (84.835)
Epoch: [95][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4619 (2.4043)	Acc@1 51.562 (55.812)	Acc@5 82.812 (84.772)
Epoch: [95][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4333 (2.4050)	Acc@1 53.906 (55.740)	Acc@5 85.156 (84.743)
Epoch: [95][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4683 (2.4071)	Acc@1 52.344 (55.663)	Acc@5 85.938 (84.705)
Epoch: [95][350/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.0684 (2.4064)	Acc@1 62.500 (55.718)	Acc@5 92.969 (84.722)
Epoch: [95][360/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.3167 (2.4077)	Acc@1 54.688 (55.668)	Acc@5 85.156 (84.684)
Epoch: [95][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5880 (2.4103)	Acc@1 52.344 (55.557)	Acc@5 80.469 (84.623)
Epoch: [95][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2796 (2.4098)	Acc@1 57.031 (55.534)	Acc@5 83.594 (84.594)
Epoch: [95][390/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.2606 (2.4107)	Acc@1 60.000 (55.542)	Acc@5 82.500 (84.606)
num momentum params: 26
[0.1, 2.41070902885437, 1.8794017910957337, 55.542, 50.41, tensor(0.3318, device='cuda:0', grad_fn=<DivBackward0>), 5.245468616485596, 0.3970801830291748]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [96 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [96][0/391]	Time 0.055 (0.055)	Data 0.150 (0.150)	Loss 2.2788 (2.2788)	Acc@1 53.125 (53.125)	Acc@5 89.844 (89.844)
Epoch: [96][10/391]	Time 0.014 (0.018)	Data 0.001 (0.015)	Loss 2.0868 (2.3371)	Acc@1 59.375 (56.108)	Acc@5 91.406 (86.648)
Epoch: [96][20/391]	Time 0.013 (0.016)	Data 0.001 (0.009)	Loss 2.3029 (2.3143)	Acc@1 56.250 (56.957)	Acc@5 84.375 (86.161)
Epoch: [96][30/391]	Time 0.013 (0.015)	Data 0.001 (0.006)	Loss 2.5366 (2.3312)	Acc@1 50.000 (57.132)	Acc@5 83.594 (85.761)
Epoch: [96][40/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.5486 (2.3293)	Acc@1 47.656 (57.050)	Acc@5 83.594 (85.899)
Epoch: [96][50/391]	Time 0.015 (0.015)	Data 0.001 (0.005)	Loss 2.3908 (2.3399)	Acc@1 62.500 (56.909)	Acc@5 82.812 (85.708)
Epoch: [96][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3359 (2.3327)	Acc@1 56.250 (57.147)	Acc@5 91.406 (85.822)
Epoch: [96][70/391]	Time 0.016 (0.014)	Data 0.001 (0.004)	Loss 2.4844 (2.3278)	Acc@1 51.562 (57.328)	Acc@5 82.812 (85.838)
Epoch: [96][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2762 (2.3240)	Acc@1 58.594 (57.407)	Acc@5 88.281 (85.909)
Epoch: [96][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3676 (2.3207)	Acc@1 56.250 (57.409)	Acc@5 85.938 (85.963)
Epoch: [96][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4793 (2.3266)	Acc@1 54.688 (57.271)	Acc@5 79.688 (85.837)
Epoch: [96][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2101 (2.3249)	Acc@1 61.719 (57.306)	Acc@5 88.281 (85.888)
Epoch: [96][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4363 (2.3349)	Acc@1 51.562 (57.076)	Acc@5 86.719 (85.705)
Epoch: [96][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5653 (2.3428)	Acc@1 52.344 (56.954)	Acc@5 80.469 (85.544)
Epoch: [96][140/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4520 (2.3482)	Acc@1 55.469 (56.887)	Acc@5 83.594 (85.472)
Epoch: [96][150/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5147 (2.3513)	Acc@1 53.125 (56.912)	Acc@5 82.812 (85.348)
Epoch: [96][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2053 (2.3546)	Acc@1 59.375 (56.760)	Acc@5 89.062 (85.365)
Epoch: [96][170/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4064 (2.3586)	Acc@1 54.688 (56.561)	Acc@5 83.594 (85.421)
Epoch: [96][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4238 (2.3659)	Acc@1 57.031 (56.405)	Acc@5 79.688 (85.281)
Epoch: [96][190/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3733 (2.3682)	Acc@1 56.250 (56.299)	Acc@5 87.500 (85.283)
Epoch: [96][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3601 (2.3697)	Acc@1 58.594 (56.254)	Acc@5 85.156 (85.207)
Epoch: [96][210/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.5973 (2.3743)	Acc@1 53.906 (56.180)	Acc@5 83.594 (85.067)
Epoch: [96][220/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.4261 (2.3781)	Acc@1 56.250 (56.123)	Acc@5 85.938 (84.994)
Epoch: [96][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3460 (2.3799)	Acc@1 57.812 (56.094)	Acc@5 83.594 (84.970)
Epoch: [96][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3681 (2.3807)	Acc@1 60.938 (56.023)	Acc@5 85.938 (85.010)
Epoch: [96][250/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3280 (2.3833)	Acc@1 57.812 (55.951)	Acc@5 83.594 (84.898)
Epoch: [96][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2247 (2.3853)	Acc@1 59.375 (55.966)	Acc@5 90.625 (84.866)
Epoch: [96][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2312 (2.3889)	Acc@1 61.719 (55.881)	Acc@5 89.062 (84.810)
Epoch: [96][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2756 (2.3925)	Acc@1 61.719 (55.830)	Acc@5 86.719 (84.745)
Epoch: [96][290/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.3654 (2.3976)	Acc@1 54.688 (55.724)	Acc@5 87.500 (84.649)
Epoch: [96][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4336 (2.4008)	Acc@1 53.125 (55.627)	Acc@5 84.375 (84.580)
Epoch: [96][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1940 (2.4017)	Acc@1 63.281 (55.624)	Acc@5 87.500 (84.626)
Epoch: [96][320/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6016 (2.4030)	Acc@1 48.438 (55.581)	Acc@5 82.031 (84.611)
Epoch: [96][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2478 (2.4046)	Acc@1 60.938 (55.542)	Acc@5 87.500 (84.592)
Epoch: [96][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5809 (2.4068)	Acc@1 52.344 (55.505)	Acc@5 81.250 (84.535)
Epoch: [96][350/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4145 (2.4083)	Acc@1 54.688 (55.469)	Acc@5 84.375 (84.493)
Epoch: [96][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4886 (2.4093)	Acc@1 54.688 (55.443)	Acc@5 84.375 (84.451)
Epoch: [96][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4763 (2.4113)	Acc@1 52.344 (55.395)	Acc@5 85.156 (84.430)
Epoch: [96][380/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.7123 (2.4125)	Acc@1 45.312 (55.362)	Acc@5 77.344 (84.400)
Epoch: [96][390/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.3675 (2.4120)	Acc@1 56.250 (55.376)	Acc@5 83.750 (84.384)
num momentum params: 26
[0.1, 2.412030727081299, 2.062851403951645, 55.376, 46.56, tensor(0.3310, device='cuda:0', grad_fn=<DivBackward0>), 5.266838312149048, 0.3923799991607666]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [97 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [97][0/391]	Time 0.060 (0.060)	Data 0.162 (0.162)	Loss 2.2173 (2.2173)	Acc@1 57.812 (57.812)	Acc@5 88.281 (88.281)
Epoch: [97][10/391]	Time 0.015 (0.019)	Data 0.001 (0.016)	Loss 2.3723 (2.3454)	Acc@1 63.281 (57.528)	Acc@5 82.031 (85.653)
Epoch: [97][20/391]	Time 0.013 (0.017)	Data 0.001 (0.009)	Loss 2.3933 (2.3598)	Acc@1 55.469 (57.031)	Acc@5 82.812 (84.821)
Epoch: [97][30/391]	Time 0.013 (0.015)	Data 0.001 (0.006)	Loss 2.3752 (2.3467)	Acc@1 56.250 (57.006)	Acc@5 85.156 (85.408)
Epoch: [97][40/391]	Time 0.015 (0.015)	Data 0.001 (0.005)	Loss 2.4202 (2.3400)	Acc@1 56.250 (56.917)	Acc@5 84.375 (85.804)
Epoch: [97][50/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.4338 (2.3198)	Acc@1 53.125 (57.338)	Acc@5 82.812 (86.229)
Epoch: [97][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4277 (2.3236)	Acc@1 53.125 (57.262)	Acc@5 84.375 (86.245)
Epoch: [97][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.1756 (2.3215)	Acc@1 60.156 (57.174)	Acc@5 87.500 (86.301)
Epoch: [97][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2203 (2.3308)	Acc@1 59.375 (56.983)	Acc@5 89.062 (86.159)
Epoch: [97][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6757 (2.3472)	Acc@1 51.562 (56.645)	Acc@5 79.688 (85.834)
Epoch: [97][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2428 (2.3455)	Acc@1 64.062 (56.745)	Acc@5 86.719 (85.922)
Epoch: [97][110/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.1589 (2.3435)	Acc@1 64.844 (56.792)	Acc@5 87.500 (85.902)
Epoch: [97][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4284 (2.3463)	Acc@1 52.344 (56.721)	Acc@5 89.844 (85.918)
Epoch: [97][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4010 (2.3555)	Acc@1 54.688 (56.542)	Acc@5 84.375 (85.711)
Epoch: [97][140/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6418 (2.3622)	Acc@1 49.219 (56.328)	Acc@5 82.812 (85.577)
Epoch: [97][150/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5852 (2.3709)	Acc@1 45.312 (56.126)	Acc@5 85.156 (85.430)
Epoch: [97][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5233 (2.3776)	Acc@1 54.688 (55.901)	Acc@5 87.500 (85.355)
Epoch: [97][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6730 (2.3840)	Acc@1 49.219 (55.766)	Acc@5 78.906 (85.193)
Epoch: [97][180/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4877 (2.3863)	Acc@1 53.125 (55.715)	Acc@5 85.156 (85.165)
Epoch: [97][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2942 (2.3914)	Acc@1 58.594 (55.669)	Acc@5 89.062 (85.119)
Epoch: [97][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2943 (2.3916)	Acc@1 59.375 (55.663)	Acc@5 85.156 (85.102)
Epoch: [97][210/391]	Time 0.012 (0.014)	Data 0.002 (0.002)	Loss 2.5482 (2.3957)	Acc@1 52.344 (55.576)	Acc@5 82.031 (84.964)
Epoch: [97][220/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2067 (2.3941)	Acc@1 59.375 (55.536)	Acc@5 87.500 (84.990)
Epoch: [97][230/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 2.7204 (2.3999)	Acc@1 51.562 (55.442)	Acc@5 82.031 (84.926)
Epoch: [97][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1208 (2.3999)	Acc@1 63.281 (55.521)	Acc@5 89.844 (84.897)
Epoch: [97][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7300 (2.3997)	Acc@1 46.875 (55.478)	Acc@5 80.469 (84.895)
Epoch: [97][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5798 (2.4049)	Acc@1 50.000 (55.373)	Acc@5 79.688 (84.821)
Epoch: [97][270/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5049 (2.4034)	Acc@1 50.000 (55.428)	Acc@5 80.469 (84.790)
Epoch: [97][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4533 (2.4033)	Acc@1 50.000 (55.463)	Acc@5 84.375 (84.817)
Epoch: [97][290/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3019 (2.4060)	Acc@1 55.469 (55.394)	Acc@5 85.156 (84.780)
Epoch: [97][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2419 (2.4074)	Acc@1 61.719 (55.381)	Acc@5 88.281 (84.738)
Epoch: [97][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3754 (2.4078)	Acc@1 56.250 (55.388)	Acc@5 88.281 (84.749)
Epoch: [97][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4154 (2.4086)	Acc@1 57.812 (55.396)	Acc@5 85.938 (84.747)
Epoch: [97][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5153 (2.4122)	Acc@1 52.344 (55.270)	Acc@5 79.688 (84.682)
Epoch: [97][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6389 (2.4168)	Acc@1 54.688 (55.185)	Acc@5 78.125 (84.590)
Epoch: [97][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1859 (2.4171)	Acc@1 57.812 (55.204)	Acc@5 91.406 (84.602)
Epoch: [97][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4615 (2.4164)	Acc@1 52.344 (55.231)	Acc@5 85.938 (84.561)
Epoch: [97][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4904 (2.4157)	Acc@1 48.438 (55.172)	Acc@5 83.594 (84.579)
Epoch: [97][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1570 (2.4136)	Acc@1 62.500 (55.223)	Acc@5 91.406 (84.635)
Epoch: [97][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.4894 (2.4169)	Acc@1 51.250 (55.142)	Acc@5 82.500 (84.582)
num momentum params: 26
[0.1, 2.4169276470947265, 2.1070886611938477, 55.142, 45.68, tensor(0.3310, device='cuda:0', grad_fn=<DivBackward0>), 5.282547473907471, 0.39262843132019043]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [98 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [98][0/391]	Time 0.054 (0.054)	Data 0.170 (0.170)	Loss 2.1573 (2.1573)	Acc@1 64.062 (64.062)	Acc@5 85.156 (85.156)
Epoch: [98][10/391]	Time 0.019 (0.019)	Data 0.001 (0.017)	Loss 2.3693 (2.3098)	Acc@1 61.719 (58.523)	Acc@5 84.375 (85.369)
Epoch: [98][20/391]	Time 0.014 (0.017)	Data 0.001 (0.009)	Loss 2.3190 (2.3090)	Acc@1 57.812 (58.296)	Acc@5 85.938 (85.975)
Epoch: [98][30/391]	Time 0.013 (0.016)	Data 0.001 (0.007)	Loss 2.2497 (2.3060)	Acc@1 57.812 (58.417)	Acc@5 83.594 (86.114)
Epoch: [98][40/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.3673 (2.3011)	Acc@1 51.562 (58.708)	Acc@5 84.375 (86.109)
Epoch: [98][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.6338 (2.3054)	Acc@1 44.531 (58.211)	Acc@5 83.594 (86.060)
Epoch: [98][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4289 (2.3155)	Acc@1 53.125 (57.787)	Acc@5 87.500 (86.027)
Epoch: [98][70/391]	Time 0.012 (0.014)	Data 0.002 (0.004)	Loss 2.2725 (2.3167)	Acc@1 57.812 (57.757)	Acc@5 86.719 (85.993)
Epoch: [98][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2109 (2.3195)	Acc@1 59.375 (57.639)	Acc@5 87.500 (85.899)
Epoch: [98][90/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3966 (2.3170)	Acc@1 60.156 (57.692)	Acc@5 82.031 (85.963)
Epoch: [98][100/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4107 (2.3208)	Acc@1 53.125 (57.611)	Acc@5 85.938 (85.883)
Epoch: [98][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3473 (2.3272)	Acc@1 56.250 (57.461)	Acc@5 82.812 (85.656)
Epoch: [98][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5713 (2.3344)	Acc@1 46.875 (57.296)	Acc@5 82.812 (85.544)
Epoch: [98][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4026 (2.3409)	Acc@1 58.594 (57.288)	Acc@5 85.156 (85.437)
Epoch: [98][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3713 (2.3384)	Acc@1 57.031 (57.258)	Acc@5 84.375 (85.511)
Epoch: [98][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3212 (2.3445)	Acc@1 52.344 (57.042)	Acc@5 84.375 (85.379)
Epoch: [98][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4842 (2.3478)	Acc@1 51.562 (56.978)	Acc@5 87.500 (85.389)
Epoch: [98][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2548 (2.3499)	Acc@1 57.031 (56.871)	Acc@5 87.500 (85.344)
Epoch: [98][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3177 (2.3561)	Acc@1 60.938 (56.811)	Acc@5 87.500 (85.221)
Epoch: [98][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6203 (2.3643)	Acc@1 51.562 (56.651)	Acc@5 80.469 (85.058)
Epoch: [98][200/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3247 (2.3651)	Acc@1 58.594 (56.604)	Acc@5 86.719 (85.047)
Epoch: [98][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4465 (2.3680)	Acc@1 57.031 (56.561)	Acc@5 83.594 (85.001)
Epoch: [98][220/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.0913 (2.3716)	Acc@1 67.188 (56.519)	Acc@5 89.062 (84.905)
Epoch: [98][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3335 (2.3763)	Acc@1 60.938 (56.433)	Acc@5 85.156 (84.825)
Epoch: [98][240/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5544 (2.3819)	Acc@1 53.125 (56.269)	Acc@5 82.812 (84.793)
Epoch: [98][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4600 (2.3880)	Acc@1 55.469 (56.154)	Acc@5 85.156 (84.717)
Epoch: [98][260/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6306 (2.3907)	Acc@1 45.312 (56.091)	Acc@5 81.250 (84.677)
Epoch: [98][270/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.1797 (2.3941)	Acc@1 60.156 (56.016)	Acc@5 88.281 (84.614)
Epoch: [98][280/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.1916 (2.3952)	Acc@1 62.500 (55.994)	Acc@5 88.281 (84.572)
Epoch: [98][290/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.2608 (2.3979)	Acc@1 57.812 (55.925)	Acc@5 86.719 (84.566)
Epoch: [98][300/391]	Time 0.014 (0.013)	Data 0.001 (0.002)	Loss 2.5198 (2.3986)	Acc@1 49.219 (55.871)	Acc@5 84.375 (84.575)
Epoch: [98][310/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3667 (2.4021)	Acc@1 57.812 (55.805)	Acc@5 87.500 (84.531)
Epoch: [98][320/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.5530 (2.4044)	Acc@1 54.688 (55.768)	Acc@5 81.250 (84.446)
Epoch: [98][330/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3595 (2.4043)	Acc@1 55.469 (55.740)	Acc@5 85.156 (84.479)
Epoch: [98][340/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.6557 (2.4078)	Acc@1 49.219 (55.680)	Acc@5 80.469 (84.414)
Epoch: [98][350/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.5881 (2.4100)	Acc@1 52.344 (55.638)	Acc@5 81.250 (84.353)
Epoch: [98][360/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.4905 (2.4110)	Acc@1 54.688 (55.599)	Acc@5 83.594 (84.347)
Epoch: [98][370/391]	Time 0.013 (0.013)	Data 0.001 (0.002)	Loss 2.3498 (2.4119)	Acc@1 56.250 (55.601)	Acc@5 83.594 (84.303)
Epoch: [98][380/391]	Time 0.013 (0.013)	Data 0.002 (0.002)	Loss 2.2224 (2.4120)	Acc@1 60.156 (55.563)	Acc@5 88.281 (84.285)
Epoch: [98][390/391]	Time 0.016 (0.013)	Data 0.001 (0.002)	Loss 2.5244 (2.4125)	Acc@1 55.000 (55.532)	Acc@5 82.500 (84.280)
num momentum params: 26
[0.1, 2.412520722808838, 2.0067775571346282, 55.532, 47.99, tensor(0.3311, device='cuda:0', grad_fn=<DivBackward0>), 5.245523929595947, 0.39483547210693354]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [99 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [99][0/391]	Time 0.054 (0.054)	Data 0.184 (0.184)	Loss 2.3998 (2.3998)	Acc@1 59.375 (59.375)	Acc@5 81.250 (81.250)
Epoch: [99][10/391]	Time 0.014 (0.020)	Data 0.004 (0.018)	Loss 2.1871 (2.3925)	Acc@1 58.594 (55.540)	Acc@5 88.281 (84.659)
Epoch: [99][20/391]	Time 0.014 (0.017)	Data 0.001 (0.010)	Loss 2.2678 (2.3676)	Acc@1 58.594 (56.362)	Acc@5 88.281 (85.007)
Epoch: [99][30/391]	Time 0.013 (0.016)	Data 0.001 (0.007)	Loss 2.4271 (2.3555)	Acc@1 51.562 (56.275)	Acc@5 84.375 (85.761)
Epoch: [99][40/391]	Time 0.013 (0.015)	Data 0.001 (0.006)	Loss 2.4822 (2.3593)	Acc@1 52.344 (56.136)	Acc@5 83.594 (85.633)
Epoch: [99][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.3910 (2.3452)	Acc@1 53.906 (56.219)	Acc@5 88.281 (85.983)
Epoch: [99][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3077 (2.3583)	Acc@1 60.938 (56.199)	Acc@5 82.812 (85.502)
Epoch: [99][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.2587 (2.3507)	Acc@1 61.719 (56.382)	Acc@5 85.156 (85.662)
Epoch: [99][80/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4125 (2.3674)	Acc@1 55.469 (56.038)	Acc@5 85.156 (85.378)
Epoch: [99][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2897 (2.3674)	Acc@1 60.938 (56.164)	Acc@5 83.594 (85.285)
Epoch: [99][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4430 (2.3751)	Acc@1 51.562 (56.018)	Acc@5 82.031 (85.125)
Epoch: [99][110/391]	Time 0.015 (0.014)	Data 0.002 (0.003)	Loss 2.1669 (2.3830)	Acc@1 59.375 (55.884)	Acc@5 89.844 (85.058)
Epoch: [99][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2702 (2.3799)	Acc@1 55.469 (55.985)	Acc@5 91.406 (85.021)
Epoch: [99][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5209 (2.3823)	Acc@1 54.688 (56.190)	Acc@5 85.156 (85.013)
Epoch: [99][140/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.7180 (2.3858)	Acc@1 48.438 (56.167)	Acc@5 82.031 (84.890)
Epoch: [99][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4060 (2.3921)	Acc@1 55.469 (56.115)	Acc@5 85.156 (84.748)
Epoch: [99][160/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3594 (2.3982)	Acc@1 58.594 (55.944)	Acc@5 85.938 (84.671)
Epoch: [99][170/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5549 (2.4021)	Acc@1 55.469 (55.866)	Acc@5 85.156 (84.654)
Epoch: [99][180/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4990 (2.4068)	Acc@1 55.469 (55.698)	Acc@5 83.594 (84.591)
Epoch: [99][190/391]	Time 0.018 (0.014)	Data 0.002 (0.002)	Loss 2.4591 (2.4039)	Acc@1 56.250 (55.706)	Acc@5 79.688 (84.620)
Epoch: [99][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4431 (2.4024)	Acc@1 56.250 (55.725)	Acc@5 84.375 (84.690)
Epoch: [99][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5136 (2.4028)	Acc@1 54.688 (55.761)	Acc@5 82.812 (84.686)
Epoch: [99][220/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.1040 (2.4051)	Acc@1 69.531 (55.720)	Acc@5 90.625 (84.619)
Epoch: [99][230/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4262 (2.4073)	Acc@1 57.812 (55.655)	Acc@5 84.375 (84.598)
Epoch: [99][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4529 (2.4073)	Acc@1 50.000 (55.660)	Acc@5 88.281 (84.602)
Epoch: [99][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5178 (2.4080)	Acc@1 53.906 (55.621)	Acc@5 81.250 (84.587)
Epoch: [99][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4241 (2.4090)	Acc@1 60.156 (55.663)	Acc@5 89.062 (84.570)
Epoch: [99][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5229 (2.4089)	Acc@1 54.688 (55.688)	Acc@5 80.469 (84.568)
Epoch: [99][280/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3240 (2.4094)	Acc@1 58.594 (55.672)	Acc@5 86.719 (84.572)
Epoch: [99][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4965 (2.4140)	Acc@1 53.125 (55.525)	Acc@5 82.812 (84.528)
Epoch: [99][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5529 (2.4166)	Acc@1 47.656 (55.458)	Acc@5 80.469 (84.450)
Epoch: [99][310/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3373 (2.4184)	Acc@1 54.688 (55.406)	Acc@5 86.719 (84.408)
Epoch: [99][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4391 (2.4171)	Acc@1 53.125 (55.444)	Acc@5 80.469 (84.409)
Epoch: [99][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7003 (2.4183)	Acc@1 49.219 (55.433)	Acc@5 78.125 (84.375)
Epoch: [99][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5026 (2.4184)	Acc@1 53.125 (55.460)	Acc@5 82.812 (84.368)
Epoch: [99][350/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3964 (2.4184)	Acc@1 57.031 (55.411)	Acc@5 88.281 (84.364)
Epoch: [99][360/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2403 (2.4156)	Acc@1 53.906 (55.425)	Acc@5 89.844 (84.440)
Epoch: [99][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5664 (2.4150)	Acc@1 53.906 (55.475)	Acc@5 81.250 (84.447)
Epoch: [99][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4132 (2.4154)	Acc@1 54.688 (55.479)	Acc@5 82.812 (84.418)
Epoch: [99][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.6377 (2.4172)	Acc@1 51.250 (55.402)	Acc@5 81.250 (84.372)
num momentum params: 26
[0.1, 2.4171736838531492, 2.020192703008652, 55.402, 47.97, tensor(0.3304, device='cuda:0', grad_fn=<DivBackward0>), 5.287565469741821, 0.4092755317687988]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [100 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [100][0/391]	Time 0.055 (0.055)	Data 0.164 (0.164)	Loss 2.4972 (2.4972)	Acc@1 53.906 (53.906)	Acc@5 83.594 (83.594)
Epoch: [100][10/391]	Time 0.014 (0.018)	Data 0.001 (0.016)	Loss 2.4364 (2.3801)	Acc@1 57.031 (57.315)	Acc@5 81.250 (82.812)
Epoch: [100][20/391]	Time 0.014 (0.016)	Data 0.001 (0.009)	Loss 2.1655 (2.3587)	Acc@1 57.812 (57.068)	Acc@5 88.281 (84.263)
Epoch: [100][30/391]	Time 0.014 (0.015)	Data 0.001 (0.007)	Loss 2.4308 (2.3510)	Acc@1 54.688 (57.434)	Acc@5 85.156 (85.081)
Epoch: [100][40/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.2244 (2.3461)	Acc@1 60.156 (57.279)	Acc@5 86.719 (85.328)
Epoch: [100][50/391]	Time 0.013 (0.015)	Data 0.002 (0.005)	Loss 2.4029 (2.3329)	Acc@1 54.688 (57.353)	Acc@5 87.500 (85.646)
Epoch: [100][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4296 (2.3322)	Acc@1 53.125 (57.415)	Acc@5 85.156 (85.502)
Epoch: [100][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.0043 (2.3260)	Acc@1 67.969 (57.526)	Acc@5 92.188 (85.640)
Epoch: [100][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2743 (2.3289)	Acc@1 59.375 (57.591)	Acc@5 85.156 (85.581)
Epoch: [100][90/391]	Time 0.016 (0.014)	Data 0.002 (0.003)	Loss 2.0436 (2.3332)	Acc@1 64.062 (57.400)	Acc@5 90.625 (85.663)
Epoch: [100][100/391]	Time 0.016 (0.014)	Data 0.001 (0.003)	Loss 2.7366 (2.3413)	Acc@1 51.562 (57.317)	Acc@5 78.906 (85.497)
Epoch: [100][110/391]	Time 0.011 (0.014)	Data 0.001 (0.003)	Loss 2.4191 (2.3395)	Acc@1 57.812 (57.285)	Acc@5 82.031 (85.550)
Epoch: [100][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5346 (2.3462)	Acc@1 56.250 (57.238)	Acc@5 81.250 (85.479)
Epoch: [100][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3694 (2.3446)	Acc@1 52.344 (57.085)	Acc@5 85.156 (85.556)
Epoch: [100][140/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2415 (2.3426)	Acc@1 57.812 (57.053)	Acc@5 85.938 (85.600)
Epoch: [100][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3354 (2.3505)	Acc@1 54.688 (56.886)	Acc@5 85.938 (85.487)
Epoch: [100][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5413 (2.3506)	Acc@1 53.125 (56.842)	Acc@5 80.469 (85.447)
Epoch: [100][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2333 (2.3527)	Acc@1 59.375 (56.753)	Acc@5 89.062 (85.357)
Epoch: [100][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4155 (2.3538)	Acc@1 56.250 (56.790)	Acc@5 87.500 (85.299)
Epoch: [100][190/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3421 (2.3602)	Acc@1 59.375 (56.606)	Acc@5 87.500 (85.230)
Epoch: [100][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5820 (2.3632)	Acc@1 49.219 (56.569)	Acc@5 79.688 (85.215)
Epoch: [100][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5020 (2.3670)	Acc@1 49.219 (56.483)	Acc@5 83.594 (85.130)
Epoch: [100][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3151 (2.3694)	Acc@1 55.469 (56.437)	Acc@5 84.375 (85.086)
Epoch: [100][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4091 (2.3710)	Acc@1 53.906 (56.453)	Acc@5 88.281 (85.062)
Epoch: [100][240/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5248 (2.3731)	Acc@1 55.469 (56.367)	Acc@5 83.594 (85.027)
Epoch: [100][250/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2960 (2.3740)	Acc@1 57.031 (56.306)	Acc@5 83.594 (85.066)
Epoch: [100][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5373 (2.3779)	Acc@1 47.656 (56.184)	Acc@5 81.250 (85.013)
Epoch: [100][270/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3826 (2.3789)	Acc@1 54.688 (56.149)	Acc@5 86.719 (85.018)
Epoch: [100][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6183 (2.3818)	Acc@1 54.688 (56.103)	Acc@5 79.688 (84.973)
Epoch: [100][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4828 (2.3847)	Acc@1 51.562 (56.022)	Acc@5 82.812 (84.928)
Epoch: [100][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5741 (2.3861)	Acc@1 51.562 (56.032)	Acc@5 82.812 (84.894)
Epoch: [100][310/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6309 (2.3897)	Acc@1 52.344 (55.966)	Acc@5 80.469 (84.812)
Epoch: [100][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3684 (2.3892)	Acc@1 55.469 (56.016)	Acc@5 88.281 (84.798)
Epoch: [100][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5666 (2.3927)	Acc@1 49.219 (55.946)	Acc@5 83.594 (84.769)
Epoch: [100][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2693 (2.3948)	Acc@1 57.812 (55.895)	Acc@5 90.625 (84.760)
Epoch: [100][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4381 (2.3961)	Acc@1 59.375 (55.878)	Acc@5 83.594 (84.720)
Epoch: [100][360/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2826 (2.3978)	Acc@1 51.562 (55.834)	Acc@5 86.719 (84.706)
Epoch: [100][370/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6099 (2.4003)	Acc@1 50.781 (55.806)	Acc@5 82.812 (84.640)
Epoch: [100][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5993 (2.4062)	Acc@1 46.875 (55.653)	Acc@5 82.812 (84.547)
Epoch: [100][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.6880 (2.4080)	Acc@1 43.750 (55.560)	Acc@5 81.250 (84.520)
num momentum params: 26
[0.1, 2.4080178332519533, 2.0527220594882967, 55.56, 47.65, tensor(0.3313, device='cuda:0', grad_fn=<DivBackward0>), 5.305278539657593, 0.4042999744415283]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [101 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [101][0/391]	Time 0.048 (0.048)	Data 0.165 (0.165)	Loss 1.9471 (1.9471)	Acc@1 66.406 (66.406)	Acc@5 89.844 (89.844)
Epoch: [101][10/391]	Time 0.014 (0.019)	Data 0.002 (0.016)	Loss 2.3028 (2.2260)	Acc@1 53.906 (59.872)	Acc@5 84.375 (86.790)
Epoch: [101][20/391]	Time 0.013 (0.016)	Data 0.001 (0.009)	Loss 2.4599 (2.2811)	Acc@1 55.469 (58.445)	Acc@5 83.594 (86.421)
Epoch: [101][30/391]	Time 0.015 (0.016)	Data 0.001 (0.007)	Loss 2.1434 (2.2953)	Acc@1 59.375 (58.165)	Acc@5 85.156 (86.038)
Epoch: [101][40/391]	Time 0.013 (0.015)	Data 0.001 (0.006)	Loss 2.8434 (2.3445)	Acc@1 46.875 (56.879)	Acc@5 75.781 (85.290)
Epoch: [101][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.2154 (2.3525)	Acc@1 58.594 (56.526)	Acc@5 87.500 (85.294)
Epoch: [101][60/391]	Time 0.015 (0.015)	Data 0.001 (0.004)	Loss 2.0275 (2.3384)	Acc@1 68.750 (57.070)	Acc@5 91.406 (85.476)
Epoch: [101][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4662 (2.3395)	Acc@1 53.906 (56.965)	Acc@5 82.031 (85.409)
Epoch: [101][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2975 (2.3466)	Acc@1 66.406 (56.964)	Acc@5 82.031 (85.262)
Epoch: [101][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3833 (2.3499)	Acc@1 53.125 (56.817)	Acc@5 82.812 (85.285)
Epoch: [101][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.2390 (2.3530)	Acc@1 61.719 (56.761)	Acc@5 85.938 (85.164)
Epoch: [101][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6252 (2.3589)	Acc@1 51.562 (56.637)	Acc@5 75.000 (85.093)
Epoch: [101][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2335 (2.3554)	Acc@1 58.594 (56.728)	Acc@5 87.500 (85.092)
Epoch: [101][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5567 (2.3550)	Acc@1 52.344 (56.733)	Acc@5 82.812 (85.103)
Epoch: [101][140/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.2619 (2.3619)	Acc@1 58.594 (56.483)	Acc@5 88.281 (85.079)
Epoch: [101][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5201 (2.3699)	Acc@1 51.562 (56.333)	Acc@5 80.469 (84.949)
Epoch: [101][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5400 (2.3788)	Acc@1 50.000 (56.075)	Acc@5 82.812 (84.846)
Epoch: [101][170/391]	Time 0.012 (0.014)	Data 0.002 (0.002)	Loss 2.2850 (2.3832)	Acc@1 57.812 (55.944)	Acc@5 88.281 (84.759)
Epoch: [101][180/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5459 (2.3826)	Acc@1 54.688 (55.965)	Acc@5 80.469 (84.776)
Epoch: [101][190/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3296 (2.3845)	Acc@1 51.562 (55.943)	Acc@5 85.938 (84.764)
Epoch: [101][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4467 (2.3837)	Acc@1 59.375 (56.098)	Acc@5 82.812 (84.771)
Epoch: [101][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2789 (2.3849)	Acc@1 56.250 (56.087)	Acc@5 86.719 (84.730)
Epoch: [101][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4194 (2.3837)	Acc@1 54.688 (56.116)	Acc@5 85.938 (84.764)
Epoch: [101][230/391]	Time 0.012 (0.014)	Data 0.002 (0.002)	Loss 2.2459 (2.3804)	Acc@1 55.469 (56.138)	Acc@5 92.188 (84.842)
Epoch: [101][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2337 (2.3801)	Acc@1 62.500 (56.162)	Acc@5 85.938 (84.809)
Epoch: [101][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4945 (2.3821)	Acc@1 50.781 (56.116)	Acc@5 81.250 (84.805)
Epoch: [101][260/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4289 (2.3813)	Acc@1 54.688 (56.133)	Acc@5 84.375 (84.830)
Epoch: [101][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6044 (2.3823)	Acc@1 50.781 (56.123)	Acc@5 84.375 (84.810)
Epoch: [101][280/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3076 (2.3849)	Acc@1 58.594 (56.089)	Acc@5 82.812 (84.731)
Epoch: [101][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6756 (2.3866)	Acc@1 46.875 (56.067)	Acc@5 82.812 (84.678)
Epoch: [101][300/391]	Time 0.011 (0.014)	Data 0.019 (0.002)	Loss 2.4350 (2.3905)	Acc@1 51.562 (55.996)	Acc@5 85.938 (84.627)
Epoch: [101][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3513 (2.3927)	Acc@1 53.125 (55.966)	Acc@5 85.938 (84.589)
Epoch: [101][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4705 (2.3911)	Acc@1 48.438 (55.987)	Acc@5 83.594 (84.655)
Epoch: [101][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2457 (2.3916)	Acc@1 61.719 (55.981)	Acc@5 85.156 (84.628)
Epoch: [101][340/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5362 (2.3943)	Acc@1 57.812 (55.886)	Acc@5 83.594 (84.611)
Epoch: [101][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5296 (2.3938)	Acc@1 55.469 (55.914)	Acc@5 83.594 (84.611)
Epoch: [101][360/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2891 (2.3945)	Acc@1 60.156 (55.867)	Acc@5 85.156 (84.587)
Epoch: [101][370/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5020 (2.3949)	Acc@1 55.469 (55.863)	Acc@5 82.031 (84.577)
Epoch: [101][380/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5361 (2.3961)	Acc@1 53.906 (55.834)	Acc@5 81.250 (84.566)
Epoch: [101][390/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 2.4774 (2.3984)	Acc@1 52.500 (55.770)	Acc@5 80.000 (84.550)
num momentum params: 26
[0.1, 2.3984329403686524, 1.9596861982345581, 55.77, 48.14, tensor(0.3330, device='cuda:0', grad_fn=<DivBackward0>), 5.327036619186401, 0.4142835140228272]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [102 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [102][0/391]	Time 0.059 (0.059)	Data 0.182 (0.182)	Loss 2.4133 (2.4133)	Acc@1 56.250 (56.250)	Acc@5 85.156 (85.156)
Epoch: [102][10/391]	Time 0.014 (0.019)	Data 0.002 (0.018)	Loss 2.0038 (2.2635)	Acc@1 64.844 (58.594)	Acc@5 93.750 (86.790)
Epoch: [102][20/391]	Time 0.013 (0.017)	Data 0.001 (0.010)	Loss 2.0579 (2.2677)	Acc@1 61.719 (58.668)	Acc@5 91.406 (86.868)
Epoch: [102][30/391]	Time 0.012 (0.016)	Data 0.002 (0.007)	Loss 2.1983 (2.2837)	Acc@1 60.156 (58.191)	Acc@5 88.281 (86.870)
Epoch: [102][40/391]	Time 0.013 (0.015)	Data 0.001 (0.006)	Loss 2.2723 (2.2995)	Acc@1 58.594 (57.603)	Acc@5 88.281 (86.833)
Epoch: [102][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.3007 (2.3066)	Acc@1 57.812 (57.552)	Acc@5 84.375 (86.458)
Epoch: [102][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.2209 (2.3308)	Acc@1 64.062 (57.134)	Acc@5 85.938 (85.950)
Epoch: [102][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.5383 (2.3374)	Acc@1 53.125 (57.295)	Acc@5 78.125 (85.574)
Epoch: [102][80/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.5224 (2.3424)	Acc@1 57.031 (57.292)	Acc@5 82.031 (85.561)
Epoch: [102][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2660 (2.3452)	Acc@1 59.375 (57.220)	Acc@5 89.062 (85.534)
Epoch: [102][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3623 (2.3416)	Acc@1 58.594 (57.271)	Acc@5 85.938 (85.628)
Epoch: [102][110/391]	Time 0.016 (0.014)	Data 0.002 (0.003)	Loss 2.4341 (2.3459)	Acc@1 53.906 (57.179)	Acc@5 85.156 (85.579)
Epoch: [102][120/391]	Time 0.016 (0.014)	Data 0.000 (0.003)	Loss 2.4425 (2.3496)	Acc@1 57.031 (57.031)	Acc@5 80.469 (85.473)
Epoch: [102][130/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4804 (2.3537)	Acc@1 59.375 (56.995)	Acc@5 82.031 (85.371)
Epoch: [102][140/391]	Time 0.015 (0.014)	Data 0.003 (0.003)	Loss 2.2801 (2.3633)	Acc@1 61.719 (56.843)	Acc@5 85.938 (85.234)
Epoch: [102][150/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.1410 (2.3690)	Acc@1 68.750 (56.809)	Acc@5 86.719 (85.182)
Epoch: [102][160/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.2582 (2.3724)	Acc@1 64.844 (56.827)	Acc@5 84.375 (85.045)
Epoch: [102][170/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.5227 (2.3767)	Acc@1 50.781 (56.574)	Acc@5 80.469 (85.010)
Epoch: [102][180/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5166 (2.3789)	Acc@1 50.000 (56.518)	Acc@5 85.938 (85.040)
Epoch: [102][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5953 (2.3869)	Acc@1 48.438 (56.315)	Acc@5 81.250 (84.903)
Epoch: [102][200/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.2788 (2.3888)	Acc@1 54.688 (56.238)	Acc@5 89.062 (84.853)
Epoch: [102][210/391]	Time 0.012 (0.014)	Data 0.002 (0.002)	Loss 2.4286 (2.3842)	Acc@1 55.469 (56.387)	Acc@5 85.156 (84.934)
Epoch: [102][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2269 (2.3834)	Acc@1 58.594 (56.367)	Acc@5 89.062 (84.944)
Epoch: [102][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3642 (2.3834)	Acc@1 55.469 (56.406)	Acc@5 85.156 (84.852)
Epoch: [102][240/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6817 (2.3853)	Acc@1 49.219 (56.386)	Acc@5 81.250 (84.852)
Epoch: [102][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5720 (2.3900)	Acc@1 48.438 (56.297)	Acc@5 82.031 (84.761)
Epoch: [102][260/391]	Time 0.012 (0.014)	Data 0.003 (0.002)	Loss 2.4473 (2.3929)	Acc@1 49.219 (56.238)	Acc@5 86.719 (84.692)
Epoch: [102][270/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6733 (2.3977)	Acc@1 48.438 (56.123)	Acc@5 82.031 (84.597)
Epoch: [102][280/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4505 (2.4002)	Acc@1 56.250 (56.072)	Acc@5 86.719 (84.556)
Epoch: [102][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5522 (2.4024)	Acc@1 52.344 (56.022)	Acc@5 82.812 (84.533)
Epoch: [102][300/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5060 (2.4053)	Acc@1 53.906 (55.905)	Acc@5 78.125 (84.479)
Epoch: [102][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4345 (2.4062)	Acc@1 53.906 (55.876)	Acc@5 83.594 (84.478)
Epoch: [102][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7016 (2.4089)	Acc@1 42.188 (55.783)	Acc@5 85.156 (84.482)
Epoch: [102][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3208 (2.4084)	Acc@1 57.812 (55.785)	Acc@5 82.812 (84.484)
Epoch: [102][340/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3806 (2.4114)	Acc@1 55.469 (55.677)	Acc@5 85.938 (84.446)
Epoch: [102][350/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.4646 (2.4127)	Acc@1 55.469 (55.620)	Acc@5 84.375 (84.433)
Epoch: [102][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2856 (2.4137)	Acc@1 57.812 (55.538)	Acc@5 84.375 (84.401)
Epoch: [102][370/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4061 (2.4156)	Acc@1 62.500 (55.513)	Acc@5 79.688 (84.358)
Epoch: [102][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4488 (2.4156)	Acc@1 51.562 (55.481)	Acc@5 86.719 (84.354)
Epoch: [102][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.4513 (2.4141)	Acc@1 52.500 (55.530)	Acc@5 82.500 (84.374)
num momentum params: 26
[0.1, 2.4141018505096437, 1.9377028524875641, 55.53, 48.81, tensor(0.3309, device='cuda:0', grad_fn=<DivBackward0>), 5.515389680862427, 0.4086792469024658]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [103 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [103][0/391]	Time 0.059 (0.059)	Data 0.168 (0.168)	Loss 2.4498 (2.4498)	Acc@1 53.125 (53.125)	Acc@5 82.812 (82.812)
Epoch: [103][10/391]	Time 0.014 (0.019)	Data 0.001 (0.017)	Loss 2.4589 (2.2924)	Acc@1 50.781 (58.097)	Acc@5 86.719 (86.506)
Epoch: [103][20/391]	Time 0.018 (0.016)	Data 0.001 (0.009)	Loss 2.4584 (2.2607)	Acc@1 53.906 (58.445)	Acc@5 86.719 (87.574)
Epoch: [103][30/391]	Time 0.014 (0.016)	Data 0.002 (0.007)	Loss 2.3643 (2.2679)	Acc@1 58.594 (58.493)	Acc@5 84.375 (87.273)
Epoch: [103][40/391]	Time 0.013 (0.015)	Data 0.001 (0.006)	Loss 2.5029 (2.2951)	Acc@1 57.031 (58.003)	Acc@5 81.250 (86.833)
Epoch: [103][50/391]	Time 0.010 (0.015)	Data 0.001 (0.005)	Loss 2.5056 (2.2978)	Acc@1 53.906 (57.996)	Acc@5 81.250 (86.458)
Epoch: [103][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.2335 (2.2981)	Acc@1 60.156 (58.120)	Acc@5 88.281 (86.373)
Epoch: [103][70/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 2.2940 (2.3024)	Acc@1 62.500 (57.846)	Acc@5 85.156 (86.235)
Epoch: [103][80/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3092 (2.3094)	Acc@1 60.156 (57.745)	Acc@5 84.375 (86.044)
Epoch: [103][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3894 (2.3086)	Acc@1 50.000 (57.632)	Acc@5 85.156 (86.204)
Epoch: [103][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.1834 (2.3124)	Acc@1 64.062 (57.666)	Acc@5 88.281 (86.193)
Epoch: [103][110/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.6062 (2.3235)	Acc@1 46.875 (57.411)	Acc@5 83.594 (86.071)
Epoch: [103][120/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.2636 (2.3238)	Acc@1 57.031 (57.399)	Acc@5 85.938 (86.092)
Epoch: [103][130/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.7039 (2.3359)	Acc@1 53.125 (57.204)	Acc@5 81.250 (85.896)
Epoch: [103][140/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5668 (2.3409)	Acc@1 52.344 (57.103)	Acc@5 83.594 (85.805)
Epoch: [103][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3808 (2.3380)	Acc@1 53.125 (57.176)	Acc@5 87.500 (85.881)
Epoch: [103][160/391]	Time 0.012 (0.014)	Data 0.001 (0.003)	Loss 2.4523 (2.3451)	Acc@1 53.906 (57.128)	Acc@5 81.250 (85.666)
Epoch: [103][170/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.2791 (2.3516)	Acc@1 60.156 (57.040)	Acc@5 85.938 (85.622)
Epoch: [103][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3225 (2.3531)	Acc@1 60.938 (56.971)	Acc@5 87.500 (85.609)
Epoch: [103][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5216 (2.3594)	Acc@1 51.562 (56.814)	Acc@5 85.156 (85.500)
Epoch: [103][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.8900 (2.3651)	Acc@1 39.062 (56.608)	Acc@5 75.000 (85.448)
Epoch: [103][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3149 (2.3663)	Acc@1 56.250 (56.646)	Acc@5 88.281 (85.412)
Epoch: [103][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1693 (2.3702)	Acc@1 60.938 (56.561)	Acc@5 85.938 (85.315)
Epoch: [103][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4739 (2.3726)	Acc@1 52.344 (56.504)	Acc@5 83.594 (85.285)
Epoch: [103][240/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.1834 (2.3728)	Acc@1 60.938 (56.522)	Acc@5 86.719 (85.234)
Epoch: [103][250/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5177 (2.3766)	Acc@1 53.125 (56.421)	Acc@5 81.250 (85.144)
Epoch: [103][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1513 (2.3784)	Acc@1 60.938 (56.358)	Acc@5 85.938 (85.057)
Epoch: [103][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3735 (2.3796)	Acc@1 57.031 (56.319)	Acc@5 84.375 (85.029)
Epoch: [103][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5182 (2.3828)	Acc@1 56.250 (56.261)	Acc@5 85.938 (85.014)
Epoch: [103][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4683 (2.3862)	Acc@1 51.562 (56.161)	Acc@5 82.812 (84.950)
Epoch: [103][300/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.5433 (2.3898)	Acc@1 50.781 (56.037)	Acc@5 78.906 (84.956)
Epoch: [103][310/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3787 (2.3922)	Acc@1 56.250 (55.931)	Acc@5 86.719 (84.945)
Epoch: [103][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6396 (2.3946)	Acc@1 52.344 (55.875)	Acc@5 79.688 (84.920)
Epoch: [103][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1848 (2.3938)	Acc@1 58.594 (55.882)	Acc@5 86.719 (84.941)
Epoch: [103][340/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6121 (2.3923)	Acc@1 54.688 (55.904)	Acc@5 80.469 (84.971)
Epoch: [103][350/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.5471 (2.3929)	Acc@1 53.906 (55.869)	Acc@5 80.469 (84.934)
Epoch: [103][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4246 (2.3927)	Acc@1 59.375 (55.902)	Acc@5 82.812 (84.929)
Epoch: [103][370/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.1863 (2.3927)	Acc@1 64.844 (55.928)	Acc@5 85.156 (84.941)
Epoch: [103][380/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.1532 (2.3922)	Acc@1 64.844 (55.938)	Acc@5 88.281 (84.906)
Epoch: [103][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.6553 (2.3944)	Acc@1 51.250 (55.868)	Acc@5 81.250 (84.874)
num momentum params: 26
[0.1, 2.394408037338257, 2.1252106761932374, 55.868, 46.24, tensor(0.3332, device='cuda:0', grad_fn=<DivBackward0>), 5.3580451011657715, 0.4010746479034424]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [104 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [104][0/391]	Time 0.060 (0.060)	Data 0.189 (0.189)	Loss 2.3487 (2.3487)	Acc@1 56.250 (56.250)	Acc@5 86.719 (86.719)
Epoch: [104][10/391]	Time 0.015 (0.021)	Data 0.002 (0.018)	Loss 2.4593 (2.3322)	Acc@1 56.250 (57.528)	Acc@5 83.594 (85.866)
Epoch: [104][20/391]	Time 0.014 (0.018)	Data 0.002 (0.010)	Loss 2.6220 (2.3637)	Acc@1 50.781 (56.622)	Acc@5 83.594 (85.900)
Epoch: [104][30/391]	Time 0.013 (0.017)	Data 0.001 (0.008)	Loss 2.4706 (2.3663)	Acc@1 53.125 (56.653)	Acc@5 81.250 (85.988)
Epoch: [104][40/391]	Time 0.013 (0.016)	Data 0.001 (0.006)	Loss 2.4141 (2.3683)	Acc@1 55.469 (56.383)	Acc@5 84.375 (85.671)
Epoch: [104][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.4640 (2.3655)	Acc@1 56.250 (56.618)	Acc@5 83.594 (85.631)
Epoch: [104][60/391]	Time 0.014 (0.015)	Data 0.001 (0.005)	Loss 2.6788 (2.3624)	Acc@1 48.438 (56.481)	Acc@5 77.344 (85.566)
Epoch: [104][70/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 2.6527 (2.3764)	Acc@1 51.562 (56.250)	Acc@5 76.562 (85.222)
Epoch: [104][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.4556 (2.3847)	Acc@1 56.250 (56.163)	Acc@5 84.375 (85.147)
Epoch: [104][90/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.3906 (2.3881)	Acc@1 57.031 (56.018)	Acc@5 85.938 (85.096)
Epoch: [104][100/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.6419 (2.3911)	Acc@1 44.531 (55.786)	Acc@5 80.469 (85.017)
Epoch: [104][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2181 (2.3887)	Acc@1 60.156 (55.750)	Acc@5 89.062 (85.220)
Epoch: [104][120/391]	Time 0.017 (0.014)	Data 0.001 (0.003)	Loss 2.3173 (2.3876)	Acc@1 57.812 (55.637)	Acc@5 89.062 (85.201)
Epoch: [104][130/391]	Time 0.012 (0.014)	Data 0.002 (0.003)	Loss 2.2540 (2.3841)	Acc@1 60.156 (55.707)	Acc@5 88.281 (85.281)
Epoch: [104][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6538 (2.3879)	Acc@1 53.125 (55.696)	Acc@5 77.344 (85.195)
Epoch: [104][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5463 (2.3905)	Acc@1 57.031 (55.727)	Acc@5 82.031 (85.151)
Epoch: [104][160/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4645 (2.3939)	Acc@1 54.688 (55.566)	Acc@5 80.469 (85.142)
Epoch: [104][170/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.7371 (2.4022)	Acc@1 51.562 (55.473)	Acc@5 83.594 (85.019)
Epoch: [104][180/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5692 (2.4042)	Acc@1 48.438 (55.443)	Acc@5 81.250 (84.940)
Epoch: [104][190/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4329 (2.3990)	Acc@1 56.250 (55.661)	Acc@5 79.688 (84.964)
Epoch: [104][200/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2369 (2.3989)	Acc@1 60.156 (55.648)	Acc@5 85.938 (85.012)
Epoch: [104][210/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.3358 (2.4001)	Acc@1 57.812 (55.654)	Acc@5 82.031 (84.953)
Epoch: [104][220/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.2592 (2.3980)	Acc@1 62.500 (55.706)	Acc@5 82.812 (84.958)
Epoch: [104][230/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.8394 (2.3954)	Acc@1 44.531 (55.739)	Acc@5 80.469 (85.014)
Epoch: [104][240/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3487 (2.3952)	Acc@1 60.156 (55.809)	Acc@5 81.250 (84.994)
Epoch: [104][250/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4213 (2.3980)	Acc@1 58.594 (55.845)	Acc@5 84.375 (84.935)
Epoch: [104][260/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.2672 (2.3968)	Acc@1 59.375 (55.837)	Acc@5 82.031 (84.911)
Epoch: [104][270/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.7816 (2.4024)	Acc@1 43.750 (55.717)	Acc@5 76.562 (84.784)
Epoch: [104][280/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3964 (2.4015)	Acc@1 53.906 (55.758)	Acc@5 85.156 (84.778)
Epoch: [104][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6140 (2.4047)	Acc@1 49.219 (55.684)	Acc@5 80.469 (84.686)
Epoch: [104][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3390 (2.4071)	Acc@1 60.156 (55.663)	Acc@5 82.812 (84.640)
Epoch: [104][310/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6105 (2.4080)	Acc@1 53.125 (55.624)	Acc@5 78.906 (84.594)
Epoch: [104][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3324 (2.4094)	Acc@1 60.156 (55.600)	Acc@5 83.594 (84.592)
Epoch: [104][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2855 (2.4103)	Acc@1 58.594 (55.582)	Acc@5 83.594 (84.564)
Epoch: [104][340/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2079 (2.4093)	Acc@1 62.500 (55.611)	Acc@5 87.500 (84.597)
Epoch: [104][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3659 (2.4113)	Acc@1 55.469 (55.549)	Acc@5 86.719 (84.540)
Epoch: [104][360/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2833 (2.4114)	Acc@1 60.938 (55.521)	Acc@5 83.594 (84.552)
Epoch: [104][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3154 (2.4108)	Acc@1 60.156 (55.568)	Acc@5 84.375 (84.525)
Epoch: [104][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4646 (2.4118)	Acc@1 55.469 (55.571)	Acc@5 82.812 (84.475)
Epoch: [104][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.2057 (2.4114)	Acc@1 70.000 (55.594)	Acc@5 88.750 (84.482)
num momentum params: 26
[0.1, 2.4114002893829345, 1.9957880568504334, 55.594, 47.96, tensor(0.3309, device='cuda:0', grad_fn=<DivBackward0>), 5.451411724090576, 0.4255197048187256]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [105 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [105][0/391]	Time 0.059 (0.059)	Data 0.176 (0.176)	Loss 2.2529 (2.2529)	Acc@1 61.719 (61.719)	Acc@5 83.594 (83.594)
Epoch: [105][10/391]	Time 0.013 (0.019)	Data 0.001 (0.018)	Loss 2.6329 (2.2734)	Acc@1 50.000 (58.736)	Acc@5 82.031 (86.861)
Epoch: [105][20/391]	Time 0.013 (0.016)	Data 0.001 (0.010)	Loss 2.1063 (2.2560)	Acc@1 61.719 (59.226)	Acc@5 89.062 (86.719)
Epoch: [105][30/391]	Time 0.013 (0.015)	Data 0.001 (0.007)	Loss 2.2125 (2.2659)	Acc@1 59.375 (58.921)	Acc@5 87.500 (86.568)
Epoch: [105][40/391]	Time 0.013 (0.015)	Data 0.002 (0.006)	Loss 2.4781 (2.2619)	Acc@1 54.688 (59.032)	Acc@5 81.250 (86.757)
Epoch: [105][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.1463 (2.2846)	Acc@1 59.375 (58.195)	Acc@5 90.625 (86.734)
Epoch: [105][60/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4834 (2.2914)	Acc@1 55.469 (58.030)	Acc@5 85.156 (86.539)
Epoch: [105][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3989 (2.3019)	Acc@1 55.469 (57.868)	Acc@5 87.500 (86.378)
Epoch: [105][80/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.2198 (2.2973)	Acc@1 57.031 (58.044)	Acc@5 90.625 (86.497)
Epoch: [105][90/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3848 (2.3017)	Acc@1 54.688 (58.087)	Acc@5 85.156 (86.478)
Epoch: [105][100/391]	Time 0.019 (0.014)	Data 0.001 (0.003)	Loss 2.5010 (2.3072)	Acc@1 50.000 (57.905)	Acc@5 83.594 (86.409)
Epoch: [105][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3953 (2.3230)	Acc@1 57.031 (57.489)	Acc@5 85.156 (86.233)
Epoch: [105][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4348 (2.3298)	Acc@1 57.031 (57.380)	Acc@5 85.938 (86.086)
Epoch: [105][130/391]	Time 0.016 (0.014)	Data 0.001 (0.003)	Loss 2.4812 (2.3360)	Acc@1 53.125 (57.097)	Acc@5 85.156 (85.902)
Epoch: [105][140/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3453 (2.3389)	Acc@1 60.156 (56.932)	Acc@5 82.812 (85.871)
Epoch: [105][150/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.6753 (2.3457)	Acc@1 53.125 (56.871)	Acc@5 81.250 (85.756)
Epoch: [105][160/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4446 (2.3542)	Acc@1 57.812 (56.755)	Acc@5 83.594 (85.675)
Epoch: [105][170/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.5415 (2.3576)	Acc@1 53.906 (56.670)	Acc@5 79.688 (85.618)
Epoch: [105][180/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5285 (2.3606)	Acc@1 50.000 (56.621)	Acc@5 83.594 (85.553)
Epoch: [105][190/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3995 (2.3634)	Acc@1 60.938 (56.622)	Acc@5 88.281 (85.475)
Epoch: [105][200/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2990 (2.3627)	Acc@1 58.594 (56.670)	Acc@5 83.594 (85.471)
Epoch: [105][210/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.1712 (2.3656)	Acc@1 58.594 (56.631)	Acc@5 86.719 (85.386)
Epoch: [105][220/391]	Time 0.022 (0.014)	Data 0.001 (0.002)	Loss 2.3881 (2.3672)	Acc@1 57.031 (56.565)	Acc@5 84.375 (85.315)
Epoch: [105][230/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6034 (2.3677)	Acc@1 54.688 (56.592)	Acc@5 78.906 (85.278)
Epoch: [105][240/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 2.4100 (2.3669)	Acc@1 57.031 (56.516)	Acc@5 84.375 (85.331)
Epoch: [105][250/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2981 (2.3641)	Acc@1 59.375 (56.543)	Acc@5 84.375 (85.362)
Epoch: [105][260/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5900 (2.3679)	Acc@1 53.125 (56.463)	Acc@5 80.469 (85.288)
Epoch: [105][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5442 (2.3722)	Acc@1 52.344 (56.342)	Acc@5 82.031 (85.194)
Epoch: [105][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7398 (2.3771)	Acc@1 48.438 (56.275)	Acc@5 79.688 (85.120)
Epoch: [105][290/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5014 (2.3812)	Acc@1 53.125 (56.223)	Acc@5 85.938 (85.076)
Epoch: [105][300/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.7825 (2.3835)	Acc@1 46.875 (56.177)	Acc@5 81.250 (85.045)
Epoch: [105][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5246 (2.3853)	Acc@1 50.781 (56.119)	Acc@5 82.031 (84.975)
Epoch: [105][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5446 (2.3866)	Acc@1 50.000 (56.080)	Acc@5 82.031 (84.947)
Epoch: [105][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4913 (2.3895)	Acc@1 56.250 (55.997)	Acc@5 82.812 (84.885)
Epoch: [105][340/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6142 (2.3918)	Acc@1 50.781 (55.975)	Acc@5 80.469 (84.838)
Epoch: [105][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5147 (2.3932)	Acc@1 53.125 (55.907)	Acc@5 82.031 (84.813)
Epoch: [105][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5072 (2.3948)	Acc@1 51.562 (55.863)	Acc@5 79.688 (84.791)
Epoch: [105][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2283 (2.3942)	Acc@1 54.688 (55.844)	Acc@5 89.844 (84.798)
Epoch: [105][380/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.7294 (2.3961)	Acc@1 46.875 (55.785)	Acc@5 82.031 (84.767)
Epoch: [105][390/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 2.2657 (2.3986)	Acc@1 57.500 (55.728)	Acc@5 85.000 (84.706)
num momentum params: 26
[0.1, 2.398609889450073, 2.0395017981529238, 55.728, 47.82, tensor(0.3326, device='cuda:0', grad_fn=<DivBackward0>), 5.328018665313721, 0.4157218933105469]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [106 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [106][0/391]	Time 0.060 (0.060)	Data 0.161 (0.161)	Loss 2.2288 (2.2288)	Acc@1 56.250 (56.250)	Acc@5 89.844 (89.844)
Epoch: [106][10/391]	Time 0.015 (0.020)	Data 0.001 (0.016)	Loss 2.2869 (2.2476)	Acc@1 56.250 (58.097)	Acc@5 85.156 (86.719)
Epoch: [106][20/391]	Time 0.015 (0.017)	Data 0.002 (0.009)	Loss 2.2808 (2.3015)	Acc@1 57.812 (57.068)	Acc@5 88.281 (86.533)
Epoch: [106][30/391]	Time 0.011 (0.016)	Data 0.001 (0.007)	Loss 2.5343 (2.3177)	Acc@1 50.000 (57.107)	Acc@5 85.156 (86.341)
Epoch: [106][40/391]	Time 0.013 (0.016)	Data 0.001 (0.005)	Loss 2.3522 (2.3109)	Acc@1 55.469 (57.298)	Acc@5 83.594 (86.376)
Epoch: [106][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.3658 (2.3332)	Acc@1 54.688 (57.001)	Acc@5 86.719 (85.815)
Epoch: [106][60/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.5248 (2.3391)	Acc@1 52.344 (56.929)	Acc@5 85.156 (85.835)
Epoch: [106][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.7669 (2.3522)	Acc@1 48.438 (56.602)	Acc@5 78.906 (85.596)
Epoch: [106][80/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 2.3581 (2.3624)	Acc@1 62.500 (56.424)	Acc@5 84.375 (85.465)
Epoch: [106][90/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4708 (2.3672)	Acc@1 53.125 (56.542)	Acc@5 79.688 (85.311)
Epoch: [106][100/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.1100 (2.3649)	Acc@1 63.281 (56.528)	Acc@5 88.281 (85.442)
Epoch: [106][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.1736 (2.3572)	Acc@1 57.812 (56.560)	Acc@5 89.062 (85.564)
Epoch: [106][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4842 (2.3599)	Acc@1 54.688 (56.547)	Acc@5 85.156 (85.440)
Epoch: [106][130/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5307 (2.3611)	Acc@1 48.438 (56.447)	Acc@5 83.594 (85.448)
Epoch: [106][140/391]	Time 0.015 (0.014)	Data 0.002 (0.003)	Loss 2.7118 (2.3630)	Acc@1 55.469 (56.455)	Acc@5 78.125 (85.467)
Epoch: [106][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.7138 (2.3781)	Acc@1 50.000 (56.240)	Acc@5 79.688 (85.151)
Epoch: [106][160/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.5943 (2.3775)	Acc@1 52.344 (56.299)	Acc@5 82.812 (85.103)
Epoch: [106][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2164 (2.3794)	Acc@1 63.281 (56.273)	Acc@5 85.156 (85.042)
Epoch: [106][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1541 (2.3780)	Acc@1 64.844 (56.319)	Acc@5 88.281 (85.035)
Epoch: [106][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2679 (2.3805)	Acc@1 59.375 (56.287)	Acc@5 89.062 (84.960)
Epoch: [106][200/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5898 (2.3841)	Acc@1 52.344 (56.130)	Acc@5 78.906 (84.884)
Epoch: [106][210/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.6158 (2.3822)	Acc@1 46.094 (56.213)	Acc@5 82.812 (84.886)
Epoch: [106][220/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4651 (2.3832)	Acc@1 60.156 (56.232)	Acc@5 85.938 (84.888)
Epoch: [106][230/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.2883 (2.3832)	Acc@1 59.375 (56.247)	Acc@5 85.938 (84.903)
Epoch: [106][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3807 (2.3840)	Acc@1 55.469 (56.218)	Acc@5 85.156 (84.897)
Epoch: [106][250/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2672 (2.3850)	Acc@1 57.812 (56.228)	Acc@5 89.844 (84.885)
Epoch: [106][260/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4768 (2.3841)	Acc@1 52.344 (56.262)	Acc@5 83.594 (84.869)
Epoch: [106][270/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4687 (2.3830)	Acc@1 52.344 (56.250)	Acc@5 83.594 (84.897)
Epoch: [106][280/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4889 (2.3859)	Acc@1 53.906 (56.239)	Acc@5 82.812 (84.853)
Epoch: [106][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3617 (2.3885)	Acc@1 60.156 (56.215)	Acc@5 83.594 (84.783)
Epoch: [106][300/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5619 (2.3935)	Acc@1 50.000 (56.170)	Acc@5 80.469 (84.712)
Epoch: [106][310/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5875 (2.3964)	Acc@1 47.656 (56.099)	Acc@5 81.250 (84.689)
Epoch: [106][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3680 (2.3988)	Acc@1 57.031 (56.031)	Acc@5 84.375 (84.682)
Epoch: [106][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4038 (2.4006)	Acc@1 53.906 (55.964)	Acc@5 89.062 (84.684)
Epoch: [106][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5527 (2.4020)	Acc@1 50.781 (55.909)	Acc@5 85.156 (84.675)
Epoch: [106][350/391]	Time 0.011 (0.014)	Data 0.004 (0.002)	Loss 2.4639 (2.4044)	Acc@1 53.125 (55.838)	Acc@5 82.812 (84.640)
Epoch: [106][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7533 (2.4061)	Acc@1 42.969 (55.804)	Acc@5 77.344 (84.578)
Epoch: [106][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2512 (2.4061)	Acc@1 59.375 (55.833)	Acc@5 87.500 (84.562)
Epoch: [106][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3154 (2.4084)	Acc@1 61.719 (55.766)	Acc@5 83.594 (84.529)
Epoch: [106][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.4189 (2.4089)	Acc@1 52.500 (55.780)	Acc@5 86.250 (84.488)
num momentum params: 26
[0.1, 2.4089286512756347, 2.0385811018943785, 55.78, 47.04, tensor(0.3315, device='cuda:0', grad_fn=<DivBackward0>), 5.354486465454102, 0.3997056484222412]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [107 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [107][0/391]	Time 0.056 (0.056)	Data 0.160 (0.160)	Loss 2.2721 (2.2721)	Acc@1 57.031 (57.031)	Acc@5 89.844 (89.844)
Epoch: [107][10/391]	Time 0.014 (0.019)	Data 0.001 (0.016)	Loss 2.2351 (2.3414)	Acc@1 62.500 (56.463)	Acc@5 85.938 (86.364)
Epoch: [107][20/391]	Time 0.017 (0.017)	Data 0.001 (0.009)	Loss 2.1921 (2.3550)	Acc@1 66.406 (56.585)	Acc@5 87.500 (85.938)
Epoch: [107][30/391]	Time 0.013 (0.016)	Data 0.001 (0.007)	Loss 2.2798 (2.3413)	Acc@1 60.938 (57.283)	Acc@5 85.938 (85.685)
Epoch: [107][40/391]	Time 0.013 (0.015)	Data 0.002 (0.005)	Loss 2.1620 (2.3549)	Acc@1 59.375 (56.879)	Acc@5 92.188 (85.537)
Epoch: [107][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.4493 (2.3493)	Acc@1 55.469 (57.230)	Acc@5 88.281 (85.585)
Epoch: [107][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.2841 (2.3261)	Acc@1 58.594 (57.761)	Acc@5 88.281 (85.861)
Epoch: [107][70/391]	Time 0.015 (0.014)	Data 0.001 (0.004)	Loss 2.4141 (2.3322)	Acc@1 59.375 (57.812)	Acc@5 82.812 (85.673)
Epoch: [107][80/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.5016 (2.3270)	Acc@1 50.781 (57.716)	Acc@5 83.594 (85.812)
Epoch: [107][90/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.4063 (2.3353)	Acc@1 54.688 (57.340)	Acc@5 83.594 (85.680)
Epoch: [107][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.1695 (2.3374)	Acc@1 60.156 (57.287)	Acc@5 89.844 (85.698)
Epoch: [107][110/391]	Time 0.018 (0.014)	Data 0.001 (0.003)	Loss 2.4637 (2.3463)	Acc@1 53.125 (57.038)	Acc@5 85.156 (85.550)
Epoch: [107][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4679 (2.3549)	Acc@1 54.688 (56.786)	Acc@5 83.594 (85.473)
Epoch: [107][130/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.4255 (2.3578)	Acc@1 56.250 (56.679)	Acc@5 83.594 (85.383)
Epoch: [107][140/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.5779 (2.3593)	Acc@1 54.688 (56.582)	Acc@5 79.688 (85.334)
Epoch: [107][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2035 (2.3585)	Acc@1 59.375 (56.478)	Acc@5 86.719 (85.394)
Epoch: [107][160/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.2651 (2.3595)	Acc@1 53.906 (56.454)	Acc@5 85.938 (85.350)
Epoch: [107][170/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4240 (2.3614)	Acc@1 57.812 (56.469)	Acc@5 84.375 (85.312)
Epoch: [107][180/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.3781 (2.3634)	Acc@1 54.688 (56.354)	Acc@5 86.719 (85.294)
Epoch: [107][190/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.0930 (2.3674)	Acc@1 67.188 (56.287)	Acc@5 87.500 (85.177)
Epoch: [107][200/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.3243 (2.3694)	Acc@1 60.156 (56.293)	Acc@5 85.156 (85.110)
Epoch: [107][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2320 (2.3738)	Acc@1 61.719 (56.231)	Acc@5 85.156 (85.038)
Epoch: [107][220/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.3664 (2.3751)	Acc@1 55.469 (56.208)	Acc@5 89.062 (85.029)
Epoch: [107][230/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3068 (2.3801)	Acc@1 60.938 (56.081)	Acc@5 83.594 (84.977)
Epoch: [107][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5091 (2.3848)	Acc@1 55.469 (55.978)	Acc@5 82.031 (84.910)
Epoch: [107][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4785 (2.3879)	Acc@1 53.125 (55.923)	Acc@5 84.375 (84.826)
Epoch: [107][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4553 (2.3905)	Acc@1 53.906 (55.819)	Acc@5 85.156 (84.812)
Epoch: [107][270/391]	Time 0.017 (0.014)	Data 0.002 (0.002)	Loss 2.4157 (2.3912)	Acc@1 55.469 (55.809)	Acc@5 83.594 (84.813)
Epoch: [107][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4438 (2.3918)	Acc@1 51.562 (55.763)	Acc@5 82.031 (84.814)
Epoch: [107][290/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.2795 (2.3937)	Acc@1 57.812 (55.697)	Acc@5 87.500 (84.802)
Epoch: [107][300/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.4030 (2.3944)	Acc@1 49.219 (55.671)	Acc@5 88.281 (84.785)
Epoch: [107][310/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.2276 (2.3930)	Acc@1 61.719 (55.743)	Acc@5 86.719 (84.802)
Epoch: [107][320/391]	Time 0.013 (0.014)	Data 0.003 (0.002)	Loss 2.2724 (2.3917)	Acc@1 58.594 (55.780)	Acc@5 84.375 (84.816)
Epoch: [107][330/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2786 (2.3919)	Acc@1 64.844 (55.802)	Acc@5 83.594 (84.781)
Epoch: [107][340/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3501 (2.3941)	Acc@1 53.906 (55.744)	Acc@5 82.812 (84.751)
Epoch: [107][350/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2011 (2.3967)	Acc@1 60.156 (55.722)	Acc@5 86.719 (84.751)
Epoch: [107][360/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2996 (2.3969)	Acc@1 63.281 (55.772)	Acc@5 84.375 (84.710)
Epoch: [107][370/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6355 (2.3995)	Acc@1 47.656 (55.717)	Acc@5 80.469 (84.668)
Epoch: [107][380/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.7392 (2.4020)	Acc@1 49.219 (55.651)	Acc@5 78.125 (84.629)
Epoch: [107][390/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 2.4901 (2.4033)	Acc@1 53.750 (55.626)	Acc@5 83.750 (84.594)
num momentum params: 26
[0.1, 2.4032754804229737, 1.9323287403583527, 55.626, 49.32, tensor(0.3320, device='cuda:0', grad_fn=<DivBackward0>), 5.394484043121338, 0.41272187232971197]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [108 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [108][0/391]	Time 0.055 (0.055)	Data 0.188 (0.188)	Loss 2.4089 (2.4089)	Acc@1 57.031 (57.031)	Acc@5 87.500 (87.500)
Epoch: [108][10/391]	Time 0.015 (0.019)	Data 0.001 (0.018)	Loss 2.4190 (2.2994)	Acc@1 49.219 (57.386)	Acc@5 84.375 (87.216)
Epoch: [108][20/391]	Time 0.014 (0.016)	Data 0.001 (0.010)	Loss 2.2226 (2.3261)	Acc@1 56.250 (56.362)	Acc@5 86.719 (86.644)
Epoch: [108][30/391]	Time 0.013 (0.015)	Data 0.001 (0.007)	Loss 2.3043 (2.3299)	Acc@1 61.719 (56.678)	Acc@5 84.375 (86.139)
Epoch: [108][40/391]	Time 0.013 (0.015)	Data 0.001 (0.006)	Loss 2.3682 (2.3147)	Acc@1 57.812 (56.974)	Acc@5 83.594 (86.166)
Epoch: [108][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.2761 (2.3170)	Acc@1 57.812 (57.215)	Acc@5 86.719 (86.060)
Epoch: [108][60/391]	Time 0.012 (0.014)	Data 0.002 (0.005)	Loss 2.3299 (2.3301)	Acc@1 60.938 (56.929)	Acc@5 84.375 (86.053)
Epoch: [108][70/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.5420 (2.3372)	Acc@1 48.438 (56.822)	Acc@5 85.156 (86.048)
Epoch: [108][80/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.4590 (2.3545)	Acc@1 51.562 (56.481)	Acc@5 85.156 (85.793)
Epoch: [108][90/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.1061 (2.3503)	Acc@1 61.719 (56.525)	Acc@5 89.844 (85.834)
Epoch: [108][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2927 (2.3514)	Acc@1 59.375 (56.343)	Acc@5 85.938 (85.953)
Epoch: [108][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4238 (2.3591)	Acc@1 60.938 (56.320)	Acc@5 86.719 (85.747)
Epoch: [108][120/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3504 (2.3712)	Acc@1 57.031 (56.173)	Acc@5 82.812 (85.486)
Epoch: [108][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4781 (2.3715)	Acc@1 53.906 (56.208)	Acc@5 82.812 (85.484)
Epoch: [108][140/391]	Time 0.013 (0.014)	Data 0.003 (0.003)	Loss 2.3544 (2.3762)	Acc@1 63.281 (56.200)	Acc@5 80.469 (85.322)
Epoch: [108][150/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.5068 (2.3804)	Acc@1 50.000 (56.043)	Acc@5 82.812 (85.167)
Epoch: [108][160/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.4880 (2.3903)	Acc@1 55.469 (55.765)	Acc@5 78.125 (84.957)
Epoch: [108][170/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5434 (2.3951)	Acc@1 56.250 (55.674)	Acc@5 83.594 (84.873)
Epoch: [108][180/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.6502 (2.4066)	Acc@1 53.906 (55.469)	Acc@5 75.000 (84.677)
Epoch: [108][190/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5839 (2.4060)	Acc@1 49.219 (55.432)	Acc@5 84.375 (84.653)
Epoch: [108][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4663 (2.4093)	Acc@1 50.000 (55.383)	Acc@5 82.812 (84.573)
Epoch: [108][210/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3620 (2.4109)	Acc@1 53.125 (55.369)	Acc@5 87.500 (84.531)
Epoch: [108][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4421 (2.4131)	Acc@1 51.562 (55.306)	Acc@5 82.812 (84.523)
Epoch: [108][230/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4119 (2.4120)	Acc@1 52.344 (55.323)	Acc@5 85.938 (84.534)
Epoch: [108][240/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3607 (2.4144)	Acc@1 57.812 (55.209)	Acc@5 83.594 (84.469)
Epoch: [108][250/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4906 (2.4135)	Acc@1 51.562 (55.229)	Acc@5 85.156 (84.487)
Epoch: [108][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3471 (2.4151)	Acc@1 57.812 (55.220)	Acc@5 87.500 (84.459)
Epoch: [108][270/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.7194 (2.4153)	Acc@1 50.781 (55.227)	Acc@5 80.469 (84.464)
Epoch: [108][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6034 (2.4148)	Acc@1 46.875 (55.294)	Acc@5 82.812 (84.453)
Epoch: [108][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1678 (2.4103)	Acc@1 61.719 (55.428)	Acc@5 82.812 (84.472)
Epoch: [108][300/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3552 (2.4098)	Acc@1 54.688 (55.526)	Acc@5 85.938 (84.476)
Epoch: [108][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6989 (2.4121)	Acc@1 46.875 (55.426)	Acc@5 80.469 (84.425)
Epoch: [108][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5207 (2.4112)	Acc@1 55.469 (55.425)	Acc@5 82.031 (84.480)
Epoch: [108][330/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4383 (2.4111)	Acc@1 57.812 (55.455)	Acc@5 84.375 (84.443)
Epoch: [108][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4228 (2.4112)	Acc@1 55.469 (55.446)	Acc@5 83.594 (84.476)
Epoch: [108][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5645 (2.4103)	Acc@1 46.875 (55.473)	Acc@5 79.688 (84.500)
Epoch: [108][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2241 (2.4094)	Acc@1 62.500 (55.510)	Acc@5 86.719 (84.514)
Epoch: [108][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4740 (2.4081)	Acc@1 58.594 (55.574)	Acc@5 82.031 (84.525)
Epoch: [108][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4854 (2.4097)	Acc@1 54.688 (55.579)	Acc@5 82.812 (84.496)
Epoch: [108][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.3618 (2.4145)	Acc@1 53.750 (55.470)	Acc@5 83.750 (84.414)
num momentum params: 26
[0.1, 2.414540657577515, 1.9680862164497375, 55.47, 48.72, tensor(0.3306, device='cuda:0', grad_fn=<DivBackward0>), 5.299026966094971, 0.4063746929168701]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [109 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [109][0/391]	Time 0.058 (0.058)	Data 0.184 (0.184)	Loss 2.5899 (2.5899)	Acc@1 53.906 (53.906)	Acc@5 80.469 (80.469)
Epoch: [109][10/391]	Time 0.013 (0.020)	Data 0.001 (0.018)	Loss 2.1468 (2.3842)	Acc@1 58.594 (54.688)	Acc@5 91.406 (85.582)
Epoch: [109][20/391]	Time 0.013 (0.017)	Data 0.002 (0.010)	Loss 2.1692 (2.3261)	Acc@1 60.938 (56.510)	Acc@5 92.969 (86.830)
Epoch: [109][30/391]	Time 0.013 (0.016)	Data 0.001 (0.007)	Loss 2.2962 (2.3105)	Acc@1 61.719 (57.233)	Acc@5 84.375 (86.542)
Epoch: [109][40/391]	Time 0.013 (0.015)	Data 0.001 (0.006)	Loss 2.2726 (2.3296)	Acc@1 60.938 (57.203)	Acc@5 84.375 (86.166)
Epoch: [109][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.2271 (2.3447)	Acc@1 60.156 (56.893)	Acc@5 87.500 (86.029)
Epoch: [109][60/391]	Time 0.014 (0.015)	Data 0.002 (0.004)	Loss 2.4543 (2.3479)	Acc@1 55.469 (56.788)	Acc@5 82.812 (85.950)
Epoch: [109][70/391]	Time 0.014 (0.015)	Data 0.002 (0.004)	Loss 2.3647 (2.3573)	Acc@1 53.906 (56.591)	Acc@5 87.500 (85.684)
Epoch: [109][80/391]	Time 0.011 (0.014)	Data 0.002 (0.004)	Loss 2.2072 (2.3501)	Acc@1 62.500 (56.944)	Acc@5 84.375 (85.677)
Epoch: [109][90/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3286 (2.3564)	Acc@1 62.500 (56.954)	Acc@5 82.031 (85.525)
Epoch: [109][100/391]	Time 0.020 (0.014)	Data 0.001 (0.003)	Loss 2.3951 (2.3594)	Acc@1 56.250 (56.907)	Acc@5 85.156 (85.450)
Epoch: [109][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3885 (2.3640)	Acc@1 60.938 (56.848)	Acc@5 85.938 (85.403)
Epoch: [109][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2615 (2.3687)	Acc@1 54.688 (56.702)	Acc@5 87.500 (85.337)
Epoch: [109][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4835 (2.3753)	Acc@1 55.469 (56.429)	Acc@5 86.719 (85.252)
Epoch: [109][140/391]	Time 0.015 (0.014)	Data 0.002 (0.003)	Loss 2.3287 (2.3772)	Acc@1 59.375 (56.316)	Acc@5 85.156 (85.239)
Epoch: [109][150/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4010 (2.3760)	Acc@1 52.344 (56.291)	Acc@5 86.719 (85.270)
Epoch: [109][160/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.5851 (2.3778)	Acc@1 49.219 (56.279)	Acc@5 80.469 (85.166)
Epoch: [109][170/391]	Time 0.011 (0.014)	Data 0.002 (0.003)	Loss 2.4936 (2.3757)	Acc@1 52.344 (56.328)	Acc@5 85.156 (85.216)
Epoch: [109][180/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.1071 (2.3727)	Acc@1 64.062 (56.414)	Acc@5 88.281 (85.294)
Epoch: [109][190/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5939 (2.3771)	Acc@1 53.125 (56.324)	Acc@5 81.250 (85.209)
Epoch: [109][200/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.0608 (2.3749)	Acc@1 63.281 (56.444)	Acc@5 89.844 (85.222)
Epoch: [109][210/391]	Time 0.016 (0.014)	Data 0.002 (0.002)	Loss 2.6777 (2.3798)	Acc@1 53.906 (56.331)	Acc@5 80.469 (85.119)
Epoch: [109][220/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2609 (2.3780)	Acc@1 60.156 (56.349)	Acc@5 89.062 (85.139)
Epoch: [109][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4240 (2.3820)	Acc@1 55.469 (56.264)	Acc@5 87.500 (85.089)
Epoch: [109][240/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5005 (2.3826)	Acc@1 54.688 (56.240)	Acc@5 82.031 (85.078)
Epoch: [109][250/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6147 (2.3852)	Acc@1 56.250 (56.206)	Acc@5 82.031 (85.004)
Epoch: [109][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4024 (2.3867)	Acc@1 50.781 (56.169)	Acc@5 85.156 (84.989)
Epoch: [109][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5798 (2.3900)	Acc@1 50.781 (56.054)	Acc@5 85.938 (84.934)
Epoch: [109][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2885 (2.3897)	Acc@1 54.688 (56.022)	Acc@5 88.281 (84.931)
Epoch: [109][290/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5223 (2.3905)	Acc@1 49.219 (56.043)	Acc@5 85.156 (84.917)
Epoch: [109][300/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5003 (2.3914)	Acc@1 52.344 (56.048)	Acc@5 81.250 (84.897)
Epoch: [109][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.8160 (2.3932)	Acc@1 44.531 (55.971)	Acc@5 80.469 (84.867)
Epoch: [109][320/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5426 (2.3971)	Acc@1 49.219 (55.865)	Acc@5 82.812 (84.762)
Epoch: [109][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4447 (2.4001)	Acc@1 50.000 (55.771)	Acc@5 84.375 (84.731)
Epoch: [109][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4002 (2.4018)	Acc@1 53.906 (55.732)	Acc@5 85.156 (84.696)
Epoch: [109][350/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6237 (2.4035)	Acc@1 49.219 (55.696)	Acc@5 82.812 (84.653)
Epoch: [109][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5139 (2.4058)	Acc@1 58.594 (55.707)	Acc@5 80.469 (84.589)
Epoch: [109][370/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 2.3507 (2.4072)	Acc@1 52.344 (55.658)	Acc@5 82.031 (84.550)
Epoch: [109][380/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4265 (2.4077)	Acc@1 56.250 (55.643)	Acc@5 85.156 (84.566)
Epoch: [109][390/391]	Time 0.017 (0.014)	Data 0.002 (0.002)	Loss 2.5531 (2.4087)	Acc@1 45.000 (55.598)	Acc@5 82.500 (84.556)
num momentum params: 26
[0.1, 2.408727626495361, 2.0971506023406983, 55.598, 46.6, tensor(0.3315, device='cuda:0', grad_fn=<DivBackward0>), 5.366090774536133, 0.4118304252624511]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [110 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [110][0/391]	Time 0.060 (0.060)	Data 0.164 (0.164)	Loss 2.3671 (2.3671)	Acc@1 53.906 (53.906)	Acc@5 87.500 (87.500)
Epoch: [110][10/391]	Time 0.013 (0.019)	Data 0.001 (0.017)	Loss 2.4263 (2.4113)	Acc@1 54.688 (55.114)	Acc@5 83.594 (84.730)
Epoch: [110][20/391]	Time 0.016 (0.017)	Data 0.001 (0.009)	Loss 2.3027 (2.4008)	Acc@1 59.375 (55.171)	Acc@5 86.719 (85.789)
Epoch: [110][30/391]	Time 0.014 (0.016)	Data 0.002 (0.007)	Loss 1.9125 (2.3420)	Acc@1 69.531 (56.779)	Acc@5 92.188 (86.416)
Epoch: [110][40/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.2945 (2.3201)	Acc@1 57.031 (57.412)	Acc@5 82.031 (86.242)
Epoch: [110][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.2785 (2.3255)	Acc@1 62.500 (57.215)	Acc@5 85.156 (86.137)
Epoch: [110][60/391]	Time 0.011 (0.014)	Data 0.016 (0.004)	Loss 2.4424 (2.3264)	Acc@1 54.688 (57.480)	Acc@5 82.031 (85.758)
Epoch: [110][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.1933 (2.3365)	Acc@1 57.812 (57.317)	Acc@5 88.281 (85.519)
Epoch: [110][80/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.2086 (2.3272)	Acc@1 60.938 (57.581)	Acc@5 85.938 (85.658)
Epoch: [110][90/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4505 (2.3342)	Acc@1 52.344 (57.246)	Acc@5 84.375 (85.448)
Epoch: [110][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.1588 (2.3398)	Acc@1 60.156 (57.039)	Acc@5 89.844 (85.404)
Epoch: [110][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4466 (2.3450)	Acc@1 58.594 (56.898)	Acc@5 83.594 (85.325)
Epoch: [110][120/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3214 (2.3564)	Acc@1 53.906 (56.528)	Acc@5 89.062 (85.247)
Epoch: [110][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2021 (2.3578)	Acc@1 57.031 (56.518)	Acc@5 85.156 (85.252)
Epoch: [110][140/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3426 (2.3632)	Acc@1 57.031 (56.411)	Acc@5 86.719 (85.167)
Epoch: [110][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5457 (2.3731)	Acc@1 55.469 (56.147)	Acc@5 80.469 (85.017)
Epoch: [110][160/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.1178 (2.3717)	Acc@1 65.625 (56.182)	Acc@5 89.844 (85.079)
Epoch: [110][170/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5273 (2.3729)	Acc@1 54.688 (56.227)	Acc@5 82.031 (85.051)
Epoch: [110][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3217 (2.3729)	Acc@1 55.469 (56.285)	Acc@5 86.719 (85.022)
Epoch: [110][190/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.7071 (2.3758)	Acc@1 48.438 (56.234)	Acc@5 82.031 (85.013)
Epoch: [110][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4607 (2.3763)	Acc@1 53.906 (56.231)	Acc@5 86.719 (85.047)
Epoch: [110][210/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6256 (2.3815)	Acc@1 53.906 (56.102)	Acc@5 81.250 (84.941)
Epoch: [110][220/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2723 (2.3799)	Acc@1 60.938 (56.193)	Acc@5 83.594 (84.958)
Epoch: [110][230/391]	Time 0.011 (0.014)	Data 0.003 (0.002)	Loss 2.8319 (2.3849)	Acc@1 45.312 (56.061)	Acc@5 78.906 (84.869)
Epoch: [110][240/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3609 (2.3852)	Acc@1 53.125 (56.055)	Acc@5 82.812 (84.816)
Epoch: [110][250/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5145 (2.3879)	Acc@1 54.688 (56.010)	Acc@5 79.688 (84.752)
Epoch: [110][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3828 (2.3912)	Acc@1 54.688 (55.957)	Acc@5 86.719 (84.644)
Epoch: [110][270/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.3204 (2.3958)	Acc@1 59.375 (55.890)	Acc@5 85.938 (84.583)
Epoch: [110][280/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3454 (2.3971)	Acc@1 58.594 (55.872)	Acc@5 82.031 (84.581)
Epoch: [110][290/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3590 (2.3980)	Acc@1 55.469 (55.861)	Acc@5 84.375 (84.550)
Epoch: [110][300/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.7719 (2.4018)	Acc@1 49.219 (55.835)	Acc@5 77.344 (84.479)
Epoch: [110][310/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3861 (2.4038)	Acc@1 54.688 (55.760)	Acc@5 83.594 (84.435)
Epoch: [110][320/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4210 (2.4022)	Acc@1 58.594 (55.797)	Acc@5 82.812 (84.463)
Epoch: [110][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4196 (2.4025)	Acc@1 58.594 (55.830)	Acc@5 85.938 (84.469)
Epoch: [110][340/391]	Time 0.010 (0.014)	Data 0.002 (0.002)	Loss 2.4269 (2.4032)	Acc@1 52.344 (55.840)	Acc@5 82.812 (84.457)
Epoch: [110][350/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6883 (2.4029)	Acc@1 46.875 (55.812)	Acc@5 79.688 (84.475)
Epoch: [110][360/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4668 (2.4029)	Acc@1 51.562 (55.806)	Acc@5 82.031 (84.470)
Epoch: [110][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4510 (2.4073)	Acc@1 52.344 (55.692)	Acc@5 80.469 (84.362)
Epoch: [110][380/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4170 (2.4090)	Acc@1 52.344 (55.637)	Acc@5 85.156 (84.344)
Epoch: [110][390/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 2.4002 (2.4091)	Acc@1 57.500 (55.632)	Acc@5 81.250 (84.330)
num momentum params: 26
[0.1, 2.409077749481201, 1.9478203213214875, 55.632, 49.11, tensor(0.3311, device='cuda:0', grad_fn=<DivBackward0>), 5.3986976146698, 0.41097283363342285]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [111 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [111][0/391]	Time 0.066 (0.066)	Data 0.157 (0.157)	Loss 2.3374 (2.3374)	Acc@1 57.812 (57.812)	Acc@5 90.625 (90.625)
Epoch: [111][10/391]	Time 0.013 (0.020)	Data 0.001 (0.016)	Loss 2.5285 (2.3050)	Acc@1 57.031 (57.884)	Acc@5 82.031 (85.369)
Epoch: [111][20/391]	Time 0.014 (0.017)	Data 0.002 (0.009)	Loss 2.2643 (2.2803)	Acc@1 59.375 (58.371)	Acc@5 89.844 (86.421)
Epoch: [111][30/391]	Time 0.014 (0.016)	Data 0.001 (0.007)	Loss 2.1516 (2.2828)	Acc@1 62.500 (58.543)	Acc@5 89.062 (86.719)
Epoch: [111][40/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.4500 (2.3010)	Acc@1 53.125 (57.412)	Acc@5 82.031 (86.452)
Epoch: [111][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.3303 (2.3015)	Acc@1 54.688 (57.598)	Acc@5 83.594 (86.382)
Epoch: [111][60/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 2.6247 (2.3166)	Acc@1 53.906 (57.697)	Acc@5 80.469 (85.950)
Epoch: [111][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.1793 (2.3263)	Acc@1 57.812 (57.460)	Acc@5 87.500 (85.893)
Epoch: [111][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2274 (2.3313)	Acc@1 64.844 (57.253)	Acc@5 85.938 (85.716)
Epoch: [111][90/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.6806 (2.3476)	Acc@1 51.562 (56.945)	Acc@5 85.938 (85.457)
Epoch: [111][100/391]	Time 0.011 (0.014)	Data 0.002 (0.003)	Loss 2.2816 (2.3491)	Acc@1 57.812 (56.915)	Acc@5 86.719 (85.450)
Epoch: [111][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2226 (2.3552)	Acc@1 58.594 (56.820)	Acc@5 89.844 (85.410)
Epoch: [111][120/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.3824 (2.3645)	Acc@1 56.250 (56.689)	Acc@5 81.250 (85.098)
Epoch: [111][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6096 (2.3752)	Acc@1 57.031 (56.572)	Acc@5 79.688 (84.888)
Epoch: [111][140/391]	Time 0.012 (0.014)	Data 0.001 (0.003)	Loss 2.5976 (2.3785)	Acc@1 47.656 (56.483)	Acc@5 80.469 (84.824)
Epoch: [111][150/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.5325 (2.3868)	Acc@1 52.344 (56.214)	Acc@5 82.031 (84.706)
Epoch: [111][160/391]	Time 0.011 (0.014)	Data 0.002 (0.002)	Loss 2.5950 (2.3919)	Acc@1 56.250 (56.109)	Acc@5 81.250 (84.608)
Epoch: [111][170/391]	Time 0.011 (0.014)	Data 0.001 (0.002)	Loss 2.2119 (2.3971)	Acc@1 58.594 (55.962)	Acc@5 85.938 (84.526)
Epoch: [111][180/391]	Time 0.012 (0.014)	Data 0.002 (0.002)	Loss 2.4525 (2.3979)	Acc@1 53.906 (55.844)	Acc@5 81.250 (84.513)
Epoch: [111][190/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4225 (2.3968)	Acc@1 55.469 (55.825)	Acc@5 86.719 (84.555)
Epoch: [111][200/391]	Time 0.012 (0.014)	Data 0.002 (0.002)	Loss 2.5958 (2.3968)	Acc@1 50.000 (55.776)	Acc@5 81.250 (84.612)
Epoch: [111][210/391]	Time 0.014 (0.014)	Data 0.000 (0.002)	Loss 2.2078 (2.3941)	Acc@1 57.031 (55.880)	Acc@5 89.062 (84.686)
Epoch: [111][220/391]	Time 0.012 (0.014)	Data 0.003 (0.002)	Loss 2.3915 (2.3934)	Acc@1 51.562 (55.911)	Acc@5 85.156 (84.736)
Epoch: [111][230/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5827 (2.3981)	Acc@1 50.781 (55.848)	Acc@5 77.344 (84.571)
Epoch: [111][240/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.1634 (2.3983)	Acc@1 63.281 (55.842)	Acc@5 88.281 (84.550)
Epoch: [111][250/391]	Time 0.021 (0.014)	Data 0.002 (0.002)	Loss 2.5370 (2.4039)	Acc@1 57.812 (55.764)	Acc@5 79.688 (84.443)
Epoch: [111][260/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3829 (2.4026)	Acc@1 57.031 (55.837)	Acc@5 86.719 (84.468)
Epoch: [111][270/391]	Time 0.021 (0.014)	Data 0.002 (0.002)	Loss 2.3803 (2.4005)	Acc@1 60.156 (55.930)	Acc@5 81.250 (84.487)
Epoch: [111][280/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3729 (2.4026)	Acc@1 57.031 (55.822)	Acc@5 84.375 (84.453)
Epoch: [111][290/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4447 (2.4052)	Acc@1 53.906 (55.767)	Acc@5 84.375 (84.413)
Epoch: [111][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6134 (2.4070)	Acc@1 55.469 (55.754)	Acc@5 81.250 (84.372)
Epoch: [111][310/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5731 (2.4075)	Acc@1 48.438 (55.695)	Acc@5 84.375 (84.398)
Epoch: [111][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4788 (2.4054)	Acc@1 58.594 (55.754)	Acc@5 83.594 (84.441)
Epoch: [111][330/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3439 (2.4061)	Acc@1 60.156 (55.766)	Acc@5 88.281 (84.448)
Epoch: [111][340/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4197 (2.4086)	Acc@1 52.344 (55.682)	Acc@5 86.719 (84.432)
Epoch: [111][350/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.1979 (2.4093)	Acc@1 61.719 (55.636)	Acc@5 87.500 (84.408)
Epoch: [111][360/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4716 (2.4126)	Acc@1 55.469 (55.557)	Acc@5 84.375 (84.351)
Epoch: [111][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.8506 (2.4138)	Acc@1 42.188 (55.521)	Acc@5 80.469 (84.343)
Epoch: [111][380/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5272 (2.4152)	Acc@1 53.125 (55.510)	Acc@5 82.031 (84.322)
Epoch: [111][390/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 2.4140 (2.4152)	Acc@1 58.750 (55.486)	Acc@5 85.000 (84.346)
num momentum params: 26
[0.1, 2.4151783297729494, 1.9562364101409913, 55.486, 48.49, tensor(0.3305, device='cuda:0', grad_fn=<DivBackward0>), 5.4273645877838135, 0.4328315258026123]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [112 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [112][0/391]	Time 0.072 (0.072)	Data 0.173 (0.173)	Loss 2.3610 (2.3610)	Acc@1 55.469 (55.469)	Acc@5 84.375 (84.375)
Epoch: [112][10/391]	Time 0.015 (0.021)	Data 0.001 (0.017)	Loss 2.3161 (2.3278)	Acc@1 57.031 (57.528)	Acc@5 84.375 (85.795)
Epoch: [112][20/391]	Time 0.014 (0.017)	Data 0.001 (0.010)	Loss 2.3359 (2.3265)	Acc@1 60.938 (57.478)	Acc@5 86.719 (85.565)
Epoch: [112][30/391]	Time 0.013 (0.016)	Data 0.001 (0.007)	Loss 2.3871 (2.3296)	Acc@1 53.125 (57.712)	Acc@5 84.375 (85.433)
Epoch: [112][40/391]	Time 0.014 (0.016)	Data 0.002 (0.006)	Loss 2.1988 (2.3292)	Acc@1 63.281 (57.203)	Acc@5 87.500 (85.957)
Epoch: [112][50/391]	Time 0.013 (0.015)	Data 0.002 (0.005)	Loss 2.4198 (2.3245)	Acc@1 54.688 (57.169)	Acc@5 85.156 (86.458)
Epoch: [112][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.4582 (2.3210)	Acc@1 50.781 (57.070)	Acc@5 84.375 (86.411)
Epoch: [112][70/391]	Time 0.012 (0.015)	Data 0.002 (0.004)	Loss 2.4816 (2.3247)	Acc@1 51.562 (57.042)	Acc@5 81.250 (86.224)
Epoch: [112][80/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4595 (2.3379)	Acc@1 56.250 (56.829)	Acc@5 82.812 (85.918)
Epoch: [112][90/391]	Time 0.015 (0.014)	Data 0.002 (0.003)	Loss 2.3220 (2.3389)	Acc@1 57.812 (56.825)	Acc@5 84.375 (85.774)
Epoch: [112][100/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4931 (2.3442)	Acc@1 55.469 (56.768)	Acc@5 83.594 (85.682)
Epoch: [112][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4396 (2.3501)	Acc@1 58.594 (56.510)	Acc@5 82.812 (85.621)
Epoch: [112][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.1958 (2.3531)	Acc@1 60.938 (56.463)	Acc@5 89.844 (85.589)
Epoch: [112][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4675 (2.3518)	Acc@1 53.906 (56.536)	Acc@5 81.250 (85.538)
Epoch: [112][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4526 (2.3503)	Acc@1 56.250 (56.582)	Acc@5 82.812 (85.588)
Epoch: [112][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3303 (2.3555)	Acc@1 57.031 (56.483)	Acc@5 84.375 (85.498)
Epoch: [112][160/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.0473 (2.3511)	Acc@1 71.094 (56.706)	Acc@5 90.625 (85.564)
Epoch: [112][170/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4121 (2.3563)	Acc@1 54.688 (56.647)	Acc@5 85.156 (85.417)
Epoch: [112][180/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.2712 (2.3592)	Acc@1 60.156 (56.621)	Acc@5 84.375 (85.299)
Epoch: [112][190/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6040 (2.3651)	Acc@1 46.875 (56.557)	Acc@5 79.688 (85.173)
Epoch: [112][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3904 (2.3657)	Acc@1 50.781 (56.491)	Acc@5 84.375 (85.145)
Epoch: [112][210/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4442 (2.3703)	Acc@1 52.344 (56.302)	Acc@5 86.719 (85.138)
Epoch: [112][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4362 (2.3749)	Acc@1 57.031 (56.211)	Acc@5 82.031 (85.082)
Epoch: [112][230/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3949 (2.3783)	Acc@1 54.688 (56.098)	Acc@5 85.938 (85.078)
Epoch: [112][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5523 (2.3793)	Acc@1 53.125 (56.081)	Acc@5 80.469 (85.001)
Epoch: [112][250/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3646 (2.3816)	Acc@1 62.500 (56.082)	Acc@5 82.031 (84.932)
Epoch: [112][260/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4871 (2.3855)	Acc@1 49.219 (55.981)	Acc@5 86.719 (84.887)
Epoch: [112][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2416 (2.3857)	Acc@1 62.500 (56.005)	Acc@5 83.594 (84.888)
Epoch: [112][280/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3971 (2.3858)	Acc@1 54.688 (55.966)	Acc@5 82.031 (84.867)
Epoch: [112][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4600 (2.3880)	Acc@1 55.469 (55.955)	Acc@5 80.469 (84.837)
Epoch: [112][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3053 (2.3864)	Acc@1 57.812 (55.972)	Acc@5 82.812 (84.834)
Epoch: [112][310/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4183 (2.3919)	Acc@1 56.250 (55.843)	Acc@5 82.031 (84.707)
Epoch: [112][320/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5502 (2.3968)	Acc@1 44.531 (55.661)	Acc@5 83.594 (84.628)
Epoch: [112][330/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2708 (2.4001)	Acc@1 60.156 (55.608)	Acc@5 84.375 (84.583)
Epoch: [112][340/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2645 (2.4031)	Acc@1 60.938 (55.551)	Acc@5 87.500 (84.533)
Epoch: [112][350/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4422 (2.4042)	Acc@1 60.156 (55.527)	Acc@5 83.594 (84.520)
Epoch: [112][360/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3401 (2.4038)	Acc@1 60.156 (55.547)	Acc@5 83.594 (84.524)
Epoch: [112][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5287 (2.4067)	Acc@1 57.031 (55.521)	Acc@5 78.125 (84.444)
Epoch: [112][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5814 (2.4075)	Acc@1 53.906 (55.487)	Acc@5 81.250 (84.445)
Epoch: [112][390/391]	Time 0.016 (0.014)	Data 0.002 (0.002)	Loss 2.5846 (2.4074)	Acc@1 50.000 (55.514)	Acc@5 82.500 (84.466)
num momentum params: 26
[0.1, 2.4073815534973146, 1.969551055431366, 55.514, 48.76, tensor(0.3316, device='cuda:0', grad_fn=<DivBackward0>), 5.336503982543945, 0.42506051063537603]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [113 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [113][0/391]	Time 0.064 (0.064)	Data 0.151 (0.151)	Loss 2.1389 (2.1389)	Acc@1 63.281 (63.281)	Acc@5 86.719 (86.719)
Epoch: [113][10/391]	Time 0.013 (0.020)	Data 0.002 (0.015)	Loss 2.3331 (2.2428)	Acc@1 53.125 (58.523)	Acc@5 83.594 (87.074)
Epoch: [113][20/391]	Time 0.014 (0.017)	Data 0.001 (0.009)	Loss 2.2158 (2.2584)	Acc@1 53.906 (58.854)	Acc@5 90.625 (86.905)
Epoch: [113][30/391]	Time 0.014 (0.016)	Data 0.001 (0.006)	Loss 2.2224 (2.2692)	Acc@1 59.375 (58.947)	Acc@5 87.500 (86.366)
Epoch: [113][40/391]	Time 0.014 (0.015)	Data 0.001 (0.005)	Loss 2.2101 (2.2656)	Acc@1 57.031 (58.956)	Acc@5 88.281 (86.471)
Epoch: [113][50/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 2.3744 (2.2878)	Acc@1 57.031 (58.594)	Acc@5 85.938 (86.275)
Epoch: [113][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.4340 (2.2951)	Acc@1 59.375 (58.607)	Acc@5 82.031 (86.142)
Epoch: [113][70/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.3356 (2.3009)	Acc@1 51.562 (58.407)	Acc@5 85.938 (86.081)
Epoch: [113][80/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3130 (2.3089)	Acc@1 57.812 (58.198)	Acc@5 90.625 (85.938)
Epoch: [113][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4251 (2.3182)	Acc@1 52.344 (57.967)	Acc@5 85.938 (85.998)
Epoch: [113][100/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.4382 (2.3268)	Acc@1 52.344 (57.735)	Acc@5 86.719 (85.914)
Epoch: [113][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2272 (2.3261)	Acc@1 58.594 (57.700)	Acc@5 85.938 (85.853)
Epoch: [113][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6030 (2.3308)	Acc@1 48.438 (57.561)	Acc@5 80.469 (85.744)
Epoch: [113][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3121 (2.3344)	Acc@1 53.125 (57.383)	Acc@5 87.500 (85.675)
Epoch: [113][140/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4458 (2.3392)	Acc@1 54.688 (57.314)	Acc@5 85.156 (85.605)
Epoch: [113][150/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6346 (2.3481)	Acc@1 52.344 (57.176)	Acc@5 84.375 (85.472)
Epoch: [113][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4789 (2.3524)	Acc@1 57.812 (57.143)	Acc@5 84.375 (85.447)
Epoch: [113][170/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4217 (2.3598)	Acc@1 48.438 (56.803)	Acc@5 86.719 (85.366)
Epoch: [113][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2974 (2.3622)	Acc@1 59.375 (56.742)	Acc@5 87.500 (85.359)
Epoch: [113][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4026 (2.3657)	Acc@1 57.031 (56.688)	Acc@5 83.594 (85.299)
Epoch: [113][200/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.7614 (2.3666)	Acc@1 49.219 (56.670)	Acc@5 75.000 (85.222)
Epoch: [113][210/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.0704 (2.3680)	Acc@1 60.156 (56.602)	Acc@5 89.062 (85.186)
Epoch: [113][220/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5632 (2.3699)	Acc@1 52.344 (56.526)	Acc@5 78.906 (85.167)
Epoch: [113][230/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3218 (2.3756)	Acc@1 57.031 (56.365)	Acc@5 86.719 (85.133)
Epoch: [113][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6638 (2.3757)	Acc@1 47.656 (56.354)	Acc@5 78.906 (85.101)
Epoch: [113][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4256 (2.3771)	Acc@1 52.344 (56.318)	Acc@5 87.500 (85.078)
Epoch: [113][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6654 (2.3808)	Acc@1 50.000 (56.229)	Acc@5 81.250 (85.016)
Epoch: [113][270/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5896 (2.3873)	Acc@1 43.750 (56.077)	Acc@5 82.031 (84.946)
Epoch: [113][280/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.7823 (2.3911)	Acc@1 45.312 (55.997)	Acc@5 78.125 (84.834)
Epoch: [113][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4020 (2.3899)	Acc@1 56.250 (56.019)	Acc@5 82.812 (84.796)
Epoch: [113][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1963 (2.3870)	Acc@1 57.031 (56.045)	Acc@5 89.062 (84.853)
Epoch: [113][310/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.4629 (2.3892)	Acc@1 51.562 (56.039)	Acc@5 84.375 (84.817)
Epoch: [113][320/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.5015 (2.3908)	Acc@1 53.906 (55.997)	Acc@5 84.375 (84.794)
Epoch: [113][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5435 (2.3964)	Acc@1 52.344 (55.856)	Acc@5 81.250 (84.672)
Epoch: [113][340/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3979 (2.3981)	Acc@1 53.906 (55.858)	Acc@5 88.281 (84.634)
Epoch: [113][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4986 (2.3983)	Acc@1 53.125 (55.820)	Acc@5 83.594 (84.620)
Epoch: [113][360/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3938 (2.3980)	Acc@1 58.594 (55.847)	Acc@5 89.062 (84.643)
Epoch: [113][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3305 (2.3962)	Acc@1 55.469 (55.875)	Acc@5 85.156 (84.689)
Epoch: [113][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6647 (2.3980)	Acc@1 50.000 (55.807)	Acc@5 78.125 (84.642)
Epoch: [113][390/391]	Time 0.018 (0.014)	Data 0.001 (0.002)	Loss 2.5522 (2.3971)	Acc@1 46.250 (55.806)	Acc@5 81.250 (84.672)
num momentum params: 26
[0.1, 2.3971475996398928, 1.8605728936195374, 55.806, 51.62, tensor(0.3330, device='cuda:0', grad_fn=<DivBackward0>), 5.334248781204224, 0.4178805351257324]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [114 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [114][0/391]	Time 0.067 (0.067)	Data 0.163 (0.163)	Loss 2.2696 (2.2696)	Acc@1 53.906 (53.906)	Acc@5 86.719 (86.719)
Epoch: [114][10/391]	Time 0.014 (0.020)	Data 0.001 (0.016)	Loss 2.2386 (2.2702)	Acc@1 60.938 (56.960)	Acc@5 85.938 (87.571)
Epoch: [114][20/391]	Time 0.013 (0.017)	Data 0.002 (0.009)	Loss 2.0725 (2.2519)	Acc@1 63.281 (58.333)	Acc@5 89.844 (87.463)
Epoch: [114][30/391]	Time 0.014 (0.016)	Data 0.001 (0.007)	Loss 2.5949 (2.2834)	Acc@1 49.219 (57.636)	Acc@5 80.469 (86.820)
Epoch: [114][40/391]	Time 0.014 (0.015)	Data 0.002 (0.005)	Loss 2.2832 (2.3201)	Acc@1 59.375 (56.841)	Acc@5 83.594 (85.938)
Epoch: [114][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.1495 (2.3126)	Acc@1 61.719 (57.261)	Acc@5 85.938 (85.907)
Epoch: [114][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.2454 (2.3134)	Acc@1 62.500 (57.787)	Acc@5 86.719 (85.681)
Epoch: [114][70/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.6688 (2.3229)	Acc@1 52.344 (57.625)	Acc@5 82.031 (85.563)
Epoch: [114][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5034 (2.3263)	Acc@1 53.125 (57.639)	Acc@5 81.250 (85.455)
Epoch: [114][90/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4382 (2.3307)	Acc@1 56.250 (57.529)	Acc@5 81.250 (85.482)
Epoch: [114][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4337 (2.3351)	Acc@1 53.906 (57.395)	Acc@5 80.469 (85.342)
Epoch: [114][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4571 (2.3441)	Acc@1 59.375 (57.221)	Acc@5 84.375 (85.191)
Epoch: [114][120/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4989 (2.3457)	Acc@1 50.781 (57.218)	Acc@5 83.594 (85.214)
Epoch: [114][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3323 (2.3489)	Acc@1 60.156 (57.151)	Acc@5 85.938 (85.270)
Epoch: [114][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3617 (2.3534)	Acc@1 56.250 (56.987)	Acc@5 85.938 (85.256)
Epoch: [114][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4218 (2.3562)	Acc@1 57.031 (56.881)	Acc@5 83.594 (85.177)
Epoch: [114][160/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6659 (2.3641)	Acc@1 49.219 (56.658)	Acc@5 82.031 (85.093)
Epoch: [114][170/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2603 (2.3700)	Acc@1 62.500 (56.620)	Acc@5 89.062 (84.932)
Epoch: [114][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3099 (2.3727)	Acc@1 58.594 (56.587)	Acc@5 85.938 (84.906)
Epoch: [114][190/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 2.6755 (2.3792)	Acc@1 48.438 (56.455)	Acc@5 82.812 (84.829)
Epoch: [114][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6308 (2.3795)	Acc@1 50.781 (56.425)	Acc@5 82.812 (84.841)
Epoch: [114][210/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5683 (2.3791)	Acc@1 53.125 (56.383)	Acc@5 82.812 (84.904)
Epoch: [114][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5427 (2.3793)	Acc@1 55.469 (56.391)	Acc@5 77.344 (84.863)
Epoch: [114][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5082 (2.3797)	Acc@1 49.219 (56.324)	Acc@5 85.156 (84.882)
Epoch: [114][240/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3818 (2.3811)	Acc@1 58.594 (56.276)	Acc@5 84.375 (84.858)
Epoch: [114][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2713 (2.3806)	Acc@1 60.938 (56.284)	Acc@5 83.594 (84.814)
Epoch: [114][260/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2512 (2.3827)	Acc@1 57.812 (56.262)	Acc@5 89.844 (84.767)
Epoch: [114][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5081 (2.3840)	Acc@1 57.031 (56.224)	Acc@5 85.156 (84.747)
Epoch: [114][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5214 (2.3883)	Acc@1 56.250 (56.128)	Acc@5 82.812 (84.692)
Epoch: [114][290/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2481 (2.3875)	Acc@1 60.938 (56.129)	Acc@5 85.938 (84.681)
Epoch: [114][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4555 (2.3908)	Acc@1 55.469 (56.066)	Acc@5 82.031 (84.627)
Epoch: [114][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4522 (2.3944)	Acc@1 53.906 (56.029)	Acc@5 85.156 (84.586)
Epoch: [114][320/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.3797 (2.3960)	Acc@1 55.469 (55.951)	Acc@5 82.812 (84.592)
Epoch: [114][330/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.3464 (2.3944)	Acc@1 57.812 (55.986)	Acc@5 85.938 (84.609)
Epoch: [114][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5882 (2.3960)	Acc@1 51.562 (55.918)	Acc@5 81.250 (84.574)
Epoch: [114][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5331 (2.3982)	Acc@1 51.562 (55.858)	Acc@5 85.156 (84.546)
Epoch: [114][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2608 (2.3978)	Acc@1 60.156 (55.830)	Acc@5 85.156 (84.557)
Epoch: [114][370/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3672 (2.3984)	Acc@1 53.125 (55.755)	Acc@5 84.375 (84.537)
Epoch: [114][380/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6891 (2.3988)	Acc@1 52.344 (55.762)	Acc@5 79.688 (84.516)
Epoch: [114][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.5636 (2.4002)	Acc@1 51.250 (55.696)	Acc@5 83.750 (84.498)
num momentum params: 26
[0.1, 2.4001612059783937, 2.1019695627689363, 55.696, 45.75, tensor(0.3318, device='cuda:0', grad_fn=<DivBackward0>), 5.338887691497803, 0.4160144329071045]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [115 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [115][0/391]	Time 0.068 (0.068)	Data 0.166 (0.166)	Loss 2.2354 (2.2354)	Acc@1 63.281 (63.281)	Acc@5 86.719 (86.719)
Epoch: [115][10/391]	Time 0.017 (0.020)	Data 0.002 (0.017)	Loss 2.3451 (2.2835)	Acc@1 55.469 (58.665)	Acc@5 85.938 (86.506)
Epoch: [115][20/391]	Time 0.012 (0.017)	Data 0.002 (0.010)	Loss 2.3832 (2.2658)	Acc@1 56.250 (59.003)	Acc@5 82.812 (87.091)
Epoch: [115][30/391]	Time 0.016 (0.016)	Data 0.001 (0.007)	Loss 2.1568 (2.2584)	Acc@1 66.406 (58.518)	Acc@5 88.281 (87.172)
Epoch: [115][40/391]	Time 0.013 (0.016)	Data 0.003 (0.006)	Loss 2.1369 (2.2834)	Acc@1 60.938 (58.136)	Acc@5 89.844 (86.757)
Epoch: [115][50/391]	Time 0.013 (0.015)	Data 0.002 (0.005)	Loss 2.4111 (2.2949)	Acc@1 50.781 (57.782)	Acc@5 87.500 (86.657)
Epoch: [115][60/391]	Time 0.015 (0.015)	Data 0.002 (0.005)	Loss 2.2410 (2.3121)	Acc@1 60.938 (57.672)	Acc@5 85.156 (86.335)
Epoch: [115][70/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.3471 (2.3224)	Acc@1 57.031 (57.273)	Acc@5 85.938 (86.158)
Epoch: [115][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.3212 (2.3223)	Acc@1 56.250 (57.263)	Acc@5 85.938 (86.227)
Epoch: [115][90/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.2578 (2.3351)	Acc@1 58.594 (57.040)	Acc@5 87.500 (85.886)
Epoch: [115][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3863 (2.3406)	Acc@1 51.562 (56.838)	Acc@5 89.062 (85.690)
Epoch: [115][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3068 (2.3435)	Acc@1 60.156 (56.905)	Acc@5 86.719 (85.529)
Epoch: [115][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3736 (2.3431)	Acc@1 51.562 (56.786)	Acc@5 88.281 (85.569)
Epoch: [115][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3336 (2.3463)	Acc@1 56.250 (56.757)	Acc@5 88.281 (85.437)
Epoch: [115][140/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2024 (2.3404)	Acc@1 60.938 (56.992)	Acc@5 86.719 (85.544)
Epoch: [115][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2422 (2.3410)	Acc@1 56.250 (57.114)	Acc@5 87.500 (85.498)
Epoch: [115][160/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5343 (2.3471)	Acc@1 50.781 (56.997)	Acc@5 81.250 (85.423)
Epoch: [115][170/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.9909 (2.3518)	Acc@1 43.750 (56.849)	Acc@5 78.125 (85.371)
Epoch: [115][180/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5761 (2.3575)	Acc@1 59.375 (56.716)	Acc@5 80.469 (85.286)
Epoch: [115][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4590 (2.3590)	Acc@1 53.906 (56.647)	Acc@5 84.375 (85.222)
Epoch: [115][200/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2171 (2.3645)	Acc@1 62.500 (56.565)	Acc@5 88.281 (85.117)
Epoch: [115][210/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4343 (2.3690)	Acc@1 57.812 (56.468)	Acc@5 85.156 (85.093)
Epoch: [115][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7121 (2.3745)	Acc@1 45.312 (56.232)	Acc@5 81.250 (85.089)
Epoch: [115][230/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5353 (2.3828)	Acc@1 53.906 (56.017)	Acc@5 83.594 (84.980)
Epoch: [115][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2589 (2.3831)	Acc@1 64.844 (56.007)	Acc@5 86.719 (84.962)
Epoch: [115][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.0704 (2.3817)	Acc@1 62.500 (56.066)	Acc@5 91.406 (84.985)
Epoch: [115][260/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3939 (2.3805)	Acc@1 59.375 (56.085)	Acc@5 82.812 (84.980)
Epoch: [115][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5262 (2.3841)	Acc@1 54.688 (55.996)	Acc@5 82.812 (84.917)
Epoch: [115][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4184 (2.3857)	Acc@1 55.469 (55.989)	Acc@5 84.375 (84.887)
Epoch: [115][290/391]	Time 0.011 (0.014)	Data 0.002 (0.002)	Loss 2.5668 (2.3865)	Acc@1 47.656 (55.920)	Acc@5 84.375 (84.893)
Epoch: [115][300/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5046 (2.3868)	Acc@1 53.906 (55.900)	Acc@5 82.812 (84.853)
Epoch: [115][310/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 2.5403 (2.3892)	Acc@1 57.031 (55.866)	Acc@5 82.812 (84.815)
Epoch: [115][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1746 (2.3923)	Acc@1 62.500 (55.783)	Acc@5 87.500 (84.772)
Epoch: [115][330/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6055 (2.3978)	Acc@1 47.656 (55.634)	Acc@5 82.031 (84.658)
Epoch: [115][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7564 (2.4025)	Acc@1 50.781 (55.574)	Acc@5 78.125 (84.593)
Epoch: [115][350/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5053 (2.4034)	Acc@1 58.594 (55.533)	Acc@5 82.812 (84.593)
Epoch: [115][360/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4457 (2.4039)	Acc@1 53.906 (55.536)	Acc@5 85.156 (84.604)
Epoch: [115][370/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5739 (2.4064)	Acc@1 48.438 (55.505)	Acc@5 85.156 (84.562)
Epoch: [115][380/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.7314 (2.4090)	Acc@1 46.094 (55.467)	Acc@5 73.438 (84.512)
Epoch: [115][390/391]	Time 0.021 (0.014)	Data 0.001 (0.002)	Loss 2.4735 (2.4103)	Acc@1 52.500 (55.420)	Acc@5 87.500 (84.510)
num momentum params: 26
[0.1, 2.4102704148864746, 1.8625759887695312, 55.42, 50.77, tensor(0.3310, device='cuda:0', grad_fn=<DivBackward0>), 5.368658065795898, 0.4238545894622803]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [116 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [116][0/391]	Time 0.065 (0.065)	Data 0.170 (0.170)	Loss 2.1894 (2.1894)	Acc@1 66.406 (66.406)	Acc@5 86.719 (86.719)
Epoch: [116][10/391]	Time 0.016 (0.020)	Data 0.001 (0.017)	Loss 2.4221 (2.3073)	Acc@1 62.500 (58.665)	Acc@5 87.500 (87.003)
Epoch: [116][20/391]	Time 0.010 (0.017)	Data 0.002 (0.010)	Loss 2.4748 (2.3077)	Acc@1 55.469 (58.668)	Acc@5 86.719 (86.421)
Epoch: [116][30/391]	Time 0.014 (0.016)	Data 0.001 (0.007)	Loss 2.2819 (2.3027)	Acc@1 62.500 (58.745)	Acc@5 85.938 (86.442)
Epoch: [116][40/391]	Time 0.013 (0.015)	Data 0.002 (0.006)	Loss 2.4390 (2.2968)	Acc@1 55.469 (58.880)	Acc@5 80.469 (86.471)
Epoch: [116][50/391]	Time 0.014 (0.015)	Data 0.002 (0.005)	Loss 2.1419 (2.2886)	Acc@1 59.375 (58.869)	Acc@5 89.062 (86.627)
Epoch: [116][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.6643 (2.3101)	Acc@1 46.875 (58.261)	Acc@5 80.469 (86.155)
Epoch: [116][70/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.4569 (2.3268)	Acc@1 52.344 (57.757)	Acc@5 85.156 (85.926)
Epoch: [116][80/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.4145 (2.3353)	Acc@1 57.031 (57.446)	Acc@5 87.500 (85.880)
Epoch: [116][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3107 (2.3408)	Acc@1 57.031 (57.263)	Acc@5 83.594 (85.714)
Epoch: [116][100/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2628 (2.3470)	Acc@1 55.469 (56.861)	Acc@5 89.062 (85.767)
Epoch: [116][110/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.3745 (2.3440)	Acc@1 58.594 (56.883)	Acc@5 85.938 (85.762)
Epoch: [116][120/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.2593 (2.3460)	Acc@1 58.594 (56.928)	Acc@5 84.375 (85.724)
Epoch: [116][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4713 (2.3550)	Acc@1 55.469 (56.721)	Acc@5 85.156 (85.639)
Epoch: [116][140/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.2023 (2.3555)	Acc@1 61.719 (56.727)	Acc@5 89.844 (85.622)
Epoch: [116][150/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3194 (2.3548)	Acc@1 54.688 (56.752)	Acc@5 86.719 (85.612)
Epoch: [116][160/391]	Time 0.012 (0.014)	Data 0.001 (0.003)	Loss 2.2159 (2.3565)	Acc@1 60.156 (56.745)	Acc@5 89.062 (85.544)
Epoch: [116][170/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4346 (2.3589)	Acc@1 53.125 (56.629)	Acc@5 82.031 (85.440)
Epoch: [116][180/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4937 (2.3625)	Acc@1 52.344 (56.621)	Acc@5 77.344 (85.381)
Epoch: [116][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4961 (2.3669)	Acc@1 52.344 (56.450)	Acc@5 82.812 (85.299)
Epoch: [116][200/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2598 (2.3682)	Acc@1 59.375 (56.417)	Acc@5 88.281 (85.218)
Epoch: [116][210/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.3396 (2.3661)	Acc@1 53.906 (56.454)	Acc@5 87.500 (85.223)
Epoch: [116][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3576 (2.3634)	Acc@1 56.250 (56.540)	Acc@5 85.938 (85.227)
Epoch: [116][230/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3985 (2.3644)	Acc@1 57.031 (56.585)	Acc@5 78.125 (85.119)
Epoch: [116][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2439 (2.3652)	Acc@1 60.938 (56.594)	Acc@5 88.281 (85.121)
Epoch: [116][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4765 (2.3660)	Acc@1 53.906 (56.611)	Acc@5 82.812 (85.072)
Epoch: [116][260/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6045 (2.3704)	Acc@1 55.469 (56.483)	Acc@5 78.906 (84.989)
Epoch: [116][270/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4331 (2.3734)	Acc@1 53.125 (56.397)	Acc@5 82.812 (84.937)
Epoch: [116][280/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6074 (2.3759)	Acc@1 49.219 (56.350)	Acc@5 82.031 (84.875)
Epoch: [116][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2796 (2.3790)	Acc@1 58.594 (56.280)	Acc@5 86.719 (84.839)
Epoch: [116][300/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3520 (2.3819)	Acc@1 55.469 (56.183)	Acc@5 85.156 (84.808)
Epoch: [116][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5459 (2.3853)	Acc@1 48.438 (56.104)	Acc@5 85.156 (84.759)
Epoch: [116][320/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4777 (2.3857)	Acc@1 49.219 (56.119)	Acc@5 87.500 (84.781)
Epoch: [116][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1602 (2.3849)	Acc@1 67.969 (56.149)	Acc@5 88.281 (84.814)
Epoch: [116][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5338 (2.3884)	Acc@1 52.344 (56.080)	Acc@5 83.594 (84.758)
Epoch: [116][350/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.2947 (2.3910)	Acc@1 61.719 (56.039)	Acc@5 83.594 (84.727)
Epoch: [116][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4420 (2.3926)	Acc@1 58.594 (56.034)	Acc@5 82.812 (84.708)
Epoch: [116][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5364 (2.3926)	Acc@1 53.906 (56.077)	Acc@5 81.250 (84.708)
Epoch: [116][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3696 (2.3930)	Acc@1 59.375 (56.098)	Acc@5 83.594 (84.695)
Epoch: [116][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.3285 (2.3925)	Acc@1 53.750 (56.060)	Acc@5 91.250 (84.706)
num momentum params: 26
[0.1, 2.392509953918457, 1.9163321793079375, 56.06, 49.81, tensor(0.3327, device='cuda:0', grad_fn=<DivBackward0>), 5.350212335586548, 0.4134631156921387]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [117 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [117][0/391]	Time 0.067 (0.067)	Data 0.175 (0.175)	Loss 2.4026 (2.4026)	Acc@1 57.031 (57.031)	Acc@5 82.812 (82.812)
Epoch: [117][10/391]	Time 0.014 (0.020)	Data 0.002 (0.017)	Loss 2.2490 (2.2965)	Acc@1 55.469 (57.102)	Acc@5 87.500 (86.080)
Epoch: [117][20/391]	Time 0.013 (0.017)	Data 0.001 (0.010)	Loss 2.6158 (2.3088)	Acc@1 49.219 (57.292)	Acc@5 82.031 (86.086)
Epoch: [117][30/391]	Time 0.014 (0.016)	Data 0.002 (0.007)	Loss 2.1340 (2.2975)	Acc@1 61.719 (57.661)	Acc@5 93.750 (86.442)
Epoch: [117][40/391]	Time 0.014 (0.016)	Data 0.002 (0.006)	Loss 2.1876 (2.3017)	Acc@1 57.031 (57.641)	Acc@5 91.406 (86.414)
Epoch: [117][50/391]	Time 0.014 (0.015)	Data 0.002 (0.005)	Loss 2.2378 (2.2930)	Acc@1 60.938 (58.134)	Acc@5 87.500 (86.550)
Epoch: [117][60/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 2.2807 (2.2899)	Acc@1 57.812 (58.235)	Acc@5 89.062 (86.847)
Epoch: [117][70/391]	Time 0.014 (0.015)	Data 0.002 (0.004)	Loss 2.1481 (2.2978)	Acc@1 59.375 (57.989)	Acc@5 89.062 (86.719)
Epoch: [117][80/391]	Time 0.014 (0.015)	Data 0.002 (0.004)	Loss 2.3158 (2.3029)	Acc@1 57.812 (57.909)	Acc@5 84.375 (86.613)
Epoch: [117][90/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.0770 (2.3084)	Acc@1 65.625 (57.581)	Acc@5 89.844 (86.487)
Epoch: [117][100/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.3270 (2.3122)	Acc@1 54.688 (57.511)	Acc@5 87.500 (86.386)
Epoch: [117][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2246 (2.3176)	Acc@1 64.844 (57.496)	Acc@5 85.938 (86.332)
Epoch: [117][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4496 (2.3200)	Acc@1 55.469 (57.438)	Acc@5 86.719 (86.351)
Epoch: [117][130/391]	Time 0.011 (0.014)	Data 0.004 (0.003)	Loss 2.3973 (2.3255)	Acc@1 60.938 (57.335)	Acc@5 85.938 (86.218)
Epoch: [117][140/391]	Time 0.017 (0.014)	Data 0.002 (0.003)	Loss 2.4380 (2.3353)	Acc@1 54.688 (57.153)	Acc@5 82.031 (86.037)
Epoch: [117][150/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5567 (2.3408)	Acc@1 53.906 (57.109)	Acc@5 86.719 (85.974)
Epoch: [117][160/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.2674 (2.3418)	Acc@1 64.844 (57.123)	Acc@5 82.812 (85.908)
Epoch: [117][170/391]	Time 0.016 (0.014)	Data 0.001 (0.003)	Loss 2.5992 (2.3456)	Acc@1 46.094 (57.045)	Acc@5 81.250 (85.796)
Epoch: [117][180/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3654 (2.3508)	Acc@1 51.562 (56.889)	Acc@5 82.812 (85.644)
Epoch: [117][190/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6429 (2.3545)	Acc@1 48.438 (56.765)	Acc@5 82.031 (85.582)
Epoch: [117][200/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.4863 (2.3606)	Acc@1 51.562 (56.619)	Acc@5 82.812 (85.498)
Epoch: [117][210/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2847 (2.3654)	Acc@1 57.031 (56.472)	Acc@5 86.719 (85.427)
Epoch: [117][220/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3643 (2.3717)	Acc@1 53.906 (56.314)	Acc@5 89.062 (85.315)
Epoch: [117][230/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5885 (2.3732)	Acc@1 50.000 (56.257)	Acc@5 85.156 (85.379)
Epoch: [117][240/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4647 (2.3774)	Acc@1 52.344 (56.169)	Acc@5 81.250 (85.270)
Epoch: [117][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5374 (2.3823)	Acc@1 53.906 (56.073)	Acc@5 81.250 (85.178)
Epoch: [117][260/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3010 (2.3831)	Acc@1 62.500 (56.151)	Acc@5 85.156 (85.123)
Epoch: [117][270/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4264 (2.3849)	Acc@1 56.250 (56.060)	Acc@5 81.250 (85.087)
Epoch: [117][280/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.7957 (2.3902)	Acc@1 49.219 (55.933)	Acc@5 74.219 (84.951)
Epoch: [117][290/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3478 (2.3929)	Acc@1 61.719 (55.871)	Acc@5 85.156 (84.915)
Epoch: [117][300/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2376 (2.3929)	Acc@1 61.719 (55.889)	Acc@5 88.281 (84.899)
Epoch: [117][310/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4370 (2.3948)	Acc@1 57.031 (55.846)	Acc@5 85.938 (84.890)
Epoch: [117][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4022 (2.3942)	Acc@1 54.688 (55.856)	Acc@5 84.375 (84.903)
Epoch: [117][330/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3631 (2.3947)	Acc@1 60.156 (55.858)	Acc@5 84.375 (84.916)
Epoch: [117][340/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3396 (2.3977)	Acc@1 57.031 (55.817)	Acc@5 85.938 (84.826)
Epoch: [117][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7618 (2.4006)	Acc@1 50.000 (55.738)	Acc@5 78.125 (84.749)
Epoch: [117][360/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 2.6043 (2.4023)	Acc@1 50.000 (55.655)	Acc@5 85.938 (84.745)
Epoch: [117][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2981 (2.4049)	Acc@1 55.469 (55.635)	Acc@5 89.062 (84.714)
Epoch: [117][380/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4560 (2.4068)	Acc@1 53.125 (55.586)	Acc@5 85.156 (84.674)
Epoch: [117][390/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 2.6533 (2.4083)	Acc@1 55.000 (55.580)	Acc@5 78.750 (84.642)
num momentum params: 26
[0.1, 2.4083484282684324, 2.0708746409416197, 55.58, 46.47, tensor(0.3308, device='cuda:0', grad_fn=<DivBackward0>), 5.4151389598846436, 0.417651653289795]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [118 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [118][0/391]	Time 0.075 (0.075)	Data 0.176 (0.176)	Loss 2.4586 (2.4586)	Acc@1 51.562 (51.562)	Acc@5 84.375 (84.375)
Epoch: [118][10/391]	Time 0.015 (0.021)	Data 0.002 (0.017)	Loss 2.1569 (2.3708)	Acc@1 62.500 (55.966)	Acc@5 85.938 (84.659)
Epoch: [118][20/391]	Time 0.013 (0.018)	Data 0.002 (0.010)	Loss 2.0594 (2.3209)	Acc@1 65.625 (57.478)	Acc@5 92.188 (85.268)
Epoch: [118][30/391]	Time 0.015 (0.017)	Data 0.002 (0.007)	Loss 2.3175 (2.2987)	Acc@1 57.031 (57.939)	Acc@5 83.594 (85.862)
Epoch: [118][40/391]	Time 0.014 (0.016)	Data 0.002 (0.006)	Loss 2.3942 (2.3161)	Acc@1 53.125 (57.431)	Acc@5 86.719 (85.938)
Epoch: [118][50/391]	Time 0.015 (0.016)	Data 0.002 (0.005)	Loss 2.5595 (2.3412)	Acc@1 49.219 (56.985)	Acc@5 82.031 (85.662)
Epoch: [118][60/391]	Time 0.014 (0.015)	Data 0.002 (0.005)	Loss 2.1547 (2.3442)	Acc@1 61.719 (56.749)	Acc@5 92.969 (85.758)
Epoch: [118][70/391]	Time 0.014 (0.015)	Data 0.002 (0.004)	Loss 2.3891 (2.3449)	Acc@1 54.688 (56.800)	Acc@5 82.812 (85.640)
Epoch: [118][80/391]	Time 0.015 (0.015)	Data 0.002 (0.004)	Loss 2.3157 (2.3474)	Acc@1 60.156 (56.636)	Acc@5 84.375 (85.677)
Epoch: [118][90/391]	Time 0.014 (0.015)	Data 0.002 (0.004)	Loss 2.0515 (2.3406)	Acc@1 64.062 (56.877)	Acc@5 91.406 (85.792)
Epoch: [118][100/391]	Time 0.013 (0.015)	Data 0.002 (0.003)	Loss 2.4180 (2.3494)	Acc@1 51.562 (56.768)	Acc@5 82.812 (85.636)
Epoch: [118][110/391]	Time 0.011 (0.015)	Data 0.004 (0.003)	Loss 2.5424 (2.3559)	Acc@1 50.000 (56.623)	Acc@5 82.031 (85.374)
Epoch: [118][120/391]	Time 0.014 (0.015)	Data 0.002 (0.003)	Loss 2.2764 (2.3592)	Acc@1 59.375 (56.624)	Acc@5 85.156 (85.285)
Epoch: [118][130/391]	Time 0.012 (0.015)	Data 0.002 (0.003)	Loss 2.2739 (2.3576)	Acc@1 60.156 (56.685)	Acc@5 84.375 (85.270)
Epoch: [118][140/391]	Time 0.017 (0.015)	Data 0.002 (0.003)	Loss 2.4578 (2.3551)	Acc@1 52.344 (56.738)	Acc@5 86.719 (85.322)
Epoch: [118][150/391]	Time 0.014 (0.015)	Data 0.002 (0.003)	Loss 2.5053 (2.3573)	Acc@1 51.562 (56.648)	Acc@5 83.594 (85.301)
Epoch: [118][160/391]	Time 0.013 (0.015)	Data 0.002 (0.003)	Loss 2.4946 (2.3607)	Acc@1 57.031 (56.619)	Acc@5 82.031 (85.239)
Epoch: [118][170/391]	Time 0.016 (0.015)	Data 0.001 (0.003)	Loss 2.1358 (2.3589)	Acc@1 59.375 (56.561)	Acc@5 88.281 (85.261)
Epoch: [118][180/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.4305 (2.3633)	Acc@1 57.812 (56.496)	Acc@5 81.250 (85.156)
Epoch: [118][190/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6655 (2.3670)	Acc@1 49.219 (56.360)	Acc@5 82.031 (85.115)
Epoch: [118][200/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3875 (2.3726)	Acc@1 54.688 (56.246)	Acc@5 86.719 (85.047)
Epoch: [118][210/391]	Time 0.015 (0.014)	Data 0.002 (0.003)	Loss 2.6560 (2.3751)	Acc@1 53.906 (56.231)	Acc@5 79.688 (85.001)
Epoch: [118][220/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.4956 (2.3774)	Acc@1 53.125 (56.190)	Acc@5 85.938 (84.944)
Epoch: [118][230/391]	Time 0.021 (0.014)	Data 0.001 (0.003)	Loss 2.4134 (2.3790)	Acc@1 58.594 (56.196)	Acc@5 82.812 (84.940)
Epoch: [118][240/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3956 (2.3778)	Acc@1 55.469 (56.182)	Acc@5 84.375 (84.926)
Epoch: [118][250/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.5326 (2.3799)	Acc@1 53.906 (56.144)	Acc@5 78.125 (84.892)
Epoch: [118][260/391]	Time 0.014 (0.014)	Data 0.003 (0.002)	Loss 2.3224 (2.3811)	Acc@1 60.156 (56.109)	Acc@5 86.719 (84.878)
Epoch: [118][270/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5607 (2.3841)	Acc@1 53.125 (56.019)	Acc@5 79.688 (84.793)
Epoch: [118][280/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3393 (2.3861)	Acc@1 56.250 (55.966)	Acc@5 82.812 (84.778)
Epoch: [118][290/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.4816 (2.3864)	Acc@1 53.125 (55.995)	Acc@5 81.250 (84.778)
Epoch: [118][300/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4040 (2.3880)	Acc@1 54.688 (55.959)	Acc@5 84.375 (84.741)
Epoch: [118][310/391]	Time 0.012 (0.014)	Data 0.003 (0.002)	Loss 2.2246 (2.3862)	Acc@1 57.031 (56.016)	Acc@5 85.938 (84.767)
Epoch: [118][320/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.1291 (2.3878)	Acc@1 64.062 (56.011)	Acc@5 86.719 (84.704)
Epoch: [118][330/391]	Time 0.012 (0.014)	Data 0.002 (0.002)	Loss 2.3651 (2.3879)	Acc@1 54.688 (56.021)	Acc@5 84.375 (84.694)
Epoch: [118][340/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6286 (2.3907)	Acc@1 48.438 (55.922)	Acc@5 78.906 (84.618)
Epoch: [118][350/391]	Time 0.011 (0.014)	Data 0.002 (0.002)	Loss 1.9607 (2.3927)	Acc@1 66.406 (55.849)	Acc@5 91.406 (84.566)
Epoch: [118][360/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3618 (2.3947)	Acc@1 56.250 (55.802)	Acc@5 84.375 (84.535)
Epoch: [118][370/391]	Time 0.025 (0.014)	Data 0.002 (0.002)	Loss 2.5200 (2.3964)	Acc@1 53.125 (55.747)	Acc@5 82.031 (84.529)
Epoch: [118][380/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3377 (2.3989)	Acc@1 60.938 (55.735)	Acc@5 85.156 (84.486)
Epoch: [118][390/391]	Time 0.017 (0.014)	Data 0.002 (0.002)	Loss 2.6689 (2.4010)	Acc@1 48.750 (55.652)	Acc@5 86.250 (84.492)
num momentum params: 26
[0.1, 2.401034666519165, 2.188535522222519, 55.652, 44.33, tensor(0.3319, device='cuda:0', grad_fn=<DivBackward0>), 5.547296524047852, 0.4443247318267823]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [119 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [119][0/391]	Time 0.066 (0.066)	Data 0.182 (0.182)	Loss 2.2586 (2.2586)	Acc@1 60.156 (60.156)	Acc@5 86.719 (86.719)
Epoch: [119][10/391]	Time 0.014 (0.021)	Data 0.002 (0.018)	Loss 2.4390 (2.3360)	Acc@1 57.031 (57.457)	Acc@5 81.250 (85.298)
Epoch: [119][20/391]	Time 0.013 (0.018)	Data 0.002 (0.010)	Loss 2.5005 (2.3651)	Acc@1 47.656 (55.804)	Acc@5 87.500 (85.007)
Epoch: [119][30/391]	Time 0.015 (0.017)	Data 0.002 (0.008)	Loss 2.4052 (2.3423)	Acc@1 53.125 (56.678)	Acc@5 85.938 (85.509)
Epoch: [119][40/391]	Time 0.013 (0.016)	Data 0.002 (0.006)	Loss 2.3310 (2.3291)	Acc@1 57.812 (57.508)	Acc@5 83.594 (85.690)
Epoch: [119][50/391]	Time 0.014 (0.016)	Data 0.002 (0.005)	Loss 2.3849 (2.3343)	Acc@1 60.938 (57.613)	Acc@5 85.156 (85.493)
Epoch: [119][60/391]	Time 0.016 (0.016)	Data 0.002 (0.005)	Loss 2.3801 (2.3380)	Acc@1 54.688 (57.454)	Acc@5 86.719 (85.630)
Epoch: [119][70/391]	Time 0.014 (0.015)	Data 0.002 (0.004)	Loss 2.3777 (2.3366)	Acc@1 54.688 (57.625)	Acc@5 87.500 (85.640)
Epoch: [119][80/391]	Time 0.014 (0.015)	Data 0.002 (0.004)	Loss 2.4641 (2.3472)	Acc@1 56.250 (57.176)	Acc@5 84.375 (85.503)
Epoch: [119][90/391]	Time 0.014 (0.015)	Data 0.002 (0.004)	Loss 2.5916 (2.3488)	Acc@1 57.031 (57.177)	Acc@5 78.906 (85.362)
Epoch: [119][100/391]	Time 0.014 (0.015)	Data 0.002 (0.004)	Loss 2.4210 (2.3518)	Acc@1 53.125 (57.062)	Acc@5 85.156 (85.303)
Epoch: [119][110/391]	Time 0.019 (0.015)	Data 0.002 (0.003)	Loss 2.3162 (2.3496)	Acc@1 60.156 (57.214)	Acc@5 84.375 (85.304)
Epoch: [119][120/391]	Time 0.014 (0.015)	Data 0.002 (0.003)	Loss 2.3503 (2.3538)	Acc@1 60.156 (57.115)	Acc@5 84.375 (85.234)
Epoch: [119][130/391]	Time 0.014 (0.015)	Data 0.002 (0.003)	Loss 2.4996 (2.3577)	Acc@1 53.906 (57.019)	Acc@5 80.469 (85.132)
Epoch: [119][140/391]	Time 0.014 (0.015)	Data 0.002 (0.003)	Loss 2.4942 (2.3596)	Acc@1 52.344 (56.981)	Acc@5 81.250 (85.101)
Epoch: [119][150/391]	Time 0.013 (0.015)	Data 0.002 (0.003)	Loss 2.6424 (2.3649)	Acc@1 46.094 (56.793)	Acc@5 82.812 (85.022)
Epoch: [119][160/391]	Time 0.016 (0.015)	Data 0.002 (0.003)	Loss 2.4769 (2.3636)	Acc@1 60.156 (56.784)	Acc@5 81.250 (85.011)
Epoch: [119][170/391]	Time 0.013 (0.015)	Data 0.002 (0.003)	Loss 2.5123 (2.3634)	Acc@1 50.781 (56.853)	Acc@5 85.938 (85.028)
Epoch: [119][180/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.3688 (2.3665)	Acc@1 58.594 (56.772)	Acc@5 82.031 (84.997)
Epoch: [119][190/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.5774 (2.3688)	Acc@1 51.562 (56.688)	Acc@5 82.812 (84.972)
Epoch: [119][200/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5485 (2.3690)	Acc@1 58.594 (56.693)	Acc@5 80.469 (85.009)
Epoch: [119][210/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.2173 (2.3709)	Acc@1 64.062 (56.731)	Acc@5 86.719 (84.960)
Epoch: [119][220/391]	Time 0.015 (0.014)	Data 0.002 (0.003)	Loss 2.4539 (2.3724)	Acc@1 53.906 (56.681)	Acc@5 79.688 (84.912)
Epoch: [119][230/391]	Time 0.015 (0.014)	Data 0.002 (0.003)	Loss 2.4877 (2.3734)	Acc@1 53.125 (56.666)	Acc@5 83.594 (84.852)
Epoch: [119][240/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4873 (2.3748)	Acc@1 53.906 (56.645)	Acc@5 83.594 (84.806)
Epoch: [119][250/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5591 (2.3807)	Acc@1 50.781 (56.483)	Acc@5 84.375 (84.696)
Epoch: [119][260/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5859 (2.3864)	Acc@1 51.562 (56.271)	Acc@5 81.250 (84.620)
Epoch: [119][270/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4197 (2.3884)	Acc@1 46.094 (56.140)	Acc@5 85.156 (84.623)
Epoch: [119][280/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4417 (2.3880)	Acc@1 56.250 (56.164)	Acc@5 82.031 (84.595)
Epoch: [119][290/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.2789 (2.3867)	Acc@1 60.156 (56.231)	Acc@5 89.062 (84.622)
Epoch: [119][300/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.3728 (2.3867)	Acc@1 53.906 (56.232)	Acc@5 82.031 (84.570)
Epoch: [119][310/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.0107 (2.3869)	Acc@1 66.406 (56.207)	Acc@5 91.406 (84.573)
Epoch: [119][320/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5553 (2.3884)	Acc@1 51.562 (56.182)	Acc@5 78.906 (84.528)
Epoch: [119][330/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2216 (2.3882)	Acc@1 58.594 (56.186)	Acc@5 83.594 (84.514)
Epoch: [119][340/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.7750 (2.3910)	Acc@1 47.656 (56.099)	Acc@5 82.812 (84.512)
Epoch: [119][350/391]	Time 0.016 (0.014)	Data 0.002 (0.002)	Loss 2.3481 (2.3931)	Acc@1 53.906 (56.070)	Acc@5 88.281 (84.484)
Epoch: [119][360/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.7249 (2.3953)	Acc@1 45.312 (55.975)	Acc@5 78.906 (84.440)
Epoch: [119][370/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5432 (2.3963)	Acc@1 56.250 (55.985)	Acc@5 83.594 (84.411)
Epoch: [119][380/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2727 (2.3980)	Acc@1 60.156 (55.922)	Acc@5 85.938 (84.408)
Epoch: [119][390/391]	Time 0.017 (0.014)	Data 0.002 (0.002)	Loss 2.3215 (2.3987)	Acc@1 55.000 (55.908)	Acc@5 88.750 (84.444)
num momentum params: 26
[0.1, 2.398747885437012, 2.0655768382549287, 55.908, 47.72, tensor(0.3317, device='cuda:0', grad_fn=<DivBackward0>), 5.550934076309204, 0.42096877098083496]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [120 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [120][0/391]	Time 0.067 (0.067)	Data 0.182 (0.182)	Loss 2.1993 (2.1993)	Acc@1 57.031 (57.031)	Acc@5 88.281 (88.281)
Epoch: [120][10/391]	Time 0.015 (0.022)	Data 0.002 (0.018)	Loss 2.1364 (2.2675)	Acc@1 57.812 (56.747)	Acc@5 90.625 (86.790)
Epoch: [120][20/391]	Time 0.016 (0.018)	Data 0.002 (0.010)	Loss 2.2941 (2.3121)	Acc@1 56.250 (56.994)	Acc@5 86.719 (86.421)
Epoch: [120][30/391]	Time 0.013 (0.017)	Data 0.002 (0.007)	Loss 2.3022 (2.2928)	Acc@1 58.594 (58.065)	Acc@5 86.719 (86.618)
Epoch: [120][40/391]	Time 0.013 (0.016)	Data 0.002 (0.006)	Loss 2.5497 (2.2905)	Acc@1 46.875 (58.079)	Acc@5 85.156 (86.700)
Epoch: [120][50/391]	Time 0.013 (0.016)	Data 0.002 (0.005)	Loss 2.5536 (2.3029)	Acc@1 51.562 (57.996)	Acc@5 82.812 (86.535)
Epoch: [120][60/391]	Time 0.013 (0.015)	Data 0.002 (0.005)	Loss 2.5142 (2.3300)	Acc@1 50.781 (57.403)	Acc@5 83.594 (86.027)
Epoch: [120][70/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.5330 (2.3477)	Acc@1 53.906 (57.251)	Acc@5 85.156 (85.508)
Epoch: [120][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.5307 (2.3485)	Acc@1 55.469 (57.359)	Acc@5 81.250 (85.503)
Epoch: [120][90/391]	Time 0.014 (0.015)	Data 0.002 (0.004)	Loss 2.4637 (2.3416)	Acc@1 50.000 (57.332)	Acc@5 85.156 (85.577)
Epoch: [120][100/391]	Time 0.015 (0.015)	Data 0.002 (0.003)	Loss 2.3213 (2.3464)	Acc@1 57.812 (57.140)	Acc@5 83.594 (85.365)
Epoch: [120][110/391]	Time 0.013 (0.015)	Data 0.003 (0.003)	Loss 2.5958 (2.3466)	Acc@1 53.125 (57.109)	Acc@5 82.812 (85.445)
Epoch: [120][120/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2908 (2.3485)	Acc@1 57.812 (56.973)	Acc@5 85.156 (85.440)
Epoch: [120][130/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.2439 (2.3453)	Acc@1 56.250 (57.139)	Acc@5 85.938 (85.425)
Epoch: [120][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2154 (2.3426)	Acc@1 59.375 (57.225)	Acc@5 84.375 (85.539)
Epoch: [120][150/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.5348 (2.3489)	Acc@1 56.250 (57.099)	Acc@5 80.469 (85.513)
Epoch: [120][160/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3443 (2.3539)	Acc@1 52.344 (56.920)	Acc@5 85.156 (85.462)
Epoch: [120][170/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5756 (2.3592)	Acc@1 46.094 (56.725)	Acc@5 85.156 (85.334)
Epoch: [120][180/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6987 (2.3630)	Acc@1 48.438 (56.647)	Acc@5 78.906 (85.329)
Epoch: [120][190/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3380 (2.3631)	Acc@1 53.906 (56.589)	Acc@5 85.938 (85.344)
Epoch: [120][200/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3338 (2.3660)	Acc@1 51.562 (56.507)	Acc@5 89.062 (85.292)
Epoch: [120][210/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.1705 (2.3676)	Acc@1 61.719 (56.520)	Acc@5 89.062 (85.271)
Epoch: [120][220/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3398 (2.3696)	Acc@1 57.031 (56.519)	Acc@5 83.594 (85.259)
Epoch: [120][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4381 (2.3725)	Acc@1 61.719 (56.541)	Acc@5 82.812 (85.173)
Epoch: [120][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3456 (2.3737)	Acc@1 55.469 (56.513)	Acc@5 85.156 (85.143)
Epoch: [120][250/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5849 (2.3772)	Acc@1 53.906 (56.390)	Acc@5 84.375 (85.122)
Epoch: [120][260/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5344 (2.3784)	Acc@1 49.219 (56.394)	Acc@5 84.375 (85.090)
Epoch: [120][270/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4894 (2.3807)	Acc@1 55.469 (56.365)	Acc@5 81.250 (85.041)
Epoch: [120][280/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6102 (2.3845)	Acc@1 46.094 (56.264)	Acc@5 82.812 (84.984)
Epoch: [120][290/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4539 (2.3823)	Acc@1 53.125 (56.282)	Acc@5 85.156 (85.019)
Epoch: [120][300/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5608 (2.3843)	Acc@1 46.875 (56.198)	Acc@5 82.812 (84.988)
Epoch: [120][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4630 (2.3862)	Acc@1 53.906 (56.175)	Acc@5 84.375 (84.950)
Epoch: [120][320/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3464 (2.3883)	Acc@1 54.688 (56.092)	Acc@5 85.938 (84.927)
Epoch: [120][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4754 (2.3909)	Acc@1 55.469 (56.068)	Acc@5 81.250 (84.866)
Epoch: [120][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6409 (2.3952)	Acc@1 48.438 (55.927)	Acc@5 79.688 (84.746)
Epoch: [120][350/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6604 (2.3976)	Acc@1 46.875 (55.823)	Acc@5 85.156 (84.716)
Epoch: [120][360/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2924 (2.3972)	Acc@1 56.250 (55.793)	Acc@5 85.938 (84.732)
Epoch: [120][370/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.8952 (2.3991)	Acc@1 47.656 (55.745)	Acc@5 76.562 (84.701)
Epoch: [120][380/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4668 (2.4014)	Acc@1 53.906 (55.735)	Acc@5 80.469 (84.644)
Epoch: [120][390/391]	Time 0.019 (0.014)	Data 0.000 (0.002)	Loss 2.5561 (2.4050)	Acc@1 55.000 (55.680)	Acc@5 80.000 (84.560)
num momentum params: 26
[0.1, 2.4050275903320313, 1.9705709159374236, 55.68, 47.73, tensor(0.3312, device='cuda:0', grad_fn=<DivBackward0>), 5.413363933563232, 0.4129951000213623]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [121 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [121][0/391]	Time 0.060 (0.060)	Data 0.172 (0.172)	Loss 2.3573 (2.3573)	Acc@1 53.906 (53.906)	Acc@5 84.375 (84.375)
Epoch: [121][10/391]	Time 0.016 (0.020)	Data 0.002 (0.017)	Loss 2.4750 (2.3826)	Acc@1 53.906 (56.179)	Acc@5 81.250 (85.511)
Epoch: [121][20/391]	Time 0.015 (0.017)	Data 0.002 (0.010)	Loss 2.2653 (2.3305)	Acc@1 59.375 (57.366)	Acc@5 83.594 (86.012)
Epoch: [121][30/391]	Time 0.015 (0.016)	Data 0.002 (0.007)	Loss 2.3709 (2.3508)	Acc@1 53.906 (57.132)	Acc@5 85.938 (85.433)
Epoch: [121][40/391]	Time 0.013 (0.016)	Data 0.002 (0.006)	Loss 2.4168 (2.3148)	Acc@1 50.781 (57.584)	Acc@5 85.938 (86.014)
Epoch: [121][50/391]	Time 0.013 (0.015)	Data 0.002 (0.005)	Loss 2.1649 (2.2914)	Acc@1 66.406 (58.211)	Acc@5 90.625 (86.458)
Epoch: [121][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.4038 (2.2971)	Acc@1 50.781 (57.838)	Acc@5 83.594 (86.168)
Epoch: [121][70/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.3113 (2.2953)	Acc@1 55.469 (57.768)	Acc@5 85.938 (86.268)
Epoch: [121][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.4305 (2.3042)	Acc@1 57.812 (57.514)	Acc@5 84.375 (86.073)
Epoch: [121][90/391]	Time 0.012 (0.014)	Data 0.003 (0.003)	Loss 2.4204 (2.3089)	Acc@1 55.469 (57.495)	Acc@5 81.250 (86.041)
Epoch: [121][100/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.2914 (2.3148)	Acc@1 61.719 (57.534)	Acc@5 87.500 (85.945)
Epoch: [121][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.0471 (2.3263)	Acc@1 64.062 (57.292)	Acc@5 88.281 (85.846)
Epoch: [121][120/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.4994 (2.3331)	Acc@1 53.125 (57.122)	Acc@5 86.719 (85.776)
Epoch: [121][130/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.3872 (2.3355)	Acc@1 54.688 (57.013)	Acc@5 84.375 (85.621)
Epoch: [121][140/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2850 (2.3394)	Acc@1 60.156 (56.898)	Acc@5 86.719 (85.539)
Epoch: [121][150/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3811 (2.3424)	Acc@1 56.250 (56.861)	Acc@5 88.281 (85.493)
Epoch: [121][160/391]	Time 0.018 (0.014)	Data 0.002 (0.003)	Loss 2.2223 (2.3437)	Acc@1 64.062 (56.900)	Acc@5 83.594 (85.443)
Epoch: [121][170/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4573 (2.3513)	Acc@1 55.469 (56.743)	Acc@5 84.375 (85.353)
Epoch: [121][180/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.5831 (2.3562)	Acc@1 50.781 (56.587)	Acc@5 81.250 (85.247)
Epoch: [121][190/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4910 (2.3582)	Acc@1 58.594 (56.532)	Acc@5 87.500 (85.238)
Epoch: [121][200/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.1818 (2.3659)	Acc@1 62.500 (56.316)	Acc@5 89.062 (85.145)
Epoch: [121][210/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4517 (2.3722)	Acc@1 50.000 (56.194)	Acc@5 84.375 (85.027)
Epoch: [121][220/391]	Time 0.010 (0.014)	Data 0.002 (0.002)	Loss 2.5523 (2.3768)	Acc@1 55.469 (56.041)	Acc@5 79.688 (84.948)
Epoch: [121][230/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3614 (2.3796)	Acc@1 56.250 (55.959)	Acc@5 83.594 (84.892)
Epoch: [121][240/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4043 (2.3804)	Acc@1 59.375 (55.949)	Acc@5 84.375 (84.877)
Epoch: [121][250/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6123 (2.3848)	Acc@1 47.656 (55.858)	Acc@5 78.906 (84.789)
Epoch: [121][260/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5448 (2.3873)	Acc@1 52.344 (55.801)	Acc@5 77.344 (84.767)
Epoch: [121][270/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4073 (2.3886)	Acc@1 52.344 (55.743)	Acc@5 82.031 (84.718)
Epoch: [121][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3529 (2.3918)	Acc@1 57.031 (55.686)	Acc@5 83.594 (84.645)
Epoch: [121][290/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4876 (2.3895)	Acc@1 56.250 (55.743)	Acc@5 82.812 (84.668)
Epoch: [121][300/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4180 (2.3877)	Acc@1 55.469 (55.757)	Acc@5 85.156 (84.715)
Epoch: [121][310/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.4964 (2.3932)	Acc@1 53.906 (55.680)	Acc@5 80.469 (84.599)
Epoch: [121][320/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3255 (2.3938)	Acc@1 60.938 (55.717)	Acc@5 83.594 (84.582)
Epoch: [121][330/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4553 (2.3966)	Acc@1 55.469 (55.662)	Acc@5 83.594 (84.543)
Epoch: [121][340/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6105 (2.3992)	Acc@1 54.688 (55.576)	Acc@5 77.344 (84.510)
Epoch: [121][350/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3910 (2.3988)	Acc@1 57.812 (55.573)	Acc@5 84.375 (84.517)
Epoch: [121][360/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4244 (2.3991)	Acc@1 58.594 (55.622)	Acc@5 82.812 (84.531)
Epoch: [121][370/391]	Time 0.012 (0.014)	Data 0.005 (0.002)	Loss 2.4097 (2.4012)	Acc@1 59.375 (55.601)	Acc@5 84.375 (84.503)
Epoch: [121][380/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3148 (2.4037)	Acc@1 57.031 (55.567)	Acc@5 85.156 (84.455)
Epoch: [121][390/391]	Time 0.019 (0.014)	Data 0.001 (0.002)	Loss 2.4737 (2.4052)	Acc@1 60.000 (55.544)	Acc@5 82.500 (84.458)
num momentum params: 26
[0.1, 2.405200954589844, 2.1150420689582825, 55.544, 44.27, tensor(0.3312, device='cuda:0', grad_fn=<DivBackward0>), 5.476181745529175, 0.4282405376434326]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [122 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [122][0/391]	Time 0.067 (0.067)	Data 0.161 (0.161)	Loss 2.3532 (2.3532)	Acc@1 53.906 (53.906)	Acc@5 85.156 (85.156)
Epoch: [122][10/391]	Time 0.014 (0.020)	Data 0.001 (0.016)	Loss 2.2099 (2.3254)	Acc@1 63.281 (57.457)	Acc@5 84.375 (85.582)
Epoch: [122][20/391]	Time 0.013 (0.017)	Data 0.002 (0.009)	Loss 2.3799 (2.3487)	Acc@1 58.594 (57.478)	Acc@5 85.938 (85.268)
Epoch: [122][30/391]	Time 0.015 (0.016)	Data 0.001 (0.007)	Loss 2.2334 (2.3130)	Acc@1 54.688 (58.266)	Acc@5 89.062 (85.786)
Epoch: [122][40/391]	Time 0.014 (0.016)	Data 0.002 (0.005)	Loss 2.3642 (2.3261)	Acc@1 56.250 (57.793)	Acc@5 82.031 (85.633)
Epoch: [122][50/391]	Time 0.013 (0.015)	Data 0.002 (0.005)	Loss 2.3358 (2.3204)	Acc@1 57.812 (58.134)	Acc@5 83.594 (85.631)
Epoch: [122][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.3261 (2.3224)	Acc@1 57.031 (57.992)	Acc@5 83.594 (85.579)
Epoch: [122][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.3092 (2.3240)	Acc@1 57.031 (57.603)	Acc@5 86.719 (85.629)
Epoch: [122][80/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.1776 (2.3321)	Acc@1 60.938 (57.321)	Acc@5 85.938 (85.523)
Epoch: [122][90/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5250 (2.3389)	Acc@1 50.000 (57.186)	Acc@5 82.812 (85.465)
Epoch: [122][100/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.1506 (2.3515)	Acc@1 62.500 (56.884)	Acc@5 90.625 (85.172)
Epoch: [122][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2040 (2.3484)	Acc@1 63.281 (57.109)	Acc@5 85.156 (85.241)
Epoch: [122][120/391]	Time 0.016 (0.014)	Data 0.002 (0.003)	Loss 2.0540 (2.3496)	Acc@1 63.281 (56.934)	Acc@5 88.281 (85.240)
Epoch: [122][130/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3035 (2.3525)	Acc@1 55.469 (56.888)	Acc@5 78.125 (85.180)
Epoch: [122][140/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3849 (2.3555)	Acc@1 56.250 (56.810)	Acc@5 85.938 (85.167)
Epoch: [122][150/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5403 (2.3607)	Acc@1 51.562 (56.545)	Acc@5 81.250 (85.115)
Epoch: [122][160/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4302 (2.3601)	Acc@1 54.688 (56.590)	Acc@5 84.375 (85.190)
Epoch: [122][170/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.8162 (2.3653)	Acc@1 45.312 (56.497)	Acc@5 73.438 (85.079)
Epoch: [122][180/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3385 (2.3668)	Acc@1 60.156 (56.505)	Acc@5 82.812 (85.022)
Epoch: [122][190/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.5813 (2.3685)	Acc@1 55.469 (56.508)	Acc@5 80.469 (85.005)
Epoch: [122][200/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.1759 (2.3771)	Acc@1 61.719 (56.332)	Acc@5 90.625 (84.884)
Epoch: [122][210/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4324 (2.3778)	Acc@1 60.156 (56.365)	Acc@5 82.031 (84.882)
Epoch: [122][220/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.0991 (2.3786)	Acc@1 65.625 (56.342)	Acc@5 86.719 (84.905)
Epoch: [122][230/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.6576 (2.3832)	Acc@1 45.312 (56.220)	Acc@5 82.031 (84.828)
Epoch: [122][240/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3040 (2.3860)	Acc@1 58.594 (56.133)	Acc@5 84.375 (84.774)
Epoch: [122][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3785 (2.3916)	Acc@1 57.031 (56.038)	Acc@5 85.156 (84.699)
Epoch: [122][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5024 (2.3927)	Acc@1 54.688 (56.017)	Acc@5 83.594 (84.668)
Epoch: [122][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3098 (2.3906)	Acc@1 57.812 (56.019)	Acc@5 88.281 (84.715)
Epoch: [122][280/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4389 (2.3896)	Acc@1 54.688 (56.036)	Acc@5 82.031 (84.700)
Epoch: [122][290/391]	Time 0.010 (0.014)	Data 0.005 (0.002)	Loss 2.6448 (2.3895)	Acc@1 50.000 (56.054)	Acc@5 77.344 (84.703)
Epoch: [122][300/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5867 (2.3924)	Acc@1 51.562 (56.016)	Acc@5 80.469 (84.666)
Epoch: [122][310/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.0431 (2.3942)	Acc@1 64.844 (55.979)	Acc@5 89.062 (84.649)
Epoch: [122][320/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.7141 (2.3951)	Acc@1 49.219 (55.963)	Acc@5 76.562 (84.648)
Epoch: [122][330/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.1985 (2.3973)	Acc@1 60.156 (55.903)	Acc@5 89.844 (84.632)
Epoch: [122][340/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 2.3368 (2.4002)	Acc@1 57.031 (55.796)	Acc@5 85.938 (84.632)
Epoch: [122][350/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.6758 (2.4037)	Acc@1 48.438 (55.696)	Acc@5 82.812 (84.602)
Epoch: [122][360/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5958 (2.4067)	Acc@1 49.219 (55.594)	Acc@5 82.031 (84.565)
Epoch: [122][370/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3755 (2.4061)	Acc@1 54.688 (55.576)	Acc@5 88.281 (84.596)
Epoch: [122][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4505 (2.4069)	Acc@1 56.250 (55.557)	Acc@5 82.812 (84.607)
Epoch: [122][390/391]	Time 0.021 (0.014)	Data 0.001 (0.002)	Loss 2.4958 (2.4077)	Acc@1 50.000 (55.510)	Acc@5 81.250 (84.602)
num momentum params: 26
[0.1, 2.407704396209717, 1.8619900810718537, 55.51, 50.4, tensor(0.3310, device='cuda:0', grad_fn=<DivBackward0>), 5.422565460205078, 0.41588377952575684]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [123 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [123][0/391]	Time 0.069 (0.069)	Data 0.174 (0.174)	Loss 2.0803 (2.0803)	Acc@1 59.375 (59.375)	Acc@5 91.406 (91.406)
Epoch: [123][10/391]	Time 0.014 (0.021)	Data 0.001 (0.017)	Loss 2.2386 (2.3345)	Acc@1 68.750 (58.665)	Acc@5 84.375 (85.085)
Epoch: [123][20/391]	Time 0.013 (0.017)	Data 0.001 (0.010)	Loss 2.2609 (2.3315)	Acc@1 60.938 (58.482)	Acc@5 87.500 (85.305)
Epoch: [123][30/391]	Time 0.014 (0.016)	Data 0.001 (0.007)	Loss 2.3519 (2.3443)	Acc@1 59.375 (57.888)	Acc@5 85.156 (85.333)
Epoch: [123][40/391]	Time 0.013 (0.016)	Data 0.001 (0.006)	Loss 2.2178 (2.3386)	Acc@1 59.375 (57.527)	Acc@5 85.156 (85.518)
Epoch: [123][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.2910 (2.3469)	Acc@1 57.031 (57.506)	Acc@5 85.156 (85.600)
Epoch: [123][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.3033 (2.3495)	Acc@1 56.250 (57.351)	Acc@5 83.594 (85.451)
Epoch: [123][70/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.4047 (2.3504)	Acc@1 49.219 (57.262)	Acc@5 88.281 (85.464)
Epoch: [123][80/391]	Time 0.016 (0.015)	Data 0.001 (0.004)	Loss 2.2447 (2.3433)	Acc@1 57.812 (57.359)	Acc@5 89.062 (85.590)
Epoch: [123][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4745 (2.3565)	Acc@1 59.375 (56.885)	Acc@5 81.250 (85.508)
Epoch: [123][100/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3965 (2.3643)	Acc@1 56.250 (56.737)	Acc@5 84.375 (85.388)
Epoch: [123][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5038 (2.3654)	Acc@1 56.250 (56.722)	Acc@5 83.594 (85.367)
Epoch: [123][120/391]	Time 0.015 (0.014)	Data 0.002 (0.003)	Loss 2.3018 (2.3673)	Acc@1 57.031 (56.663)	Acc@5 85.156 (85.363)
Epoch: [123][130/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4080 (2.3743)	Acc@1 60.938 (56.536)	Acc@5 82.031 (85.258)
Epoch: [123][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.0945 (2.3761)	Acc@1 61.719 (56.389)	Acc@5 89.844 (85.167)
Epoch: [123][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4887 (2.3771)	Acc@1 55.469 (56.405)	Acc@5 80.469 (85.048)
Epoch: [123][160/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4895 (2.3832)	Acc@1 50.000 (56.226)	Acc@5 82.031 (84.865)
Epoch: [123][170/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.4372 (2.3877)	Acc@1 57.031 (56.081)	Acc@5 86.719 (84.827)
Epoch: [123][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3870 (2.3899)	Acc@1 55.469 (56.077)	Acc@5 85.156 (84.824)
Epoch: [123][190/391]	Time 0.017 (0.014)	Data 0.002 (0.002)	Loss 2.3769 (2.3922)	Acc@1 59.375 (56.058)	Acc@5 83.594 (84.780)
Epoch: [123][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4674 (2.3917)	Acc@1 53.125 (55.986)	Acc@5 82.031 (84.834)
Epoch: [123][210/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.1228 (2.3864)	Acc@1 63.281 (56.139)	Acc@5 89.844 (84.938)
Epoch: [123][220/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3146 (2.3848)	Acc@1 54.688 (56.186)	Acc@5 85.938 (84.912)
Epoch: [123][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6219 (2.3859)	Acc@1 50.781 (56.155)	Acc@5 80.469 (84.920)
Epoch: [123][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4417 (2.3883)	Acc@1 53.906 (56.075)	Acc@5 83.594 (84.900)
Epoch: [123][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7321 (2.3983)	Acc@1 50.781 (55.852)	Acc@5 78.906 (84.720)
Epoch: [123][260/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3161 (2.4020)	Acc@1 58.594 (55.804)	Acc@5 87.500 (84.647)
Epoch: [123][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1111 (2.4010)	Acc@1 60.938 (55.826)	Acc@5 85.938 (84.626)
Epoch: [123][280/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3352 (2.3991)	Acc@1 60.156 (55.861)	Acc@5 86.719 (84.661)
Epoch: [123][290/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.1086 (2.3963)	Acc@1 60.938 (55.885)	Acc@5 86.719 (84.697)
Epoch: [123][300/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 2.2837 (2.3983)	Acc@1 57.031 (55.853)	Acc@5 82.812 (84.663)
Epoch: [123][310/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 2.3770 (2.4015)	Acc@1 58.594 (55.800)	Acc@5 85.938 (84.651)
Epoch: [123][320/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.7865 (2.4058)	Acc@1 50.781 (55.702)	Acc@5 78.906 (84.584)
Epoch: [123][330/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.1968 (2.4050)	Acc@1 61.719 (55.724)	Acc@5 85.156 (84.561)
Epoch: [123][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.0583 (2.4032)	Acc@1 62.500 (55.773)	Acc@5 91.406 (84.588)
Epoch: [123][350/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.4151 (2.4033)	Acc@1 55.469 (55.789)	Acc@5 85.156 (84.593)
Epoch: [123][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4246 (2.4038)	Acc@1 52.344 (55.763)	Acc@5 83.594 (84.574)
Epoch: [123][370/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2463 (2.4051)	Acc@1 57.812 (55.726)	Acc@5 84.375 (84.571)
Epoch: [123][380/391]	Time 0.010 (0.014)	Data 0.001 (0.002)	Loss 2.4696 (2.4044)	Acc@1 59.375 (55.778)	Acc@5 81.250 (84.553)
Epoch: [123][390/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 2.4974 (2.4044)	Acc@1 56.250 (55.754)	Acc@5 83.750 (84.568)
num momentum params: 26
[0.1, 2.404357257614136, 2.014450671672821, 55.754, 48.23, tensor(0.3319, device='cuda:0', grad_fn=<DivBackward0>), 5.419877290725708, 0.4256458282470703]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [124 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [124][0/391]	Time 0.065 (0.065)	Data 0.191 (0.191)	Loss 2.2201 (2.2201)	Acc@1 57.031 (57.031)	Acc@5 86.719 (86.719)
Epoch: [124][10/391]	Time 0.014 (0.020)	Data 0.002 (0.019)	Loss 2.5607 (2.3373)	Acc@1 55.469 (57.670)	Acc@5 78.906 (85.724)
Epoch: [124][20/391]	Time 0.014 (0.018)	Data 0.002 (0.010)	Loss 2.4438 (2.3728)	Acc@1 52.344 (56.362)	Acc@5 82.031 (84.635)
Epoch: [124][30/391]	Time 0.013 (0.016)	Data 0.001 (0.008)	Loss 2.3328 (2.3634)	Acc@1 53.125 (56.250)	Acc@5 85.938 (85.181)
Epoch: [124][40/391]	Time 0.014 (0.016)	Data 0.002 (0.006)	Loss 2.5155 (2.3560)	Acc@1 51.562 (56.307)	Acc@5 81.250 (85.442)
Epoch: [124][50/391]	Time 0.014 (0.015)	Data 0.002 (0.005)	Loss 2.3917 (2.3563)	Acc@1 53.906 (56.189)	Acc@5 86.719 (85.524)
Epoch: [124][60/391]	Time 0.014 (0.015)	Data 0.001 (0.005)	Loss 2.7098 (2.3526)	Acc@1 51.562 (56.365)	Acc@5 79.688 (85.720)
Epoch: [124][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.4984 (2.3626)	Acc@1 55.469 (56.261)	Acc@5 86.719 (85.420)
Epoch: [124][80/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 2.3603 (2.3571)	Acc@1 53.906 (56.182)	Acc@5 85.938 (85.581)
Epoch: [124][90/391]	Time 0.012 (0.014)	Data 0.003 (0.004)	Loss 2.5546 (2.3573)	Acc@1 49.219 (55.941)	Acc@5 84.375 (85.671)
Epoch: [124][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.2673 (2.3632)	Acc@1 57.812 (55.770)	Acc@5 85.156 (85.597)
Epoch: [124][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4661 (2.3654)	Acc@1 52.344 (55.842)	Acc@5 82.031 (85.424)
Epoch: [124][120/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.5233 (2.3700)	Acc@1 50.781 (55.759)	Acc@5 82.031 (85.285)
Epoch: [124][130/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.6243 (2.3723)	Acc@1 51.562 (55.737)	Acc@5 79.688 (85.311)
Epoch: [124][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2693 (2.3703)	Acc@1 56.250 (55.879)	Acc@5 89.062 (85.356)
Epoch: [124][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3055 (2.3771)	Acc@1 59.375 (55.691)	Acc@5 87.500 (85.265)
Epoch: [124][160/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3985 (2.3767)	Acc@1 46.875 (55.692)	Acc@5 85.938 (85.273)
Epoch: [124][170/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.4264 (2.3777)	Acc@1 56.250 (55.702)	Acc@5 81.250 (85.197)
Epoch: [124][180/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3528 (2.3778)	Acc@1 57.812 (55.823)	Acc@5 84.375 (85.156)
Epoch: [124][190/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.4889 (2.3815)	Acc@1 54.688 (55.751)	Acc@5 82.812 (85.099)
Epoch: [124][200/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4859 (2.3824)	Acc@1 55.469 (55.780)	Acc@5 76.562 (85.059)
Epoch: [124][210/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5842 (2.3836)	Acc@1 53.906 (55.839)	Acc@5 78.125 (85.004)
Epoch: [124][220/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5640 (2.3868)	Acc@1 49.219 (55.759)	Acc@5 85.156 (84.972)
Epoch: [124][230/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3539 (2.3895)	Acc@1 55.469 (55.685)	Acc@5 84.375 (84.906)
Epoch: [124][240/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3454 (2.3929)	Acc@1 57.812 (55.566)	Acc@5 87.500 (84.816)
Epoch: [124][250/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4582 (2.3945)	Acc@1 55.469 (55.565)	Acc@5 85.938 (84.811)
Epoch: [124][260/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3124 (2.3924)	Acc@1 61.719 (55.636)	Acc@5 87.500 (84.815)
Epoch: [124][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4697 (2.3930)	Acc@1 52.344 (55.656)	Acc@5 86.719 (84.793)
Epoch: [124][280/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.0679 (2.3901)	Acc@1 64.844 (55.741)	Acc@5 91.406 (84.800)
Epoch: [124][290/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5393 (2.3885)	Acc@1 52.344 (55.777)	Acc@5 81.250 (84.810)
Epoch: [124][300/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6550 (2.3891)	Acc@1 53.125 (55.785)	Acc@5 79.688 (84.777)
Epoch: [124][310/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4041 (2.3911)	Acc@1 58.594 (55.758)	Acc@5 84.375 (84.719)
Epoch: [124][320/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6330 (2.3944)	Acc@1 49.219 (55.642)	Acc@5 75.781 (84.648)
Epoch: [124][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4291 (2.3991)	Acc@1 60.938 (55.568)	Acc@5 87.500 (84.559)
Epoch: [124][340/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2979 (2.3994)	Acc@1 54.688 (55.579)	Acc@5 87.500 (84.547)
Epoch: [124][350/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3167 (2.3988)	Acc@1 59.375 (55.605)	Acc@5 86.719 (84.578)
Epoch: [124][360/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3731 (2.3984)	Acc@1 57.031 (55.657)	Acc@5 87.500 (84.602)
Epoch: [124][370/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3427 (2.3993)	Acc@1 58.594 (55.633)	Acc@5 84.375 (84.583)
Epoch: [124][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5094 (2.4012)	Acc@1 53.125 (55.590)	Acc@5 79.688 (84.564)
Epoch: [124][390/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 2.0288 (2.4019)	Acc@1 63.750 (55.580)	Acc@5 90.000 (84.554)
num momentum params: 26
[0.1, 2.40188837020874, 2.0091645276546477, 55.58, 47.79, tensor(0.3322, device='cuda:0', grad_fn=<DivBackward0>), 5.3904502391815186, 0.4165463447570801]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [125 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [125][0/391]	Time 0.062 (0.062)	Data 0.180 (0.180)	Loss 2.1992 (2.1992)	Acc@1 60.938 (60.938)	Acc@5 87.500 (87.500)
Epoch: [125][10/391]	Time 0.013 (0.020)	Data 0.002 (0.018)	Loss 2.6115 (2.2975)	Acc@1 48.438 (58.310)	Acc@5 83.594 (86.151)
Epoch: [125][20/391]	Time 0.016 (0.017)	Data 0.001 (0.010)	Loss 2.0481 (2.2639)	Acc@1 63.281 (59.152)	Acc@5 92.969 (86.682)
Epoch: [125][30/391]	Time 0.013 (0.016)	Data 0.001 (0.007)	Loss 2.1663 (2.2522)	Acc@1 62.500 (59.325)	Acc@5 89.062 (87.021)
Epoch: [125][40/391]	Time 0.013 (0.016)	Data 0.002 (0.006)	Loss 2.1622 (2.2548)	Acc@1 62.500 (59.394)	Acc@5 88.281 (86.928)
Epoch: [125][50/391]	Time 0.014 (0.015)	Data 0.002 (0.005)	Loss 2.2110 (2.2524)	Acc@1 62.500 (59.390)	Acc@5 85.938 (86.811)
Epoch: [125][60/391]	Time 0.015 (0.015)	Data 0.001 (0.005)	Loss 2.2161 (2.2638)	Acc@1 57.031 (58.837)	Acc@5 89.844 (86.796)
Epoch: [125][70/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.4181 (2.2917)	Acc@1 53.906 (58.077)	Acc@5 84.375 (86.510)
Epoch: [125][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.3688 (2.3023)	Acc@1 56.250 (57.812)	Acc@5 88.281 (86.381)
Epoch: [125][90/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.2803 (2.3110)	Acc@1 59.375 (57.598)	Acc@5 85.156 (86.255)
Epoch: [125][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3242 (2.3202)	Acc@1 55.469 (57.372)	Acc@5 90.625 (86.146)
Epoch: [125][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2381 (2.3278)	Acc@1 60.156 (57.193)	Acc@5 89.062 (86.022)
Epoch: [125][120/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.3359 (2.3328)	Acc@1 57.812 (57.141)	Acc@5 85.938 (85.957)
Epoch: [125][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6105 (2.3366)	Acc@1 50.000 (57.121)	Acc@5 77.344 (85.884)
Epoch: [125][140/391]	Time 0.021 (0.014)	Data 0.002 (0.003)	Loss 2.2362 (2.3346)	Acc@1 58.594 (57.270)	Acc@5 85.156 (85.915)
Epoch: [125][150/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.0780 (2.3390)	Acc@1 61.719 (57.140)	Acc@5 91.406 (85.813)
Epoch: [125][160/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2743 (2.3453)	Acc@1 57.031 (56.915)	Acc@5 89.062 (85.768)
Epoch: [125][170/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.1435 (2.3452)	Acc@1 59.375 (56.830)	Acc@5 85.156 (85.791)
Epoch: [125][180/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3807 (2.3504)	Acc@1 55.469 (56.755)	Acc@5 85.156 (85.735)
Epoch: [125][190/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.6193 (2.3563)	Acc@1 46.875 (56.647)	Acc@5 85.156 (85.586)
Epoch: [125][200/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4256 (2.3625)	Acc@1 52.344 (56.518)	Acc@5 88.281 (85.498)
Epoch: [125][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6559 (2.3664)	Acc@1 44.531 (56.428)	Acc@5 82.812 (85.464)
Epoch: [125][220/391]	Time 0.012 (0.014)	Data 0.002 (0.002)	Loss 2.1736 (2.3674)	Acc@1 57.812 (56.437)	Acc@5 89.062 (85.489)
Epoch: [125][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4009 (2.3694)	Acc@1 57.812 (56.385)	Acc@5 87.500 (85.464)
Epoch: [125][240/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4326 (2.3708)	Acc@1 58.594 (56.308)	Acc@5 87.500 (85.467)
Epoch: [125][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5782 (2.3736)	Acc@1 53.906 (56.315)	Acc@5 78.906 (85.415)
Epoch: [125][260/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4854 (2.3750)	Acc@1 54.688 (56.337)	Acc@5 78.906 (85.363)
Epoch: [125][270/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.5654 (2.3731)	Acc@1 48.438 (56.394)	Acc@5 85.938 (85.387)
Epoch: [125][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2653 (2.3730)	Acc@1 55.469 (56.420)	Acc@5 88.281 (85.390)
Epoch: [125][290/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5599 (2.3755)	Acc@1 52.344 (56.360)	Acc@5 84.375 (85.401)
Epoch: [125][300/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4251 (2.3791)	Acc@1 51.562 (56.247)	Acc@5 88.281 (85.338)
Epoch: [125][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3694 (2.3805)	Acc@1 53.125 (56.160)	Acc@5 87.500 (85.312)
Epoch: [125][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3484 (2.3809)	Acc@1 55.469 (56.165)	Acc@5 83.594 (85.268)
Epoch: [125][330/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5524 (2.3824)	Acc@1 54.688 (56.141)	Acc@5 85.156 (85.229)
Epoch: [125][340/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.1866 (2.3844)	Acc@1 60.938 (56.110)	Acc@5 88.281 (85.197)
Epoch: [125][350/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3044 (2.3874)	Acc@1 57.812 (56.061)	Acc@5 89.062 (85.145)
Epoch: [125][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5070 (2.3894)	Acc@1 51.562 (55.986)	Acc@5 80.469 (85.143)
Epoch: [125][370/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4945 (2.3921)	Acc@1 56.250 (55.911)	Acc@5 82.812 (85.072)
Epoch: [125][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4959 (2.3930)	Acc@1 51.562 (55.910)	Acc@5 85.156 (85.046)
Epoch: [125][390/391]	Time 0.018 (0.014)	Data 0.001 (0.002)	Loss 2.7317 (2.3960)	Acc@1 45.000 (55.864)	Acc@5 76.250 (85.002)
num momentum params: 26
[0.1, 2.395952869567871, 1.974502990245819, 55.864, 48.48, tensor(0.3326, device='cuda:0', grad_fn=<DivBackward0>), 5.384408473968506, 0.41698765754699707]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [126 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [126][0/391]	Time 0.067 (0.067)	Data 0.176 (0.176)	Loss 2.2976 (2.2976)	Acc@1 51.562 (51.562)	Acc@5 86.719 (86.719)
Epoch: [126][10/391]	Time 0.015 (0.020)	Data 0.002 (0.017)	Loss 2.3906 (2.3408)	Acc@1 51.562 (56.392)	Acc@5 84.375 (86.151)
Epoch: [126][20/391]	Time 0.015 (0.017)	Data 0.002 (0.010)	Loss 2.2040 (2.2850)	Acc@1 61.719 (57.999)	Acc@5 87.500 (86.719)
Epoch: [126][30/391]	Time 0.015 (0.016)	Data 0.002 (0.007)	Loss 2.2832 (2.2934)	Acc@1 61.719 (58.165)	Acc@5 89.844 (86.416)
Epoch: [126][40/391]	Time 0.013 (0.016)	Data 0.001 (0.006)	Loss 2.3721 (2.2973)	Acc@1 54.688 (57.984)	Acc@5 87.500 (86.338)
Epoch: [126][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.4497 (2.3003)	Acc@1 53.125 (57.767)	Acc@5 85.156 (86.412)
Epoch: [126][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.1282 (2.3288)	Acc@1 60.938 (57.326)	Acc@5 92.188 (85.835)
Epoch: [126][70/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 2.2959 (2.3320)	Acc@1 62.500 (57.108)	Acc@5 85.938 (85.739)
Epoch: [126][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.4239 (2.3250)	Acc@1 58.594 (57.533)	Acc@5 88.281 (85.938)
Epoch: [126][90/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3048 (2.3326)	Acc@1 57.031 (57.263)	Acc@5 86.719 (85.860)
Epoch: [126][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5405 (2.3401)	Acc@1 55.469 (57.147)	Acc@5 82.812 (85.760)
Epoch: [126][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2551 (2.3448)	Acc@1 57.812 (57.010)	Acc@5 88.281 (85.663)
Epoch: [126][120/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5289 (2.3506)	Acc@1 48.438 (56.896)	Acc@5 84.375 (85.640)
Epoch: [126][130/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3645 (2.3530)	Acc@1 58.594 (56.823)	Acc@5 88.281 (85.645)
Epoch: [126][140/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.4207 (2.3562)	Acc@1 54.688 (56.815)	Acc@5 84.375 (85.511)
Epoch: [126][150/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.6147 (2.3635)	Acc@1 50.000 (56.540)	Acc@5 82.031 (85.467)
Epoch: [126][160/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5654 (2.3689)	Acc@1 50.781 (56.439)	Acc@5 83.594 (85.350)
Epoch: [126][170/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2026 (2.3672)	Acc@1 63.281 (56.510)	Acc@5 88.281 (85.362)
Epoch: [126][180/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.1466 (2.3629)	Acc@1 56.250 (56.634)	Acc@5 89.844 (85.329)
Epoch: [126][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3136 (2.3600)	Acc@1 53.125 (56.561)	Acc@5 86.719 (85.402)
Epoch: [126][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2183 (2.3604)	Acc@1 60.156 (56.576)	Acc@5 89.844 (85.362)
Epoch: [126][210/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5735 (2.3609)	Acc@1 47.656 (56.539)	Acc@5 81.250 (85.397)
Epoch: [126][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6454 (2.3643)	Acc@1 47.656 (56.398)	Acc@5 81.250 (85.333)
Epoch: [126][230/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4114 (2.3683)	Acc@1 56.250 (56.304)	Acc@5 84.375 (85.221)
Epoch: [126][240/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.3935 (2.3699)	Acc@1 59.375 (56.334)	Acc@5 84.375 (85.185)
Epoch: [126][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4502 (2.3699)	Acc@1 52.344 (56.365)	Acc@5 83.594 (85.144)
Epoch: [126][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5493 (2.3719)	Acc@1 54.688 (56.325)	Acc@5 80.469 (85.123)
Epoch: [126][270/391]	Time 0.011 (0.014)	Data 0.004 (0.002)	Loss 2.1760 (2.3754)	Acc@1 58.594 (56.279)	Acc@5 90.625 (85.050)
Epoch: [126][280/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3762 (2.3773)	Acc@1 59.375 (56.214)	Acc@5 82.812 (85.048)
Epoch: [126][290/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4765 (2.3792)	Acc@1 52.344 (56.164)	Acc@5 85.156 (85.041)
Epoch: [126][300/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5195 (2.3801)	Acc@1 56.250 (56.131)	Acc@5 84.375 (85.021)
Epoch: [126][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4625 (2.3831)	Acc@1 54.688 (56.069)	Acc@5 82.812 (84.958)
Epoch: [126][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5555 (2.3858)	Acc@1 50.781 (56.004)	Acc@5 82.812 (84.947)
Epoch: [126][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5641 (2.3875)	Acc@1 52.344 (55.948)	Acc@5 82.031 (84.892)
Epoch: [126][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4339 (2.3900)	Acc@1 54.688 (55.925)	Acc@5 83.594 (84.849)
Epoch: [126][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6328 (2.3949)	Acc@1 52.344 (55.796)	Acc@5 78.125 (84.751)
Epoch: [126][360/391]	Time 0.020 (0.014)	Data 0.001 (0.002)	Loss 2.3507 (2.3970)	Acc@1 56.250 (55.763)	Acc@5 84.375 (84.702)
Epoch: [126][370/391]	Time 0.022 (0.014)	Data 0.001 (0.002)	Loss 2.4143 (2.3988)	Acc@1 57.031 (55.717)	Acc@5 82.812 (84.672)
Epoch: [126][380/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2768 (2.4008)	Acc@1 61.719 (55.655)	Acc@5 82.031 (84.625)
Epoch: [126][390/391]	Time 0.018 (0.014)	Data 0.001 (0.002)	Loss 2.5808 (2.4013)	Acc@1 50.000 (55.652)	Acc@5 80.000 (84.618)
num momentum params: 26
[0.1, 2.401335888442993, 1.9975032937526702, 55.652, 48.37, tensor(0.3312, device='cuda:0', grad_fn=<DivBackward0>), 5.3822691440582275, 0.42000794410705566]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [127 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [127][0/391]	Time 0.065 (0.065)	Data 0.193 (0.193)	Loss 2.2603 (2.2603)	Acc@1 59.375 (59.375)	Acc@5 89.062 (89.062)
Epoch: [127][10/391]	Time 0.014 (0.020)	Data 0.001 (0.019)	Loss 2.1865 (2.3665)	Acc@1 59.375 (55.469)	Acc@5 85.938 (85.582)
Epoch: [127][20/391]	Time 0.013 (0.017)	Data 0.001 (0.011)	Loss 2.2690 (2.3230)	Acc@1 56.250 (56.436)	Acc@5 85.156 (86.384)
Epoch: [127][30/391]	Time 0.013 (0.016)	Data 0.002 (0.008)	Loss 2.3005 (2.3229)	Acc@1 54.688 (56.578)	Acc@5 86.719 (86.240)
Epoch: [127][40/391]	Time 0.013 (0.016)	Data 0.001 (0.006)	Loss 2.3886 (2.3207)	Acc@1 58.594 (56.974)	Acc@5 85.156 (86.261)
Epoch: [127][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.2092 (2.3451)	Acc@1 59.375 (56.664)	Acc@5 85.156 (85.463)
Epoch: [127][60/391]	Time 0.013 (0.015)	Data 0.002 (0.005)	Loss 2.0641 (2.3364)	Acc@1 64.844 (56.839)	Acc@5 91.406 (85.643)
Epoch: [127][70/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 2.3890 (2.3451)	Acc@1 60.156 (56.921)	Acc@5 79.688 (85.321)
Epoch: [127][80/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.2755 (2.3424)	Acc@1 64.844 (57.147)	Acc@5 86.719 (85.349)
Epoch: [127][90/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.0921 (2.3301)	Acc@1 63.281 (57.546)	Acc@5 92.188 (85.534)
Epoch: [127][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2154 (2.3352)	Acc@1 62.500 (57.403)	Acc@5 85.938 (85.450)
Epoch: [127][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4668 (2.3408)	Acc@1 50.000 (57.116)	Acc@5 86.719 (85.473)
Epoch: [127][120/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.1730 (2.3514)	Acc@1 56.250 (56.818)	Acc@5 90.625 (85.324)
Epoch: [127][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.1855 (2.3561)	Acc@1 61.719 (56.739)	Acc@5 87.500 (85.204)
Epoch: [127][140/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2622 (2.3610)	Acc@1 56.250 (56.621)	Acc@5 85.156 (85.156)
Epoch: [127][150/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4592 (2.3663)	Acc@1 56.250 (56.483)	Acc@5 85.938 (85.161)
Epoch: [127][160/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4455 (2.3691)	Acc@1 52.344 (56.439)	Acc@5 83.594 (85.132)
Epoch: [127][170/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3995 (2.3727)	Acc@1 51.562 (56.282)	Acc@5 85.156 (85.069)
Epoch: [127][180/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6475 (2.3732)	Acc@1 49.219 (56.207)	Acc@5 81.250 (85.092)
Epoch: [127][190/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3687 (2.3719)	Acc@1 53.906 (56.246)	Acc@5 85.156 (85.119)
Epoch: [127][200/391]	Time 0.020 (0.014)	Data 0.002 (0.002)	Loss 2.4244 (2.3731)	Acc@1 50.000 (56.258)	Acc@5 82.812 (85.036)
Epoch: [127][210/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2074 (2.3746)	Acc@1 60.938 (56.246)	Acc@5 86.719 (85.023)
Epoch: [127][220/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4484 (2.3790)	Acc@1 57.812 (56.144)	Acc@5 84.375 (84.965)
Epoch: [127][230/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3467 (2.3809)	Acc@1 55.469 (56.115)	Acc@5 85.156 (84.923)
Epoch: [127][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3887 (2.3830)	Acc@1 50.781 (56.088)	Acc@5 87.500 (84.916)
Epoch: [127][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4631 (2.3855)	Acc@1 56.250 (55.992)	Acc@5 82.812 (84.898)
Epoch: [127][260/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3423 (2.3862)	Acc@1 55.469 (55.996)	Acc@5 84.375 (84.875)
Epoch: [127][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5519 (2.3878)	Acc@1 50.000 (55.918)	Acc@5 82.031 (84.836)
Epoch: [127][280/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4499 (2.3914)	Acc@1 51.562 (55.819)	Acc@5 82.031 (84.792)
Epoch: [127][290/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.6162 (2.3951)	Acc@1 52.344 (55.716)	Acc@5 81.250 (84.727)
Epoch: [127][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2773 (2.3922)	Acc@1 56.250 (55.759)	Acc@5 87.500 (84.868)
Epoch: [127][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3245 (2.3934)	Acc@1 60.938 (55.755)	Acc@5 84.375 (84.850)
Epoch: [127][320/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.0873 (2.3932)	Acc@1 63.281 (55.780)	Acc@5 88.281 (84.840)
Epoch: [127][330/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3641 (2.3960)	Acc@1 57.031 (55.750)	Acc@5 84.375 (84.807)
Epoch: [127][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6171 (2.3996)	Acc@1 52.344 (55.629)	Acc@5 81.250 (84.758)
Epoch: [127][350/391]	Time 0.016 (0.014)	Data 0.002 (0.002)	Loss 2.4980 (2.4025)	Acc@1 53.906 (55.582)	Acc@5 81.250 (84.700)
Epoch: [127][360/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4759 (2.4037)	Acc@1 55.469 (55.573)	Acc@5 82.031 (84.674)
Epoch: [127][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.0907 (2.4038)	Acc@1 64.062 (55.549)	Acc@5 89.062 (84.693)
Epoch: [127][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3677 (2.4048)	Acc@1 55.469 (55.545)	Acc@5 89.844 (84.662)
Epoch: [127][390/391]	Time 0.018 (0.014)	Data 0.001 (0.002)	Loss 2.6210 (2.4063)	Acc@1 52.500 (55.544)	Acc@5 83.750 (84.656)
num momentum params: 26
[0.1, 2.40630115234375, 1.9238002848625184, 55.544, 49.57, tensor(0.3306, device='cuda:0', grad_fn=<DivBackward0>), 5.358396768569946, 0.41777038574218756]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [128 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [128][0/391]	Time 0.061 (0.061)	Data 0.181 (0.181)	Loss 2.3296 (2.3296)	Acc@1 58.594 (58.594)	Acc@5 88.281 (88.281)
Epoch: [128][10/391]	Time 0.013 (0.020)	Data 0.002 (0.018)	Loss 2.3714 (2.3399)	Acc@1 53.906 (56.463)	Acc@5 85.156 (87.145)
Epoch: [128][20/391]	Time 0.014 (0.017)	Data 0.002 (0.010)	Loss 2.2192 (2.3177)	Acc@1 57.031 (56.362)	Acc@5 89.844 (86.979)
Epoch: [128][30/391]	Time 0.014 (0.016)	Data 0.001 (0.007)	Loss 2.3036 (2.2989)	Acc@1 53.906 (56.956)	Acc@5 85.938 (86.845)
Epoch: [128][40/391]	Time 0.013 (0.016)	Data 0.001 (0.006)	Loss 2.3498 (2.2867)	Acc@1 53.125 (57.527)	Acc@5 85.156 (86.757)
Epoch: [128][50/391]	Time 0.013 (0.015)	Data 0.002 (0.005)	Loss 2.3892 (2.3058)	Acc@1 57.031 (57.276)	Acc@5 83.594 (86.382)
Epoch: [128][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.3540 (2.3037)	Acc@1 53.125 (57.223)	Acc@5 86.719 (86.424)
Epoch: [128][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.3266 (2.3039)	Acc@1 55.469 (57.339)	Acc@5 85.938 (86.466)
Epoch: [128][80/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.1954 (2.3097)	Acc@1 58.594 (57.186)	Acc@5 87.500 (86.381)
Epoch: [128][90/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.4393 (2.3281)	Acc@1 53.125 (56.757)	Acc@5 85.156 (86.161)
Epoch: [128][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2402 (2.3310)	Acc@1 60.938 (56.915)	Acc@5 86.719 (86.077)
Epoch: [128][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4411 (2.3362)	Acc@1 50.000 (56.883)	Acc@5 80.469 (85.860)
Epoch: [128][120/391]	Time 0.012 (0.014)	Data 0.001 (0.003)	Loss 2.2549 (2.3364)	Acc@1 59.375 (56.876)	Acc@5 83.594 (85.744)
Epoch: [128][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3088 (2.3327)	Acc@1 59.375 (57.013)	Acc@5 86.719 (85.848)
Epoch: [128][140/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.5374 (2.3398)	Acc@1 51.562 (56.898)	Acc@5 86.719 (85.716)
Epoch: [128][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4319 (2.3457)	Acc@1 53.125 (56.731)	Acc@5 86.719 (85.575)
Epoch: [128][160/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4952 (2.3485)	Acc@1 53.906 (56.716)	Acc@5 82.812 (85.447)
Epoch: [128][170/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.2102 (2.3503)	Acc@1 61.719 (56.698)	Acc@5 89.844 (85.385)
Epoch: [128][180/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.7372 (2.3573)	Acc@1 46.875 (56.526)	Acc@5 78.906 (85.260)
Epoch: [128][190/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4080 (2.3619)	Acc@1 53.906 (56.483)	Acc@5 83.594 (85.103)
Epoch: [128][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1937 (2.3655)	Acc@1 60.938 (56.367)	Acc@5 85.156 (85.036)
Epoch: [128][210/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5406 (2.3710)	Acc@1 55.469 (56.287)	Acc@5 80.469 (84.927)
Epoch: [128][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3440 (2.3759)	Acc@1 58.594 (56.133)	Acc@5 83.594 (84.888)
Epoch: [128][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3097 (2.3822)	Acc@1 54.688 (56.044)	Acc@5 85.156 (84.733)
Epoch: [128][240/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.2528 (2.3812)	Acc@1 56.250 (56.046)	Acc@5 89.062 (84.783)
Epoch: [128][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4903 (2.3826)	Acc@1 46.094 (55.992)	Acc@5 85.156 (84.783)
Epoch: [128][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5939 (2.3845)	Acc@1 52.344 (56.026)	Acc@5 82.031 (84.731)
Epoch: [128][270/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2628 (2.3830)	Acc@1 56.250 (56.008)	Acc@5 86.719 (84.779)
Epoch: [128][280/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4858 (2.3864)	Acc@1 51.562 (55.944)	Acc@5 85.938 (84.728)
Epoch: [128][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1992 (2.3875)	Acc@1 56.250 (55.939)	Acc@5 88.281 (84.727)
Epoch: [128][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6511 (2.3872)	Acc@1 45.312 (55.889)	Acc@5 78.906 (84.736)
Epoch: [128][310/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4876 (2.3858)	Acc@1 50.000 (55.898)	Acc@5 85.156 (84.764)
Epoch: [128][320/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4160 (2.3862)	Acc@1 56.250 (55.907)	Acc@5 85.938 (84.723)
Epoch: [128][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2436 (2.3853)	Acc@1 63.281 (55.934)	Acc@5 85.938 (84.701)
Epoch: [128][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4801 (2.3886)	Acc@1 53.906 (55.854)	Acc@5 86.719 (84.634)
Epoch: [128][350/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6427 (2.3892)	Acc@1 51.562 (55.840)	Acc@5 80.469 (84.633)
Epoch: [128][360/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4832 (2.3918)	Acc@1 53.125 (55.819)	Acc@5 82.812 (84.581)
Epoch: [128][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3140 (2.3928)	Acc@1 54.688 (55.797)	Acc@5 85.156 (84.529)
Epoch: [128][380/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5155 (2.3935)	Acc@1 55.469 (55.797)	Acc@5 85.938 (84.506)
Epoch: [128][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.4679 (2.3949)	Acc@1 61.250 (55.762)	Acc@5 83.750 (84.498)
num momentum params: 26
[0.1, 2.3948987966918946, 2.0444082510471344, 55.762, 47.33, tensor(0.3316, device='cuda:0', grad_fn=<DivBackward0>), 5.340292930603027, 0.42203378677368164]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [129 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [129][0/391]	Time 0.070 (0.070)	Data 0.161 (0.161)	Loss 2.4366 (2.4366)	Acc@1 53.906 (53.906)	Acc@5 81.250 (81.250)
Epoch: [129][10/391]	Time 0.016 (0.020)	Data 0.001 (0.016)	Loss 2.2175 (2.3297)	Acc@1 60.156 (57.812)	Acc@5 88.281 (85.938)
Epoch: [129][20/391]	Time 0.013 (0.017)	Data 0.003 (0.009)	Loss 2.0854 (2.2856)	Acc@1 66.406 (58.445)	Acc@5 88.281 (86.533)
Epoch: [129][30/391]	Time 0.013 (0.016)	Data 0.001 (0.007)	Loss 2.1531 (2.2900)	Acc@1 58.594 (58.543)	Acc@5 87.500 (86.013)
Epoch: [129][40/391]	Time 0.013 (0.016)	Data 0.002 (0.006)	Loss 2.4022 (2.2938)	Acc@1 57.031 (58.384)	Acc@5 86.719 (86.300)
Epoch: [129][50/391]	Time 0.013 (0.015)	Data 0.002 (0.005)	Loss 2.6822 (2.3058)	Acc@1 46.094 (58.165)	Acc@5 84.375 (86.275)
Epoch: [129][60/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 2.5239 (2.3213)	Acc@1 56.250 (57.531)	Acc@5 84.375 (86.002)
Epoch: [129][70/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 2.3040 (2.3226)	Acc@1 57.031 (57.526)	Acc@5 87.500 (85.926)
Epoch: [129][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.4101 (2.3303)	Acc@1 61.719 (57.475)	Acc@5 77.344 (85.667)
Epoch: [129][90/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.4072 (2.3344)	Acc@1 53.125 (57.203)	Acc@5 85.938 (85.646)
Epoch: [129][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5746 (2.3400)	Acc@1 49.219 (56.977)	Acc@5 82.031 (85.466)
Epoch: [129][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4089 (2.3428)	Acc@1 49.219 (56.890)	Acc@5 86.719 (85.367)
Epoch: [129][120/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.3670 (2.3424)	Acc@1 55.469 (56.831)	Acc@5 85.156 (85.415)
Epoch: [129][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.0949 (2.3447)	Acc@1 60.938 (56.793)	Acc@5 90.625 (85.413)
Epoch: [129][140/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4507 (2.3494)	Acc@1 51.562 (56.732)	Acc@5 83.594 (85.256)
Epoch: [129][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4990 (2.3527)	Acc@1 50.000 (56.586)	Acc@5 82.031 (85.229)
Epoch: [129][160/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5322 (2.3616)	Acc@1 54.688 (56.376)	Acc@5 81.250 (85.088)
Epoch: [129][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7718 (2.3655)	Acc@1 48.438 (56.296)	Acc@5 75.781 (85.033)
Epoch: [129][180/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4199 (2.3689)	Acc@1 57.812 (56.215)	Acc@5 81.250 (84.966)
Epoch: [129][190/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5201 (2.3701)	Acc@1 53.906 (56.148)	Acc@5 81.250 (84.907)
Epoch: [129][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3486 (2.3733)	Acc@1 52.344 (56.087)	Acc@5 82.812 (84.845)
Epoch: [129][210/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.4984 (2.3723)	Acc@1 50.781 (56.050)	Acc@5 79.688 (84.875)
Epoch: [129][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4453 (2.3757)	Acc@1 60.156 (55.942)	Acc@5 83.594 (84.803)
Epoch: [129][230/391]	Time 0.010 (0.014)	Data 0.006 (0.002)	Loss 2.2640 (2.3730)	Acc@1 61.719 (56.067)	Acc@5 83.594 (84.889)
Epoch: [129][240/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4732 (2.3758)	Acc@1 56.250 (56.000)	Acc@5 82.812 (84.835)
Epoch: [129][250/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 2.2553 (2.3775)	Acc@1 57.812 (55.961)	Acc@5 86.719 (84.823)
Epoch: [129][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6887 (2.3811)	Acc@1 48.438 (55.882)	Acc@5 81.250 (84.755)
Epoch: [129][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.0846 (2.3821)	Acc@1 61.719 (55.901)	Acc@5 90.625 (84.741)
Epoch: [129][280/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.1654 (2.3831)	Acc@1 63.281 (55.891)	Acc@5 90.625 (84.748)
Epoch: [129][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3831 (2.3828)	Acc@1 62.500 (55.909)	Acc@5 81.250 (84.735)
Epoch: [129][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4266 (2.3833)	Acc@1 57.031 (55.868)	Acc@5 79.688 (84.754)
Epoch: [129][310/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5499 (2.3829)	Acc@1 53.125 (55.883)	Acc@5 82.031 (84.752)
Epoch: [129][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5602 (2.3837)	Acc@1 48.438 (55.839)	Acc@5 85.156 (84.723)
Epoch: [129][330/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6003 (2.3855)	Acc@1 51.562 (55.769)	Acc@5 82.031 (84.708)
Epoch: [129][340/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3510 (2.3880)	Acc@1 57.031 (55.707)	Acc@5 86.719 (84.666)
Epoch: [129][350/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5851 (2.3903)	Acc@1 50.000 (55.640)	Acc@5 78.125 (84.662)
Epoch: [129][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7859 (2.3897)	Acc@1 43.750 (55.633)	Acc@5 80.469 (84.700)
Epoch: [129][370/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4482 (2.3917)	Acc@1 57.031 (55.601)	Acc@5 79.688 (84.682)
Epoch: [129][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3180 (2.3953)	Acc@1 60.938 (55.551)	Acc@5 87.500 (84.635)
Epoch: [129][390/391]	Time 0.017 (0.014)	Data 0.002 (0.002)	Loss 2.1068 (2.3957)	Acc@1 66.250 (55.534)	Acc@5 92.500 (84.638)
num momentum params: 26
[0.1, 2.3956529638671875, 2.1081303262710573, 55.534, 45.81, tensor(0.3315, device='cuda:0', grad_fn=<DivBackward0>), 5.367079734802246, 0.4158318042755127]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [130 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [130][0/391]	Time 0.064 (0.064)	Data 0.173 (0.173)	Loss 2.4291 (2.4291)	Acc@1 56.250 (56.250)	Acc@5 82.812 (82.812)
Epoch: [130][10/391]	Time 0.013 (0.020)	Data 0.001 (0.017)	Loss 2.2695 (2.3414)	Acc@1 59.375 (57.102)	Acc@5 89.062 (85.938)
Epoch: [130][20/391]	Time 0.014 (0.017)	Data 0.001 (0.010)	Loss 2.4262 (2.3211)	Acc@1 50.781 (57.292)	Acc@5 89.844 (86.310)
Epoch: [130][30/391]	Time 0.016 (0.016)	Data 0.001 (0.007)	Loss 2.2257 (2.2905)	Acc@1 59.375 (57.863)	Acc@5 85.938 (86.719)
Epoch: [130][40/391]	Time 0.013 (0.015)	Data 0.002 (0.006)	Loss 2.5364 (2.2965)	Acc@1 57.812 (57.965)	Acc@5 80.469 (86.490)
Epoch: [130][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.1811 (2.3096)	Acc@1 61.719 (57.537)	Acc@5 89.062 (86.167)
Epoch: [130][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.2437 (2.3085)	Acc@1 59.375 (57.774)	Acc@5 87.500 (86.117)
Epoch: [130][70/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.1986 (2.3258)	Acc@1 55.469 (57.438)	Acc@5 87.500 (85.971)
Epoch: [130][80/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.6050 (2.3381)	Acc@1 49.219 (57.205)	Acc@5 83.594 (85.735)
Epoch: [130][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3008 (2.3345)	Acc@1 59.375 (57.160)	Acc@5 86.719 (85.809)
Epoch: [130][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4111 (2.3348)	Acc@1 53.906 (57.333)	Acc@5 90.625 (85.860)
Epoch: [130][110/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.3527 (2.3366)	Acc@1 54.688 (57.264)	Acc@5 88.281 (85.846)
Epoch: [130][120/391]	Time 0.012 (0.014)	Data 0.001 (0.003)	Loss 2.3853 (2.3470)	Acc@1 57.812 (57.025)	Acc@5 86.719 (85.718)
Epoch: [130][130/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.3550 (2.3469)	Acc@1 55.469 (57.097)	Acc@5 87.500 (85.687)
Epoch: [130][140/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4653 (2.3512)	Acc@1 49.219 (56.904)	Acc@5 82.812 (85.611)
Epoch: [130][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6352 (2.3590)	Acc@1 55.469 (56.700)	Acc@5 77.344 (85.420)
Epoch: [130][160/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2299 (2.3624)	Acc@1 63.281 (56.638)	Acc@5 86.719 (85.365)
Epoch: [130][170/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.2573 (2.3661)	Acc@1 56.250 (56.570)	Acc@5 89.062 (85.307)
Epoch: [130][180/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3603 (2.3646)	Acc@1 60.938 (56.613)	Acc@5 82.031 (85.350)
Epoch: [130][190/391]	Time 0.015 (0.014)	Data 0.002 (0.003)	Loss 2.3015 (2.3700)	Acc@1 60.938 (56.491)	Acc@5 86.719 (85.242)
Epoch: [130][200/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6773 (2.3780)	Acc@1 48.438 (56.262)	Acc@5 79.688 (85.141)
Epoch: [130][210/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.4614 (2.3831)	Acc@1 55.469 (56.198)	Acc@5 84.375 (85.012)
Epoch: [130][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2255 (2.3882)	Acc@1 64.062 (56.010)	Acc@5 84.375 (84.888)
Epoch: [130][230/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3233 (2.3928)	Acc@1 53.125 (55.908)	Acc@5 89.844 (84.835)
Epoch: [130][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6870 (2.3945)	Acc@1 48.438 (55.851)	Acc@5 75.781 (84.754)
Epoch: [130][250/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5313 (2.3959)	Acc@1 51.562 (55.842)	Acc@5 84.375 (84.752)
Epoch: [130][260/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5683 (2.3995)	Acc@1 47.656 (55.714)	Acc@5 83.594 (84.680)
Epoch: [130][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4188 (2.3998)	Acc@1 57.031 (55.763)	Acc@5 85.938 (84.649)
Epoch: [130][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1102 (2.3981)	Acc@1 65.625 (55.761)	Acc@5 89.062 (84.714)
Epoch: [130][290/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6863 (2.4012)	Acc@1 50.781 (55.665)	Acc@5 82.031 (84.662)
Epoch: [130][300/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2349 (2.4008)	Acc@1 61.719 (55.697)	Acc@5 85.938 (84.663)
Epoch: [130][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3579 (2.4019)	Acc@1 58.594 (55.685)	Acc@5 86.719 (84.604)
Epoch: [130][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2569 (2.4007)	Acc@1 58.594 (55.712)	Acc@5 85.156 (84.628)
Epoch: [130][330/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5022 (2.4003)	Acc@1 55.469 (55.717)	Acc@5 79.688 (84.642)
Epoch: [130][340/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.0920 (2.3999)	Acc@1 61.719 (55.739)	Acc@5 89.844 (84.645)
Epoch: [130][350/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6063 (2.4045)	Acc@1 50.000 (55.651)	Acc@5 86.719 (84.578)
Epoch: [130][360/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4711 (2.4065)	Acc@1 53.125 (55.655)	Acc@5 81.250 (84.505)
Epoch: [130][370/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.1835 (2.4084)	Acc@1 63.281 (55.566)	Acc@5 92.188 (84.501)
Epoch: [130][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2644 (2.4098)	Acc@1 58.594 (55.522)	Acc@5 89.062 (84.465)
Epoch: [130][390/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 2.6611 (2.4124)	Acc@1 50.000 (55.472)	Acc@5 78.750 (84.406)
num momentum params: 26
[0.1, 2.412359112854004, 2.3858654475212098, 55.472, 41.94, tensor(0.3294, device='cuda:0', grad_fn=<DivBackward0>), 5.356488227844238, 0.40769529342651367]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [131 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [131][0/391]	Time 0.071 (0.071)	Data 0.195 (0.195)	Loss 2.4709 (2.4709)	Acc@1 53.125 (53.125)	Acc@5 80.469 (80.469)
Epoch: [131][10/391]	Time 0.016 (0.021)	Data 0.001 (0.019)	Loss 2.0808 (2.3045)	Acc@1 67.969 (56.605)	Acc@5 90.625 (86.151)
Epoch: [131][20/391]	Time 0.014 (0.018)	Data 0.001 (0.011)	Loss 2.0013 (2.2944)	Acc@1 61.719 (56.994)	Acc@5 92.188 (86.793)
Epoch: [131][30/391]	Time 0.011 (0.017)	Data 0.002 (0.008)	Loss 2.2661 (2.2824)	Acc@1 55.469 (57.586)	Acc@5 92.188 (86.996)
Epoch: [131][40/391]	Time 0.014 (0.016)	Data 0.002 (0.006)	Loss 2.5535 (2.2992)	Acc@1 47.656 (57.241)	Acc@5 84.375 (86.852)
Epoch: [131][50/391]	Time 0.014 (0.015)	Data 0.002 (0.005)	Loss 2.1745 (2.3151)	Acc@1 60.938 (57.047)	Acc@5 89.062 (86.504)
Epoch: [131][60/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.2232 (2.3181)	Acc@1 53.125 (56.916)	Acc@5 87.500 (86.296)
Epoch: [131][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.5490 (2.3361)	Acc@1 50.781 (56.547)	Acc@5 84.375 (85.960)
Epoch: [131][80/391]	Time 0.014 (0.015)	Data 0.002 (0.004)	Loss 2.3368 (2.3432)	Acc@1 54.688 (56.318)	Acc@5 86.719 (85.860)
Epoch: [131][90/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.3598 (2.3503)	Acc@1 53.125 (56.250)	Acc@5 85.156 (85.646)
Epoch: [131][100/391]	Time 0.014 (0.015)	Data 0.002 (0.003)	Loss 2.0512 (2.3463)	Acc@1 63.281 (56.405)	Acc@5 87.500 (85.659)
Epoch: [131][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.1609 (2.3431)	Acc@1 60.938 (56.440)	Acc@5 88.281 (85.783)
Epoch: [131][120/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.5918 (2.3495)	Acc@1 48.438 (56.327)	Acc@5 83.594 (85.724)
Epoch: [131][130/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.6276 (2.3528)	Acc@1 46.875 (56.280)	Acc@5 78.906 (85.562)
Epoch: [131][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2796 (2.3584)	Acc@1 53.125 (56.145)	Acc@5 87.500 (85.511)
Epoch: [131][150/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.1955 (2.3630)	Acc@1 63.281 (56.074)	Acc@5 85.156 (85.348)
Epoch: [131][160/391]	Time 0.012 (0.014)	Data 0.003 (0.003)	Loss 2.2697 (2.3618)	Acc@1 58.594 (56.216)	Acc@5 91.406 (85.307)
Epoch: [131][170/391]	Time 0.016 (0.014)	Data 0.002 (0.003)	Loss 2.5003 (2.3571)	Acc@1 50.781 (56.268)	Acc@5 84.375 (85.421)
Epoch: [131][180/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5726 (2.3611)	Acc@1 55.469 (56.220)	Acc@5 82.031 (85.342)
Epoch: [131][190/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5844 (2.3643)	Acc@1 51.562 (56.103)	Acc@5 82.031 (85.279)
Epoch: [131][200/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4298 (2.3645)	Acc@1 55.469 (56.083)	Acc@5 83.594 (85.269)
Epoch: [131][210/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.5614 (2.3658)	Acc@1 50.000 (56.128)	Acc@5 83.594 (85.193)
Epoch: [131][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5262 (2.3640)	Acc@1 54.688 (56.218)	Acc@5 83.594 (85.202)
Epoch: [131][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3910 (2.3699)	Acc@1 60.156 (56.061)	Acc@5 85.156 (85.133)
Epoch: [131][240/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.2581 (2.3725)	Acc@1 61.719 (56.062)	Acc@5 84.375 (85.082)
Epoch: [131][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1946 (2.3730)	Acc@1 66.406 (56.088)	Acc@5 85.938 (85.047)
Epoch: [131][260/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5787 (2.3746)	Acc@1 54.688 (56.094)	Acc@5 77.344 (85.007)
Epoch: [131][270/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2515 (2.3729)	Acc@1 60.938 (56.117)	Acc@5 83.594 (85.078)
Epoch: [131][280/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.7167 (2.3754)	Acc@1 47.656 (56.075)	Acc@5 75.000 (85.031)
Epoch: [131][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5208 (2.3793)	Acc@1 56.250 (55.984)	Acc@5 85.938 (84.974)
Epoch: [131][300/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4822 (2.3809)	Acc@1 56.250 (55.928)	Acc@5 79.688 (84.954)
Epoch: [131][310/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6199 (2.3859)	Acc@1 50.781 (55.775)	Acc@5 78.906 (84.898)
Epoch: [131][320/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2640 (2.3886)	Acc@1 55.469 (55.719)	Acc@5 86.719 (84.903)
Epoch: [131][330/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4393 (2.3889)	Acc@1 53.906 (55.705)	Acc@5 85.938 (84.892)
Epoch: [131][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3838 (2.3913)	Acc@1 57.812 (55.622)	Acc@5 81.250 (84.856)
Epoch: [131][350/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.2317 (2.3908)	Acc@1 63.281 (55.662)	Acc@5 86.719 (84.834)
Epoch: [131][360/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.1304 (2.3917)	Acc@1 64.062 (55.646)	Acc@5 89.062 (84.816)
Epoch: [131][370/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5533 (2.3934)	Acc@1 50.781 (55.578)	Acc@5 82.031 (84.798)
Epoch: [131][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5042 (2.3944)	Acc@1 50.000 (55.536)	Acc@5 87.500 (84.806)
Epoch: [131][390/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 2.3680 (2.3949)	Acc@1 61.250 (55.522)	Acc@5 86.250 (84.794)
num momentum params: 26
[0.1, 2.394939651260376, 1.924387845993042, 55.522, 49.32, tensor(0.3319, device='cuda:0', grad_fn=<DivBackward0>), 5.406954526901245, 0.4114086627960205]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [132 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [132][0/391]	Time 0.068 (0.068)	Data 0.193 (0.193)	Loss 2.1648 (2.1648)	Acc@1 60.938 (60.938)	Acc@5 89.062 (89.062)
Epoch: [132][10/391]	Time 0.014 (0.021)	Data 0.001 (0.019)	Loss 2.2444 (2.2440)	Acc@1 53.906 (59.446)	Acc@5 89.062 (87.713)
Epoch: [132][20/391]	Time 0.014 (0.018)	Data 0.002 (0.010)	Loss 2.3076 (2.2388)	Acc@1 56.250 (58.817)	Acc@5 86.719 (87.351)
Epoch: [132][30/391]	Time 0.013 (0.016)	Data 0.001 (0.008)	Loss 2.0853 (2.2659)	Acc@1 58.594 (58.039)	Acc@5 89.062 (86.946)
Epoch: [132][40/391]	Time 0.014 (0.016)	Data 0.002 (0.006)	Loss 2.0387 (2.2601)	Acc@1 64.844 (58.117)	Acc@5 91.406 (86.928)
Epoch: [132][50/391]	Time 0.013 (0.015)	Data 0.002 (0.005)	Loss 2.4813 (2.2886)	Acc@1 52.344 (57.659)	Acc@5 85.156 (86.596)
Epoch: [132][60/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.0953 (2.2980)	Acc@1 61.719 (57.403)	Acc@5 89.062 (86.206)
Epoch: [132][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.5376 (2.3202)	Acc@1 54.688 (56.965)	Acc@5 80.469 (85.739)
Epoch: [132][80/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.5161 (2.3351)	Acc@1 53.125 (56.694)	Acc@5 83.594 (85.561)
Epoch: [132][90/391]	Time 0.013 (0.014)	Data 0.002 (0.004)	Loss 2.2198 (2.3422)	Acc@1 62.500 (56.585)	Acc@5 88.281 (85.500)
Epoch: [132][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4969 (2.3493)	Acc@1 56.250 (56.513)	Acc@5 81.250 (85.311)
Epoch: [132][110/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.2849 (2.3493)	Acc@1 58.594 (56.447)	Acc@5 83.594 (85.262)
Epoch: [132][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6810 (2.3530)	Acc@1 49.219 (56.424)	Acc@5 81.250 (85.279)
Epoch: [132][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4455 (2.3584)	Acc@1 54.688 (56.310)	Acc@5 84.375 (85.240)
Epoch: [132][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2775 (2.3585)	Acc@1 64.062 (56.499)	Acc@5 84.375 (85.217)
Epoch: [132][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2798 (2.3544)	Acc@1 54.688 (56.602)	Acc@5 85.156 (85.239)
Epoch: [132][160/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2330 (2.3564)	Acc@1 57.812 (56.638)	Acc@5 87.500 (85.151)
Epoch: [132][170/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3377 (2.3580)	Acc@1 57.031 (56.602)	Acc@5 84.375 (85.115)
Epoch: [132][180/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3416 (2.3603)	Acc@1 54.688 (56.552)	Acc@5 85.938 (85.165)
Epoch: [132][190/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2678 (2.3612)	Acc@1 62.500 (56.569)	Acc@5 86.719 (85.095)
Epoch: [132][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5778 (2.3707)	Acc@1 56.250 (56.390)	Acc@5 80.469 (85.001)
Epoch: [132][210/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4207 (2.3721)	Acc@1 57.031 (56.398)	Acc@5 83.594 (84.986)
Epoch: [132][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2507 (2.3712)	Acc@1 62.500 (56.448)	Acc@5 85.938 (84.969)
Epoch: [132][230/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3791 (2.3752)	Acc@1 57.812 (56.348)	Acc@5 85.156 (84.923)
Epoch: [132][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5086 (2.3790)	Acc@1 55.469 (56.279)	Acc@5 82.031 (84.852)
Epoch: [132][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4861 (2.3818)	Acc@1 51.562 (56.157)	Acc@5 85.938 (84.842)
Epoch: [132][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5850 (2.3840)	Acc@1 50.781 (56.133)	Acc@5 82.812 (84.764)
Epoch: [132][270/391]	Time 0.020 (0.014)	Data 0.001 (0.002)	Loss 2.4521 (2.3840)	Acc@1 53.906 (56.106)	Acc@5 82.031 (84.732)
Epoch: [132][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3359 (2.3834)	Acc@1 55.469 (56.130)	Acc@5 87.500 (84.773)
Epoch: [132][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5018 (2.3864)	Acc@1 53.125 (56.024)	Acc@5 85.156 (84.740)
Epoch: [132][300/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.1256 (2.3859)	Acc@1 60.156 (56.003)	Acc@5 89.062 (84.728)
Epoch: [132][310/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4044 (2.3899)	Acc@1 55.469 (55.921)	Acc@5 82.812 (84.686)
Epoch: [132][320/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5147 (2.3941)	Acc@1 53.906 (55.844)	Acc@5 81.250 (84.575)
Epoch: [132][330/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4856 (2.3944)	Acc@1 56.250 (55.884)	Acc@5 89.062 (84.583)
Epoch: [132][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6085 (2.3955)	Acc@1 50.781 (55.833)	Acc@5 81.250 (84.561)
Epoch: [132][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6641 (2.3974)	Acc@1 51.562 (55.789)	Acc@5 76.562 (84.520)
Epoch: [132][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2112 (2.3996)	Acc@1 63.281 (55.726)	Acc@5 85.156 (84.457)
Epoch: [132][370/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4247 (2.3982)	Acc@1 57.031 (55.717)	Acc@5 84.375 (84.518)
Epoch: [132][380/391]	Time 0.020 (0.014)	Data 0.001 (0.002)	Loss 2.4989 (2.4012)	Acc@1 50.000 (55.649)	Acc@5 83.594 (84.482)
Epoch: [132][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.4521 (2.4028)	Acc@1 51.250 (55.594)	Acc@5 85.000 (84.436)
num momentum params: 26
[0.1, 2.4028215812683107, 1.9380942142009736, 55.594, 48.42, tensor(0.3310, device='cuda:0', grad_fn=<DivBackward0>), 5.357043981552124, 0.4121584892272949]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [133 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [133][0/391]	Time 0.080 (0.080)	Data 0.177 (0.177)	Loss 2.2425 (2.2425)	Acc@1 63.281 (63.281)	Acc@5 85.156 (85.156)
Epoch: [133][10/391]	Time 0.014 (0.022)	Data 0.002 (0.018)	Loss 2.0903 (2.3665)	Acc@1 60.156 (55.327)	Acc@5 89.062 (85.298)
Epoch: [133][20/391]	Time 0.011 (0.018)	Data 0.003 (0.010)	Loss 2.3644 (2.3610)	Acc@1 56.250 (56.176)	Acc@5 86.719 (84.896)
Epoch: [133][30/391]	Time 0.013 (0.017)	Data 0.001 (0.007)	Loss 2.5529 (2.3534)	Acc@1 46.875 (56.729)	Acc@5 79.688 (85.106)
Epoch: [133][40/391]	Time 0.014 (0.016)	Data 0.002 (0.006)	Loss 2.1842 (2.3220)	Acc@1 61.719 (57.298)	Acc@5 88.281 (85.537)
Epoch: [133][50/391]	Time 0.014 (0.016)	Data 0.001 (0.005)	Loss 2.0481 (2.3140)	Acc@1 60.938 (57.261)	Acc@5 89.062 (85.555)
Epoch: [133][60/391]	Time 0.015 (0.015)	Data 0.002 (0.005)	Loss 2.6201 (2.3157)	Acc@1 57.031 (57.492)	Acc@5 78.906 (85.694)
Epoch: [133][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.3004 (2.3175)	Acc@1 57.031 (57.438)	Acc@5 85.938 (85.574)
Epoch: [133][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.5751 (2.3267)	Acc@1 57.812 (57.330)	Acc@5 82.031 (85.523)
Epoch: [133][90/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.4118 (2.3387)	Acc@1 52.344 (56.963)	Acc@5 85.938 (85.422)
Epoch: [133][100/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 2.2506 (2.3407)	Acc@1 57.812 (56.900)	Acc@5 88.281 (85.442)
Epoch: [133][110/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.5787 (2.3442)	Acc@1 46.875 (56.848)	Acc@5 81.250 (85.445)
Epoch: [133][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.1551 (2.3344)	Acc@1 55.469 (57.051)	Acc@5 90.625 (85.557)
Epoch: [133][130/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2668 (2.3410)	Acc@1 57.812 (56.787)	Acc@5 85.938 (85.413)
Epoch: [133][140/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4334 (2.3436)	Acc@1 54.688 (56.787)	Acc@5 85.938 (85.334)
Epoch: [133][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3803 (2.3429)	Acc@1 52.344 (56.824)	Acc@5 85.938 (85.415)
Epoch: [133][160/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2810 (2.3429)	Acc@1 59.375 (56.803)	Acc@5 83.594 (85.418)
Epoch: [133][170/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3419 (2.3427)	Acc@1 53.125 (56.730)	Acc@5 86.719 (85.398)
Epoch: [133][180/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2306 (2.3434)	Acc@1 58.594 (56.720)	Acc@5 87.500 (85.407)
Epoch: [133][190/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6774 (2.3503)	Acc@1 46.875 (56.577)	Acc@5 78.906 (85.316)
Epoch: [133][200/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.8105 (2.3608)	Acc@1 46.875 (56.402)	Acc@5 78.906 (85.203)
Epoch: [133][210/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.7598 (2.3648)	Acc@1 48.438 (56.272)	Acc@5 78.125 (85.149)
Epoch: [133][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2739 (2.3680)	Acc@1 61.719 (56.257)	Acc@5 89.062 (85.078)
Epoch: [133][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6462 (2.3728)	Acc@1 55.469 (56.209)	Acc@5 76.562 (84.974)
Epoch: [133][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5449 (2.3755)	Acc@1 53.906 (56.159)	Acc@5 83.594 (84.978)
Epoch: [133][250/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6741 (2.3768)	Acc@1 52.344 (56.125)	Acc@5 78.906 (84.913)
Epoch: [133][260/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4118 (2.3778)	Acc@1 58.594 (56.154)	Acc@5 82.812 (84.902)
Epoch: [133][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3996 (2.3813)	Acc@1 54.688 (56.045)	Acc@5 82.812 (84.828)
Epoch: [133][280/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3717 (2.3826)	Acc@1 54.688 (56.019)	Acc@5 82.031 (84.800)
Epoch: [133][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3874 (2.3868)	Acc@1 57.031 (55.920)	Acc@5 84.375 (84.751)
Epoch: [133][300/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5472 (2.3906)	Acc@1 50.000 (55.824)	Acc@5 79.688 (84.671)
Epoch: [133][310/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.4023 (2.3927)	Acc@1 53.906 (55.813)	Acc@5 78.906 (84.606)
Epoch: [133][320/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3808 (2.3908)	Acc@1 53.906 (55.870)	Acc@5 87.500 (84.633)
Epoch: [133][330/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3502 (2.3897)	Acc@1 59.375 (55.903)	Acc@5 84.375 (84.649)
Epoch: [133][340/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4340 (2.3915)	Acc@1 51.562 (55.879)	Acc@5 85.938 (84.650)
Epoch: [133][350/391]	Time 0.010 (0.014)	Data 0.013 (0.002)	Loss 2.5836 (2.3957)	Acc@1 51.562 (55.836)	Acc@5 78.125 (84.564)
Epoch: [133][360/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6485 (2.3960)	Acc@1 52.344 (55.819)	Acc@5 81.250 (84.578)
Epoch: [133][370/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5254 (2.3965)	Acc@1 58.594 (55.841)	Acc@5 81.250 (84.592)
Epoch: [133][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4225 (2.3983)	Acc@1 55.469 (55.795)	Acc@5 87.500 (84.576)
Epoch: [133][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.3683 (2.3988)	Acc@1 60.000 (55.794)	Acc@5 83.750 (84.568)
num momentum params: 26
[0.1, 2.398845579376221, 1.9575095307826995, 55.794, 48.5, tensor(0.3318, device='cuda:0', grad_fn=<DivBackward0>), 5.35974645614624, 0.40999484062194824]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [134 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [134][0/391]	Time 0.071 (0.071)	Data 0.180 (0.180)	Loss 2.1218 (2.1218)	Acc@1 64.844 (64.844)	Acc@5 89.844 (89.844)
Epoch: [134][10/391]	Time 0.024 (0.022)	Data 0.001 (0.018)	Loss 2.4257 (2.3888)	Acc@1 57.031 (57.173)	Acc@5 84.375 (85.653)
Epoch: [134][20/391]	Time 0.014 (0.018)	Data 0.001 (0.010)	Loss 2.3888 (2.3577)	Acc@1 54.688 (57.664)	Acc@5 83.594 (85.863)
Epoch: [134][30/391]	Time 0.013 (0.017)	Data 0.002 (0.007)	Loss 2.2787 (2.3376)	Acc@1 58.594 (58.014)	Acc@5 88.281 (86.089)
Epoch: [134][40/391]	Time 0.014 (0.016)	Data 0.001 (0.006)	Loss 2.4292 (2.3373)	Acc@1 57.031 (57.717)	Acc@5 85.156 (85.938)
Epoch: [134][50/391]	Time 0.013 (0.016)	Data 0.001 (0.005)	Loss 2.3731 (2.3475)	Acc@1 60.156 (57.629)	Acc@5 84.375 (85.646)
Epoch: [134][60/391]	Time 0.016 (0.015)	Data 0.002 (0.005)	Loss 2.3591 (2.3483)	Acc@1 57.812 (57.710)	Acc@5 87.500 (85.630)
Epoch: [134][70/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 2.2785 (2.3455)	Acc@1 60.938 (57.879)	Acc@5 85.938 (85.585)
Epoch: [134][80/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 2.2516 (2.3452)	Acc@1 60.156 (57.890)	Acc@5 85.156 (85.610)
Epoch: [134][90/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.5474 (2.3487)	Acc@1 55.469 (57.735)	Acc@5 78.906 (85.543)
Epoch: [134][100/391]	Time 0.014 (0.015)	Data 0.002 (0.003)	Loss 2.6480 (2.3571)	Acc@1 45.312 (57.287)	Acc@5 78.906 (85.450)
Epoch: [134][110/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 2.5237 (2.3621)	Acc@1 52.344 (57.144)	Acc@5 78.906 (85.318)
Epoch: [134][120/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.4321 (2.3656)	Acc@1 57.031 (56.896)	Acc@5 87.500 (85.389)
Epoch: [134][130/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3338 (2.3703)	Acc@1 57.031 (56.805)	Acc@5 84.375 (85.371)
Epoch: [134][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6742 (2.3735)	Acc@1 46.875 (56.715)	Acc@5 81.250 (85.334)
Epoch: [134][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2650 (2.3753)	Acc@1 55.469 (56.695)	Acc@5 89.062 (85.291)
Epoch: [134][160/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3235 (2.3802)	Acc@1 57.812 (56.619)	Acc@5 83.594 (85.132)
Epoch: [134][170/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3760 (2.3821)	Acc@1 56.250 (56.515)	Acc@5 89.062 (85.115)
Epoch: [134][180/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4992 (2.3795)	Acc@1 52.344 (56.613)	Acc@5 83.594 (85.152)
Epoch: [134][190/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3599 (2.3796)	Acc@1 52.344 (56.577)	Acc@5 84.375 (85.193)
Epoch: [134][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5515 (2.3831)	Acc@1 53.906 (56.464)	Acc@5 80.469 (85.090)
Epoch: [134][210/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4205 (2.3833)	Acc@1 50.781 (56.457)	Acc@5 85.938 (85.060)
Epoch: [134][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5462 (2.3897)	Acc@1 53.125 (56.314)	Acc@5 76.562 (84.923)
Epoch: [134][230/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.0310 (2.3912)	Acc@1 64.844 (56.277)	Acc@5 89.844 (84.882)
Epoch: [134][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4287 (2.3918)	Acc@1 56.250 (56.286)	Acc@5 84.375 (84.852)
Epoch: [134][250/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3672 (2.3926)	Acc@1 53.906 (56.206)	Acc@5 83.594 (84.873)
Epoch: [134][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3491 (2.3936)	Acc@1 59.375 (56.163)	Acc@5 80.469 (84.827)
Epoch: [134][270/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5576 (2.3959)	Acc@1 51.562 (56.100)	Acc@5 83.594 (84.822)
Epoch: [134][280/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5469 (2.3990)	Acc@1 51.562 (56.005)	Acc@5 80.469 (84.786)
Epoch: [134][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2437 (2.4028)	Acc@1 60.938 (55.928)	Acc@5 87.500 (84.716)
Epoch: [134][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3463 (2.4040)	Acc@1 57.031 (55.913)	Acc@5 82.812 (84.705)
Epoch: [134][310/391]	Time 0.011 (0.014)	Data 0.001 (0.002)	Loss 2.4161 (2.4029)	Acc@1 53.906 (55.916)	Acc@5 86.719 (84.754)
Epoch: [134][320/391]	Time 0.017 (0.014)	Data 0.002 (0.002)	Loss 2.2503 (2.4031)	Acc@1 59.375 (55.926)	Acc@5 86.719 (84.725)
Epoch: [134][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1862 (2.4022)	Acc@1 59.375 (55.894)	Acc@5 87.500 (84.762)
Epoch: [134][340/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.2919 (2.4026)	Acc@1 64.062 (55.897)	Acc@5 87.500 (84.764)
Epoch: [134][350/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4006 (2.4045)	Acc@1 56.250 (55.840)	Acc@5 83.594 (84.707)
Epoch: [134][360/391]	Time 0.012 (0.014)	Data 0.002 (0.002)	Loss 2.4909 (2.4061)	Acc@1 55.469 (55.789)	Acc@5 85.156 (84.680)
Epoch: [134][370/391]	Time 0.012 (0.014)	Data 0.002 (0.002)	Loss 2.7045 (2.4100)	Acc@1 53.906 (55.713)	Acc@5 78.906 (84.598)
Epoch: [134][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2829 (2.4124)	Acc@1 59.375 (55.668)	Acc@5 83.594 (84.560)
Epoch: [134][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.5036 (2.4131)	Acc@1 53.750 (55.632)	Acc@5 82.500 (84.532)
num momentum params: 26
[0.1, 2.4130793259429932, 2.1653084564208984, 55.632, 45.92, tensor(0.3298, device='cuda:0', grad_fn=<DivBackward0>), 5.414749383926392, 0.41166162490844727]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [135 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [135][0/391]	Time 0.064 (0.064)	Data 0.177 (0.177)	Loss 2.0954 (2.0954)	Acc@1 64.844 (64.844)	Acc@5 89.062 (89.062)
Epoch: [135][10/391]	Time 0.011 (0.020)	Data 0.004 (0.018)	Loss 2.1015 (2.2451)	Acc@1 62.500 (59.233)	Acc@5 91.406 (88.352)
Epoch: [135][20/391]	Time 0.014 (0.017)	Data 0.001 (0.010)	Loss 2.3276 (2.2577)	Acc@1 57.812 (59.189)	Acc@5 87.500 (87.984)
Epoch: [135][30/391]	Time 0.013 (0.016)	Data 0.001 (0.007)	Loss 2.1794 (2.2515)	Acc@1 63.281 (59.098)	Acc@5 87.500 (87.828)
Epoch: [135][40/391]	Time 0.014 (0.015)	Data 0.001 (0.006)	Loss 2.5232 (2.2824)	Acc@1 52.344 (58.346)	Acc@5 80.469 (87.138)
Epoch: [135][50/391]	Time 0.013 (0.015)	Data 0.002 (0.005)	Loss 2.3035 (2.2898)	Acc@1 60.156 (58.058)	Acc@5 89.062 (86.903)
Epoch: [135][60/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.2624 (2.2702)	Acc@1 56.250 (58.581)	Acc@5 87.500 (87.269)
Epoch: [135][70/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 2.1950 (2.2770)	Acc@1 60.938 (58.363)	Acc@5 86.719 (87.181)
Epoch: [135][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.4065 (2.2945)	Acc@1 55.469 (57.938)	Acc@5 82.812 (86.786)
Epoch: [135][90/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.5727 (2.3111)	Acc@1 48.438 (57.478)	Acc@5 83.594 (86.504)
Epoch: [135][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.1931 (2.3086)	Acc@1 59.375 (57.712)	Acc@5 89.062 (86.618)
Epoch: [135][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3403 (2.3196)	Acc@1 57.031 (57.559)	Acc@5 88.281 (86.268)
Epoch: [135][120/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.1875 (2.3308)	Acc@1 58.594 (57.283)	Acc@5 87.500 (86.125)
Epoch: [135][130/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5532 (2.3406)	Acc@1 51.562 (57.139)	Acc@5 82.031 (85.973)
Epoch: [135][140/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.3368 (2.3463)	Acc@1 57.812 (57.031)	Acc@5 89.062 (85.865)
Epoch: [135][150/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4601 (2.3467)	Acc@1 55.469 (56.969)	Acc@5 82.812 (85.886)
Epoch: [135][160/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.6540 (2.3522)	Acc@1 50.000 (56.871)	Acc@5 82.812 (85.758)
Epoch: [135][170/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.3435 (2.3524)	Acc@1 58.594 (56.944)	Acc@5 81.250 (85.682)
Epoch: [135][180/391]	Time 0.020 (0.014)	Data 0.002 (0.003)	Loss 2.4612 (2.3567)	Acc@1 57.031 (56.828)	Acc@5 87.500 (85.605)
Epoch: [135][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.0834 (2.3623)	Acc@1 61.719 (56.733)	Acc@5 90.625 (85.426)
Epoch: [135][200/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3285 (2.3638)	Acc@1 54.688 (56.701)	Acc@5 87.500 (85.370)
Epoch: [135][210/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2845 (2.3647)	Acc@1 52.344 (56.561)	Acc@5 88.281 (85.393)
Epoch: [135][220/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2256 (2.3648)	Acc@1 57.812 (56.505)	Acc@5 86.719 (85.390)
Epoch: [135][230/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.5310 (2.3653)	Acc@1 56.250 (56.541)	Acc@5 81.250 (85.379)
Epoch: [135][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4517 (2.3717)	Acc@1 56.250 (56.415)	Acc@5 82.031 (85.234)
Epoch: [135][250/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.5499 (2.3729)	Acc@1 53.906 (56.390)	Acc@5 80.469 (85.190)
Epoch: [135][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2788 (2.3724)	Acc@1 57.812 (56.385)	Acc@5 85.938 (85.165)
Epoch: [135][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6584 (2.3728)	Acc@1 54.688 (56.374)	Acc@5 78.125 (85.110)
Epoch: [135][280/391]	Time 0.012 (0.014)	Data 0.003 (0.002)	Loss 2.2779 (2.3736)	Acc@1 57.031 (56.367)	Acc@5 85.938 (85.112)
Epoch: [135][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3512 (2.3754)	Acc@1 62.500 (56.363)	Acc@5 81.250 (85.041)
Epoch: [135][300/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2887 (2.3779)	Acc@1 60.938 (56.312)	Acc@5 82.812 (85.001)
Epoch: [135][310/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3789 (2.3808)	Acc@1 60.938 (56.268)	Acc@5 80.469 (84.928)
Epoch: [135][320/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4172 (2.3829)	Acc@1 54.688 (56.233)	Acc@5 81.250 (84.889)
Epoch: [135][330/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5898 (2.3851)	Acc@1 52.344 (56.210)	Acc@5 82.031 (84.845)
Epoch: [135][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4159 (2.3867)	Acc@1 52.344 (56.186)	Acc@5 85.156 (84.819)
Epoch: [135][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5644 (2.3887)	Acc@1 53.906 (56.161)	Acc@5 84.375 (84.789)
Epoch: [135][360/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4756 (2.3885)	Acc@1 59.375 (56.114)	Acc@5 82.812 (84.788)
Epoch: [135][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5719 (2.3908)	Acc@1 50.000 (56.039)	Acc@5 83.594 (84.741)
Epoch: [135][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5299 (2.3937)	Acc@1 55.469 (55.977)	Acc@5 80.469 (84.687)
Epoch: [135][390/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 2.5734 (2.3949)	Acc@1 47.500 (55.948)	Acc@5 82.500 (84.640)
num momentum params: 26
[0.1, 2.394917703704834, 2.1319783008098603, 55.948, 46.0, tensor(0.3322, device='cuda:0', grad_fn=<DivBackward0>), 5.377815008163452, 0.42556190490722656]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [136 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [136][0/391]	Time 0.063 (0.063)	Data 0.181 (0.181)	Loss 2.3609 (2.3609)	Acc@1 54.688 (54.688)	Acc@5 84.375 (84.375)
Epoch: [136][10/391]	Time 0.013 (0.020)	Data 0.001 (0.018)	Loss 2.4745 (2.3551)	Acc@1 57.812 (57.102)	Acc@5 84.375 (85.369)
Epoch: [136][20/391]	Time 0.012 (0.018)	Data 0.002 (0.010)	Loss 2.0957 (2.2944)	Acc@1 64.062 (58.333)	Acc@5 85.938 (86.384)
Epoch: [136][30/391]	Time 0.013 (0.016)	Data 0.001 (0.007)	Loss 2.3308 (2.3028)	Acc@1 60.156 (57.964)	Acc@5 85.938 (86.542)
Epoch: [136][40/391]	Time 0.013 (0.016)	Data 0.001 (0.006)	Loss 2.1698 (2.3156)	Acc@1 62.500 (57.565)	Acc@5 89.844 (86.490)
Epoch: [136][50/391]	Time 0.015 (0.015)	Data 0.002 (0.005)	Loss 2.4952 (2.3176)	Acc@1 50.781 (57.384)	Acc@5 82.812 (86.320)
Epoch: [136][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.2874 (2.3143)	Acc@1 60.156 (57.403)	Acc@5 83.594 (86.347)
Epoch: [136][70/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.4138 (2.3212)	Acc@1 53.906 (57.339)	Acc@5 85.938 (86.279)
Epoch: [136][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.4098 (2.3305)	Acc@1 53.906 (57.195)	Acc@5 83.594 (86.073)
Epoch: [136][90/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.3427 (2.3393)	Acc@1 57.031 (56.851)	Acc@5 86.719 (85.963)
Epoch: [136][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2433 (2.3429)	Acc@1 57.812 (56.675)	Acc@5 87.500 (85.968)
Epoch: [136][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3478 (2.3455)	Acc@1 53.906 (56.700)	Acc@5 86.719 (85.923)
Epoch: [136][120/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.4154 (2.3430)	Acc@1 47.656 (56.696)	Acc@5 88.281 (85.944)
Epoch: [136][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3555 (2.3451)	Acc@1 56.250 (56.644)	Acc@5 82.812 (85.872)
Epoch: [136][140/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.3369 (2.3461)	Acc@1 54.688 (56.649)	Acc@5 85.938 (85.821)
Epoch: [136][150/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3155 (2.3521)	Acc@1 58.594 (56.493)	Acc@5 84.375 (85.637)
Epoch: [136][160/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4859 (2.3535)	Acc@1 52.344 (56.580)	Acc@5 82.031 (85.593)
Epoch: [136][170/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3620 (2.3619)	Acc@1 61.719 (56.510)	Acc@5 81.250 (85.325)
Epoch: [136][180/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3431 (2.3643)	Acc@1 58.594 (56.505)	Acc@5 87.500 (85.290)
Epoch: [136][190/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3169 (2.3650)	Acc@1 55.469 (56.442)	Acc@5 85.938 (85.279)
Epoch: [136][200/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3295 (2.3616)	Acc@1 55.469 (56.561)	Acc@5 87.500 (85.339)
Epoch: [136][210/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.6169 (2.3666)	Acc@1 53.125 (56.517)	Acc@5 82.812 (85.234)
Epoch: [136][220/391]	Time 0.019 (0.014)	Data 0.001 (0.002)	Loss 2.5868 (2.3679)	Acc@1 49.219 (56.512)	Acc@5 82.812 (85.177)
Epoch: [136][230/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.1655 (2.3654)	Acc@1 60.156 (56.588)	Acc@5 90.625 (85.204)
Epoch: [136][240/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3054 (2.3634)	Acc@1 60.156 (56.678)	Acc@5 85.938 (85.257)
Epoch: [136][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5246 (2.3680)	Acc@1 53.125 (56.580)	Acc@5 82.031 (85.159)
Epoch: [136][260/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3592 (2.3691)	Acc@1 58.594 (56.615)	Acc@5 87.500 (85.171)
Epoch: [136][270/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.3746 (2.3714)	Acc@1 56.250 (56.561)	Acc@5 88.281 (85.171)
Epoch: [136][280/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6896 (2.3764)	Acc@1 53.906 (56.484)	Acc@5 78.906 (85.034)
Epoch: [136][290/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3206 (2.3800)	Acc@1 61.719 (56.408)	Acc@5 82.812 (84.933)
Epoch: [136][300/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.1975 (2.3797)	Acc@1 59.375 (56.385)	Acc@5 87.500 (84.923)
Epoch: [136][310/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.7892 (2.3816)	Acc@1 48.438 (56.320)	Acc@5 77.344 (84.867)
Epoch: [136][320/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2786 (2.3809)	Acc@1 57.812 (56.360)	Acc@5 89.844 (84.845)
Epoch: [136][330/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2354 (2.3800)	Acc@1 60.938 (56.460)	Acc@5 85.156 (84.838)
Epoch: [136][340/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4846 (2.3810)	Acc@1 54.688 (56.424)	Acc@5 82.812 (84.819)
Epoch: [136][350/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4280 (2.3806)	Acc@1 55.469 (56.424)	Acc@5 82.031 (84.831)
Epoch: [136][360/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5686 (2.3821)	Acc@1 50.781 (56.384)	Acc@5 88.281 (84.845)
Epoch: [136][370/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5377 (2.3828)	Acc@1 52.344 (56.319)	Acc@5 79.688 (84.821)
Epoch: [136][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5711 (2.3846)	Acc@1 50.781 (56.273)	Acc@5 81.250 (84.804)
Epoch: [136][390/391]	Time 0.018 (0.014)	Data 0.001 (0.002)	Loss 2.4948 (2.3878)	Acc@1 52.500 (56.200)	Acc@5 83.750 (84.746)
num momentum params: 26
[0.1, 2.38782588470459, 2.074777479171753, 56.2, 46.73, tensor(0.3323, device='cuda:0', grad_fn=<DivBackward0>), 5.403410911560059, 0.4217324256896973]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [137 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [137][0/391]	Time 0.067 (0.067)	Data 0.170 (0.170)	Loss 2.3718 (2.3718)	Acc@1 57.812 (57.812)	Acc@5 81.250 (81.250)
Epoch: [137][10/391]	Time 0.013 (0.021)	Data 0.001 (0.017)	Loss 2.2654 (2.3467)	Acc@1 60.156 (56.747)	Acc@5 88.281 (86.009)
Epoch: [137][20/391]	Time 0.014 (0.018)	Data 0.001 (0.010)	Loss 2.0939 (2.3344)	Acc@1 67.188 (56.585)	Acc@5 86.719 (85.193)
Epoch: [137][30/391]	Time 0.015 (0.016)	Data 0.001 (0.007)	Loss 2.3789 (2.3157)	Acc@1 54.688 (57.409)	Acc@5 80.469 (85.534)
Epoch: [137][40/391]	Time 0.014 (0.016)	Data 0.001 (0.006)	Loss 2.3583 (2.3285)	Acc@1 60.156 (57.050)	Acc@5 85.938 (85.614)
Epoch: [137][50/391]	Time 0.013 (0.015)	Data 0.002 (0.005)	Loss 2.5530 (2.3229)	Acc@1 56.250 (57.430)	Acc@5 82.812 (85.738)
Epoch: [137][60/391]	Time 0.015 (0.015)	Data 0.001 (0.004)	Loss 2.2500 (2.3073)	Acc@1 61.719 (57.582)	Acc@5 85.156 (86.014)
Epoch: [137][70/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.2737 (2.3182)	Acc@1 59.375 (57.339)	Acc@5 89.062 (85.849)
Epoch: [137][80/391]	Time 0.012 (0.015)	Data 0.005 (0.004)	Loss 2.2060 (2.3237)	Acc@1 59.375 (57.215)	Acc@5 88.281 (85.889)
Epoch: [137][90/391]	Time 0.013 (0.015)	Data 0.002 (0.003)	Loss 2.4417 (2.3225)	Acc@1 54.688 (57.237)	Acc@5 84.375 (86.006)
Epoch: [137][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5672 (2.3284)	Acc@1 46.094 (56.985)	Acc@5 82.031 (85.876)
Epoch: [137][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3172 (2.3344)	Acc@1 54.688 (56.834)	Acc@5 85.156 (85.740)
Epoch: [137][120/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5593 (2.3403)	Acc@1 57.031 (56.708)	Acc@5 78.906 (85.705)
Epoch: [137][130/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5635 (2.3518)	Acc@1 52.344 (56.512)	Acc@5 81.250 (85.472)
Epoch: [137][140/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4033 (2.3594)	Acc@1 55.469 (56.350)	Acc@5 79.688 (85.311)
Epoch: [137][150/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.5525 (2.3639)	Acc@1 49.219 (56.136)	Acc@5 82.812 (85.260)
Epoch: [137][160/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5512 (2.3707)	Acc@1 55.469 (56.070)	Acc@5 82.812 (85.113)
Epoch: [137][170/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5883 (2.3812)	Acc@1 50.000 (55.825)	Acc@5 80.469 (84.896)
Epoch: [137][180/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4047 (2.3853)	Acc@1 55.469 (55.663)	Acc@5 86.719 (84.811)
Epoch: [137][190/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.3704 (2.3820)	Acc@1 53.125 (55.726)	Acc@5 85.938 (84.858)
Epoch: [137][200/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.5446 (2.3790)	Acc@1 53.125 (55.869)	Acc@5 79.688 (84.869)
Epoch: [137][210/391]	Time 0.019 (0.014)	Data 0.002 (0.002)	Loss 2.7249 (2.3843)	Acc@1 46.094 (55.783)	Acc@5 78.906 (84.779)
Epoch: [137][220/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5890 (2.3845)	Acc@1 47.656 (55.748)	Acc@5 84.375 (84.820)
Epoch: [137][230/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5595 (2.3855)	Acc@1 57.031 (55.739)	Acc@5 81.250 (84.798)
Epoch: [137][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4484 (2.3861)	Acc@1 55.469 (55.741)	Acc@5 80.469 (84.800)
Epoch: [137][250/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4541 (2.3836)	Acc@1 57.031 (55.789)	Acc@5 85.156 (84.892)
Epoch: [137][260/391]	Time 0.012 (0.014)	Data 0.002 (0.002)	Loss 2.4712 (2.3851)	Acc@1 55.469 (55.774)	Acc@5 81.250 (84.866)
Epoch: [137][270/391]	Time 0.014 (0.014)	Data 0.004 (0.002)	Loss 2.3292 (2.3867)	Acc@1 53.906 (55.711)	Acc@5 88.281 (84.862)
Epoch: [137][280/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5835 (2.3882)	Acc@1 51.562 (55.677)	Acc@5 77.344 (84.800)
Epoch: [137][290/391]	Time 0.016 (0.014)	Data 0.002 (0.002)	Loss 2.7032 (2.3913)	Acc@1 54.688 (55.689)	Acc@5 78.906 (84.727)
Epoch: [137][300/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3273 (2.3915)	Acc@1 58.594 (55.645)	Acc@5 87.500 (84.754)
Epoch: [137][310/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3264 (2.3945)	Acc@1 56.250 (55.562)	Acc@5 85.938 (84.729)
Epoch: [137][320/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.3204 (2.3965)	Acc@1 56.250 (55.542)	Acc@5 83.594 (84.684)
Epoch: [137][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2818 (2.3982)	Acc@1 55.469 (55.518)	Acc@5 82.812 (84.625)
Epoch: [137][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5214 (2.3986)	Acc@1 55.469 (55.526)	Acc@5 78.906 (84.613)
Epoch: [137][350/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6170 (2.3991)	Acc@1 51.562 (55.542)	Acc@5 80.469 (84.613)
Epoch: [137][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4633 (2.4006)	Acc@1 52.344 (55.519)	Acc@5 84.375 (84.596)
Epoch: [137][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5559 (2.4018)	Acc@1 50.000 (55.477)	Acc@5 84.375 (84.565)
Epoch: [137][380/391]	Time 0.012 (0.014)	Data 0.002 (0.002)	Loss 2.7193 (2.4048)	Acc@1 47.656 (55.344)	Acc@5 80.469 (84.549)
Epoch: [137][390/391]	Time 0.023 (0.014)	Data 0.001 (0.002)	Loss 2.5670 (2.4066)	Acc@1 52.500 (55.302)	Acc@5 87.500 (84.542)
num momentum params: 26
[0.1, 2.4065654055023193, 2.2551273739337923, 55.302, 43.78, tensor(0.3303, device='cuda:0', grad_fn=<DivBackward0>), 5.397203683853149, 0.4211447238922119]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [138 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [138][0/391]	Time 0.067 (0.067)	Data 0.166 (0.166)	Loss 2.5806 (2.5806)	Acc@1 53.906 (53.906)	Acc@5 80.469 (80.469)
Epoch: [138][10/391]	Time 0.019 (0.022)	Data 0.002 (0.017)	Loss 2.3039 (2.4257)	Acc@1 60.938 (56.392)	Acc@5 82.031 (83.665)
Epoch: [138][20/391]	Time 0.014 (0.018)	Data 0.001 (0.010)	Loss 2.2703 (2.3845)	Acc@1 60.156 (56.882)	Acc@5 83.594 (84.449)
Epoch: [138][30/391]	Time 0.014 (0.017)	Data 0.002 (0.007)	Loss 2.4108 (2.3373)	Acc@1 57.031 (57.812)	Acc@5 82.812 (85.181)
Epoch: [138][40/391]	Time 0.013 (0.016)	Data 0.001 (0.006)	Loss 2.1336 (2.3200)	Acc@1 61.719 (58.289)	Acc@5 85.938 (85.595)
Epoch: [138][50/391]	Time 0.013 (0.016)	Data 0.001 (0.005)	Loss 2.3289 (2.3279)	Acc@1 55.469 (57.889)	Acc@5 83.594 (85.692)
Epoch: [138][60/391]	Time 0.014 (0.015)	Data 0.002 (0.004)	Loss 2.2350 (2.3231)	Acc@1 59.375 (57.825)	Acc@5 87.500 (85.528)
Epoch: [138][70/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.2006 (2.3189)	Acc@1 58.594 (57.824)	Acc@5 88.281 (85.805)
Epoch: [138][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.2435 (2.3215)	Acc@1 64.062 (57.899)	Acc@5 86.719 (85.687)
Epoch: [138][90/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 2.7806 (2.3289)	Acc@1 46.875 (57.667)	Acc@5 75.000 (85.637)
Epoch: [138][100/391]	Time 0.013 (0.015)	Data 0.002 (0.003)	Loss 2.6878 (2.3335)	Acc@1 50.781 (57.689)	Acc@5 78.906 (85.551)
Epoch: [138][110/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4696 (2.3437)	Acc@1 57.812 (57.538)	Acc@5 83.594 (85.367)
Epoch: [138][120/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.8314 (2.3511)	Acc@1 50.000 (57.290)	Acc@5 74.219 (85.285)
Epoch: [138][130/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.5497 (2.3571)	Acc@1 56.250 (57.174)	Acc@5 83.594 (85.246)
Epoch: [138][140/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.4997 (2.3654)	Acc@1 46.094 (56.948)	Acc@5 89.062 (85.123)
Epoch: [138][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3454 (2.3702)	Acc@1 57.812 (56.742)	Acc@5 84.375 (85.017)
Epoch: [138][160/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3515 (2.3710)	Acc@1 57.031 (56.735)	Acc@5 87.500 (85.054)
Epoch: [138][170/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.9985 (2.3686)	Acc@1 65.625 (56.698)	Acc@5 89.844 (85.056)
Epoch: [138][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5458 (2.3690)	Acc@1 47.656 (56.634)	Acc@5 85.156 (85.079)
Epoch: [138][190/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6737 (2.3716)	Acc@1 47.656 (56.483)	Acc@5 82.812 (85.066)
Epoch: [138][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5632 (2.3764)	Acc@1 50.000 (56.328)	Acc@5 82.031 (84.997)
Epoch: [138][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6020 (2.3777)	Acc@1 50.000 (56.231)	Acc@5 81.250 (84.979)
Epoch: [138][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3134 (2.3794)	Acc@1 54.688 (56.172)	Acc@5 90.625 (84.930)
Epoch: [138][230/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3111 (2.3784)	Acc@1 61.719 (56.186)	Acc@5 84.375 (84.936)
Epoch: [138][240/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4856 (2.3834)	Acc@1 49.219 (56.039)	Acc@5 85.938 (84.868)
Epoch: [138][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6175 (2.3884)	Acc@1 50.781 (55.914)	Acc@5 85.938 (84.783)
Epoch: [138][260/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.5932 (2.3929)	Acc@1 51.562 (55.813)	Acc@5 78.906 (84.689)
Epoch: [138][270/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4028 (2.3975)	Acc@1 55.469 (55.673)	Acc@5 84.375 (84.637)
Epoch: [138][280/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3690 (2.3991)	Acc@1 59.375 (55.644)	Acc@5 82.812 (84.620)
Epoch: [138][290/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2187 (2.3990)	Acc@1 58.594 (55.633)	Acc@5 90.625 (84.638)
Epoch: [138][300/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5113 (2.4017)	Acc@1 52.344 (55.565)	Acc@5 82.812 (84.614)
Epoch: [138][310/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 2.4224 (2.4023)	Acc@1 59.375 (55.614)	Acc@5 83.594 (84.609)
Epoch: [138][320/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4139 (2.4012)	Acc@1 51.562 (55.581)	Acc@5 85.938 (84.633)
Epoch: [138][330/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3826 (2.4017)	Acc@1 60.156 (55.566)	Acc@5 82.812 (84.630)
Epoch: [138][340/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3401 (2.3992)	Acc@1 59.375 (55.620)	Acc@5 87.500 (84.700)
Epoch: [138][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4604 (2.4003)	Acc@1 50.000 (55.593)	Acc@5 84.375 (84.693)
Epoch: [138][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5096 (2.4001)	Acc@1 53.906 (55.601)	Acc@5 82.031 (84.695)
Epoch: [138][370/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6310 (2.4014)	Acc@1 52.344 (55.576)	Acc@5 78.125 (84.661)
Epoch: [138][380/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5558 (2.4017)	Acc@1 53.125 (55.573)	Acc@5 83.594 (84.681)
Epoch: [138][390/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 2.4312 (2.4009)	Acc@1 53.750 (55.608)	Acc@5 87.500 (84.690)
num momentum params: 26
[0.1, 2.400922144165039, 2.008948184251785, 55.608, 47.71, tensor(0.3312, device='cuda:0', grad_fn=<DivBackward0>), 5.379239082336426, 0.41535496711730957]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [139 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [139][0/391]	Time 0.070 (0.070)	Data 0.172 (0.172)	Loss 2.4402 (2.4402)	Acc@1 53.125 (53.125)	Acc@5 83.594 (83.594)
Epoch: [139][10/391]	Time 0.014 (0.021)	Data 0.002 (0.017)	Loss 2.2162 (2.2288)	Acc@1 57.812 (58.949)	Acc@5 85.156 (87.003)
Epoch: [139][20/391]	Time 0.014 (0.017)	Data 0.001 (0.010)	Loss 2.4893 (2.2349)	Acc@1 51.562 (58.743)	Acc@5 85.156 (87.426)
Epoch: [139][30/391]	Time 0.013 (0.016)	Data 0.001 (0.007)	Loss 2.3728 (2.2413)	Acc@1 57.812 (58.896)	Acc@5 84.375 (87.450)
Epoch: [139][40/391]	Time 0.013 (0.015)	Data 0.001 (0.006)	Loss 2.2900 (2.2654)	Acc@1 55.469 (58.289)	Acc@5 87.500 (86.890)
Epoch: [139][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.3541 (2.2768)	Acc@1 58.594 (58.042)	Acc@5 82.812 (86.642)
Epoch: [139][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.3622 (2.2795)	Acc@1 57.812 (58.145)	Acc@5 85.938 (86.629)
Epoch: [139][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.2212 (2.2929)	Acc@1 57.031 (57.945)	Acc@5 87.500 (86.510)
Epoch: [139][80/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 2.2563 (2.2923)	Acc@1 54.688 (57.938)	Acc@5 85.156 (86.574)
Epoch: [139][90/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3803 (2.3025)	Acc@1 53.906 (57.830)	Acc@5 86.719 (86.332)
Epoch: [139][100/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.2927 (2.3110)	Acc@1 53.125 (57.333)	Acc@5 91.406 (86.255)
Epoch: [139][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4806 (2.3241)	Acc@1 48.438 (57.003)	Acc@5 85.938 (86.057)
Epoch: [139][120/391]	Time 0.015 (0.014)	Data 0.002 (0.003)	Loss 2.4089 (2.3350)	Acc@1 50.781 (56.644)	Acc@5 83.594 (85.944)
Epoch: [139][130/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.2465 (2.3411)	Acc@1 64.844 (56.608)	Acc@5 83.594 (85.914)
Epoch: [139][140/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3717 (2.3485)	Acc@1 57.031 (56.405)	Acc@5 85.156 (85.744)
Epoch: [139][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3206 (2.3512)	Acc@1 60.156 (56.312)	Acc@5 85.156 (85.715)
Epoch: [139][160/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4542 (2.3566)	Acc@1 57.812 (56.240)	Acc@5 83.594 (85.641)
Epoch: [139][170/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2326 (2.3500)	Acc@1 59.375 (56.442)	Acc@5 89.062 (85.796)
Epoch: [139][180/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 1.9966 (2.3465)	Acc@1 66.406 (56.492)	Acc@5 91.406 (85.804)
Epoch: [139][190/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.1688 (2.3464)	Acc@1 60.938 (56.479)	Acc@5 84.375 (85.708)
Epoch: [139][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3067 (2.3515)	Acc@1 55.469 (56.394)	Acc@5 89.062 (85.634)
Epoch: [139][210/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5166 (2.3534)	Acc@1 50.781 (56.354)	Acc@5 85.156 (85.593)
Epoch: [139][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4254 (2.3550)	Acc@1 57.031 (56.335)	Acc@5 84.375 (85.552)
Epoch: [139][230/391]	Time 0.013 (0.014)	Data 0.003 (0.002)	Loss 2.4355 (2.3574)	Acc@1 53.906 (56.314)	Acc@5 82.812 (85.450)
Epoch: [139][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1803 (2.3600)	Acc@1 59.375 (56.182)	Acc@5 90.625 (85.435)
Epoch: [139][250/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5119 (2.3644)	Acc@1 53.125 (56.116)	Acc@5 82.812 (85.315)
Epoch: [139][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4136 (2.3675)	Acc@1 53.125 (56.058)	Acc@5 85.938 (85.288)
Epoch: [139][270/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4285 (2.3687)	Acc@1 57.812 (56.028)	Acc@5 82.031 (85.240)
Epoch: [139][280/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.3131 (2.3707)	Acc@1 57.812 (56.030)	Acc@5 83.594 (85.195)
Epoch: [139][290/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4631 (2.3715)	Acc@1 52.344 (56.006)	Acc@5 81.250 (85.148)
Epoch: [139][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6546 (2.3725)	Acc@1 50.781 (56.016)	Acc@5 82.031 (85.161)
Epoch: [139][310/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5381 (2.3723)	Acc@1 48.438 (55.946)	Acc@5 83.594 (85.171)
Epoch: [139][320/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6031 (2.3753)	Acc@1 51.562 (55.844)	Acc@5 82.031 (85.127)
Epoch: [139][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3436 (2.3741)	Acc@1 56.250 (55.908)	Acc@5 89.844 (85.170)
Epoch: [139][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4114 (2.3731)	Acc@1 57.031 (55.938)	Acc@5 85.938 (85.159)
Epoch: [139][350/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.1303 (2.3741)	Acc@1 63.281 (55.947)	Acc@5 91.406 (85.163)
Epoch: [139][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2728 (2.3780)	Acc@1 56.250 (55.889)	Acc@5 86.719 (85.076)
Epoch: [139][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.8339 (2.3824)	Acc@1 47.656 (55.761)	Acc@5 78.125 (84.990)
Epoch: [139][380/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5812 (2.3841)	Acc@1 54.688 (55.731)	Acc@5 77.344 (84.980)
Epoch: [139][390/391]	Time 0.018 (0.014)	Data 0.001 (0.002)	Loss 2.5466 (2.3849)	Acc@1 56.250 (55.744)	Acc@5 83.750 (84.960)
num momentum params: 26
[0.1, 2.384935952301025, 2.0184112310409548, 55.744, 47.3, tensor(0.3328, device='cuda:0', grad_fn=<DivBackward0>), 5.348021507263184, 0.41541194915771484]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [140 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [140][0/391]	Time 0.067 (0.067)	Data 0.173 (0.173)	Loss 2.3623 (2.3623)	Acc@1 54.688 (54.688)	Acc@5 87.500 (87.500)
Epoch: [140][10/391]	Time 0.014 (0.021)	Data 0.002 (0.017)	Loss 2.1184 (2.2702)	Acc@1 60.156 (57.102)	Acc@5 86.719 (87.429)
Epoch: [140][20/391]	Time 0.014 (0.018)	Data 0.002 (0.010)	Loss 2.3065 (2.2744)	Acc@1 53.906 (57.515)	Acc@5 84.375 (86.979)
Epoch: [140][30/391]	Time 0.013 (0.017)	Data 0.001 (0.007)	Loss 2.4457 (2.2540)	Acc@1 51.562 (58.518)	Acc@5 85.938 (87.248)
Epoch: [140][40/391]	Time 0.013 (0.016)	Data 0.001 (0.006)	Loss 2.2997 (2.2490)	Acc@1 57.031 (58.613)	Acc@5 85.938 (87.233)
Epoch: [140][50/391]	Time 0.014 (0.015)	Data 0.001 (0.005)	Loss 2.6166 (2.2775)	Acc@1 51.562 (57.904)	Acc@5 82.812 (86.749)
Epoch: [140][60/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.3050 (2.2781)	Acc@1 58.594 (57.953)	Acc@5 86.719 (86.616)
Epoch: [140][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.2924 (2.2891)	Acc@1 60.938 (58.022)	Acc@5 83.594 (86.290)
Epoch: [140][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.4908 (2.3066)	Acc@1 59.375 (57.755)	Acc@5 82.031 (86.073)
Epoch: [140][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3879 (2.3229)	Acc@1 54.688 (57.280)	Acc@5 85.938 (85.920)
Epoch: [140][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4162 (2.3281)	Acc@1 53.125 (57.116)	Acc@5 85.156 (85.930)
Epoch: [140][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2527 (2.3282)	Acc@1 64.844 (57.242)	Acc@5 85.938 (85.853)
Epoch: [140][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2947 (2.3273)	Acc@1 60.156 (57.322)	Acc@5 83.594 (85.802)
Epoch: [140][130/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3017 (2.3355)	Acc@1 54.688 (57.091)	Acc@5 84.375 (85.645)
Epoch: [140][140/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.6837 (2.3424)	Acc@1 52.344 (56.959)	Acc@5 78.125 (85.533)
Epoch: [140][150/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5715 (2.3534)	Acc@1 50.000 (56.674)	Acc@5 82.031 (85.425)
Epoch: [140][160/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.3984 (2.3573)	Acc@1 51.562 (56.628)	Acc@5 85.156 (85.428)
Epoch: [140][170/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3217 (2.3618)	Acc@1 60.938 (56.597)	Acc@5 82.812 (85.257)
Epoch: [140][180/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.3436 (2.3638)	Acc@1 58.594 (56.600)	Acc@5 82.812 (85.156)
Epoch: [140][190/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.1796 (2.3617)	Acc@1 60.938 (56.708)	Acc@5 91.406 (85.230)
Epoch: [140][200/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5451 (2.3595)	Acc@1 51.562 (56.763)	Acc@5 82.031 (85.273)
Epoch: [140][210/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.2071 (2.3646)	Acc@1 56.250 (56.580)	Acc@5 89.062 (85.190)
Epoch: [140][220/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2876 (2.3697)	Acc@1 58.594 (56.455)	Acc@5 85.156 (85.103)
Epoch: [140][230/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2441 (2.3731)	Acc@1 54.688 (56.382)	Acc@5 85.938 (85.045)
Epoch: [140][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4717 (2.3766)	Acc@1 50.000 (56.188)	Acc@5 85.938 (85.014)
Epoch: [140][250/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4435 (2.3759)	Acc@1 55.469 (56.213)	Acc@5 82.812 (85.050)
Epoch: [140][260/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6130 (2.3788)	Acc@1 50.000 (56.157)	Acc@5 83.594 (85.010)
Epoch: [140][270/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6497 (2.3839)	Acc@1 46.875 (56.025)	Acc@5 80.469 (84.963)
Epoch: [140][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4527 (2.3848)	Acc@1 53.906 (55.997)	Acc@5 84.375 (84.973)
Epoch: [140][290/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4998 (2.3864)	Acc@1 53.125 (55.960)	Acc@5 84.375 (84.950)
Epoch: [140][300/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3601 (2.3881)	Acc@1 54.688 (55.954)	Acc@5 86.719 (84.917)
Epoch: [140][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4395 (2.3901)	Acc@1 58.594 (55.891)	Acc@5 84.375 (84.910)
Epoch: [140][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4409 (2.3944)	Acc@1 57.031 (55.822)	Acc@5 82.031 (84.830)
Epoch: [140][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4894 (2.3980)	Acc@1 56.250 (55.766)	Acc@5 82.812 (84.774)
Epoch: [140][340/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3111 (2.3970)	Acc@1 58.594 (55.803)	Acc@5 84.375 (84.787)
Epoch: [140][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5924 (2.3961)	Acc@1 46.094 (55.785)	Acc@5 84.375 (84.809)
Epoch: [140][360/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.7308 (2.3967)	Acc@1 53.906 (55.752)	Acc@5 82.812 (84.819)
Epoch: [140][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.8071 (2.3982)	Acc@1 41.406 (55.684)	Acc@5 75.781 (84.821)
Epoch: [140][380/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3376 (2.3993)	Acc@1 57.812 (55.635)	Acc@5 83.594 (84.810)
Epoch: [140][390/391]	Time 0.019 (0.014)	Data 0.001 (0.002)	Loss 2.6479 (2.3996)	Acc@1 52.500 (55.614)	Acc@5 82.500 (84.794)
num momentum params: 26
[0.1, 2.3996353546905516, 1.8743646121025086, 55.614, 50.35, tensor(0.3307, device='cuda:0', grad_fn=<DivBackward0>), 5.356394529342651, 0.4244015216827392]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [141 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [141][0/391]	Time 0.065 (0.065)	Data 0.168 (0.168)	Loss 2.3238 (2.3238)	Acc@1 60.938 (60.938)	Acc@5 84.375 (84.375)
Epoch: [141][10/391]	Time 0.014 (0.021)	Data 0.001 (0.017)	Loss 2.3204 (2.3120)	Acc@1 57.031 (56.818)	Acc@5 89.844 (87.074)
Epoch: [141][20/391]	Time 0.014 (0.017)	Data 0.001 (0.010)	Loss 2.4235 (2.2922)	Acc@1 56.250 (57.552)	Acc@5 84.375 (87.091)
Epoch: [141][30/391]	Time 0.014 (0.016)	Data 0.001 (0.007)	Loss 2.1179 (2.2685)	Acc@1 63.281 (58.392)	Acc@5 89.844 (87.223)
Epoch: [141][40/391]	Time 0.014 (0.016)	Data 0.001 (0.006)	Loss 2.2290 (2.2562)	Acc@1 61.719 (58.937)	Acc@5 84.375 (87.119)
Epoch: [141][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.1893 (2.2707)	Acc@1 60.938 (58.670)	Acc@5 89.844 (86.949)
Epoch: [141][60/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.2284 (2.2742)	Acc@1 59.375 (58.440)	Acc@5 86.719 (86.847)
Epoch: [141][70/391]	Time 0.015 (0.015)	Data 0.001 (0.004)	Loss 2.5538 (2.2851)	Acc@1 53.906 (58.143)	Acc@5 78.125 (86.565)
Epoch: [141][80/391]	Time 0.015 (0.015)	Data 0.002 (0.004)	Loss 2.3537 (2.2918)	Acc@1 61.719 (58.121)	Acc@5 82.812 (86.391)
Epoch: [141][90/391]	Time 0.019 (0.015)	Data 0.001 (0.003)	Loss 2.2888 (2.3006)	Acc@1 64.844 (58.070)	Acc@5 87.500 (86.152)
Epoch: [141][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2130 (2.3054)	Acc@1 62.500 (57.983)	Acc@5 90.625 (86.108)
Epoch: [141][110/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.2312 (2.3128)	Acc@1 57.812 (57.777)	Acc@5 89.844 (86.008)
Epoch: [141][120/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.5473 (2.3290)	Acc@1 54.688 (57.432)	Acc@5 80.469 (85.770)
Epoch: [141][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4284 (2.3441)	Acc@1 53.906 (57.103)	Acc@5 82.031 (85.448)
Epoch: [141][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3207 (2.3442)	Acc@1 55.469 (57.120)	Acc@5 87.500 (85.472)
Epoch: [141][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4138 (2.3496)	Acc@1 56.250 (56.974)	Acc@5 85.156 (85.343)
Epoch: [141][160/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4016 (2.3505)	Acc@1 55.469 (56.954)	Acc@5 85.938 (85.287)
Epoch: [141][170/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3871 (2.3531)	Acc@1 57.031 (56.844)	Acc@5 84.375 (85.275)
Epoch: [141][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1182 (2.3505)	Acc@1 65.625 (56.902)	Acc@5 86.719 (85.346)
Epoch: [141][190/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3902 (2.3510)	Acc@1 55.469 (56.872)	Acc@5 82.031 (85.389)
Epoch: [141][200/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.8122 (2.3574)	Acc@1 45.312 (56.697)	Acc@5 74.219 (85.234)
Epoch: [141][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3820 (2.3621)	Acc@1 53.125 (56.605)	Acc@5 87.500 (85.186)
Epoch: [141][220/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3301 (2.3633)	Acc@1 54.688 (56.543)	Acc@5 87.500 (85.149)
Epoch: [141][230/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6667 (2.3651)	Acc@1 50.000 (56.510)	Acc@5 83.594 (85.119)
Epoch: [141][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4236 (2.3657)	Acc@1 55.469 (56.470)	Acc@5 81.250 (85.111)
Epoch: [141][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4379 (2.3660)	Acc@1 57.031 (56.459)	Acc@5 82.031 (85.116)
Epoch: [141][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2914 (2.3707)	Acc@1 57.812 (56.316)	Acc@5 89.062 (85.051)
Epoch: [141][270/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.1053 (2.3737)	Acc@1 57.812 (56.207)	Acc@5 90.625 (85.029)
Epoch: [141][280/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3650 (2.3756)	Acc@1 53.125 (56.150)	Acc@5 88.281 (85.037)
Epoch: [141][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4315 (2.3757)	Acc@1 58.594 (56.178)	Acc@5 82.031 (85.038)
Epoch: [141][300/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3400 (2.3758)	Acc@1 54.688 (56.183)	Acc@5 85.156 (85.037)
Epoch: [141][310/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.4206 (2.3773)	Acc@1 58.594 (56.144)	Acc@5 80.469 (85.026)
Epoch: [141][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4655 (2.3793)	Acc@1 53.125 (56.085)	Acc@5 85.156 (85.022)
Epoch: [141][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3841 (2.3789)	Acc@1 53.906 (56.108)	Acc@5 85.938 (85.019)
Epoch: [141][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4730 (2.3825)	Acc@1 55.469 (56.076)	Acc@5 81.250 (84.943)
Epoch: [141][350/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4925 (2.3841)	Acc@1 55.469 (56.041)	Acc@5 82.812 (84.905)
Epoch: [141][360/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.7986 (2.3874)	Acc@1 45.312 (55.986)	Acc@5 77.344 (84.836)
Epoch: [141][370/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3364 (2.3885)	Acc@1 60.938 (55.985)	Acc@5 82.031 (84.805)
Epoch: [141][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6651 (2.3892)	Acc@1 52.344 (55.973)	Acc@5 78.906 (84.775)
Epoch: [141][390/391]	Time 0.019 (0.014)	Data 0.001 (0.002)	Loss 2.5508 (2.3902)	Acc@1 50.000 (55.946)	Acc@5 86.250 (84.768)
num momentum params: 26
[0.1, 2.390168801498413, 2.0498014163970946, 55.946, 47.62, tensor(0.3318, device='cuda:0', grad_fn=<DivBackward0>), 5.408134460449219, 0.41663837432861334]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [142 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [142][0/391]	Time 0.067 (0.067)	Data 0.186 (0.186)	Loss 2.1799 (2.1799)	Acc@1 61.719 (61.719)	Acc@5 85.156 (85.156)
Epoch: [142][10/391]	Time 0.013 (0.022)	Data 0.001 (0.018)	Loss 2.2064 (2.2897)	Acc@1 62.500 (57.599)	Acc@5 87.500 (87.287)
Epoch: [142][20/391]	Time 0.013 (0.018)	Data 0.001 (0.010)	Loss 2.1964 (2.2962)	Acc@1 66.406 (57.552)	Acc@5 86.719 (87.165)
Epoch: [142][30/391]	Time 0.013 (0.017)	Data 0.001 (0.007)	Loss 2.1593 (2.3095)	Acc@1 60.156 (57.661)	Acc@5 89.844 (86.769)
Epoch: [142][40/391]	Time 0.013 (0.016)	Data 0.001 (0.006)	Loss 2.3197 (2.3186)	Acc@1 57.812 (57.412)	Acc@5 86.719 (86.566)
Epoch: [142][50/391]	Time 0.014 (0.015)	Data 0.001 (0.005)	Loss 2.6498 (2.3278)	Acc@1 49.219 (57.338)	Acc@5 78.906 (86.167)
Epoch: [142][60/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.3900 (2.3398)	Acc@1 56.250 (56.890)	Acc@5 82.812 (85.758)
Epoch: [142][70/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.5471 (2.3496)	Acc@1 57.031 (56.613)	Acc@5 83.594 (85.552)
Epoch: [142][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.2732 (2.3467)	Acc@1 60.156 (56.655)	Acc@5 91.406 (85.725)
Epoch: [142][90/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.4436 (2.3517)	Acc@1 53.125 (56.490)	Acc@5 85.156 (85.680)
Epoch: [142][100/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.4794 (2.3540)	Acc@1 56.250 (56.451)	Acc@5 83.594 (85.605)
Epoch: [142][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4689 (2.3546)	Acc@1 54.688 (56.447)	Acc@5 87.500 (85.607)
Epoch: [142][120/391]	Time 0.015 (0.014)	Data 0.002 (0.003)	Loss 2.6926 (2.3528)	Acc@1 48.438 (56.560)	Acc@5 77.344 (85.550)
Epoch: [142][130/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.7227 (2.3584)	Acc@1 50.781 (56.339)	Acc@5 79.688 (85.538)
Epoch: [142][140/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.4204 (2.3648)	Acc@1 51.562 (56.167)	Acc@5 84.375 (85.444)
Epoch: [142][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4913 (2.3671)	Acc@1 48.438 (56.167)	Acc@5 85.156 (85.368)
Epoch: [142][160/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5917 (2.3667)	Acc@1 50.781 (56.158)	Acc@5 80.469 (85.365)
Epoch: [142][170/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5537 (2.3658)	Acc@1 53.906 (56.204)	Acc@5 83.594 (85.417)
Epoch: [142][180/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3986 (2.3696)	Acc@1 57.812 (56.090)	Acc@5 85.938 (85.368)
Epoch: [142][190/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.3408 (2.3745)	Acc@1 59.375 (56.029)	Acc@5 88.281 (85.295)
Epoch: [142][200/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6356 (2.3728)	Acc@1 49.219 (56.118)	Acc@5 80.469 (85.327)
Epoch: [142][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.0868 (2.3704)	Acc@1 67.188 (56.272)	Acc@5 85.156 (85.271)
Epoch: [142][220/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4149 (2.3704)	Acc@1 53.906 (56.296)	Acc@5 85.938 (85.276)
Epoch: [142][230/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2499 (2.3753)	Acc@1 56.250 (56.179)	Acc@5 87.500 (85.214)
Epoch: [142][240/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2903 (2.3777)	Acc@1 56.250 (56.107)	Acc@5 88.281 (85.189)
Epoch: [142][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1969 (2.3778)	Acc@1 60.156 (56.206)	Acc@5 86.719 (85.159)
Epoch: [142][260/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5497 (2.3802)	Acc@1 52.344 (56.190)	Acc@5 82.031 (85.129)
Epoch: [142][270/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3884 (2.3802)	Acc@1 51.562 (56.172)	Acc@5 86.719 (85.125)
Epoch: [142][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6893 (2.3846)	Acc@1 51.562 (56.041)	Acc@5 79.688 (85.081)
Epoch: [142][290/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4230 (2.3868)	Acc@1 55.469 (55.995)	Acc@5 89.062 (85.049)
Epoch: [142][300/391]	Time 0.016 (0.014)	Data 0.002 (0.002)	Loss 2.2867 (2.3864)	Acc@1 57.812 (55.998)	Acc@5 89.844 (85.058)
Epoch: [142][310/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4388 (2.3848)	Acc@1 60.156 (56.067)	Acc@5 82.812 (85.066)
Epoch: [142][320/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.1892 (2.3838)	Acc@1 64.844 (56.155)	Acc@5 85.938 (85.042)
Epoch: [142][330/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3872 (2.3846)	Acc@1 57.812 (56.132)	Acc@5 82.031 (84.993)
Epoch: [142][340/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3241 (2.3868)	Acc@1 58.594 (56.062)	Acc@5 83.594 (84.950)
Epoch: [142][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4481 (2.3876)	Acc@1 59.375 (56.014)	Acc@5 85.938 (84.931)
Epoch: [142][360/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.2796 (2.3904)	Acc@1 56.250 (55.910)	Acc@5 86.719 (84.899)
Epoch: [142][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3725 (2.3906)	Acc@1 57.812 (55.886)	Acc@5 85.156 (84.916)
Epoch: [142][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4147 (2.3928)	Acc@1 57.031 (55.809)	Acc@5 81.250 (84.859)
Epoch: [142][390/391]	Time 0.018 (0.014)	Data 0.001 (0.002)	Loss 2.4534 (2.3924)	Acc@1 57.500 (55.806)	Acc@5 82.500 (84.840)
num momentum params: 26
[0.1, 2.3923787185668943, 2.1714010441303255, 55.806, 45.36, tensor(0.3316, device='cuda:0', grad_fn=<DivBackward0>), 5.426713466644287, 0.42787384986877447]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [143 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [143][0/391]	Time 0.075 (0.075)	Data 0.190 (0.190)	Loss 2.5093 (2.5093)	Acc@1 57.031 (57.031)	Acc@5 78.125 (78.125)
Epoch: [143][10/391]	Time 0.015 (0.022)	Data 0.001 (0.018)	Loss 2.2591 (2.3559)	Acc@1 54.688 (56.889)	Acc@5 87.500 (86.151)
Epoch: [143][20/391]	Time 0.014 (0.018)	Data 0.001 (0.010)	Loss 2.3096 (2.2943)	Acc@1 54.688 (58.147)	Acc@5 88.281 (86.235)
Epoch: [143][30/391]	Time 0.014 (0.017)	Data 0.001 (0.008)	Loss 2.1294 (2.3084)	Acc@1 59.375 (57.636)	Acc@5 92.188 (86.164)
Epoch: [143][40/391]	Time 0.013 (0.016)	Data 0.001 (0.006)	Loss 2.5914 (2.3175)	Acc@1 48.438 (57.470)	Acc@5 82.031 (86.071)
Epoch: [143][50/391]	Time 0.013 (0.016)	Data 0.001 (0.005)	Loss 2.4674 (2.3248)	Acc@1 56.250 (57.613)	Acc@5 81.250 (85.846)
Epoch: [143][60/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.1201 (2.3215)	Acc@1 61.719 (57.774)	Acc@5 88.281 (85.886)
Epoch: [143][70/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.2751 (2.3200)	Acc@1 61.719 (57.812)	Acc@5 90.625 (85.838)
Epoch: [143][80/391]	Time 0.012 (0.015)	Data 0.002 (0.004)	Loss 2.5572 (2.3336)	Acc@1 46.094 (57.427)	Acc@5 82.031 (85.610)
Epoch: [143][90/391]	Time 0.014 (0.015)	Data 0.002 (0.004)	Loss 2.5257 (2.3414)	Acc@1 56.250 (57.160)	Acc@5 84.375 (85.379)
Epoch: [143][100/391]	Time 0.014 (0.015)	Data 0.001 (0.003)	Loss 2.6953 (2.3577)	Acc@1 47.656 (56.877)	Acc@5 78.906 (85.094)
Epoch: [143][110/391]	Time 0.013 (0.015)	Data 0.002 (0.003)	Loss 2.4848 (2.3657)	Acc@1 56.250 (56.715)	Acc@5 80.469 (84.882)
Epoch: [143][120/391]	Time 0.013 (0.015)	Data 0.002 (0.003)	Loss 2.5265 (2.3682)	Acc@1 53.906 (56.657)	Acc@5 82.031 (84.879)
Epoch: [143][130/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.4149 (2.3771)	Acc@1 51.562 (56.471)	Acc@5 82.812 (84.709)
Epoch: [143][140/391]	Time 0.017 (0.014)	Data 0.002 (0.003)	Loss 2.3075 (2.3780)	Acc@1 59.375 (56.538)	Acc@5 85.156 (84.658)
Epoch: [143][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.0534 (2.3791)	Acc@1 65.625 (56.472)	Acc@5 89.844 (84.634)
Epoch: [143][160/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.7049 (2.3765)	Acc@1 47.656 (56.434)	Acc@5 78.125 (84.724)
Epoch: [143][170/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5384 (2.3761)	Acc@1 46.875 (56.360)	Acc@5 85.156 (84.745)
Epoch: [143][180/391]	Time 0.019 (0.014)	Data 0.002 (0.003)	Loss 2.4142 (2.3772)	Acc@1 55.469 (56.371)	Acc@5 83.594 (84.703)
Epoch: [143][190/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.6674 (2.3768)	Acc@1 51.562 (56.389)	Acc@5 81.250 (84.747)
Epoch: [143][200/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5860 (2.3784)	Acc@1 50.781 (56.332)	Acc@5 78.906 (84.705)
Epoch: [143][210/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.4354 (2.3800)	Acc@1 53.906 (56.231)	Acc@5 84.375 (84.730)
Epoch: [143][220/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.1033 (2.3821)	Acc@1 62.500 (56.285)	Acc@5 85.938 (84.686)
Epoch: [143][230/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.2765 (2.3795)	Acc@1 63.281 (56.311)	Acc@5 84.375 (84.700)
Epoch: [143][240/391]	Time 0.015 (0.014)	Data 0.002 (0.003)	Loss 2.3122 (2.3795)	Acc@1 57.812 (56.354)	Acc@5 85.156 (84.657)
Epoch: [143][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4647 (2.3803)	Acc@1 54.688 (56.328)	Acc@5 78.906 (84.636)
Epoch: [143][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4490 (2.3825)	Acc@1 54.688 (56.301)	Acc@5 83.594 (84.579)
Epoch: [143][270/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5998 (2.3861)	Acc@1 49.219 (56.138)	Acc@5 82.031 (84.534)
Epoch: [143][280/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.3559 (2.3882)	Acc@1 54.688 (56.078)	Acc@5 84.375 (84.522)
Epoch: [143][290/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4711 (2.3922)	Acc@1 50.000 (55.939)	Acc@5 82.031 (84.490)
Epoch: [143][300/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.5089 (2.3936)	Acc@1 50.000 (55.910)	Acc@5 82.812 (84.455)
Epoch: [143][310/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6126 (2.3970)	Acc@1 51.562 (55.853)	Acc@5 77.344 (84.393)
Epoch: [143][320/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.5714 (2.3976)	Acc@1 55.469 (55.878)	Acc@5 85.938 (84.414)
Epoch: [143][330/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4687 (2.3957)	Acc@1 55.469 (55.953)	Acc@5 83.594 (84.436)
Epoch: [143][340/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3353 (2.3976)	Acc@1 58.594 (55.902)	Acc@5 85.938 (84.400)
Epoch: [143][350/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6326 (2.3977)	Acc@1 54.688 (55.967)	Acc@5 78.906 (84.393)
Epoch: [143][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3999 (2.4008)	Acc@1 56.250 (55.930)	Acc@5 85.156 (84.340)
Epoch: [143][370/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2681 (2.4051)	Acc@1 59.375 (55.774)	Acc@5 87.500 (84.301)
Epoch: [143][380/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4168 (2.4046)	Acc@1 57.812 (55.768)	Acc@5 83.594 (84.318)
Epoch: [143][390/391]	Time 0.019 (0.014)	Data 0.001 (0.002)	Loss 2.5065 (2.4044)	Acc@1 46.250 (55.724)	Acc@5 80.000 (84.342)
num momentum params: 26
[0.1, 2.4044434271240234, 2.1586536717414857, 55.724, 45.27, tensor(0.3298, device='cuda:0', grad_fn=<DivBackward0>), 5.4454121589660645, 0.41965460777282715]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [144 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [144][0/391]	Time 0.067 (0.067)	Data 0.183 (0.183)	Loss 2.3316 (2.3316)	Acc@1 60.156 (60.156)	Acc@5 84.375 (84.375)
Epoch: [144][10/391]	Time 0.013 (0.021)	Data 0.001 (0.018)	Loss 2.4215 (2.3560)	Acc@1 58.594 (58.097)	Acc@5 82.812 (83.949)
Epoch: [144][20/391]	Time 0.015 (0.018)	Data 0.001 (0.010)	Loss 2.3472 (2.3525)	Acc@1 57.812 (57.292)	Acc@5 85.938 (84.561)
Epoch: [144][30/391]	Time 0.013 (0.017)	Data 0.001 (0.007)	Loss 2.4666 (2.3471)	Acc@1 55.469 (56.855)	Acc@5 82.812 (84.753)
Epoch: [144][40/391]	Time 0.016 (0.016)	Data 0.001 (0.006)	Loss 2.3975 (2.3427)	Acc@1 52.344 (56.555)	Acc@5 88.281 (84.889)
Epoch: [144][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.1369 (2.3481)	Acc@1 66.406 (56.801)	Acc@5 85.938 (84.666)
Epoch: [144][60/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 2.0240 (2.3377)	Acc@1 64.062 (56.993)	Acc@5 89.844 (84.862)
Epoch: [144][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.4342 (2.3359)	Acc@1 57.031 (57.174)	Acc@5 83.594 (84.848)
Epoch: [144][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.3670 (2.3391)	Acc@1 52.344 (56.944)	Acc@5 86.719 (84.857)
Epoch: [144][90/391]	Time 0.012 (0.015)	Data 0.002 (0.003)	Loss 2.3025 (2.3474)	Acc@1 55.469 (56.817)	Acc@5 88.281 (84.959)
Epoch: [144][100/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 2.3293 (2.3575)	Acc@1 53.906 (56.552)	Acc@5 86.719 (84.893)
Epoch: [144][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2384 (2.3555)	Acc@1 59.375 (56.722)	Acc@5 89.062 (84.945)
Epoch: [144][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5434 (2.3575)	Acc@1 53.906 (56.586)	Acc@5 81.250 (84.879)
Epoch: [144][130/391]	Time 0.015 (0.014)	Data 0.002 (0.003)	Loss 2.3033 (2.3649)	Acc@1 56.250 (56.435)	Acc@5 85.938 (84.703)
Epoch: [144][140/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.5918 (2.3658)	Acc@1 46.875 (56.389)	Acc@5 82.031 (84.685)
Epoch: [144][150/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3813 (2.3686)	Acc@1 54.688 (56.353)	Acc@5 83.594 (84.608)
Epoch: [144][160/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3426 (2.3700)	Acc@1 60.156 (56.434)	Acc@5 87.500 (84.622)
Epoch: [144][170/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3161 (2.3745)	Acc@1 59.375 (56.309)	Acc@5 85.938 (84.571)
Epoch: [144][180/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2562 (2.3715)	Acc@1 55.469 (56.397)	Acc@5 86.719 (84.638)
Epoch: [144][190/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3504 (2.3743)	Acc@1 57.812 (56.315)	Acc@5 85.156 (84.584)
Epoch: [144][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3541 (2.3721)	Acc@1 59.375 (56.402)	Acc@5 87.500 (84.620)
Epoch: [144][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3354 (2.3733)	Acc@1 58.594 (56.354)	Acc@5 87.500 (84.660)
Epoch: [144][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4587 (2.3724)	Acc@1 60.156 (56.406)	Acc@5 83.594 (84.704)
Epoch: [144][230/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3631 (2.3717)	Acc@1 57.812 (56.395)	Acc@5 85.156 (84.744)
Epoch: [144][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3836 (2.3738)	Acc@1 56.250 (56.338)	Acc@5 84.375 (84.738)
Epoch: [144][250/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5545 (2.3743)	Acc@1 50.000 (56.309)	Acc@5 82.812 (84.742)
Epoch: [144][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3186 (2.3733)	Acc@1 55.469 (56.355)	Acc@5 86.719 (84.716)
Epoch: [144][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5429 (2.3772)	Acc@1 50.781 (56.285)	Acc@5 80.469 (84.672)
Epoch: [144][280/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2516 (2.3791)	Acc@1 58.594 (56.242)	Acc@5 88.281 (84.675)
Epoch: [144][290/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3293 (2.3816)	Acc@1 53.125 (56.196)	Acc@5 91.406 (84.662)
Epoch: [144][300/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3087 (2.3841)	Acc@1 57.812 (56.102)	Acc@5 85.156 (84.648)
Epoch: [144][310/391]	Time 0.015 (0.014)	Data 0.002 (0.002)	Loss 2.4416 (2.3868)	Acc@1 57.031 (56.097)	Acc@5 85.156 (84.646)
Epoch: [144][320/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2677 (2.3856)	Acc@1 59.375 (56.099)	Acc@5 89.062 (84.704)
Epoch: [144][330/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3905 (2.3877)	Acc@1 57.031 (56.099)	Acc@5 85.156 (84.661)
Epoch: [144][340/391]	Time 0.011 (0.014)	Data 0.002 (0.002)	Loss 2.3736 (2.3883)	Acc@1 54.688 (56.064)	Acc@5 84.375 (84.613)
Epoch: [144][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3939 (2.3912)	Acc@1 53.906 (55.998)	Acc@5 85.938 (84.604)
Epoch: [144][360/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.1952 (2.3913)	Acc@1 63.281 (55.988)	Acc@5 89.844 (84.620)
Epoch: [144][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3161 (2.3927)	Acc@1 54.688 (55.943)	Acc@5 86.719 (84.594)
Epoch: [144][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4499 (2.3937)	Acc@1 57.812 (55.908)	Acc@5 82.812 (84.607)
Epoch: [144][390/391]	Time 0.019 (0.014)	Data 0.001 (0.002)	Loss 2.3770 (2.3941)	Acc@1 55.000 (55.870)	Acc@5 81.250 (84.626)
num momentum params: 26
[0.1, 2.3940983898925783, 2.1270511984825133, 55.87, 45.44, tensor(0.3314, device='cuda:0', grad_fn=<DivBackward0>), 5.387604236602783, 0.406186580657959]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [145 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [145][0/391]	Time 0.069 (0.069)	Data 0.183 (0.183)	Loss 2.2462 (2.2462)	Acc@1 60.156 (60.156)	Acc@5 88.281 (88.281)
Epoch: [145][10/391]	Time 0.015 (0.022)	Data 0.001 (0.018)	Loss 2.0442 (2.2478)	Acc@1 65.625 (59.517)	Acc@5 90.625 (87.642)
Epoch: [145][20/391]	Time 0.015 (0.018)	Data 0.001 (0.010)	Loss 2.4415 (2.2901)	Acc@1 54.688 (58.147)	Acc@5 85.156 (86.682)
Epoch: [145][30/391]	Time 0.013 (0.017)	Data 0.001 (0.007)	Loss 2.2551 (2.2956)	Acc@1 61.719 (58.266)	Acc@5 89.062 (86.265)
Epoch: [145][40/391]	Time 0.013 (0.016)	Data 0.001 (0.006)	Loss 2.0666 (2.2887)	Acc@1 64.062 (58.441)	Acc@5 90.625 (86.509)
Epoch: [145][50/391]	Time 0.014 (0.015)	Data 0.001 (0.005)	Loss 2.3614 (2.3130)	Acc@1 58.594 (57.966)	Acc@5 79.688 (86.045)
Epoch: [145][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.3003 (2.3114)	Acc@1 58.594 (58.197)	Acc@5 89.844 (85.771)
Epoch: [145][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.4930 (2.3228)	Acc@1 56.250 (57.801)	Acc@5 81.250 (85.563)
Epoch: [145][80/391]	Time 0.015 (0.015)	Data 0.002 (0.004)	Loss 2.2409 (2.3236)	Acc@1 57.812 (57.793)	Acc@5 85.938 (85.696)
Epoch: [145][90/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 2.2184 (2.3132)	Acc@1 64.062 (58.079)	Acc@5 89.844 (85.843)
Epoch: [145][100/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.3356 (2.3245)	Acc@1 57.031 (57.743)	Acc@5 86.719 (85.744)
Epoch: [145][110/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.2831 (2.3276)	Acc@1 55.469 (57.644)	Acc@5 84.375 (85.586)
Epoch: [145][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.0858 (2.3311)	Acc@1 64.062 (57.425)	Acc@5 89.062 (85.486)
Epoch: [145][130/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.2104 (2.3300)	Acc@1 61.719 (57.467)	Acc@5 87.500 (85.526)
Epoch: [145][140/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3038 (2.3330)	Acc@1 57.812 (57.414)	Acc@5 84.375 (85.411)
Epoch: [145][150/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4767 (2.3383)	Acc@1 57.031 (57.321)	Acc@5 81.250 (85.394)
Epoch: [145][160/391]	Time 0.012 (0.014)	Data 0.003 (0.003)	Loss 2.4230 (2.3413)	Acc@1 53.906 (57.206)	Acc@5 83.594 (85.360)
Epoch: [145][170/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5194 (2.3387)	Acc@1 53.906 (57.255)	Acc@5 82.812 (85.408)
Epoch: [145][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.0677 (2.3379)	Acc@1 63.281 (57.329)	Acc@5 89.062 (85.381)
Epoch: [145][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2621 (2.3398)	Acc@1 63.281 (57.256)	Acc@5 85.156 (85.365)
Epoch: [145][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3692 (2.3416)	Acc@1 53.125 (57.191)	Acc@5 85.156 (85.374)
Epoch: [145][210/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6928 (2.3515)	Acc@1 50.781 (57.039)	Acc@5 78.906 (85.197)
Epoch: [145][220/391]	Time 0.016 (0.014)	Data 0.002 (0.002)	Loss 2.4848 (2.3538)	Acc@1 55.469 (57.003)	Acc@5 85.938 (85.177)
Epoch: [145][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2292 (2.3583)	Acc@1 58.594 (56.855)	Acc@5 85.156 (85.129)
Epoch: [145][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4400 (2.3594)	Acc@1 55.469 (56.814)	Acc@5 82.812 (85.082)
Epoch: [145][250/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 2.5019 (2.3654)	Acc@1 55.469 (56.742)	Acc@5 85.938 (84.979)
Epoch: [145][260/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.8873 (2.3676)	Acc@1 47.656 (56.675)	Acc@5 75.781 (84.983)
Epoch: [145][270/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2452 (2.3716)	Acc@1 67.188 (56.619)	Acc@5 83.594 (84.903)
Epoch: [145][280/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.4150 (2.3737)	Acc@1 51.562 (56.559)	Acc@5 85.938 (84.850)
Epoch: [145][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3789 (2.3733)	Acc@1 55.469 (56.610)	Acc@5 87.500 (84.912)
Epoch: [145][300/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4194 (2.3753)	Acc@1 52.344 (56.546)	Acc@5 82.812 (84.881)
Epoch: [145][310/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 2.5005 (2.3751)	Acc@1 50.000 (56.509)	Acc@5 83.594 (84.875)
Epoch: [145][320/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.2881 (2.3764)	Acc@1 58.594 (56.484)	Acc@5 85.938 (84.823)
Epoch: [145][330/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 2.2274 (2.3756)	Acc@1 57.812 (56.505)	Acc@5 91.406 (84.868)
Epoch: [145][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6241 (2.3767)	Acc@1 50.000 (56.486)	Acc@5 80.469 (84.819)
Epoch: [145][350/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.1388 (2.3778)	Acc@1 60.938 (56.435)	Acc@5 91.406 (84.802)
Epoch: [145][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5419 (2.3786)	Acc@1 46.094 (56.371)	Acc@5 82.812 (84.801)
Epoch: [145][370/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4452 (2.3830)	Acc@1 50.781 (56.258)	Acc@5 84.375 (84.706)
Epoch: [145][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6055 (2.3863)	Acc@1 52.344 (56.193)	Acc@5 82.812 (84.635)
Epoch: [145][390/391]	Time 0.018 (0.014)	Data 0.001 (0.002)	Loss 2.3468 (2.3889)	Acc@1 55.000 (56.126)	Acc@5 90.000 (84.608)
num momentum params: 26
[0.1, 2.388891071243286, 2.0142742514610292, 56.126, 47.27, tensor(0.3324, device='cuda:0', grad_fn=<DivBackward0>), 5.406094789505005, 0.4200639724731445]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [146 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [146][0/391]	Time 0.066 (0.066)	Data 0.185 (0.185)	Loss 2.3484 (2.3484)	Acc@1 57.812 (57.812)	Acc@5 89.062 (89.062)
Epoch: [146][10/391]	Time 0.016 (0.021)	Data 0.002 (0.018)	Loss 2.4063 (2.2906)	Acc@1 57.812 (59.233)	Acc@5 82.812 (86.222)
Epoch: [146][20/391]	Time 0.014 (0.018)	Data 0.001 (0.010)	Loss 2.3852 (2.3036)	Acc@1 56.250 (58.110)	Acc@5 87.500 (86.012)
Epoch: [146][30/391]	Time 0.013 (0.017)	Data 0.002 (0.007)	Loss 2.2393 (2.2904)	Acc@1 58.594 (58.569)	Acc@5 88.281 (86.290)
Epoch: [146][40/391]	Time 0.013 (0.016)	Data 0.001 (0.006)	Loss 2.1720 (2.2927)	Acc@1 61.719 (58.498)	Acc@5 87.500 (86.261)
Epoch: [146][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.6239 (2.3104)	Acc@1 52.344 (57.920)	Acc@5 82.812 (85.999)
Epoch: [146][60/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.2678 (2.3207)	Acc@1 60.156 (57.531)	Acc@5 85.938 (85.784)
Epoch: [146][70/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 2.5563 (2.3356)	Acc@1 50.000 (57.064)	Acc@5 81.250 (85.486)
Epoch: [146][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.4024 (2.3294)	Acc@1 51.562 (57.234)	Acc@5 87.500 (85.716)
Epoch: [146][90/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 2.1747 (2.3300)	Acc@1 53.906 (57.169)	Acc@5 91.406 (85.843)
Epoch: [146][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4180 (2.3310)	Acc@1 58.594 (57.248)	Acc@5 82.031 (85.791)
Epoch: [146][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3944 (2.3364)	Acc@1 56.250 (57.186)	Acc@5 86.719 (85.670)
Epoch: [146][120/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 2.3806 (2.3406)	Acc@1 50.781 (57.070)	Acc@5 85.938 (85.647)
Epoch: [146][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3208 (2.3477)	Acc@1 55.469 (56.870)	Acc@5 89.062 (85.454)
Epoch: [146][140/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2592 (2.3564)	Acc@1 64.062 (56.704)	Acc@5 83.594 (85.273)
Epoch: [146][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4027 (2.3589)	Acc@1 54.688 (56.576)	Acc@5 88.281 (85.244)
Epoch: [146][160/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.2710 (2.3678)	Acc@1 57.812 (56.415)	Acc@5 86.719 (85.161)
Epoch: [146][170/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3210 (2.3741)	Acc@1 55.469 (56.259)	Acc@5 86.719 (85.074)
Epoch: [146][180/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6371 (2.3715)	Acc@1 51.562 (56.306)	Acc@5 79.688 (85.139)
Epoch: [146][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5932 (2.3662)	Acc@1 50.781 (56.455)	Acc@5 85.156 (85.259)
Epoch: [146][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3103 (2.3660)	Acc@1 59.375 (56.421)	Acc@5 86.719 (85.285)
Epoch: [146][210/391]	Time 0.011 (0.014)	Data 0.004 (0.002)	Loss 2.4375 (2.3650)	Acc@1 53.906 (56.417)	Acc@5 85.156 (85.256)
Epoch: [146][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5358 (2.3715)	Acc@1 50.000 (56.257)	Acc@5 82.031 (85.121)
Epoch: [146][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6345 (2.3740)	Acc@1 52.344 (56.243)	Acc@5 81.250 (85.078)
Epoch: [146][240/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3149 (2.3752)	Acc@1 61.719 (56.205)	Acc@5 85.938 (85.088)
Epoch: [146][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3075 (2.3780)	Acc@1 56.250 (56.166)	Acc@5 85.938 (85.044)
Epoch: [146][260/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6020 (2.3796)	Acc@1 49.219 (56.148)	Acc@5 82.812 (85.031)
Epoch: [146][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4709 (2.3826)	Acc@1 54.688 (56.120)	Acc@5 84.375 (84.995)
Epoch: [146][280/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.2716 (2.3842)	Acc@1 62.500 (56.117)	Acc@5 86.719 (84.953)
Epoch: [146][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2470 (2.3874)	Acc@1 60.938 (56.049)	Acc@5 87.500 (84.896)
Epoch: [146][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3835 (2.3904)	Acc@1 55.469 (55.998)	Acc@5 85.156 (84.840)
Epoch: [146][310/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.1099 (2.3928)	Acc@1 64.062 (55.923)	Acc@5 88.281 (84.792)
Epoch: [146][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3169 (2.3927)	Acc@1 57.031 (55.919)	Acc@5 84.375 (84.796)
Epoch: [146][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4178 (2.3932)	Acc@1 56.250 (55.922)	Acc@5 86.719 (84.823)
Epoch: [146][340/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3516 (2.3938)	Acc@1 57.031 (55.909)	Acc@5 87.500 (84.783)
Epoch: [146][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2865 (2.3933)	Acc@1 58.594 (55.916)	Acc@5 85.938 (84.791)
Epoch: [146][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3576 (2.3951)	Acc@1 49.219 (55.871)	Acc@5 89.844 (84.758)
Epoch: [146][370/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6500 (2.3972)	Acc@1 50.781 (55.837)	Acc@5 82.031 (84.733)
Epoch: [146][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4004 (2.3967)	Acc@1 57.031 (55.826)	Acc@5 82.031 (84.754)
Epoch: [146][390/391]	Time 0.018 (0.014)	Data 0.001 (0.002)	Loss 2.2985 (2.3973)	Acc@1 63.750 (55.826)	Acc@5 82.500 (84.758)
num momentum params: 26
[0.1, 2.3973403967285156, 2.0058507537841797, 55.826, 47.98, tensor(0.3305, device='cuda:0', grad_fn=<DivBackward0>), 5.325475454330444, 0.40267944335937494]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [147 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [147][0/391]	Time 0.072 (0.072)	Data 0.172 (0.172)	Loss 2.3189 (2.3189)	Acc@1 53.906 (53.906)	Acc@5 84.375 (84.375)
Epoch: [147][10/391]	Time 0.015 (0.021)	Data 0.001 (0.017)	Loss 2.1693 (2.2216)	Acc@1 60.156 (61.364)	Acc@5 90.625 (86.790)
Epoch: [147][20/391]	Time 0.014 (0.018)	Data 0.001 (0.010)	Loss 1.9834 (2.2189)	Acc@1 64.062 (60.082)	Acc@5 89.844 (87.202)
Epoch: [147][30/391]	Time 0.013 (0.016)	Data 0.001 (0.007)	Loss 2.1567 (2.2272)	Acc@1 57.031 (59.148)	Acc@5 87.500 (87.248)
Epoch: [147][40/391]	Time 0.013 (0.016)	Data 0.002 (0.006)	Loss 2.3125 (2.2632)	Acc@1 58.594 (58.765)	Acc@5 82.812 (86.395)
Epoch: [147][50/391]	Time 0.015 (0.015)	Data 0.001 (0.005)	Loss 2.4615 (2.2860)	Acc@1 50.000 (58.180)	Acc@5 82.031 (86.244)
Epoch: [147][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.3768 (2.2904)	Acc@1 58.594 (58.145)	Acc@5 85.938 (86.232)
Epoch: [147][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.3805 (2.3040)	Acc@1 50.781 (57.989)	Acc@5 89.062 (85.982)
Epoch: [147][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.7548 (2.3158)	Acc@1 49.219 (57.793)	Acc@5 75.781 (85.725)
Epoch: [147][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3054 (2.3108)	Acc@1 55.469 (57.958)	Acc@5 85.156 (85.800)
Epoch: [147][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.6157 (2.3196)	Acc@1 50.000 (57.681)	Acc@5 80.469 (85.659)
Epoch: [147][110/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 2.2220 (2.3276)	Acc@1 60.156 (57.545)	Acc@5 86.719 (85.550)
Epoch: [147][120/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 2.6101 (2.3286)	Acc@1 50.781 (57.619)	Acc@5 83.594 (85.421)
Epoch: [147][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3699 (2.3273)	Acc@1 55.469 (57.544)	Acc@5 82.031 (85.389)
Epoch: [147][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3443 (2.3332)	Acc@1 59.375 (57.353)	Acc@5 86.719 (85.334)
Epoch: [147][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3880 (2.3329)	Acc@1 56.250 (57.481)	Acc@5 82.812 (85.389)
Epoch: [147][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3046 (2.3335)	Acc@1 58.594 (57.434)	Acc@5 85.156 (85.355)
Epoch: [147][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5085 (2.3337)	Acc@1 51.562 (57.488)	Acc@5 83.594 (85.298)
Epoch: [147][180/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5725 (2.3333)	Acc@1 50.781 (57.402)	Acc@5 81.250 (85.350)
Epoch: [147][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4982 (2.3336)	Acc@1 53.906 (57.358)	Acc@5 83.594 (85.443)
Epoch: [147][200/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.6579 (2.3374)	Acc@1 49.219 (57.276)	Acc@5 80.469 (85.413)
Epoch: [147][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6018 (2.3405)	Acc@1 50.781 (57.242)	Acc@5 76.562 (85.315)
Epoch: [147][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5128 (2.3456)	Acc@1 52.344 (57.098)	Acc@5 81.250 (85.262)
Epoch: [147][230/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4243 (2.3469)	Acc@1 52.344 (57.018)	Acc@5 86.719 (85.275)
Epoch: [147][240/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3252 (2.3490)	Acc@1 55.469 (56.976)	Acc@5 84.375 (85.266)
Epoch: [147][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4901 (2.3530)	Acc@1 53.906 (56.876)	Acc@5 82.031 (85.166)
Epoch: [147][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5997 (2.3574)	Acc@1 54.688 (56.771)	Acc@5 81.250 (85.111)
Epoch: [147][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3103 (2.3613)	Acc@1 55.469 (56.680)	Acc@5 89.844 (85.073)
Epoch: [147][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6208 (2.3640)	Acc@1 50.781 (56.586)	Acc@5 82.031 (85.065)
Epoch: [147][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3167 (2.3663)	Acc@1 57.031 (56.446)	Acc@5 86.719 (85.025)
Epoch: [147][300/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.6452 (2.3709)	Acc@1 54.688 (56.330)	Acc@5 79.688 (84.938)
Epoch: [147][310/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3728 (2.3747)	Acc@1 57.031 (56.202)	Acc@5 87.500 (84.887)
Epoch: [147][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2690 (2.3778)	Acc@1 60.156 (56.148)	Acc@5 86.719 (84.869)
Epoch: [147][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4790 (2.3798)	Acc@1 53.906 (56.049)	Acc@5 85.156 (84.845)
Epoch: [147][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5378 (2.3818)	Acc@1 50.000 (55.993)	Acc@5 82.812 (84.801)
Epoch: [147][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4592 (2.3822)	Acc@1 53.906 (56.045)	Acc@5 85.938 (84.800)
Epoch: [147][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5396 (2.3863)	Acc@1 52.344 (55.949)	Acc@5 85.938 (84.754)
Epoch: [147][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3098 (2.3881)	Acc@1 56.250 (55.924)	Acc@5 85.938 (84.716)
Epoch: [147][380/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6047 (2.3893)	Acc@1 50.000 (55.887)	Acc@5 78.906 (84.674)
Epoch: [147][390/391]	Time 0.019 (0.014)	Data 0.001 (0.002)	Loss 2.2723 (2.3898)	Acc@1 60.000 (55.884)	Acc@5 86.250 (84.672)
num momentum params: 26
[0.1, 2.389785671157837, 2.1040854048728943, 55.884, 46.09, tensor(0.3316, device='cuda:0', grad_fn=<DivBackward0>), 5.318122863769531, 0.39913225173950195]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [148 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [148][0/391]	Time 0.066 (0.066)	Data 0.175 (0.175)	Loss 2.3941 (2.3941)	Acc@1 57.812 (57.812)	Acc@5 85.156 (85.156)
Epoch: [148][10/391]	Time 0.015 (0.021)	Data 0.001 (0.017)	Loss 2.3400 (2.2505)	Acc@1 57.812 (59.446)	Acc@5 83.594 (86.435)
Epoch: [148][20/391]	Time 0.014 (0.018)	Data 0.001 (0.010)	Loss 2.2254 (2.2520)	Acc@1 63.281 (59.189)	Acc@5 85.156 (86.607)
Epoch: [148][30/391]	Time 0.013 (0.016)	Data 0.001 (0.007)	Loss 2.1798 (2.2493)	Acc@1 54.688 (58.619)	Acc@5 91.406 (86.920)
Epoch: [148][40/391]	Time 0.013 (0.016)	Data 0.001 (0.006)	Loss 2.2637 (2.2468)	Acc@1 60.938 (58.746)	Acc@5 85.156 (87.005)
Epoch: [148][50/391]	Time 0.014 (0.015)	Data 0.000 (0.005)	Loss 2.3285 (2.2674)	Acc@1 50.781 (58.195)	Acc@5 89.844 (86.749)
Epoch: [148][60/391]	Time 0.015 (0.015)	Data 0.001 (0.004)	Loss 2.2939 (2.2937)	Acc@1 57.031 (57.787)	Acc@5 85.156 (86.322)
Epoch: [148][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.5259 (2.3090)	Acc@1 50.000 (57.438)	Acc@5 83.594 (86.092)
Epoch: [148][80/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 2.5509 (2.3198)	Acc@1 53.906 (57.272)	Acc@5 79.688 (85.851)
Epoch: [148][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2127 (2.3219)	Acc@1 55.469 (57.091)	Acc@5 90.625 (85.834)
Epoch: [148][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3676 (2.3208)	Acc@1 53.906 (56.985)	Acc@5 85.938 (85.914)
Epoch: [148][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3589 (2.3309)	Acc@1 59.375 (56.890)	Acc@5 84.375 (85.818)
Epoch: [148][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2336 (2.3359)	Acc@1 64.844 (56.960)	Acc@5 86.719 (85.744)
Epoch: [148][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3518 (2.3356)	Acc@1 56.250 (56.930)	Acc@5 85.156 (85.729)
Epoch: [148][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5676 (2.3361)	Acc@1 55.469 (56.954)	Acc@5 79.688 (85.749)
Epoch: [148][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.4526 (2.3323)	Acc@1 53.906 (57.005)	Acc@5 83.594 (85.844)
Epoch: [148][160/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.3871 (2.3348)	Acc@1 50.000 (56.944)	Acc@5 87.500 (85.753)
Epoch: [148][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5318 (2.3408)	Acc@1 53.125 (56.803)	Acc@5 80.469 (85.590)
Epoch: [148][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.8850 (2.3503)	Acc@1 44.531 (56.578)	Acc@5 72.656 (85.359)
Epoch: [148][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2974 (2.3578)	Acc@1 60.938 (56.442)	Acc@5 83.594 (85.226)
Epoch: [148][200/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4412 (2.3600)	Acc@1 52.344 (56.359)	Acc@5 82.031 (85.113)
Epoch: [148][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5078 (2.3660)	Acc@1 50.781 (56.243)	Acc@5 80.469 (85.038)
Epoch: [148][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5743 (2.3676)	Acc@1 53.906 (56.229)	Acc@5 79.688 (84.997)
Epoch: [148][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4848 (2.3684)	Acc@1 56.250 (56.270)	Acc@5 83.594 (84.984)
Epoch: [148][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3614 (2.3675)	Acc@1 54.688 (56.312)	Acc@5 87.500 (85.004)
Epoch: [148][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4846 (2.3708)	Acc@1 58.594 (56.378)	Acc@5 83.594 (84.948)
Epoch: [148][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4058 (2.3723)	Acc@1 55.469 (56.358)	Acc@5 89.844 (85.004)
Epoch: [148][270/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3972 (2.3743)	Acc@1 49.219 (56.262)	Acc@5 85.156 (84.952)
Epoch: [148][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5477 (2.3769)	Acc@1 54.688 (56.208)	Acc@5 80.469 (84.864)
Epoch: [148][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4262 (2.3779)	Acc@1 55.469 (56.159)	Acc@5 81.250 (84.839)
Epoch: [148][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3542 (2.3770)	Acc@1 54.688 (56.193)	Acc@5 85.938 (84.884)
Epoch: [148][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4040 (2.3797)	Acc@1 55.469 (56.104)	Acc@5 82.812 (84.817)
Epoch: [148][320/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.4066 (2.3785)	Acc@1 57.031 (56.085)	Acc@5 83.594 (84.840)
Epoch: [148][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4966 (2.3792)	Acc@1 52.344 (56.047)	Acc@5 83.594 (84.842)
Epoch: [148][340/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.5605 (2.3817)	Acc@1 53.125 (55.970)	Acc@5 78.906 (84.794)
Epoch: [148][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3413 (2.3838)	Acc@1 57.031 (55.916)	Acc@5 90.625 (84.753)
Epoch: [148][360/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.4594 (2.3849)	Acc@1 55.469 (55.925)	Acc@5 84.375 (84.700)
Epoch: [148][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6737 (2.3891)	Acc@1 54.688 (55.844)	Acc@5 77.344 (84.663)
Epoch: [148][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.7308 (2.3902)	Acc@1 46.875 (55.793)	Acc@5 78.906 (84.660)
Epoch: [148][390/391]	Time 0.019 (0.014)	Data 0.001 (0.002)	Loss 2.4652 (2.3927)	Acc@1 55.000 (55.762)	Acc@5 83.750 (84.592)
num momentum params: 26
[0.1, 2.392674791641235, 2.1409784007072448, 55.762, 45.79, tensor(0.3312, device='cuda:0', grad_fn=<DivBackward0>), 5.352416753768921, 0.40673184394836426]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [149 | 180] LR: 0.100000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [149][0/391]	Time 0.068 (0.068)	Data 0.172 (0.172)	Loss 2.3832 (2.3832)	Acc@1 53.125 (53.125)	Acc@5 82.812 (82.812)
Epoch: [149][10/391]	Time 0.014 (0.021)	Data 0.001 (0.017)	Loss 2.2695 (2.4199)	Acc@1 60.938 (56.179)	Acc@5 84.375 (83.381)
Epoch: [149][20/391]	Time 0.013 (0.018)	Data 0.001 (0.010)	Loss 2.2339 (2.3560)	Acc@1 58.594 (56.957)	Acc@5 85.156 (84.524)
Epoch: [149][30/391]	Time 0.014 (0.016)	Data 0.001 (0.007)	Loss 2.3698 (2.3111)	Acc@1 53.906 (57.661)	Acc@5 83.594 (85.383)
Epoch: [149][40/391]	Time 0.014 (0.016)	Data 0.001 (0.006)	Loss 2.1999 (2.3177)	Acc@1 62.500 (57.641)	Acc@5 85.938 (85.328)
Epoch: [149][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 2.4061 (2.3243)	Acc@1 55.469 (57.506)	Acc@5 83.594 (85.340)
Epoch: [149][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.4931 (2.3410)	Acc@1 51.562 (57.147)	Acc@5 84.375 (85.028)
Epoch: [149][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.3091 (2.3422)	Acc@1 60.938 (57.075)	Acc@5 85.156 (85.101)
Epoch: [149][80/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.1462 (2.3386)	Acc@1 60.156 (57.205)	Acc@5 88.281 (85.176)
Epoch: [149][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5451 (2.3476)	Acc@1 49.219 (57.005)	Acc@5 85.156 (85.010)
Epoch: [149][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.3051 (2.3476)	Acc@1 58.594 (56.892)	Acc@5 83.594 (85.032)
Epoch: [149][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.3827 (2.3514)	Acc@1 59.375 (56.806)	Acc@5 85.156 (84.952)
Epoch: [149][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.5733 (2.3624)	Acc@1 51.562 (56.547)	Acc@5 83.594 (84.775)
Epoch: [149][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.2691 (2.3619)	Acc@1 57.812 (56.399)	Acc@5 87.500 (84.834)
Epoch: [149][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.1608 (2.3601)	Acc@1 63.281 (56.494)	Acc@5 85.938 (84.874)
Epoch: [149][150/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 2.4262 (2.3669)	Acc@1 59.375 (56.359)	Acc@5 78.125 (84.753)
Epoch: [149][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3140 (2.3736)	Acc@1 57.812 (56.260)	Acc@5 85.938 (84.622)
Epoch: [149][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4576 (2.3726)	Acc@1 52.344 (56.287)	Acc@5 85.156 (84.681)
Epoch: [149][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3071 (2.3739)	Acc@1 57.031 (56.319)	Acc@5 85.156 (84.694)
Epoch: [149][190/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.3531 (2.3753)	Acc@1 55.469 (56.197)	Acc@5 81.250 (84.670)
Epoch: [149][200/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 2.4957 (2.3759)	Acc@1 53.906 (56.316)	Acc@5 82.812 (84.670)
Epoch: [149][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6845 (2.3747)	Acc@1 46.094 (56.324)	Acc@5 83.594 (84.701)
Epoch: [149][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3371 (2.3764)	Acc@1 54.688 (56.275)	Acc@5 89.062 (84.693)
Epoch: [149][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2487 (2.3763)	Acc@1 58.594 (56.277)	Acc@5 86.719 (84.690)
Epoch: [149][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2152 (2.3756)	Acc@1 60.156 (56.295)	Acc@5 87.500 (84.712)
Epoch: [149][250/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3859 (2.3763)	Acc@1 52.344 (56.269)	Acc@5 82.812 (84.705)
Epoch: [149][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3648 (2.3761)	Acc@1 52.344 (56.295)	Acc@5 87.500 (84.725)
Epoch: [149][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6072 (2.3806)	Acc@1 50.781 (56.207)	Acc@5 83.594 (84.655)
Epoch: [149][280/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 2.6414 (2.3799)	Acc@1 56.250 (56.228)	Acc@5 80.469 (84.650)
Epoch: [149][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.1406 (2.3800)	Acc@1 66.406 (56.212)	Acc@5 89.062 (84.635)
Epoch: [149][300/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3607 (2.3827)	Acc@1 57.031 (56.164)	Acc@5 88.281 (84.650)
Epoch: [149][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5336 (2.3813)	Acc@1 53.125 (56.172)	Acc@5 78.906 (84.712)
Epoch: [149][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.6648 (2.3837)	Acc@1 48.438 (56.102)	Acc@5 78.906 (84.708)
Epoch: [149][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.5735 (2.3853)	Acc@1 48.438 (56.071)	Acc@5 83.594 (84.677)
Epoch: [149][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.3123 (2.3875)	Acc@1 57.812 (56.025)	Acc@5 86.719 (84.629)
Epoch: [149][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.2696 (2.3890)	Acc@1 60.156 (55.994)	Acc@5 87.500 (84.586)
Epoch: [149][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4891 (2.3885)	Acc@1 53.125 (56.021)	Acc@5 83.594 (84.615)
Epoch: [149][370/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 2.3013 (2.3886)	Acc@1 57.031 (55.978)	Acc@5 88.281 (84.642)
Epoch: [149][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 2.4922 (2.3884)	Acc@1 55.469 (55.967)	Acc@5 85.938 (84.658)
Epoch: [149][390/391]	Time 0.020 (0.014)	Data 0.001 (0.002)	Loss 2.8557 (2.3905)	Acc@1 42.500 (55.882)	Acc@5 77.500 (84.616)
num momentum params: 26
[0.1, 2.3904526012420653, 1.8727656614780426, 55.882, 50.03, tensor(0.3322, device='cuda:0', grad_fn=<DivBackward0>), 5.340321779251099, 0.42253994941711426]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [150 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [150][0/391]	Time 0.071 (0.071)	Data 0.189 (0.189)	Loss 2.3600 (2.3600)	Acc@1 58.594 (58.594)	Acc@5 88.281 (88.281)
Epoch: [150][10/391]	Time 0.016 (0.022)	Data 0.002 (0.018)	Loss 2.1069 (2.2616)	Acc@1 62.500 (59.730)	Acc@5 89.844 (86.648)
Epoch: [150][20/391]	Time 0.014 (0.018)	Data 0.001 (0.010)	Loss 2.2160 (2.2283)	Acc@1 57.812 (60.305)	Acc@5 88.281 (87.016)
Epoch: [150][30/391]	Time 0.014 (0.017)	Data 0.001 (0.007)	Loss 2.4102 (2.1817)	Acc@1 53.906 (61.290)	Acc@5 82.812 (87.651)
Epoch: [150][40/391]	Time 0.013 (0.016)	Data 0.002 (0.006)	Loss 2.0723 (2.1405)	Acc@1 67.969 (62.557)	Acc@5 85.156 (88.205)
Epoch: [150][50/391]	Time 0.013 (0.015)	Data 0.002 (0.005)	Loss 2.0417 (2.1060)	Acc@1 65.625 (63.220)	Acc@5 87.500 (88.787)
Epoch: [150][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.8441 (2.0733)	Acc@1 69.531 (64.062)	Acc@5 92.188 (89.075)
Epoch: [150][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 2.0418 (2.0640)	Acc@1 64.062 (64.151)	Acc@5 88.281 (89.173)
Epoch: [150][80/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 1.9254 (2.0461)	Acc@1 69.531 (64.651)	Acc@5 91.406 (89.419)
Epoch: [150][90/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 1.8932 (2.0318)	Acc@1 64.844 (65.007)	Acc@5 92.969 (89.595)
Epoch: [150][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.0083 (2.0207)	Acc@1 67.188 (65.246)	Acc@5 91.406 (89.743)
Epoch: [150][110/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 1.8415 (2.0042)	Acc@1 71.094 (65.681)	Acc@5 95.312 (90.097)
Epoch: [150][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.8044 (1.9979)	Acc@1 74.219 (65.851)	Acc@5 94.531 (90.199)
Epoch: [150][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.9624 (1.9903)	Acc@1 67.188 (65.846)	Acc@5 89.844 (90.339)
Epoch: [150][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.9887 (1.9817)	Acc@1 65.625 (66.063)	Acc@5 88.281 (90.414)
Epoch: [150][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.7861 (1.9717)	Acc@1 70.312 (66.349)	Acc@5 90.625 (90.527)
Epoch: [150][160/391]	Time 0.016 (0.014)	Data 0.001 (0.003)	Loss 1.6367 (1.9613)	Acc@1 75.781 (66.586)	Acc@5 91.406 (90.678)
Epoch: [150][170/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 2.0837 (1.9567)	Acc@1 61.719 (66.699)	Acc@5 87.500 (90.735)
Epoch: [150][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.8657 (1.9453)	Acc@1 65.625 (67.101)	Acc@5 91.406 (90.845)
Epoch: [150][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.7940 (1.9384)	Acc@1 71.875 (67.286)	Acc@5 92.969 (90.928)
Epoch: [150][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.8713 (1.9355)	Acc@1 67.969 (67.355)	Acc@5 93.750 (90.971)
Epoch: [150][210/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.9500 (1.9274)	Acc@1 67.188 (67.543)	Acc@5 91.406 (91.103)
Epoch: [150][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.6711 (1.9225)	Acc@1 74.219 (67.619)	Acc@5 92.188 (91.145)
Epoch: [150][230/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 1.8197 (1.9191)	Acc@1 71.875 (67.718)	Acc@5 93.750 (91.173)
Epoch: [150][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.7669 (1.9134)	Acc@1 71.094 (67.849)	Acc@5 89.844 (91.234)
Epoch: [150][250/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 1.8518 (1.9067)	Acc@1 66.406 (67.991)	Acc@5 91.406 (91.332)
Epoch: [150][260/391]	Time 0.011 (0.014)	Data 0.003 (0.002)	Loss 1.7647 (1.9005)	Acc@1 70.312 (68.115)	Acc@5 92.969 (91.409)
Epoch: [150][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.6607 (1.8951)	Acc@1 75.000 (68.286)	Acc@5 92.188 (91.421)
Epoch: [150][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.6426 (1.8903)	Acc@1 74.219 (68.322)	Acc@5 94.531 (91.495)
Epoch: [150][290/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 1.5980 (1.8839)	Acc@1 76.562 (68.444)	Acc@5 94.531 (91.589)
Epoch: [150][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.8608 (1.8797)	Acc@1 69.531 (68.540)	Acc@5 92.969 (91.658)
Epoch: [150][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5745 (1.8758)	Acc@1 79.688 (68.622)	Acc@5 93.750 (91.688)
Epoch: [150][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.8883 (1.8718)	Acc@1 68.750 (68.709)	Acc@5 89.844 (91.752)
Epoch: [150][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.8267 (1.8680)	Acc@1 69.531 (68.811)	Acc@5 92.969 (91.786)
Epoch: [150][340/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 1.6139 (1.8636)	Acc@1 73.438 (68.913)	Acc@5 93.750 (91.835)
Epoch: [150][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.8420 (1.8610)	Acc@1 67.188 (68.977)	Acc@5 91.406 (91.867)
Epoch: [150][360/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 1.6739 (1.8585)	Acc@1 72.656 (69.012)	Acc@5 92.969 (91.902)
Epoch: [150][370/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 1.7365 (1.8532)	Acc@1 76.562 (69.203)	Acc@5 89.844 (91.928)
Epoch: [150][380/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.7762 (1.8513)	Acc@1 74.219 (69.263)	Acc@5 92.188 (91.954)
Epoch: [150][390/391]	Time 0.019 (0.014)	Data 0.001 (0.002)	Loss 2.0381 (1.8493)	Acc@1 66.250 (69.288)	Acc@5 88.750 (91.958)
num momentum params: 26
[0.010000000000000002, 1.8493345607757568, 1.2212896782159806, 69.288, 65.61, tensor(0.4258, device='cuda:0', grad_fn=<DivBackward0>), 5.36261773109436, 0.4111964702606202]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [151 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [151][0/391]	Time 0.078 (0.078)	Data 0.178 (0.178)	Loss 1.8259 (1.8259)	Acc@1 68.750 (68.750)	Acc@5 93.750 (93.750)
Epoch: [151][10/391]	Time 0.013 (0.022)	Data 0.001 (0.017)	Loss 1.5509 (1.6955)	Acc@1 74.219 (73.224)	Acc@5 96.875 (93.892)
Epoch: [151][20/391]	Time 0.014 (0.018)	Data 0.001 (0.010)	Loss 1.7367 (1.6778)	Acc@1 71.875 (73.251)	Acc@5 94.531 (94.122)
Epoch: [151][30/391]	Time 0.014 (0.017)	Data 0.001 (0.007)	Loss 1.8174 (1.6680)	Acc@1 73.438 (73.690)	Acc@5 91.406 (94.204)
Epoch: [151][40/391]	Time 0.013 (0.016)	Data 0.001 (0.006)	Loss 1.7823 (1.6821)	Acc@1 69.531 (73.342)	Acc@5 94.531 (93.883)
Epoch: [151][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 1.7841 (1.6908)	Acc@1 69.531 (73.131)	Acc@5 89.062 (93.735)
Epoch: [151][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.7399 (1.6882)	Acc@1 72.656 (73.066)	Acc@5 92.969 (93.673)
Epoch: [151][70/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 1.4841 (1.6872)	Acc@1 78.125 (72.898)	Acc@5 96.875 (93.772)
Epoch: [151][80/391]	Time 0.012 (0.015)	Data 0.001 (0.004)	Loss 1.6987 (1.6840)	Acc@1 73.438 (73.061)	Acc@5 93.750 (93.682)
Epoch: [151][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.6066 (1.6813)	Acc@1 71.875 (73.137)	Acc@5 95.312 (93.690)
Epoch: [151][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.8292 (1.6772)	Acc@1 71.875 (73.352)	Acc@5 90.625 (93.704)
Epoch: [151][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.7091 (1.6714)	Acc@1 68.750 (73.395)	Acc@5 93.750 (93.785)
Epoch: [151][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.5902 (1.6696)	Acc@1 78.125 (73.483)	Acc@5 95.312 (93.750)
Epoch: [151][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.6944 (1.6736)	Acc@1 72.656 (73.360)	Acc@5 92.188 (93.684)
Epoch: [151][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.7874 (1.6720)	Acc@1 70.312 (73.438)	Acc@5 90.625 (93.684)
Epoch: [151][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.7266 (1.6713)	Acc@1 72.656 (73.417)	Acc@5 92.188 (93.734)
Epoch: [151][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.8119 (1.6714)	Acc@1 67.969 (73.428)	Acc@5 92.188 (93.750)
Epoch: [151][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.6097 (1.6713)	Acc@1 75.781 (73.364)	Acc@5 92.969 (93.791)
Epoch: [151][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.6333 (1.6690)	Acc@1 73.438 (73.433)	Acc@5 93.750 (93.776)
Epoch: [151][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5846 (1.6679)	Acc@1 75.781 (73.487)	Acc@5 92.969 (93.770)
Epoch: [151][200/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 1.6599 (1.6681)	Acc@1 76.562 (73.519)	Acc@5 93.750 (93.734)
Epoch: [151][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.7737 (1.6683)	Acc@1 69.531 (73.456)	Acc@5 95.312 (93.735)
Epoch: [151][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5318 (1.6688)	Acc@1 74.219 (73.430)	Acc@5 96.875 (93.739)
Epoch: [151][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5472 (1.6668)	Acc@1 75.781 (73.488)	Acc@5 96.094 (93.807)
Epoch: [151][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5509 (1.6639)	Acc@1 75.781 (73.541)	Acc@5 95.312 (93.857)
Epoch: [151][250/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.4437 (1.6607)	Acc@1 79.688 (73.662)	Acc@5 96.875 (93.909)
Epoch: [151][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.8548 (1.6607)	Acc@1 64.844 (73.647)	Acc@5 92.969 (93.912)
Epoch: [151][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4597 (1.6589)	Acc@1 78.125 (73.688)	Acc@5 96.875 (93.935)
Epoch: [151][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5928 (1.6586)	Acc@1 74.219 (73.693)	Acc@5 94.531 (93.981)
Epoch: [151][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.7144 (1.6589)	Acc@1 75.000 (73.698)	Acc@5 94.531 (93.992)
Epoch: [151][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5590 (1.6579)	Acc@1 78.125 (73.692)	Acc@5 93.750 (94.017)
Epoch: [151][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.7569 (1.6553)	Acc@1 71.875 (73.739)	Acc@5 94.531 (94.036)
Epoch: [151][320/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.7547 (1.6548)	Acc@1 72.656 (73.766)	Acc@5 91.406 (94.006)
Epoch: [151][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3501 (1.6532)	Acc@1 79.688 (73.810)	Acc@5 98.438 (94.017)
Epoch: [151][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4794 (1.6528)	Acc@1 84.375 (73.829)	Acc@5 93.750 (94.032)
Epoch: [151][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.7821 (1.6534)	Acc@1 70.312 (73.787)	Acc@5 93.750 (94.024)
Epoch: [151][360/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.4583 (1.6508)	Acc@1 74.219 (73.810)	Acc@5 96.094 (94.055)
Epoch: [151][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.7360 (1.6517)	Acc@1 68.750 (73.772)	Acc@5 92.969 (94.047)
Epoch: [151][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.7060 (1.6497)	Acc@1 72.656 (73.831)	Acc@5 92.969 (94.062)
Epoch: [151][390/391]	Time 0.018 (0.014)	Data 0.001 (0.002)	Loss 1.5274 (1.6486)	Acc@1 76.250 (73.852)	Acc@5 96.250 (94.070)
num momentum params: 26
[0.010000000000000002, 1.6485998136138915, 1.1848109328746796, 73.852, 66.66, tensor(0.4636, device='cuda:0', grad_fn=<DivBackward0>), 5.302396774291992, 0.41370439529418945]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [152 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [152][0/391]	Time 0.070 (0.070)	Data 0.176 (0.176)	Loss 1.5244 (1.5244)	Acc@1 81.250 (81.250)	Acc@5 95.312 (95.312)
Epoch: [152][10/391]	Time 0.013 (0.021)	Data 0.001 (0.017)	Loss 1.6534 (1.5858)	Acc@1 72.656 (75.497)	Acc@5 94.531 (94.815)
Epoch: [152][20/391]	Time 0.010 (0.018)	Data 0.004 (0.010)	Loss 1.6213 (1.5646)	Acc@1 73.438 (75.893)	Acc@5 93.750 (94.940)
Epoch: [152][30/391]	Time 0.013 (0.016)	Data 0.001 (0.007)	Loss 1.7133 (1.5732)	Acc@1 75.000 (75.756)	Acc@5 95.312 (94.884)
Epoch: [152][40/391]	Time 0.013 (0.016)	Data 0.001 (0.006)	Loss 1.5861 (1.5525)	Acc@1 74.219 (76.296)	Acc@5 95.312 (95.312)
Epoch: [152][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 1.6692 (1.5522)	Acc@1 73.438 (76.210)	Acc@5 94.531 (95.358)
Epoch: [152][60/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 1.4911 (1.5458)	Acc@1 79.688 (76.306)	Acc@5 92.969 (95.300)
Epoch: [152][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.6370 (1.5498)	Acc@1 72.656 (76.177)	Acc@5 94.531 (95.213)
Epoch: [152][80/391]	Time 0.013 (0.014)	Data 0.001 (0.004)	Loss 1.6267 (1.5479)	Acc@1 74.219 (76.273)	Acc@5 95.312 (95.197)
Epoch: [152][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.5408 (1.5478)	Acc@1 73.438 (76.219)	Acc@5 97.656 (95.192)
Epoch: [152][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.5596 (1.5459)	Acc@1 79.688 (76.377)	Acc@5 93.750 (95.212)
Epoch: [152][110/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 1.5422 (1.5448)	Acc@1 72.656 (76.443)	Acc@5 96.875 (95.186)
Epoch: [152][120/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 1.6502 (1.5457)	Acc@1 77.344 (76.408)	Acc@5 92.188 (95.132)
Epoch: [152][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.7307 (1.5456)	Acc@1 72.656 (76.497)	Acc@5 92.969 (95.122)
Epoch: [152][140/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 1.6659 (1.5480)	Acc@1 70.312 (76.380)	Acc@5 91.406 (95.069)
Epoch: [152][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.5265 (1.5516)	Acc@1 76.562 (76.288)	Acc@5 94.531 (95.002)
Epoch: [152][160/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.6554 (1.5532)	Acc@1 74.219 (76.189)	Acc@5 93.750 (95.060)
Epoch: [152][170/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 1.4141 (1.5503)	Acc@1 80.469 (76.284)	Acc@5 96.875 (95.052)
Epoch: [152][180/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.5163 (1.5468)	Acc@1 74.219 (76.308)	Acc@5 96.875 (95.088)
Epoch: [152][190/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 1.5289 (1.5469)	Acc@1 79.688 (76.260)	Acc@5 95.312 (95.124)
Epoch: [152][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3749 (1.5466)	Acc@1 79.688 (76.213)	Acc@5 97.656 (95.130)
Epoch: [152][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5106 (1.5498)	Acc@1 78.906 (76.159)	Acc@5 95.312 (95.068)
Epoch: [152][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4935 (1.5486)	Acc@1 76.562 (76.167)	Acc@5 97.656 (95.097)
Epoch: [152][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5968 (1.5492)	Acc@1 76.562 (76.187)	Acc@5 92.969 (95.083)
Epoch: [152][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4999 (1.5488)	Acc@1 74.219 (76.170)	Acc@5 92.969 (95.102)
Epoch: [152][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5736 (1.5474)	Acc@1 69.531 (76.205)	Acc@5 96.094 (95.123)
Epoch: [152][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4212 (1.5443)	Acc@1 81.250 (76.281)	Acc@5 92.969 (95.163)
Epoch: [152][270/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.4969 (1.5436)	Acc@1 76.562 (76.283)	Acc@5 94.531 (95.194)
Epoch: [152][280/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 1.6233 (1.5459)	Acc@1 71.094 (76.187)	Acc@5 92.188 (95.123)
Epoch: [152][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5034 (1.5468)	Acc@1 74.219 (76.106)	Acc@5 94.531 (95.114)
Epoch: [152][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4108 (1.5467)	Acc@1 78.906 (76.085)	Acc@5 98.438 (95.107)
Epoch: [152][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4378 (1.5481)	Acc@1 81.250 (76.060)	Acc@5 98.438 (95.096)
Epoch: [152][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.6649 (1.5487)	Acc@1 75.000 (76.073)	Acc@5 93.750 (95.081)
Epoch: [152][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5539 (1.5507)	Acc@1 78.906 (76.074)	Acc@5 95.312 (95.036)
Epoch: [152][340/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 1.5642 (1.5501)	Acc@1 73.438 (76.058)	Acc@5 95.312 (95.063)
Epoch: [152][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5650 (1.5494)	Acc@1 76.562 (76.086)	Acc@5 94.531 (95.072)
Epoch: [152][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.7543 (1.5514)	Acc@1 70.312 (76.030)	Acc@5 87.500 (95.053)
Epoch: [152][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5621 (1.5512)	Acc@1 74.219 (76.034)	Acc@5 94.531 (95.043)
Epoch: [152][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4138 (1.5492)	Acc@1 77.344 (76.060)	Acc@5 96.875 (95.052)
Epoch: [152][390/391]	Time 0.019 (0.014)	Data 0.001 (0.002)	Loss 1.4937 (1.5471)	Acc@1 80.000 (76.098)	Acc@5 92.500 (95.082)
num momentum params: 26
[0.010000000000000002, 1.547099939956665, 1.1681780606508254, 76.098, 67.27, tensor(0.4817, device='cuda:0', grad_fn=<DivBackward0>), 5.308436870574951, 0.40738654136657715]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [153 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [153][0/391]	Time 0.077 (0.077)	Data 0.174 (0.174)	Loss 1.4825 (1.4825)	Acc@1 76.562 (76.562)	Acc@5 96.875 (96.875)
Epoch: [153][10/391]	Time 0.014 (0.022)	Data 0.001 (0.017)	Loss 1.4539 (1.4826)	Acc@1 77.344 (76.989)	Acc@5 96.094 (95.668)
Epoch: [153][20/391]	Time 0.017 (0.018)	Data 0.001 (0.010)	Loss 1.6988 (1.4948)	Acc@1 71.875 (76.600)	Acc@5 93.750 (95.499)
Epoch: [153][30/391]	Time 0.013 (0.017)	Data 0.001 (0.007)	Loss 1.4911 (1.4882)	Acc@1 76.562 (76.991)	Acc@5 95.312 (95.565)
Epoch: [153][40/391]	Time 0.013 (0.016)	Data 0.001 (0.006)	Loss 1.6244 (1.4943)	Acc@1 74.219 (77.287)	Acc@5 94.531 (95.408)
Epoch: [153][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 1.5155 (1.4860)	Acc@1 79.688 (77.497)	Acc@5 97.656 (95.573)
Epoch: [153][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.5091 (1.4876)	Acc@1 78.125 (77.485)	Acc@5 95.312 (95.530)
Epoch: [153][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.4991 (1.4791)	Acc@1 76.562 (77.773)	Acc@5 96.094 (95.621)
Epoch: [153][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.5542 (1.4778)	Acc@1 80.469 (77.797)	Acc@5 92.188 (95.592)
Epoch: [153][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.6334 (1.4811)	Acc@1 72.656 (77.558)	Acc@5 94.531 (95.553)
Epoch: [153][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.3614 (1.4798)	Acc@1 83.594 (77.638)	Acc@5 96.875 (95.568)
Epoch: [153][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.5266 (1.4789)	Acc@1 74.219 (77.660)	Acc@5 96.875 (95.573)
Epoch: [153][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.5628 (1.4837)	Acc@1 77.344 (77.486)	Acc@5 93.750 (95.513)
Epoch: [153][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.4060 (1.4847)	Acc@1 78.906 (77.511)	Acc@5 97.656 (95.521)
Epoch: [153][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.3962 (1.4832)	Acc@1 80.469 (77.565)	Acc@5 96.094 (95.484)
Epoch: [153][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.6236 (1.4827)	Acc@1 73.438 (77.540)	Acc@5 95.312 (95.499)
Epoch: [153][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4778 (1.4826)	Acc@1 75.781 (77.523)	Acc@5 96.875 (95.516)
Epoch: [153][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2605 (1.4805)	Acc@1 84.375 (77.600)	Acc@5 97.656 (95.514)
Epoch: [153][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5651 (1.4816)	Acc@1 72.656 (77.577)	Acc@5 95.312 (95.502)
Epoch: [153][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4345 (1.4793)	Acc@1 78.906 (77.634)	Acc@5 94.531 (95.529)
Epoch: [153][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5284 (1.4803)	Acc@1 75.000 (77.565)	Acc@5 98.438 (95.530)
Epoch: [153][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4388 (1.4811)	Acc@1 75.000 (77.559)	Acc@5 99.219 (95.542)
Epoch: [153][220/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.5412 (1.4812)	Acc@1 77.344 (77.549)	Acc@5 96.094 (95.528)
Epoch: [153][230/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 1.5922 (1.4803)	Acc@1 76.562 (77.604)	Acc@5 94.531 (95.559)
Epoch: [153][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5325 (1.4791)	Acc@1 78.125 (77.597)	Acc@5 94.531 (95.601)
Epoch: [153][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.6369 (1.4788)	Acc@1 74.219 (77.590)	Acc@5 92.188 (95.602)
Epoch: [153][260/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 1.4973 (1.4770)	Acc@1 79.688 (77.652)	Acc@5 94.531 (95.609)
Epoch: [153][270/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 1.4598 (1.4756)	Acc@1 75.000 (77.675)	Acc@5 94.531 (95.592)
Epoch: [153][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3839 (1.4752)	Acc@1 79.688 (77.672)	Acc@5 93.750 (95.554)
Epoch: [153][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5587 (1.4773)	Acc@1 77.344 (77.652)	Acc@5 92.969 (95.527)
Epoch: [153][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4566 (1.4782)	Acc@1 78.906 (77.598)	Acc@5 96.875 (95.531)
Epoch: [153][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.6285 (1.4780)	Acc@1 71.094 (77.580)	Acc@5 95.312 (95.516)
Epoch: [153][320/391]	Time 0.023 (0.014)	Data 0.001 (0.002)	Loss 1.3998 (1.4772)	Acc@1 78.906 (77.602)	Acc@5 98.438 (95.524)
Epoch: [153][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.6469 (1.4771)	Acc@1 68.750 (77.618)	Acc@5 94.531 (95.532)
Epoch: [153][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5418 (1.4777)	Acc@1 72.656 (77.587)	Acc@5 96.875 (95.537)
Epoch: [153][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3907 (1.4758)	Acc@1 75.781 (77.602)	Acc@5 97.656 (95.553)
Epoch: [153][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4154 (1.4756)	Acc@1 79.688 (77.619)	Acc@5 96.094 (95.555)
Epoch: [153][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5433 (1.4744)	Acc@1 75.000 (77.615)	Acc@5 95.312 (95.582)
Epoch: [153][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4589 (1.4736)	Acc@1 80.469 (77.680)	Acc@5 93.750 (95.581)
Epoch: [153][390/391]	Time 0.019 (0.014)	Data 0.001 (0.002)	Loss 1.5418 (1.4735)	Acc@1 71.250 (77.650)	Acc@5 95.000 (95.580)
num momentum params: 26
[0.010000000000000002, 1.4735310482788087, 1.1754250770807266, 77.65, 67.16, tensor(0.4928, device='cuda:0', grad_fn=<DivBackward0>), 5.326953649520874, 0.4028902053833007]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [154 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [154][0/391]	Time 0.076 (0.076)	Data 0.179 (0.179)	Loss 1.3603 (1.3603)	Acc@1 81.250 (81.250)	Acc@5 94.531 (94.531)
Epoch: [154][10/391]	Time 0.016 (0.022)	Data 0.001 (0.018)	Loss 1.3508 (1.3795)	Acc@1 81.250 (81.108)	Acc@5 98.438 (96.236)
Epoch: [154][20/391]	Time 0.014 (0.018)	Data 0.001 (0.010)	Loss 1.4213 (1.3926)	Acc@1 78.125 (79.650)	Acc@5 98.438 (96.391)
Epoch: [154][30/391]	Time 0.013 (0.017)	Data 0.001 (0.007)	Loss 1.5623 (1.3935)	Acc@1 75.000 (79.435)	Acc@5 92.969 (96.371)
Epoch: [154][40/391]	Time 0.013 (0.016)	Data 0.001 (0.006)	Loss 1.5144 (1.3719)	Acc@1 71.875 (79.992)	Acc@5 96.094 (96.589)
Epoch: [154][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 1.4630 (1.3707)	Acc@1 76.562 (80.009)	Acc@5 94.531 (96.569)
Epoch: [154][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.3859 (1.3864)	Acc@1 80.469 (79.611)	Acc@5 94.531 (96.388)
Epoch: [154][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.3377 (1.3965)	Acc@1 79.688 (79.324)	Acc@5 97.656 (96.303)
Epoch: [154][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.3170 (1.3959)	Acc@1 83.594 (79.446)	Acc@5 96.094 (96.325)
Epoch: [154][90/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 1.4512 (1.3987)	Acc@1 75.000 (79.310)	Acc@5 97.656 (96.377)
Epoch: [154][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.3323 (1.3940)	Acc@1 79.688 (79.494)	Acc@5 96.875 (96.411)
Epoch: [154][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.3859 (1.3916)	Acc@1 81.250 (79.638)	Acc@5 95.312 (96.446)
Epoch: [154][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.4892 (1.3903)	Acc@1 75.781 (79.662)	Acc@5 92.969 (96.391)
Epoch: [154][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.3508 (1.3875)	Acc@1 77.344 (79.765)	Acc@5 99.219 (96.434)
Epoch: [154][140/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 1.2305 (1.3861)	Acc@1 83.594 (79.820)	Acc@5 97.656 (96.404)
Epoch: [154][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.4165 (1.3883)	Acc@1 77.344 (79.739)	Acc@5 95.312 (96.368)
Epoch: [154][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2713 (1.3871)	Acc@1 80.469 (79.678)	Acc@5 99.219 (96.365)
Epoch: [154][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2375 (1.3887)	Acc@1 85.156 (79.678)	Acc@5 98.438 (96.354)
Epoch: [154][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1713 (1.3879)	Acc@1 82.812 (79.709)	Acc@5 98.438 (96.353)
Epoch: [154][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4095 (1.3871)	Acc@1 77.344 (79.732)	Acc@5 97.656 (96.347)
Epoch: [154][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5252 (1.3874)	Acc@1 77.344 (79.684)	Acc@5 94.531 (96.374)
Epoch: [154][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3830 (1.3864)	Acc@1 80.469 (79.706)	Acc@5 97.656 (96.375)
Epoch: [154][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4197 (1.3862)	Acc@1 77.344 (79.723)	Acc@5 94.531 (96.369)
Epoch: [154][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4272 (1.3881)	Acc@1 78.906 (79.677)	Acc@5 96.875 (96.361)
Epoch: [154][240/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.3902 (1.3852)	Acc@1 78.125 (79.798)	Acc@5 96.094 (96.392)
Epoch: [154][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5194 (1.3865)	Acc@1 71.875 (79.759)	Acc@5 95.312 (96.383)
Epoch: [154][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3180 (1.3889)	Acc@1 81.250 (79.658)	Acc@5 96.094 (96.378)
Epoch: [154][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4970 (1.3902)	Acc@1 76.562 (79.601)	Acc@5 95.312 (96.339)
Epoch: [154][280/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.3170 (1.3908)	Acc@1 82.031 (79.579)	Acc@5 96.875 (96.333)
Epoch: [154][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4061 (1.3914)	Acc@1 76.562 (79.594)	Acc@5 95.312 (96.309)
Epoch: [154][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3370 (1.3911)	Acc@1 80.469 (79.617)	Acc@5 96.094 (96.301)
Epoch: [154][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3841 (1.3926)	Acc@1 80.469 (79.564)	Acc@5 95.312 (96.285)
Epoch: [154][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4253 (1.3955)	Acc@1 75.000 (79.430)	Acc@5 96.094 (96.259)
Epoch: [154][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5095 (1.3958)	Acc@1 76.562 (79.397)	Acc@5 94.531 (96.259)
Epoch: [154][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3712 (1.3953)	Acc@1 78.906 (79.422)	Acc@5 96.875 (96.266)
Epoch: [154][350/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.4141 (1.3948)	Acc@1 78.125 (79.447)	Acc@5 96.094 (96.265)
Epoch: [154][360/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 1.3506 (1.3967)	Acc@1 80.469 (79.395)	Acc@5 97.656 (96.243)
Epoch: [154][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2131 (1.3959)	Acc@1 83.594 (79.439)	Acc@5 96.875 (96.237)
Epoch: [154][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3907 (1.3957)	Acc@1 81.250 (79.409)	Acc@5 96.094 (96.252)
Epoch: [154][390/391]	Time 0.018 (0.014)	Data 0.001 (0.002)	Loss 1.5511 (1.3961)	Acc@1 72.500 (79.382)	Acc@5 97.500 (96.260)
num momentum params: 26
[0.010000000000000002, 1.3961441514587403, 1.188271351456642, 79.382, 66.73, tensor(0.5074, device='cuda:0', grad_fn=<DivBackward0>), 5.326246500015259, 0.4021568298339844]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [155 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [155][0/391]	Time 0.073 (0.073)	Data 0.178 (0.178)	Loss 1.3420 (1.3420)	Acc@1 75.781 (75.781)	Acc@5 97.656 (97.656)
Epoch: [155][10/391]	Time 0.015 (0.021)	Data 0.001 (0.018)	Loss 1.2498 (1.2912)	Acc@1 84.375 (81.960)	Acc@5 98.438 (97.301)
Epoch: [155][20/391]	Time 0.013 (0.018)	Data 0.001 (0.010)	Loss 1.2371 (1.3211)	Acc@1 82.812 (81.362)	Acc@5 96.875 (96.987)
Epoch: [155][30/391]	Time 0.013 (0.016)	Data 0.001 (0.007)	Loss 1.2681 (1.3283)	Acc@1 83.594 (81.502)	Acc@5 96.875 (96.850)
Epoch: [155][40/391]	Time 0.014 (0.016)	Data 0.001 (0.006)	Loss 1.3647 (1.3396)	Acc@1 79.688 (81.059)	Acc@5 94.531 (96.665)
Epoch: [155][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 1.3842 (1.3482)	Acc@1 78.906 (80.499)	Acc@5 95.312 (96.599)
Epoch: [155][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.4658 (1.3477)	Acc@1 77.344 (80.686)	Acc@5 94.531 (96.593)
Epoch: [155][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.3844 (1.3504)	Acc@1 80.469 (80.623)	Acc@5 96.094 (96.600)
Epoch: [155][80/391]	Time 0.014 (0.014)	Data 0.001 (0.004)	Loss 1.1766 (1.3417)	Acc@1 85.938 (80.864)	Acc@5 99.219 (96.779)
Epoch: [155][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.3643 (1.3422)	Acc@1 78.125 (80.769)	Acc@5 96.875 (96.720)
Epoch: [155][100/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 1.2589 (1.3427)	Acc@1 82.812 (80.832)	Acc@5 97.656 (96.713)
Epoch: [155][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.2852 (1.3388)	Acc@1 82.812 (80.919)	Acc@5 96.875 (96.776)
Epoch: [155][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.4521 (1.3387)	Acc@1 78.906 (80.940)	Acc@5 96.875 (96.791)
Epoch: [155][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.2271 (1.3359)	Acc@1 83.594 (80.946)	Acc@5 97.656 (96.827)
Epoch: [155][140/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 1.3807 (1.3349)	Acc@1 78.125 (80.995)	Acc@5 96.094 (96.803)
Epoch: [155][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.2278 (1.3334)	Acc@1 82.031 (80.976)	Acc@5 99.219 (96.834)
Epoch: [155][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2701 (1.3329)	Acc@1 81.250 (80.935)	Acc@5 98.438 (96.851)
Epoch: [155][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3313 (1.3319)	Acc@1 81.250 (80.871)	Acc@5 96.094 (96.861)
Epoch: [155][180/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.2270 (1.3324)	Acc@1 85.156 (80.866)	Acc@5 96.094 (96.858)
Epoch: [155][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2832 (1.3300)	Acc@1 81.250 (80.861)	Acc@5 96.875 (96.875)
Epoch: [155][200/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.3004 (1.3294)	Acc@1 79.688 (80.842)	Acc@5 99.219 (96.891)
Epoch: [155][210/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 1.4409 (1.3297)	Acc@1 80.469 (80.839)	Acc@5 94.531 (96.879)
Epoch: [155][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3397 (1.3289)	Acc@1 80.469 (80.840)	Acc@5 97.656 (96.893)
Epoch: [155][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3598 (1.3279)	Acc@1 77.344 (80.871)	Acc@5 98.438 (96.922)
Epoch: [155][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4493 (1.3296)	Acc@1 78.125 (80.832)	Acc@5 95.312 (96.904)
Epoch: [155][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3607 (1.3303)	Acc@1 76.562 (80.777)	Acc@5 96.875 (96.931)
Epoch: [155][260/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.4815 (1.3336)	Acc@1 76.562 (80.744)	Acc@5 96.094 (96.872)
Epoch: [155][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4689 (1.3358)	Acc@1 75.781 (80.671)	Acc@5 93.750 (96.835)
Epoch: [155][280/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.5554 (1.3363)	Acc@1 76.562 (80.630)	Acc@5 93.750 (96.800)
Epoch: [155][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2719 (1.3378)	Acc@1 80.469 (80.557)	Acc@5 96.094 (96.760)
Epoch: [155][300/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 1.3119 (1.3381)	Acc@1 82.031 (80.510)	Acc@5 96.875 (96.776)
Epoch: [155][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5025 (1.3381)	Acc@1 76.562 (80.524)	Acc@5 96.875 (96.780)
Epoch: [155][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3145 (1.3362)	Acc@1 78.906 (80.571)	Acc@5 99.219 (96.790)
Epoch: [155][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2824 (1.3346)	Acc@1 78.125 (80.577)	Acc@5 98.438 (96.818)
Epoch: [155][340/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 1.3720 (1.3348)	Acc@1 77.344 (80.524)	Acc@5 96.875 (96.822)
Epoch: [155][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2774 (1.3364)	Acc@1 79.688 (80.451)	Acc@5 97.656 (96.786)
Epoch: [155][360/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 1.2811 (1.3357)	Acc@1 83.594 (80.458)	Acc@5 96.094 (96.791)
Epoch: [155][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3466 (1.3370)	Acc@1 83.594 (80.448)	Acc@5 96.875 (96.776)
Epoch: [155][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2729 (1.3375)	Acc@1 82.031 (80.444)	Acc@5 98.438 (96.777)
Epoch: [155][390/391]	Time 0.019 (0.014)	Data 0.001 (0.002)	Loss 1.3153 (1.3381)	Acc@1 76.250 (80.406)	Acc@5 98.750 (96.768)
num momentum params: 26
[0.010000000000000002, 1.3381467568588257, 1.1886071276664734, 80.406, 66.89, tensor(0.5168, device='cuda:0', grad_fn=<DivBackward0>), 5.311164617538452, 0.40431714057922363]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [156 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [156][0/391]	Time 0.073 (0.073)	Data 0.184 (0.184)	Loss 1.3831 (1.3831)	Acc@1 81.250 (81.250)	Acc@5 97.656 (97.656)
Epoch: [156][10/391]	Time 0.015 (0.022)	Data 0.002 (0.018)	Loss 1.1235 (1.2776)	Acc@1 88.281 (82.599)	Acc@5 98.438 (97.585)
Epoch: [156][20/391]	Time 0.014 (0.018)	Data 0.001 (0.010)	Loss 1.1273 (1.2467)	Acc@1 86.719 (83.408)	Acc@5 98.438 (97.396)
Epoch: [156][30/391]	Time 0.016 (0.017)	Data 0.001 (0.007)	Loss 1.2592 (1.2520)	Acc@1 83.594 (83.039)	Acc@5 95.312 (97.455)
Epoch: [156][40/391]	Time 0.014 (0.016)	Data 0.001 (0.006)	Loss 1.3339 (1.2544)	Acc@1 77.344 (82.641)	Acc@5 96.094 (97.370)
Epoch: [156][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 1.3365 (1.2608)	Acc@1 75.781 (82.322)	Acc@5 96.094 (97.365)
Epoch: [156][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.5140 (1.2557)	Acc@1 75.000 (82.403)	Acc@5 94.531 (97.477)
Epoch: [156][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.2575 (1.2578)	Acc@1 83.594 (82.229)	Acc@5 98.438 (97.425)
Epoch: [156][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.2671 (1.2634)	Acc@1 77.344 (82.051)	Acc@5 96.875 (97.357)
Epoch: [156][90/391]	Time 0.014 (0.015)	Data 0.001 (0.003)	Loss 1.2602 (1.2679)	Acc@1 82.031 (81.980)	Acc@5 98.438 (97.296)
Epoch: [156][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.3209 (1.2647)	Acc@1 78.906 (82.155)	Acc@5 97.656 (97.355)
Epoch: [156][110/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 1.3466 (1.2664)	Acc@1 81.250 (82.095)	Acc@5 97.656 (97.340)
Epoch: [156][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.2569 (1.2654)	Acc@1 79.688 (82.057)	Acc@5 96.094 (97.333)
Epoch: [156][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.1409 (1.2656)	Acc@1 85.156 (82.091)	Acc@5 99.219 (97.346)
Epoch: [156][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.2364 (1.2673)	Acc@1 85.938 (82.059)	Acc@5 96.094 (97.313)
Epoch: [156][150/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 1.1574 (1.2680)	Acc@1 82.812 (82.067)	Acc@5 98.438 (97.258)
Epoch: [156][160/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0973 (1.2687)	Acc@1 89.844 (81.988)	Acc@5 98.438 (97.302)
Epoch: [156][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2878 (1.2685)	Acc@1 82.031 (81.899)	Acc@5 98.438 (97.318)
Epoch: [156][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4350 (1.2720)	Acc@1 76.562 (81.742)	Acc@5 94.531 (97.289)
Epoch: [156][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2587 (1.2728)	Acc@1 80.469 (81.675)	Acc@5 97.656 (97.276)
Epoch: [156][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1375 (1.2717)	Acc@1 85.938 (81.782)	Acc@5 99.219 (97.306)
Epoch: [156][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2558 (1.2723)	Acc@1 80.469 (81.742)	Acc@5 99.219 (97.301)
Epoch: [156][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2237 (1.2737)	Acc@1 82.812 (81.678)	Acc@5 96.875 (97.264)
Epoch: [156][230/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 1.2620 (1.2750)	Acc@1 79.688 (81.612)	Acc@5 98.438 (97.274)
Epoch: [156][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3237 (1.2755)	Acc@1 78.906 (81.542)	Acc@5 97.656 (97.290)
Epoch: [156][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2535 (1.2752)	Acc@1 78.906 (81.530)	Acc@5 98.438 (97.298)
Epoch: [156][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5530 (1.2761)	Acc@1 71.875 (81.498)	Acc@5 96.875 (97.288)
Epoch: [156][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3502 (1.2780)	Acc@1 75.000 (81.403)	Acc@5 97.656 (97.253)
Epoch: [156][280/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.2567 (1.2776)	Acc@1 81.250 (81.422)	Acc@5 96.875 (97.242)
Epoch: [156][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3035 (1.2792)	Acc@1 80.469 (81.368)	Acc@5 95.312 (97.213)
Epoch: [156][300/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.3424 (1.2808)	Acc@1 76.562 (81.336)	Acc@5 96.094 (97.186)
Epoch: [156][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4289 (1.2841)	Acc@1 79.688 (81.270)	Acc@5 95.312 (97.126)
Epoch: [156][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.5287 (1.2858)	Acc@1 71.094 (81.211)	Acc@5 96.094 (97.089)
Epoch: [156][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1572 (1.2853)	Acc@1 82.812 (81.248)	Acc@5 96.875 (97.087)
Epoch: [156][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1020 (1.2852)	Acc@1 83.594 (81.248)	Acc@5 100.000 (97.074)
Epoch: [156][350/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.2456 (1.2860)	Acc@1 82.812 (81.232)	Acc@5 97.656 (97.051)
Epoch: [156][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2214 (1.2846)	Acc@1 82.812 (81.259)	Acc@5 96.875 (97.068)
Epoch: [156][370/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.2796 (1.2835)	Acc@1 81.250 (81.279)	Acc@5 96.875 (97.079)
Epoch: [156][380/391]	Time 0.011 (0.014)	Data 0.001 (0.002)	Loss 1.3158 (1.2831)	Acc@1 79.688 (81.291)	Acc@5 98.438 (97.080)
Epoch: [156][390/391]	Time 0.019 (0.014)	Data 0.001 (0.002)	Loss 1.0502 (1.2838)	Acc@1 90.000 (81.276)	Acc@5 100.000 (97.086)
num momentum params: 26
[0.010000000000000002, 1.283820948677063, 1.20223941385746, 81.276, 67.2, tensor(0.5262, device='cuda:0', grad_fn=<DivBackward0>), 5.34081244468689, 0.41478610038757324]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [157 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [157][0/391]	Time 0.066 (0.066)	Data 0.185 (0.185)	Loss 1.1346 (1.1346)	Acc@1 89.062 (89.062)	Acc@5 97.656 (97.656)
Epoch: [157][10/391]	Time 0.014 (0.026)	Data 0.001 (0.018)	Loss 1.1304 (1.2418)	Acc@1 85.938 (83.310)	Acc@5 97.656 (97.088)
Epoch: [157][20/391]	Time 0.013 (0.020)	Data 0.002 (0.010)	Loss 1.1435 (1.2421)	Acc@1 85.938 (82.664)	Acc@5 97.656 (97.247)
Epoch: [157][30/391]	Time 0.013 (0.018)	Data 0.002 (0.007)	Loss 1.3855 (1.2368)	Acc@1 82.031 (82.863)	Acc@5 96.875 (97.379)
Epoch: [157][40/391]	Time 0.013 (0.017)	Data 0.001 (0.006)	Loss 1.0937 (1.2231)	Acc@1 86.719 (83.098)	Acc@5 99.219 (97.580)
Epoch: [157][50/391]	Time 0.013 (0.016)	Data 0.001 (0.005)	Loss 1.2518 (1.2207)	Acc@1 81.250 (83.150)	Acc@5 96.875 (97.564)
Epoch: [157][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.2572 (1.2213)	Acc@1 78.906 (83.107)	Acc@5 99.219 (97.643)
Epoch: [157][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.2297 (1.2170)	Acc@1 84.375 (83.275)	Acc@5 96.875 (97.678)
Epoch: [157][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.1514 (1.2151)	Acc@1 82.812 (83.314)	Acc@5 100.000 (97.637)
Epoch: [157][90/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 1.1086 (1.2140)	Acc@1 85.938 (83.388)	Acc@5 97.656 (97.656)
Epoch: [157][100/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 1.2585 (1.2165)	Acc@1 81.250 (83.377)	Acc@5 97.656 (97.618)
Epoch: [157][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.2727 (1.2221)	Acc@1 83.594 (83.242)	Acc@5 98.438 (97.593)
Epoch: [157][120/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 1.2202 (1.2173)	Acc@1 85.156 (83.439)	Acc@5 98.438 (97.630)
Epoch: [157][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.2659 (1.2193)	Acc@1 82.812 (83.272)	Acc@5 97.656 (97.615)
Epoch: [157][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.3922 (1.2234)	Acc@1 82.031 (83.112)	Acc@5 95.312 (97.579)
Epoch: [157][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.1177 (1.2233)	Acc@1 89.062 (83.056)	Acc@5 97.656 (97.573)
Epoch: [157][160/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.1661 (1.2230)	Acc@1 82.812 (83.036)	Acc@5 97.656 (97.545)
Epoch: [157][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1865 (1.2221)	Acc@1 85.156 (82.959)	Acc@5 99.219 (97.574)
Epoch: [157][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1426 (1.2200)	Acc@1 85.938 (83.015)	Acc@5 99.219 (97.596)
Epoch: [157][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2029 (1.2177)	Acc@1 80.469 (83.058)	Acc@5 96.875 (97.619)
Epoch: [157][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2725 (1.2186)	Acc@1 78.906 (83.011)	Acc@5 96.875 (97.625)
Epoch: [157][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2324 (1.2201)	Acc@1 84.375 (82.990)	Acc@5 96.875 (97.604)
Epoch: [157][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2970 (1.2193)	Acc@1 78.125 (83.021)	Acc@5 97.656 (97.628)
Epoch: [157][230/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.2534 (1.2211)	Acc@1 83.594 (82.955)	Acc@5 95.312 (97.599)
Epoch: [157][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2038 (1.2223)	Acc@1 79.688 (82.929)	Acc@5 97.656 (97.595)
Epoch: [157][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2893 (1.2245)	Acc@1 77.344 (82.784)	Acc@5 97.656 (97.566)
Epoch: [157][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3940 (1.2258)	Acc@1 75.781 (82.708)	Acc@5 93.750 (97.566)
Epoch: [157][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3717 (1.2250)	Acc@1 78.906 (82.726)	Acc@5 96.875 (97.558)
Epoch: [157][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2501 (1.2268)	Acc@1 81.250 (82.682)	Acc@5 98.438 (97.537)
Epoch: [157][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1699 (1.2261)	Acc@1 82.812 (82.678)	Acc@5 98.438 (97.554)
Epoch: [157][300/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 1.1689 (1.2263)	Acc@1 83.594 (82.659)	Acc@5 98.438 (97.563)
Epoch: [157][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2960 (1.2262)	Acc@1 82.031 (82.632)	Acc@5 96.094 (97.568)
Epoch: [157][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.4017 (1.2285)	Acc@1 78.906 (82.533)	Acc@5 95.312 (97.554)
Epoch: [157][330/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.3034 (1.2306)	Acc@1 78.906 (82.475)	Acc@5 96.094 (97.543)
Epoch: [157][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2507 (1.2302)	Acc@1 83.594 (82.496)	Acc@5 96.094 (97.544)
Epoch: [157][350/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.3700 (1.2321)	Acc@1 80.469 (82.425)	Acc@5 93.750 (97.520)
Epoch: [157][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2093 (1.2328)	Acc@1 82.031 (82.399)	Acc@5 98.438 (97.490)
Epoch: [157][370/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.2404 (1.2338)	Acc@1 81.250 (82.366)	Acc@5 97.656 (97.477)
Epoch: [157][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1661 (1.2337)	Acc@1 82.812 (82.361)	Acc@5 97.656 (97.474)
Epoch: [157][390/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 1.3720 (1.2351)	Acc@1 75.000 (82.298)	Acc@5 98.750 (97.474)
num momentum params: 26
[0.010000000000000002, 1.235128511581421, 1.2368867498636247, 82.298, 66.46, tensor(0.5345, device='cuda:0', grad_fn=<DivBackward0>), 5.323152780532837, 0.3938636779785156]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [158 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [158][0/391]	Time 0.058 (0.058)	Data 0.184 (0.184)	Loss 1.1883 (1.1883)	Acc@1 84.375 (84.375)	Acc@5 97.656 (97.656)
Epoch: [158][10/391]	Time 0.016 (0.020)	Data 0.002 (0.018)	Loss 1.0640 (1.1784)	Acc@1 88.281 (84.020)	Acc@5 99.219 (97.869)
Epoch: [158][20/391]	Time 0.014 (0.017)	Data 0.001 (0.010)	Loss 1.2868 (1.1803)	Acc@1 79.688 (83.408)	Acc@5 96.875 (97.842)
Epoch: [158][30/391]	Time 0.015 (0.016)	Data 0.001 (0.007)	Loss 1.1006 (1.1643)	Acc@1 85.156 (84.073)	Acc@5 99.219 (97.908)
Epoch: [158][40/391]	Time 0.014 (0.016)	Data 0.001 (0.006)	Loss 1.3295 (1.1724)	Acc@1 79.688 (83.899)	Acc@5 96.094 (97.961)
Epoch: [158][50/391]	Time 0.016 (0.015)	Data 0.001 (0.005)	Loss 1.2125 (1.1721)	Acc@1 83.594 (83.778)	Acc@5 96.875 (97.917)
Epoch: [158][60/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 1.1505 (1.1730)	Acc@1 84.375 (83.901)	Acc@5 98.438 (97.784)
Epoch: [158][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.1622 (1.1728)	Acc@1 84.375 (83.924)	Acc@5 98.438 (97.843)
Epoch: [158][80/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 1.1393 (1.1726)	Acc@1 82.812 (83.999)	Acc@5 99.219 (97.830)
Epoch: [158][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.1995 (1.1752)	Acc@1 83.594 (83.868)	Acc@5 97.656 (97.811)
Epoch: [158][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.3512 (1.1770)	Acc@1 75.781 (83.834)	Acc@5 97.656 (97.811)
Epoch: [158][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.1388 (1.1751)	Acc@1 85.156 (83.932)	Acc@5 97.656 (97.783)
Epoch: [158][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.1376 (1.1739)	Acc@1 85.938 (83.897)	Acc@5 97.656 (97.837)
Epoch: [158][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.1082 (1.1730)	Acc@1 83.594 (83.934)	Acc@5 98.438 (97.859)
Epoch: [158][140/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 1.1884 (1.1703)	Acc@1 82.812 (84.065)	Acc@5 96.875 (97.867)
Epoch: [158][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.2460 (1.1711)	Acc@1 81.250 (84.018)	Acc@5 96.875 (97.848)
Epoch: [158][160/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.1625 (1.1706)	Acc@1 82.031 (84.021)	Acc@5 98.438 (97.860)
Epoch: [158][170/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0610 (1.1727)	Acc@1 87.500 (83.936)	Acc@5 99.219 (97.848)
Epoch: [158][180/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0784 (1.1709)	Acc@1 83.594 (83.978)	Acc@5 98.438 (97.859)
Epoch: [158][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0597 (1.1717)	Acc@1 87.500 (83.921)	Acc@5 99.219 (97.857)
Epoch: [158][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1179 (1.1714)	Acc@1 84.375 (83.920)	Acc@5 99.219 (97.893)
Epoch: [158][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1626 (1.1718)	Acc@1 81.250 (83.883)	Acc@5 98.438 (97.882)
Epoch: [158][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3352 (1.1730)	Acc@1 78.906 (83.855)	Acc@5 97.656 (97.858)
Epoch: [158][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1318 (1.1729)	Acc@1 85.156 (83.820)	Acc@5 100.000 (97.859)
Epoch: [158][240/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.2593 (1.1740)	Acc@1 82.812 (83.766)	Acc@5 96.875 (97.851)
Epoch: [158][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3582 (1.1762)	Acc@1 78.125 (83.706)	Acc@5 94.531 (97.834)
Epoch: [158][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2373 (1.1787)	Acc@1 79.688 (83.603)	Acc@5 97.656 (97.812)
Epoch: [158][270/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 1.2308 (1.1792)	Acc@1 84.375 (83.568)	Acc@5 99.219 (97.818)
Epoch: [158][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2522 (1.1799)	Acc@1 81.250 (83.555)	Acc@5 96.094 (97.806)
Epoch: [158][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1901 (1.1807)	Acc@1 86.719 (83.486)	Acc@5 96.875 (97.785)
Epoch: [158][300/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.1842 (1.1810)	Acc@1 82.812 (83.506)	Acc@5 97.656 (97.770)
Epoch: [158][310/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 1.1442 (1.1823)	Acc@1 84.375 (83.458)	Acc@5 98.438 (97.752)
Epoch: [158][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2186 (1.1849)	Acc@1 85.156 (83.394)	Acc@5 99.219 (97.729)
Epoch: [158][330/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 1.2220 (1.1865)	Acc@1 80.469 (83.303)	Acc@5 100.000 (97.713)
Epoch: [158][340/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.1728 (1.1880)	Acc@1 85.938 (83.246)	Acc@5 97.656 (97.714)
Epoch: [158][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3553 (1.1901)	Acc@1 79.688 (83.182)	Acc@5 93.750 (97.681)
Epoch: [158][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2266 (1.1906)	Acc@1 82.031 (83.172)	Acc@5 97.656 (97.667)
Epoch: [158][370/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 1.4254 (1.1914)	Acc@1 71.094 (83.141)	Acc@5 95.312 (97.654)
Epoch: [158][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1715 (1.1915)	Acc@1 82.812 (83.151)	Acc@5 98.438 (97.648)
Epoch: [158][390/391]	Time 0.016 (0.014)	Data 0.002 (0.002)	Loss 1.1441 (1.1927)	Acc@1 82.500 (83.104)	Acc@5 100.000 (97.646)
num momentum params: 26
[0.010000000000000002, 1.1927058065032958, 1.2467622762918473, 83.104, 67.16, tensor(0.5421, device='cuda:0', grad_fn=<DivBackward0>), 5.321329355239868, 0.4037609100341797]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [159 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [159][0/391]	Time 0.058 (0.058)	Data 0.174 (0.174)	Loss 1.2405 (1.2405)	Acc@1 78.125 (78.125)	Acc@5 95.312 (95.312)
Epoch: [159][10/391]	Time 0.016 (0.021)	Data 0.001 (0.017)	Loss 1.0347 (1.1281)	Acc@1 85.938 (84.659)	Acc@5 99.219 (98.011)
Epoch: [159][20/391]	Time 0.017 (0.017)	Data 0.001 (0.010)	Loss 1.1197 (1.1258)	Acc@1 85.156 (85.082)	Acc@5 98.438 (98.103)
Epoch: [159][30/391]	Time 0.014 (0.016)	Data 0.002 (0.007)	Loss 1.1926 (1.1254)	Acc@1 80.469 (85.106)	Acc@5 95.312 (98.085)
Epoch: [159][40/391]	Time 0.014 (0.016)	Data 0.002 (0.006)	Loss 1.1017 (1.1289)	Acc@1 81.250 (84.851)	Acc@5 98.438 (98.056)
Epoch: [159][50/391]	Time 0.014 (0.015)	Data 0.002 (0.005)	Loss 1.0700 (1.1215)	Acc@1 84.375 (85.110)	Acc@5 96.875 (98.085)
Epoch: [159][60/391]	Time 0.014 (0.015)	Data 0.002 (0.004)	Loss 1.0433 (1.1248)	Acc@1 83.594 (84.926)	Acc@5 100.000 (97.989)
Epoch: [159][70/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 1.1794 (1.1239)	Acc@1 83.594 (84.991)	Acc@5 97.656 (97.986)
Epoch: [159][80/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 1.0682 (1.1226)	Acc@1 85.156 (84.925)	Acc@5 98.438 (98.003)
Epoch: [159][90/391]	Time 0.015 (0.015)	Data 0.002 (0.004)	Loss 1.2705 (1.1275)	Acc@1 78.125 (84.710)	Acc@5 96.875 (98.017)
Epoch: [159][100/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 1.2655 (1.1289)	Acc@1 82.031 (84.708)	Acc@5 96.875 (98.058)
Epoch: [159][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0584 (1.1264)	Acc@1 89.844 (84.840)	Acc@5 100.000 (98.100)
Epoch: [159][120/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 1.0257 (1.1306)	Acc@1 88.281 (84.659)	Acc@5 100.000 (98.063)
Epoch: [159][130/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 1.1547 (1.1292)	Acc@1 84.375 (84.667)	Acc@5 98.438 (98.074)
Epoch: [159][140/391]	Time 0.015 (0.014)	Data 0.002 (0.003)	Loss 1.0105 (1.1267)	Acc@1 89.062 (84.757)	Acc@5 100.000 (98.100)
Epoch: [159][150/391]	Time 0.011 (0.014)	Data 0.012 (0.003)	Loss 1.0055 (1.1244)	Acc@1 89.844 (84.846)	Acc@5 98.438 (98.127)
Epoch: [159][160/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 1.0264 (1.1230)	Acc@1 88.281 (84.904)	Acc@5 99.219 (98.132)
Epoch: [159][170/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 1.0114 (1.1209)	Acc@1 88.281 (84.914)	Acc@5 99.219 (98.163)
Epoch: [159][180/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 1.2169 (1.1234)	Acc@1 82.812 (84.876)	Acc@5 99.219 (98.122)
Epoch: [159][190/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 1.1385 (1.1234)	Acc@1 81.250 (84.854)	Acc@5 97.656 (98.131)
Epoch: [159][200/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.2296 (1.1263)	Acc@1 82.031 (84.748)	Acc@5 97.656 (98.119)
Epoch: [159][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1217 (1.1287)	Acc@1 84.375 (84.668)	Acc@5 98.438 (98.101)
Epoch: [159][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1520 (1.1306)	Acc@1 84.375 (84.601)	Acc@5 98.438 (98.084)
Epoch: [159][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1853 (1.1326)	Acc@1 82.812 (84.520)	Acc@5 97.656 (98.082)
Epoch: [159][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0013 (1.1317)	Acc@1 92.188 (84.570)	Acc@5 98.438 (98.065)
Epoch: [159][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1272 (1.1321)	Acc@1 81.250 (84.556)	Acc@5 99.219 (98.064)
Epoch: [159][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1816 (1.1338)	Acc@1 82.812 (84.534)	Acc@5 98.438 (98.036)
Epoch: [159][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1669 (1.1354)	Acc@1 82.812 (84.485)	Acc@5 97.656 (98.017)
Epoch: [159][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1765 (1.1370)	Acc@1 82.812 (84.428)	Acc@5 96.875 (98.020)
Epoch: [159][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2428 (1.1385)	Acc@1 82.812 (84.391)	Acc@5 97.656 (98.024)
Epoch: [159][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1729 (1.1406)	Acc@1 82.812 (84.359)	Acc@5 97.656 (98.014)
Epoch: [159][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3151 (1.1417)	Acc@1 77.344 (84.335)	Acc@5 96.094 (98.000)
Epoch: [159][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2151 (1.1435)	Acc@1 82.812 (84.304)	Acc@5 96.094 (97.960)
Epoch: [159][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2405 (1.1454)	Acc@1 82.812 (84.250)	Acc@5 96.875 (97.939)
Epoch: [159][340/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 1.0844 (1.1444)	Acc@1 82.812 (84.251)	Acc@5 100.000 (97.959)
Epoch: [159][350/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.1076 (1.1455)	Acc@1 82.031 (84.201)	Acc@5 99.219 (97.957)
Epoch: [159][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0977 (1.1466)	Acc@1 86.719 (84.156)	Acc@5 98.438 (97.948)
Epoch: [159][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2993 (1.1488)	Acc@1 77.344 (84.091)	Acc@5 96.875 (97.915)
Epoch: [159][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1973 (1.1506)	Acc@1 83.594 (84.031)	Acc@5 98.438 (97.902)
Epoch: [159][390/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 0.9863 (1.1517)	Acc@1 87.500 (84.012)	Acc@5 100.000 (97.900)
num momentum params: 26
[0.010000000000000002, 1.151719840927124, 1.3001895648241044, 84.012, 65.91, tensor(0.5508, device='cuda:0', grad_fn=<DivBackward0>), 5.354593992233276, 0.39415526390075684]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [160 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [160][0/391]	Time 0.059 (0.059)	Data 0.186 (0.186)	Loss 1.0910 (1.0910)	Acc@1 84.375 (84.375)	Acc@5 99.219 (99.219)
Epoch: [160][10/391]	Time 0.015 (0.020)	Data 0.001 (0.018)	Loss 1.0507 (1.1114)	Acc@1 85.156 (84.517)	Acc@5 98.438 (98.295)
Epoch: [160][20/391]	Time 0.015 (0.017)	Data 0.001 (0.010)	Loss 1.2382 (1.1021)	Acc@1 78.906 (84.524)	Acc@5 97.656 (98.586)
Epoch: [160][30/391]	Time 0.014 (0.017)	Data 0.001 (0.007)	Loss 1.0656 (1.0966)	Acc@1 84.375 (84.778)	Acc@5 99.219 (98.765)
Epoch: [160][40/391]	Time 0.013 (0.016)	Data 0.001 (0.006)	Loss 1.0311 (1.0838)	Acc@1 85.938 (85.442)	Acc@5 100.000 (98.838)
Epoch: [160][50/391]	Time 0.014 (0.015)	Data 0.001 (0.005)	Loss 0.9946 (1.0798)	Acc@1 89.062 (85.585)	Acc@5 99.219 (98.790)
Epoch: [160][60/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 1.3663 (1.0804)	Acc@1 79.688 (85.707)	Acc@5 96.094 (98.617)
Epoch: [160][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.1904 (1.0841)	Acc@1 82.031 (85.541)	Acc@5 97.656 (98.493)
Epoch: [160][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.1552 (1.0870)	Acc@1 78.906 (85.494)	Acc@5 98.438 (98.466)
Epoch: [160][90/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 1.1091 (1.0914)	Acc@1 83.594 (85.311)	Acc@5 96.094 (98.403)
Epoch: [160][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 1.0612 (1.0914)	Acc@1 85.938 (85.342)	Acc@5 99.219 (98.376)
Epoch: [160][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0395 (1.0983)	Acc@1 86.719 (85.114)	Acc@5 99.219 (98.339)
Epoch: [160][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9863 (1.1012)	Acc@1 87.500 (84.982)	Acc@5 100.000 (98.341)
Epoch: [160][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0927 (1.1044)	Acc@1 85.156 (84.816)	Acc@5 99.219 (98.294)
Epoch: [160][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0475 (1.1033)	Acc@1 84.375 (84.846)	Acc@5 98.438 (98.288)
Epoch: [160][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0075 (1.1010)	Acc@1 87.500 (84.954)	Acc@5 98.438 (98.308)
Epoch: [160][160/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 1.0841 (1.1008)	Acc@1 83.594 (84.962)	Acc@5 99.219 (98.316)
Epoch: [160][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1436 (1.1000)	Acc@1 85.156 (84.996)	Acc@5 97.656 (98.332)
Epoch: [160][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1894 (1.0988)	Acc@1 82.031 (85.001)	Acc@5 98.438 (98.355)
Epoch: [160][190/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.3005 (1.1011)	Acc@1 78.125 (84.915)	Acc@5 97.656 (98.343)
Epoch: [160][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1009 (1.1021)	Acc@1 85.938 (84.942)	Acc@5 97.656 (98.321)
Epoch: [160][210/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.2802 (1.1044)	Acc@1 78.125 (84.830)	Acc@5 98.438 (98.323)
Epoch: [160][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0698 (1.1059)	Acc@1 86.719 (84.799)	Acc@5 97.656 (98.303)
Epoch: [160][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1563 (1.1058)	Acc@1 82.031 (84.761)	Acc@5 96.875 (98.306)
Epoch: [160][240/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 1.0635 (1.1062)	Acc@1 85.938 (84.735)	Acc@5 99.219 (98.298)
Epoch: [160][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0150 (1.1058)	Acc@1 88.281 (84.749)	Acc@5 99.219 (98.307)
Epoch: [160][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1361 (1.1054)	Acc@1 83.594 (84.806)	Acc@5 98.438 (98.303)
Epoch: [160][270/391]	Time 0.012 (0.014)	Data 0.002 (0.002)	Loss 1.0546 (1.1055)	Acc@1 87.500 (84.810)	Acc@5 95.312 (98.305)
Epoch: [160][280/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 0.9954 (1.1047)	Acc@1 88.281 (84.820)	Acc@5 99.219 (98.307)
Epoch: [160][290/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 1.1507 (1.1061)	Acc@1 82.031 (84.737)	Acc@5 97.656 (98.311)
Epoch: [160][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1072 (1.1068)	Acc@1 82.812 (84.681)	Acc@5 99.219 (98.318)
Epoch: [160][310/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 1.1410 (1.1074)	Acc@1 84.375 (84.689)	Acc@5 99.219 (98.302)
Epoch: [160][320/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 1.0971 (1.1090)	Acc@1 87.500 (84.640)	Acc@5 98.438 (98.277)
Epoch: [160][330/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.3176 (1.1108)	Acc@1 79.688 (84.587)	Acc@5 95.312 (98.260)
Epoch: [160][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2117 (1.1125)	Acc@1 82.031 (84.558)	Acc@5 96.875 (98.240)
Epoch: [160][350/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.1798 (1.1129)	Acc@1 82.812 (84.529)	Acc@5 97.656 (98.237)
Epoch: [160][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1087 (1.1137)	Acc@1 82.031 (84.505)	Acc@5 98.438 (98.225)
Epoch: [160][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1154 (1.1150)	Acc@1 85.938 (84.444)	Acc@5 98.438 (98.216)
Epoch: [160][380/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 1.0979 (1.1161)	Acc@1 83.594 (84.406)	Acc@5 97.656 (98.208)
Epoch: [160][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 0.9310 (1.1185)	Acc@1 88.750 (84.332)	Acc@5 100.000 (98.190)
num momentum params: 26
[0.010000000000000002, 1.1185244527816773, 1.3254649424552918, 84.332, 65.79, tensor(0.5572, device='cuda:0', grad_fn=<DivBackward0>), 5.336935520172119, 0.387920618057251]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [161 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [161][0/391]	Time 0.057 (0.057)	Data 0.172 (0.172)	Loss 1.0819 (1.0819)	Acc@1 87.500 (87.500)	Acc@5 98.438 (98.438)
Epoch: [161][10/391]	Time 0.016 (0.020)	Data 0.001 (0.017)	Loss 1.0623 (1.0398)	Acc@1 87.500 (87.145)	Acc@5 98.438 (98.509)
Epoch: [161][20/391]	Time 0.015 (0.018)	Data 0.001 (0.010)	Loss 1.0456 (1.0591)	Acc@1 86.719 (86.458)	Acc@5 99.219 (98.624)
Epoch: [161][30/391]	Time 0.013 (0.017)	Data 0.001 (0.007)	Loss 1.2173 (1.0660)	Acc@1 80.469 (86.089)	Acc@5 96.875 (98.538)
Epoch: [161][40/391]	Time 0.015 (0.016)	Data 0.001 (0.006)	Loss 1.0559 (1.0638)	Acc@1 82.031 (86.109)	Acc@5 97.656 (98.418)
Epoch: [161][50/391]	Time 0.015 (0.015)	Data 0.001 (0.005)	Loss 0.9778 (1.0641)	Acc@1 92.188 (86.229)	Acc@5 99.219 (98.468)
Epoch: [161][60/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 1.0065 (1.0613)	Acc@1 88.281 (86.232)	Acc@5 98.438 (98.489)
Epoch: [161][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.1298 (1.0622)	Acc@1 83.594 (86.092)	Acc@5 97.656 (98.493)
Epoch: [161][80/391]	Time 0.017 (0.015)	Data 0.001 (0.004)	Loss 0.9852 (1.0620)	Acc@1 89.062 (86.082)	Acc@5 99.219 (98.534)
Epoch: [161][90/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 0.9135 (1.0606)	Acc@1 92.188 (86.083)	Acc@5 99.219 (98.583)
Epoch: [161][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0098 (1.0623)	Acc@1 86.719 (86.077)	Acc@5 98.438 (98.554)
Epoch: [161][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.1033 (1.0609)	Acc@1 87.500 (86.071)	Acc@5 98.438 (98.578)
Epoch: [161][120/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 1.0066 (1.0604)	Acc@1 89.062 (86.144)	Acc@5 100.000 (98.586)
Epoch: [161][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.2660 (1.0633)	Acc@1 84.375 (86.069)	Acc@5 94.531 (98.539)
Epoch: [161][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.2163 (1.0662)	Acc@1 82.031 (86.004)	Acc@5 96.094 (98.515)
Epoch: [161][150/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 1.1386 (1.0687)	Acc@1 86.719 (85.870)	Acc@5 96.875 (98.484)
Epoch: [161][160/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0101 (1.0695)	Acc@1 89.062 (85.889)	Acc@5 99.219 (98.496)
Epoch: [161][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1134 (1.0692)	Acc@1 85.156 (85.887)	Acc@5 96.875 (98.483)
Epoch: [161][180/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 1.2337 (1.0704)	Acc@1 80.469 (85.834)	Acc@5 97.656 (98.459)
Epoch: [161][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0701 (1.0737)	Acc@1 86.719 (85.758)	Acc@5 98.438 (98.413)
Epoch: [161][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1241 (1.0746)	Acc@1 82.812 (85.685)	Acc@5 98.438 (98.410)
Epoch: [161][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0880 (1.0743)	Acc@1 82.812 (85.660)	Acc@5 99.219 (98.419)
Epoch: [161][220/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 1.0808 (1.0747)	Acc@1 85.938 (85.584)	Acc@5 97.656 (98.420)
Epoch: [161][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1207 (1.0750)	Acc@1 85.938 (85.579)	Acc@5 98.438 (98.414)
Epoch: [161][240/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.1760 (1.0759)	Acc@1 77.344 (85.513)	Acc@5 98.438 (98.389)
Epoch: [161][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0363 (1.0759)	Acc@1 84.375 (85.480)	Acc@5 97.656 (98.397)
Epoch: [161][260/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.1246 (1.0789)	Acc@1 86.719 (85.414)	Acc@5 96.875 (98.363)
Epoch: [161][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0308 (1.0797)	Acc@1 85.938 (85.407)	Acc@5 100.000 (98.368)
Epoch: [161][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2999 (1.0815)	Acc@1 78.906 (85.381)	Acc@5 96.875 (98.335)
Epoch: [161][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2293 (1.0834)	Acc@1 77.344 (85.299)	Acc@5 96.875 (98.314)
Epoch: [161][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2059 (1.0857)	Acc@1 83.594 (85.203)	Acc@5 96.875 (98.282)
Epoch: [161][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0684 (1.0870)	Acc@1 84.375 (85.141)	Acc@5 99.219 (98.259)
Epoch: [161][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1670 (1.0873)	Acc@1 82.812 (85.122)	Acc@5 99.219 (98.270)
Epoch: [161][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1310 (1.0886)	Acc@1 81.250 (85.055)	Acc@5 97.656 (98.260)
Epoch: [161][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1240 (1.0908)	Acc@1 85.156 (84.971)	Acc@5 97.656 (98.236)
Epoch: [161][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0735 (1.0917)	Acc@1 85.156 (84.945)	Acc@5 98.438 (98.244)
Epoch: [161][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0636 (1.0927)	Acc@1 85.938 (84.892)	Acc@5 98.438 (98.243)
Epoch: [161][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1367 (1.0933)	Acc@1 84.375 (84.874)	Acc@5 96.875 (98.214)
Epoch: [161][380/391]	Time 0.010 (0.014)	Data 0.002 (0.002)	Loss 1.1590 (1.0938)	Acc@1 83.594 (84.834)	Acc@5 96.875 (98.210)
Epoch: [161][390/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 1.2053 (1.0947)	Acc@1 78.750 (84.802)	Acc@5 96.250 (98.210)
num momentum params: 26
[0.010000000000000002, 1.0946842905807495, 1.3115888065099717, 84.802, 66.39, tensor(0.5590, device='cuda:0', grad_fn=<DivBackward0>), 5.330481290817261, 0.40500497817993164]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [162 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [162][0/391]	Time 0.063 (0.063)	Data 0.173 (0.173)	Loss 1.0450 (1.0450)	Acc@1 83.594 (83.594)	Acc@5 97.656 (97.656)
Epoch: [162][10/391]	Time 0.015 (0.020)	Data 0.001 (0.017)	Loss 1.0310 (1.0453)	Acc@1 89.062 (86.577)	Acc@5 99.219 (98.722)
Epoch: [162][20/391]	Time 0.014 (0.018)	Data 0.001 (0.010)	Loss 1.0624 (1.0211)	Acc@1 85.156 (87.091)	Acc@5 97.656 (98.847)
Epoch: [162][30/391]	Time 0.024 (0.017)	Data 0.001 (0.007)	Loss 0.9441 (1.0258)	Acc@1 92.969 (87.147)	Acc@5 98.438 (98.790)
Epoch: [162][40/391]	Time 0.015 (0.016)	Data 0.001 (0.006)	Loss 0.9314 (1.0211)	Acc@1 90.625 (87.043)	Acc@5 99.219 (98.742)
Epoch: [162][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 1.0940 (1.0218)	Acc@1 85.938 (87.194)	Acc@5 98.438 (98.713)
Epoch: [162][60/391]	Time 0.015 (0.015)	Data 0.001 (0.004)	Loss 1.0137 (1.0205)	Acc@1 84.375 (87.013)	Acc@5 98.438 (98.745)
Epoch: [162][70/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 0.9888 (1.0150)	Acc@1 87.500 (87.214)	Acc@5 99.219 (98.790)
Epoch: [162][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 0.9709 (1.0172)	Acc@1 89.844 (87.076)	Acc@5 99.219 (98.756)
Epoch: [162][90/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 1.0307 (1.0224)	Acc@1 85.938 (86.873)	Acc@5 98.438 (98.712)
Epoch: [162][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0407 (1.0242)	Acc@1 83.594 (86.757)	Acc@5 98.438 (98.724)
Epoch: [162][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.1587 (1.0256)	Acc@1 83.594 (86.684)	Acc@5 97.656 (98.719)
Epoch: [162][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9608 (1.0249)	Acc@1 89.844 (86.732)	Acc@5 99.219 (98.702)
Epoch: [162][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0472 (1.0254)	Acc@1 85.156 (86.719)	Acc@5 98.438 (98.700)
Epoch: [162][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0824 (1.0265)	Acc@1 86.719 (86.774)	Acc@5 98.438 (98.676)
Epoch: [162][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9933 (1.0252)	Acc@1 86.719 (86.796)	Acc@5 99.219 (98.681)
Epoch: [162][160/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.1537 (1.0264)	Acc@1 82.812 (86.753)	Acc@5 96.875 (98.685)
Epoch: [162][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0144 (1.0271)	Acc@1 87.500 (86.755)	Acc@5 99.219 (98.680)
Epoch: [162][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0527 (1.0294)	Acc@1 86.719 (86.701)	Acc@5 98.438 (98.640)
Epoch: [162][190/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.2004 (1.0326)	Acc@1 80.469 (86.629)	Acc@5 96.094 (98.609)
Epoch: [162][200/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.1323 (1.0345)	Acc@1 79.688 (86.513)	Acc@5 99.219 (98.612)
Epoch: [162][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2697 (1.0370)	Acc@1 84.375 (86.411)	Acc@5 96.094 (98.597)
Epoch: [162][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0528 (1.0358)	Acc@1 85.938 (86.436)	Acc@5 99.219 (98.611)
Epoch: [162][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1656 (1.0372)	Acc@1 82.812 (86.377)	Acc@5 96.875 (98.600)
Epoch: [162][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0758 (1.0382)	Acc@1 86.719 (86.365)	Acc@5 98.438 (98.596)
Epoch: [162][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1245 (1.0411)	Acc@1 84.375 (86.280)	Acc@5 96.094 (98.578)
Epoch: [162][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0127 (1.0419)	Acc@1 86.719 (86.252)	Acc@5 99.219 (98.575)
Epoch: [162][270/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0152 (1.0436)	Acc@1 85.156 (86.185)	Acc@5 100.000 (98.564)
Epoch: [162][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9972 (1.0460)	Acc@1 85.938 (86.102)	Acc@5 99.219 (98.540)
Epoch: [162][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1191 (1.0474)	Acc@1 83.594 (86.050)	Acc@5 98.438 (98.531)
Epoch: [162][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0209 (1.0496)	Acc@1 84.375 (85.943)	Acc@5 100.000 (98.518)
Epoch: [162][310/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0933 (1.0506)	Acc@1 83.594 (85.902)	Acc@5 99.219 (98.528)
Epoch: [162][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1094 (1.0532)	Acc@1 85.938 (85.799)	Acc@5 97.656 (98.503)
Epoch: [162][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1502 (1.0551)	Acc@1 85.156 (85.735)	Acc@5 99.219 (98.499)
Epoch: [162][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1332 (1.0563)	Acc@1 84.375 (85.734)	Acc@5 99.219 (98.509)
Epoch: [162][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1557 (1.0566)	Acc@1 82.812 (85.731)	Acc@5 98.438 (98.509)
Epoch: [162][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0616 (1.0572)	Acc@1 88.281 (85.710)	Acc@5 96.875 (98.509)
Epoch: [162][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1433 (1.0585)	Acc@1 78.906 (85.628)	Acc@5 99.219 (98.494)
Epoch: [162][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1953 (1.0605)	Acc@1 82.031 (85.589)	Acc@5 97.656 (98.470)
Epoch: [162][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 1.1680 (1.0609)	Acc@1 81.250 (85.572)	Acc@5 95.000 (98.468)
num momentum params: 26
[0.010000000000000002, 1.060868498916626, 1.373171896338463, 85.572, 65.13, tensor(0.5686, device='cuda:0', grad_fn=<DivBackward0>), 5.305158376693726, 0.3900277614593506]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [163 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [163][0/391]	Time 0.069 (0.069)	Data 0.184 (0.184)	Loss 0.9067 (0.9067)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [163][10/391]	Time 0.015 (0.020)	Data 0.001 (0.018)	Loss 1.0394 (1.0103)	Acc@1 84.375 (86.577)	Acc@5 100.000 (99.006)
Epoch: [163][20/391]	Time 0.013 (0.018)	Data 0.002 (0.010)	Loss 0.9989 (1.0146)	Acc@1 86.719 (86.533)	Acc@5 99.219 (98.921)
Epoch: [163][30/391]	Time 0.015 (0.016)	Data 0.001 (0.007)	Loss 1.0170 (1.0066)	Acc@1 85.156 (86.719)	Acc@5 99.219 (98.816)
Epoch: [163][40/391]	Time 0.013 (0.016)	Data 0.001 (0.006)	Loss 1.0081 (1.0007)	Acc@1 85.156 (86.681)	Acc@5 99.219 (98.914)
Epoch: [163][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 0.9779 (1.0088)	Acc@1 89.062 (86.566)	Acc@5 99.219 (98.820)
Epoch: [163][60/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 1.0480 (1.0081)	Acc@1 80.469 (86.680)	Acc@5 98.438 (98.796)
Epoch: [163][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.1195 (1.0133)	Acc@1 82.812 (86.554)	Acc@5 96.875 (98.768)
Epoch: [163][80/391]	Time 0.012 (0.015)	Data 0.001 (0.004)	Loss 1.0941 (1.0125)	Acc@1 85.938 (86.642)	Acc@5 99.219 (98.775)
Epoch: [163][90/391]	Time 0.016 (0.015)	Data 0.001 (0.003)	Loss 1.0568 (1.0121)	Acc@1 85.938 (86.684)	Acc@5 99.219 (98.798)
Epoch: [163][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.1142 (1.0123)	Acc@1 85.156 (86.750)	Acc@5 97.656 (98.793)
Epoch: [163][110/391]	Time 0.016 (0.014)	Data 0.001 (0.003)	Loss 0.9711 (1.0150)	Acc@1 87.500 (86.641)	Acc@5 98.438 (98.789)
Epoch: [163][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.1511 (1.0228)	Acc@1 85.156 (86.473)	Acc@5 97.656 (98.747)
Epoch: [163][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0971 (1.0252)	Acc@1 85.156 (86.415)	Acc@5 99.219 (98.730)
Epoch: [163][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.1695 (1.0286)	Acc@1 82.031 (86.348)	Acc@5 97.656 (98.665)
Epoch: [163][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9612 (1.0282)	Acc@1 90.625 (86.382)	Acc@5 98.438 (98.665)
Epoch: [163][160/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0428 (1.0305)	Acc@1 85.938 (86.326)	Acc@5 99.219 (98.641)
Epoch: [163][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0216 (1.0312)	Acc@1 85.938 (86.257)	Acc@5 99.219 (98.643)
Epoch: [163][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0002 (1.0293)	Acc@1 88.281 (86.309)	Acc@5 99.219 (98.645)
Epoch: [163][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0652 (1.0300)	Acc@1 88.281 (86.281)	Acc@5 97.656 (98.650)
Epoch: [163][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9849 (1.0298)	Acc@1 88.281 (86.283)	Acc@5 97.656 (98.647)
Epoch: [163][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9792 (1.0308)	Acc@1 85.938 (86.249)	Acc@5 99.219 (98.641)
Epoch: [163][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1195 (1.0330)	Acc@1 84.375 (86.171)	Acc@5 96.875 (98.632)
Epoch: [163][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0765 (1.0358)	Acc@1 81.250 (86.039)	Acc@5 98.438 (98.596)
Epoch: [163][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0752 (1.0356)	Acc@1 84.375 (86.051)	Acc@5 97.656 (98.590)
Epoch: [163][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0394 (1.0365)	Acc@1 82.812 (85.994)	Acc@5 100.000 (98.590)
Epoch: [163][260/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 0.9761 (1.0379)	Acc@1 87.500 (85.940)	Acc@5 99.219 (98.581)
Epoch: [163][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9793 (1.0383)	Acc@1 87.500 (85.946)	Acc@5 98.438 (98.576)
Epoch: [163][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1298 (1.0424)	Acc@1 82.812 (85.849)	Acc@5 100.000 (98.563)
Epoch: [163][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9750 (1.0440)	Acc@1 89.844 (85.801)	Acc@5 100.000 (98.550)
Epoch: [163][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1301 (1.0450)	Acc@1 83.594 (85.761)	Acc@5 96.094 (98.536)
Epoch: [163][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0377 (1.0455)	Acc@1 86.719 (85.774)	Acc@5 98.438 (98.528)
Epoch: [163][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0793 (1.0495)	Acc@1 85.156 (85.694)	Acc@5 99.219 (98.501)
Epoch: [163][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1330 (1.0508)	Acc@1 82.031 (85.635)	Acc@5 98.438 (98.480)
Epoch: [163][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9311 (1.0524)	Acc@1 89.844 (85.589)	Acc@5 99.219 (98.463)
Epoch: [163][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0926 (1.0534)	Acc@1 85.938 (85.586)	Acc@5 97.656 (98.440)
Epoch: [163][360/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.1946 (1.0551)	Acc@1 81.250 (85.524)	Acc@5 96.875 (98.412)
Epoch: [163][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8867 (1.0556)	Acc@1 89.062 (85.489)	Acc@5 99.219 (98.404)
Epoch: [163][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0482 (1.0560)	Acc@1 82.812 (85.445)	Acc@5 99.219 (98.390)
Epoch: [163][390/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 1.0985 (1.0564)	Acc@1 86.250 (85.450)	Acc@5 98.750 (98.370)
num momentum params: 26
[0.010000000000000002, 1.0563829560852052, 1.3753615552186966, 85.45, 65.36, tensor(0.5642, device='cuda:0', grad_fn=<DivBackward0>), 5.316276788711548, 0.4084589481353759]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [164 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [164][0/391]	Time 0.062 (0.062)	Data 0.170 (0.170)	Loss 1.0536 (1.0536)	Acc@1 87.500 (87.500)	Acc@5 96.875 (96.875)
Epoch: [164][10/391]	Time 0.014 (0.021)	Data 0.001 (0.017)	Loss 0.9947 (0.9976)	Acc@1 86.719 (87.287)	Acc@5 98.438 (98.509)
Epoch: [164][20/391]	Time 0.017 (0.018)	Data 0.001 (0.010)	Loss 0.9017 (1.0035)	Acc@1 90.625 (86.905)	Acc@5 98.438 (98.475)
Epoch: [164][30/391]	Time 0.013 (0.017)	Data 0.001 (0.007)	Loss 0.9868 (0.9887)	Acc@1 85.156 (87.324)	Acc@5 100.000 (98.614)
Epoch: [164][40/391]	Time 0.014 (0.016)	Data 0.001 (0.006)	Loss 0.8815 (0.9819)	Acc@1 91.406 (87.519)	Acc@5 100.000 (98.685)
Epoch: [164][50/391]	Time 0.015 (0.015)	Data 0.001 (0.005)	Loss 1.0382 (0.9828)	Acc@1 87.500 (87.607)	Acc@5 99.219 (98.759)
Epoch: [164][60/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 1.2099 (0.9932)	Acc@1 79.688 (87.295)	Acc@5 96.875 (98.719)
Epoch: [164][70/391]	Time 0.015 (0.015)	Data 0.001 (0.004)	Loss 1.1356 (0.9966)	Acc@1 78.125 (87.060)	Acc@5 99.219 (98.768)
Epoch: [164][80/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 0.8963 (0.9968)	Acc@1 90.625 (87.114)	Acc@5 98.438 (98.698)
Epoch: [164][90/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 0.9525 (0.9977)	Acc@1 89.844 (87.045)	Acc@5 99.219 (98.755)
Epoch: [164][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.8639 (0.9949)	Acc@1 92.188 (87.136)	Acc@5 98.438 (98.778)
Epoch: [164][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9594 (0.9947)	Acc@1 92.188 (87.155)	Acc@5 98.438 (98.789)
Epoch: [164][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0733 (0.9968)	Acc@1 84.375 (87.080)	Acc@5 99.219 (98.799)
Epoch: [164][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9161 (0.9994)	Acc@1 89.844 (86.993)	Acc@5 99.219 (98.813)
Epoch: [164][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0240 (1.0010)	Acc@1 85.938 (86.879)	Acc@5 96.875 (98.803)
Epoch: [164][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0203 (1.0044)	Acc@1 84.375 (86.812)	Acc@5 98.438 (98.753)
Epoch: [164][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9513 (1.0045)	Acc@1 89.062 (86.796)	Acc@5 100.000 (98.743)
Epoch: [164][170/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 0.9555 (1.0068)	Acc@1 89.062 (86.751)	Acc@5 99.219 (98.734)
Epoch: [164][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9809 (1.0098)	Acc@1 86.719 (86.658)	Acc@5 99.219 (98.718)
Epoch: [164][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0274 (1.0117)	Acc@1 87.500 (86.629)	Acc@5 98.438 (98.712)
Epoch: [164][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2343 (1.0151)	Acc@1 80.469 (86.513)	Acc@5 96.875 (98.682)
Epoch: [164][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9444 (1.0151)	Acc@1 86.719 (86.504)	Acc@5 99.219 (98.678)
Epoch: [164][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0701 (1.0195)	Acc@1 88.281 (86.383)	Acc@5 97.656 (98.660)
Epoch: [164][230/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.1126 (1.0210)	Acc@1 83.594 (86.337)	Acc@5 97.656 (98.651)
Epoch: [164][240/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0116 (1.0227)	Acc@1 85.938 (86.258)	Acc@5 100.000 (98.658)
Epoch: [164][250/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.1293 (1.0234)	Acc@1 82.812 (86.255)	Acc@5 99.219 (98.658)
Epoch: [164][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2570 (1.0251)	Acc@1 78.906 (86.174)	Acc@5 96.875 (98.671)
Epoch: [164][270/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0732 (1.0278)	Acc@1 87.500 (86.119)	Acc@5 97.656 (98.651)
Epoch: [164][280/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0437 (1.0278)	Acc@1 85.156 (86.093)	Acc@5 98.438 (98.660)
Epoch: [164][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0323 (1.0298)	Acc@1 86.719 (86.015)	Acc@5 100.000 (98.650)
Epoch: [164][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1689 (1.0299)	Acc@1 83.594 (86.010)	Acc@5 98.438 (98.640)
Epoch: [164][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9702 (1.0305)	Acc@1 85.938 (85.983)	Acc@5 99.219 (98.643)
Epoch: [164][320/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0332 (1.0325)	Acc@1 89.062 (85.945)	Acc@5 98.438 (98.644)
Epoch: [164][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0409 (1.0323)	Acc@1 85.938 (85.942)	Acc@5 97.656 (98.650)
Epoch: [164][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0439 (1.0330)	Acc@1 82.812 (85.910)	Acc@5 97.656 (98.657)
Epoch: [164][350/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 0.9282 (1.0328)	Acc@1 86.719 (85.897)	Acc@5 99.219 (98.653)
Epoch: [164][360/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0185 (1.0335)	Acc@1 87.500 (85.868)	Acc@5 98.438 (98.660)
Epoch: [164][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0449 (1.0348)	Acc@1 85.938 (85.826)	Acc@5 99.219 (98.652)
Epoch: [164][380/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.1119 (1.0343)	Acc@1 82.812 (85.843)	Acc@5 96.875 (98.655)
Epoch: [164][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 1.0538 (1.0358)	Acc@1 86.250 (85.794)	Acc@5 97.500 (98.650)
num momentum params: 26
[0.010000000000000002, 1.0358120685195922, 1.3878381365537644, 85.794, 64.86, tensor(0.5685, device='cuda:0', grad_fn=<DivBackward0>), 5.330255031585693, 0.39635181427001953]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [165 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [165][0/391]	Time 0.068 (0.068)	Data 0.177 (0.177)	Loss 0.9795 (0.9795)	Acc@1 86.719 (86.719)	Acc@5 98.438 (98.438)
Epoch: [165][10/391]	Time 0.014 (0.022)	Data 0.001 (0.017)	Loss 1.0335 (0.9999)	Acc@1 84.375 (86.577)	Acc@5 96.094 (98.438)
Epoch: [165][20/391]	Time 0.016 (0.018)	Data 0.001 (0.010)	Loss 0.9863 (0.9943)	Acc@1 85.938 (86.905)	Acc@5 99.219 (98.735)
Epoch: [165][30/391]	Time 0.013 (0.017)	Data 0.001 (0.007)	Loss 1.0121 (1.0025)	Acc@1 85.938 (86.870)	Acc@5 99.219 (98.538)
Epoch: [165][40/391]	Time 0.015 (0.016)	Data 0.001 (0.006)	Loss 1.0432 (1.0111)	Acc@1 88.281 (86.890)	Acc@5 97.656 (98.495)
Epoch: [165][50/391]	Time 0.014 (0.015)	Data 0.001 (0.005)	Loss 0.9035 (1.0111)	Acc@1 90.625 (86.918)	Acc@5 99.219 (98.637)
Epoch: [165][60/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 1.0442 (1.0124)	Acc@1 86.719 (86.693)	Acc@5 96.875 (98.681)
Epoch: [165][70/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 0.9184 (1.0077)	Acc@1 92.188 (86.873)	Acc@5 98.438 (98.691)
Epoch: [165][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 0.9818 (1.0032)	Acc@1 84.375 (87.114)	Acc@5 100.000 (98.736)
Epoch: [165][90/391]	Time 0.014 (0.015)	Data 0.001 (0.003)	Loss 0.9643 (1.0001)	Acc@1 89.062 (87.234)	Acc@5 98.438 (98.721)
Epoch: [165][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0005 (0.9993)	Acc@1 87.500 (87.260)	Acc@5 99.219 (98.662)
Epoch: [165][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.1122 (1.0016)	Acc@1 87.500 (87.282)	Acc@5 96.875 (98.642)
Epoch: [165][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9686 (1.0025)	Acc@1 88.281 (87.203)	Acc@5 99.219 (98.631)
Epoch: [165][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9965 (1.0023)	Acc@1 89.062 (87.208)	Acc@5 96.875 (98.587)
Epoch: [165][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0410 (1.0011)	Acc@1 85.156 (87.223)	Acc@5 100.000 (98.604)
Epoch: [165][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9358 (1.0025)	Acc@1 89.062 (87.159)	Acc@5 99.219 (98.588)
Epoch: [165][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8563 (1.0001)	Acc@1 91.406 (87.170)	Acc@5 99.219 (98.627)
Epoch: [165][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0578 (0.9994)	Acc@1 82.812 (87.180)	Acc@5 97.656 (98.625)
Epoch: [165][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0471 (1.0000)	Acc@1 81.250 (87.116)	Acc@5 98.438 (98.649)
Epoch: [165][190/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 1.1604 (1.0038)	Acc@1 77.344 (86.952)	Acc@5 96.875 (98.630)
Epoch: [165][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9723 (1.0043)	Acc@1 85.938 (86.921)	Acc@5 99.219 (98.659)
Epoch: [165][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9999 (1.0081)	Acc@1 86.719 (86.774)	Acc@5 98.438 (98.623)
Epoch: [165][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1563 (1.0109)	Acc@1 81.250 (86.645)	Acc@5 98.438 (98.628)
Epoch: [165][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1330 (1.0126)	Acc@1 82.812 (86.621)	Acc@5 96.875 (98.607)
Epoch: [165][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1236 (1.0124)	Acc@1 83.594 (86.583)	Acc@5 96.094 (98.622)
Epoch: [165][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9820 (1.0127)	Acc@1 87.500 (86.566)	Acc@5 99.219 (98.615)
Epoch: [165][260/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0176 (1.0133)	Acc@1 86.719 (86.524)	Acc@5 100.000 (98.626)
Epoch: [165][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0563 (1.0173)	Acc@1 85.156 (86.393)	Acc@5 96.875 (98.613)
Epoch: [165][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0637 (1.0177)	Acc@1 85.938 (86.388)	Acc@5 99.219 (98.618)
Epoch: [165][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0465 (1.0198)	Acc@1 85.938 (86.319)	Acc@5 100.000 (98.604)
Epoch: [165][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0766 (1.0200)	Acc@1 82.031 (86.322)	Acc@5 100.000 (98.622)
Epoch: [165][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0175 (1.0227)	Acc@1 89.062 (86.246)	Acc@5 98.438 (98.608)
Epoch: [165][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9712 (1.0245)	Acc@1 86.719 (86.178)	Acc@5 100.000 (98.608)
Epoch: [165][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1891 (1.0261)	Acc@1 81.250 (86.136)	Acc@5 96.875 (98.596)
Epoch: [165][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0954 (1.0274)	Acc@1 84.375 (86.080)	Acc@5 98.438 (98.577)
Epoch: [165][350/391]	Time 0.014 (0.014)	Data 0.002 (0.002)	Loss 1.0026 (1.0286)	Acc@1 87.500 (86.027)	Acc@5 99.219 (98.580)
Epoch: [165][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1391 (1.0303)	Acc@1 83.594 (85.974)	Acc@5 97.656 (98.576)
Epoch: [165][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1256 (1.0329)	Acc@1 82.031 (85.900)	Acc@5 98.438 (98.555)
Epoch: [165][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1932 (1.0339)	Acc@1 78.906 (85.843)	Acc@5 97.656 (98.548)
Epoch: [165][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 1.1387 (1.0353)	Acc@1 80.000 (85.806)	Acc@5 97.500 (98.524)
num momentum params: 26
[0.010000000000000002, 1.035319287071228, 1.4947234255075454, 85.806, 63.4, tensor(0.5635, device='cuda:0', grad_fn=<DivBackward0>), 5.333101272583008, 0.40517163276672363]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [166 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [166][0/391]	Time 0.066 (0.066)	Data 0.182 (0.182)	Loss 1.0126 (1.0126)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [166][10/391]	Time 0.015 (0.020)	Data 0.001 (0.018)	Loss 1.1305 (1.0066)	Acc@1 82.031 (86.648)	Acc@5 97.656 (99.077)
Epoch: [166][20/391]	Time 0.013 (0.018)	Data 0.001 (0.010)	Loss 0.9835 (1.0171)	Acc@1 85.938 (86.124)	Acc@5 99.219 (98.810)
Epoch: [166][30/391]	Time 0.014 (0.017)	Data 0.001 (0.007)	Loss 0.9426 (0.9930)	Acc@1 88.281 (87.122)	Acc@5 98.438 (98.916)
Epoch: [166][40/391]	Time 0.014 (0.016)	Data 0.001 (0.006)	Loss 0.9162 (0.9917)	Acc@1 89.844 (87.214)	Acc@5 98.438 (98.857)
Epoch: [166][50/391]	Time 0.013 (0.016)	Data 0.001 (0.005)	Loss 1.0716 (0.9927)	Acc@1 81.250 (87.025)	Acc@5 96.875 (98.851)
Epoch: [166][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 0.9072 (0.9870)	Acc@1 90.625 (87.231)	Acc@5 98.438 (98.886)
Epoch: [166][70/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 1.0283 (0.9804)	Acc@1 85.156 (87.599)	Acc@5 99.219 (98.922)
Epoch: [166][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.0019 (0.9780)	Acc@1 89.062 (87.645)	Acc@5 100.000 (98.987)
Epoch: [166][90/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 1.0566 (0.9779)	Acc@1 85.938 (87.569)	Acc@5 96.875 (98.987)
Epoch: [166][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9213 (0.9796)	Acc@1 90.625 (87.585)	Acc@5 99.219 (98.940)
Epoch: [166][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0634 (0.9783)	Acc@1 84.375 (87.606)	Acc@5 99.219 (98.958)
Epoch: [166][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9280 (0.9775)	Acc@1 90.625 (87.642)	Acc@5 99.219 (98.960)
Epoch: [166][130/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 1.0663 (0.9791)	Acc@1 82.812 (87.536)	Acc@5 99.219 (98.968)
Epoch: [166][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0201 (0.9825)	Acc@1 84.375 (87.367)	Acc@5 96.875 (98.942)
Epoch: [166][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9616 (0.9828)	Acc@1 89.062 (87.340)	Acc@5 100.000 (98.929)
Epoch: [166][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0094 (0.9830)	Acc@1 82.812 (87.316)	Acc@5 100.000 (98.932)
Epoch: [166][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9989 (0.9854)	Acc@1 86.719 (87.235)	Acc@5 98.438 (98.894)
Epoch: [166][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9675 (0.9890)	Acc@1 87.500 (87.137)	Acc@5 99.219 (98.878)
Epoch: [166][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0118 (0.9884)	Acc@1 86.719 (87.111)	Acc@5 99.219 (98.879)
Epoch: [166][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8920 (0.9893)	Acc@1 88.281 (87.049)	Acc@5 100.000 (98.892)
Epoch: [166][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0749 (0.9899)	Acc@1 85.938 (86.993)	Acc@5 98.438 (98.882)
Epoch: [166][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9727 (0.9923)	Acc@1 87.500 (86.878)	Acc@5 99.219 (98.872)
Epoch: [166][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0622 (0.9928)	Acc@1 87.500 (86.841)	Acc@5 97.656 (98.877)
Epoch: [166][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0680 (0.9940)	Acc@1 85.938 (86.771)	Acc@5 96.875 (98.872)
Epoch: [166][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9619 (0.9955)	Acc@1 89.062 (86.756)	Acc@5 98.438 (98.870)
Epoch: [166][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0531 (0.9973)	Acc@1 85.938 (86.719)	Acc@5 97.656 (98.857)
Epoch: [166][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1129 (0.9996)	Acc@1 85.156 (86.641)	Acc@5 97.656 (98.850)
Epoch: [166][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0996 (1.0005)	Acc@1 84.375 (86.608)	Acc@5 96.875 (98.846)
Epoch: [166][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0090 (1.0014)	Acc@1 89.062 (86.558)	Acc@5 98.438 (98.840)
Epoch: [166][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0026 (1.0028)	Acc@1 84.375 (86.529)	Acc@5 98.438 (98.816)
Epoch: [166][310/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0792 (1.0053)	Acc@1 86.719 (86.463)	Acc@5 100.000 (98.809)
Epoch: [166][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1080 (1.0071)	Acc@1 83.594 (86.405)	Acc@5 98.438 (98.807)
Epoch: [166][330/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.1187 (1.0101)	Acc@1 82.031 (86.275)	Acc@5 97.656 (98.799)
Epoch: [166][340/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.1821 (1.0130)	Acc@1 83.594 (86.206)	Acc@5 96.875 (98.763)
Epoch: [166][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1933 (1.0144)	Acc@1 78.906 (86.142)	Acc@5 99.219 (98.771)
Epoch: [166][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0338 (1.0148)	Acc@1 89.844 (86.156)	Acc@5 96.094 (98.756)
Epoch: [166][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0866 (1.0158)	Acc@1 83.594 (86.114)	Acc@5 98.438 (98.749)
Epoch: [166][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1380 (1.0170)	Acc@1 82.812 (86.048)	Acc@5 97.656 (98.737)
Epoch: [166][390/391]	Time 0.019 (0.014)	Data 0.001 (0.002)	Loss 1.0654 (1.0190)	Acc@1 81.250 (85.984)	Acc@5 98.750 (98.710)
num momentum params: 26
[0.010000000000000002, 1.0190219509887695, 1.455740728378296, 85.984, 64.39, tensor(0.5681, device='cuda:0', grad_fn=<DivBackward0>), 5.298750877380371, 0.3932418823242187]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [167 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [167][0/391]	Time 0.070 (0.070)	Data 0.171 (0.171)	Loss 0.8406 (0.8406)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)
Epoch: [167][10/391]	Time 0.014 (0.020)	Data 0.001 (0.017)	Loss 1.0798 (0.9652)	Acc@1 82.812 (87.855)	Acc@5 98.438 (99.148)
Epoch: [167][20/391]	Time 0.013 (0.018)	Data 0.001 (0.010)	Loss 0.9599 (0.9573)	Acc@1 86.719 (87.872)	Acc@5 99.219 (99.033)
Epoch: [167][30/391]	Time 0.014 (0.017)	Data 0.001 (0.007)	Loss 0.9721 (0.9511)	Acc@1 86.719 (88.130)	Acc@5 100.000 (99.143)
Epoch: [167][40/391]	Time 0.014 (0.016)	Data 0.001 (0.006)	Loss 0.9556 (0.9534)	Acc@1 88.281 (88.091)	Acc@5 98.438 (99.123)
Epoch: [167][50/391]	Time 0.014 (0.015)	Data 0.001 (0.005)	Loss 1.0214 (0.9543)	Acc@1 84.375 (88.174)	Acc@5 99.219 (99.157)
Epoch: [167][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.0704 (0.9569)	Acc@1 81.250 (88.012)	Acc@5 100.000 (99.168)
Epoch: [167][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 0.9901 (0.9553)	Acc@1 85.156 (88.050)	Acc@5 100.000 (99.186)
Epoch: [167][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 0.9823 (0.9546)	Acc@1 86.719 (88.166)	Acc@5 98.438 (99.171)
Epoch: [167][90/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 1.0315 (0.9594)	Acc@1 85.938 (87.972)	Acc@5 97.656 (99.124)
Epoch: [167][100/391]	Time 0.014 (0.015)	Data 0.001 (0.003)	Loss 1.0336 (0.9637)	Acc@1 84.375 (87.802)	Acc@5 99.219 (99.080)
Epoch: [167][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9543 (0.9690)	Acc@1 90.625 (87.690)	Acc@5 99.219 (98.986)
Epoch: [167][120/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 0.9632 (0.9727)	Acc@1 87.500 (87.500)	Acc@5 100.000 (98.941)
Epoch: [167][130/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 1.0530 (0.9752)	Acc@1 85.938 (87.452)	Acc@5 99.219 (98.927)
Epoch: [167][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9082 (0.9749)	Acc@1 92.969 (87.478)	Acc@5 100.000 (98.953)
Epoch: [167][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9457 (0.9750)	Acc@1 90.625 (87.474)	Acc@5 98.438 (98.960)
Epoch: [167][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9755 (0.9746)	Acc@1 86.719 (87.456)	Acc@5 99.219 (98.957)
Epoch: [167][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8984 (0.9729)	Acc@1 89.062 (87.468)	Acc@5 98.438 (98.986)
Epoch: [167][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8740 (0.9743)	Acc@1 92.969 (87.409)	Acc@5 100.000 (98.986)
Epoch: [167][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0574 (0.9760)	Acc@1 84.375 (87.324)	Acc@5 98.438 (98.973)
Epoch: [167][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0990 (0.9793)	Acc@1 82.812 (87.189)	Acc@5 96.875 (98.947)
Epoch: [167][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9420 (0.9807)	Acc@1 89.062 (87.133)	Acc@5 98.438 (98.937)
Epoch: [167][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9837 (0.9818)	Acc@1 87.500 (87.072)	Acc@5 97.656 (98.954)
Epoch: [167][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0686 (0.9826)	Acc@1 84.375 (87.020)	Acc@5 98.438 (98.965)
Epoch: [167][240/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.1903 (0.9870)	Acc@1 78.906 (86.868)	Acc@5 97.656 (98.927)
Epoch: [167][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9513 (0.9880)	Acc@1 88.281 (86.809)	Acc@5 99.219 (98.936)
Epoch: [167][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1165 (0.9899)	Acc@1 82.812 (86.752)	Acc@5 98.438 (98.937)
Epoch: [167][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9951 (0.9912)	Acc@1 85.938 (86.736)	Acc@5 99.219 (98.930)
Epoch: [167][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1942 (0.9921)	Acc@1 83.594 (86.702)	Acc@5 95.312 (98.910)
Epoch: [167][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9281 (0.9929)	Acc@1 89.844 (86.649)	Acc@5 98.438 (98.913)
Epoch: [167][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0413 (0.9945)	Acc@1 83.594 (86.581)	Acc@5 98.438 (98.912)
Epoch: [167][310/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0610 (0.9974)	Acc@1 84.375 (86.488)	Acc@5 99.219 (98.877)
Epoch: [167][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0384 (0.9977)	Acc@1 85.156 (86.458)	Acc@5 98.438 (98.876)
Epoch: [167][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9543 (0.9985)	Acc@1 89.062 (86.445)	Acc@5 97.656 (98.867)
Epoch: [167][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0311 (0.9996)	Acc@1 84.375 (86.421)	Acc@5 99.219 (98.861)
Epoch: [167][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1556 (1.0014)	Acc@1 82.031 (86.389)	Acc@5 96.875 (98.845)
Epoch: [167][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0917 (1.0028)	Acc@1 82.031 (86.344)	Acc@5 97.656 (98.834)
Epoch: [167][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2429 (1.0047)	Acc@1 78.906 (86.249)	Acc@5 95.312 (98.827)
Epoch: [167][380/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0453 (1.0047)	Acc@1 84.375 (86.257)	Acc@5 99.219 (98.819)
Epoch: [167][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 1.0190 (1.0066)	Acc@1 86.250 (86.200)	Acc@5 98.750 (98.800)
num momentum params: 26
[0.010000000000000002, 1.006581889190674, 1.4706077587604522, 86.2, 64.79, tensor(0.5711, device='cuda:0', grad_fn=<DivBackward0>), 5.342150688171387, 0.399249792098999]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [168 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [168][0/391]	Time 0.068 (0.068)	Data 0.179 (0.179)	Loss 0.8964 (0.8964)	Acc@1 89.062 (89.062)	Acc@5 98.438 (98.438)
Epoch: [168][10/391]	Time 0.014 (0.021)	Data 0.001 (0.017)	Loss 1.1348 (0.9578)	Acc@1 83.594 (87.997)	Acc@5 98.438 (98.722)
Epoch: [168][20/391]	Time 0.015 (0.018)	Data 0.001 (0.010)	Loss 0.9323 (0.9558)	Acc@1 86.719 (87.612)	Acc@5 98.438 (98.884)
Epoch: [168][30/391]	Time 0.014 (0.017)	Data 0.001 (0.007)	Loss 0.8921 (0.9564)	Acc@1 90.625 (87.676)	Acc@5 100.000 (99.017)
Epoch: [168][40/391]	Time 0.013 (0.016)	Data 0.001 (0.006)	Loss 0.9522 (0.9633)	Acc@1 86.719 (87.481)	Acc@5 99.219 (98.990)
Epoch: [168][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 1.0979 (0.9663)	Acc@1 86.719 (87.469)	Acc@5 97.656 (98.974)
Epoch: [168][60/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 0.9768 (0.9618)	Acc@1 87.500 (87.526)	Acc@5 99.219 (99.014)
Epoch: [168][70/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 0.8757 (0.9607)	Acc@1 90.625 (87.588)	Acc@5 100.000 (99.054)
Epoch: [168][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 0.8946 (0.9654)	Acc@1 89.062 (87.413)	Acc@5 100.000 (99.055)
Epoch: [168][90/391]	Time 0.014 (0.015)	Data 0.001 (0.003)	Loss 0.9305 (0.9655)	Acc@1 88.281 (87.483)	Acc@5 98.438 (99.047)
Epoch: [168][100/391]	Time 0.017 (0.015)	Data 0.001 (0.003)	Loss 1.0180 (0.9676)	Acc@1 85.938 (87.430)	Acc@5 97.656 (99.002)
Epoch: [168][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.1519 (0.9701)	Acc@1 82.812 (87.352)	Acc@5 97.656 (98.972)
Epoch: [168][120/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 1.0848 (0.9717)	Acc@1 80.469 (87.268)	Acc@5 97.656 (98.954)
Epoch: [168][130/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 0.9144 (0.9695)	Acc@1 88.281 (87.285)	Acc@5 99.219 (98.962)
Epoch: [168][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0697 (0.9746)	Acc@1 82.031 (87.084)	Acc@5 98.438 (98.931)
Epoch: [168][150/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 1.0104 (0.9752)	Acc@1 85.156 (87.045)	Acc@5 98.438 (98.934)
Epoch: [168][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1245 (0.9752)	Acc@1 82.812 (87.058)	Acc@5 97.656 (98.952)
Epoch: [168][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1264 (0.9796)	Acc@1 84.375 (87.048)	Acc@5 96.094 (98.945)
Epoch: [168][180/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 0.9366 (0.9820)	Acc@1 89.844 (86.995)	Acc@5 100.000 (98.934)
Epoch: [168][190/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 0.8516 (0.9809)	Acc@1 89.844 (86.960)	Acc@5 100.000 (98.965)
Epoch: [168][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8702 (0.9835)	Acc@1 94.531 (86.886)	Acc@5 98.438 (98.923)
Epoch: [168][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9147 (0.9847)	Acc@1 89.844 (86.841)	Acc@5 99.219 (98.919)
Epoch: [168][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8741 (0.9852)	Acc@1 91.406 (86.846)	Acc@5 99.219 (98.911)
Epoch: [168][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1261 (0.9872)	Acc@1 84.375 (86.766)	Acc@5 97.656 (98.894)
Epoch: [168][240/391]	Time 0.012 (0.014)	Data 0.002 (0.002)	Loss 0.9880 (0.9884)	Acc@1 86.719 (86.771)	Acc@5 99.219 (98.882)
Epoch: [168][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9674 (0.9905)	Acc@1 83.594 (86.700)	Acc@5 98.438 (98.851)
Epoch: [168][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9537 (0.9907)	Acc@1 85.938 (86.704)	Acc@5 99.219 (98.845)
Epoch: [168][270/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0365 (0.9914)	Acc@1 86.719 (86.676)	Acc@5 97.656 (98.835)
Epoch: [168][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1370 (0.9932)	Acc@1 82.031 (86.605)	Acc@5 98.438 (98.818)
Epoch: [168][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0809 (0.9939)	Acc@1 80.469 (86.585)	Acc@5 99.219 (98.819)
Epoch: [168][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9758 (0.9956)	Acc@1 89.062 (86.560)	Acc@5 97.656 (98.798)
Epoch: [168][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1500 (0.9981)	Acc@1 84.375 (86.488)	Acc@5 98.438 (98.794)
Epoch: [168][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0989 (1.0001)	Acc@1 83.594 (86.419)	Acc@5 99.219 (98.790)
Epoch: [168][330/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 1.1342 (1.0013)	Acc@1 81.250 (86.369)	Acc@5 98.438 (98.784)
Epoch: [168][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9496 (1.0029)	Acc@1 87.500 (86.267)	Acc@5 98.438 (98.783)
Epoch: [168][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2256 (1.0060)	Acc@1 76.562 (86.162)	Acc@5 98.438 (98.765)
Epoch: [168][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9278 (1.0086)	Acc@1 87.500 (86.095)	Acc@5 97.656 (98.745)
Epoch: [168][370/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 1.0011 (1.0095)	Acc@1 84.375 (86.068)	Acc@5 99.219 (98.745)
Epoch: [168][380/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.1258 (1.0098)	Acc@1 84.375 (86.073)	Acc@5 97.656 (98.733)
Epoch: [168][390/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 1.2494 (1.0117)	Acc@1 81.250 (86.040)	Acc@5 98.750 (98.716)
num momentum params: 26
[0.010000000000000002, 1.011698929901123, 1.4510707676410675, 86.04, 64.26, tensor(0.5656, device='cuda:0', grad_fn=<DivBackward0>), 5.316940546035767, 0.39649009704589844]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [169 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [169][0/391]	Time 0.065 (0.065)	Data 0.169 (0.169)	Loss 0.9574 (0.9574)	Acc@1 88.281 (88.281)	Acc@5 98.438 (98.438)
Epoch: [169][10/391]	Time 0.014 (0.021)	Data 0.002 (0.017)	Loss 1.0496 (0.9501)	Acc@1 84.375 (87.997)	Acc@5 97.656 (98.651)
Epoch: [169][20/391]	Time 0.015 (0.018)	Data 0.001 (0.010)	Loss 0.8738 (0.9467)	Acc@1 89.844 (88.058)	Acc@5 99.219 (98.810)
Epoch: [169][30/391]	Time 0.015 (0.017)	Data 0.001 (0.007)	Loss 1.0146 (0.9434)	Acc@1 85.156 (88.231)	Acc@5 99.219 (98.866)
Epoch: [169][40/391]	Time 0.015 (0.016)	Data 0.001 (0.006)	Loss 0.8058 (0.9455)	Acc@1 93.750 (88.148)	Acc@5 99.219 (98.952)
Epoch: [169][50/391]	Time 0.013 (0.016)	Data 0.001 (0.005)	Loss 1.0451 (0.9465)	Acc@1 87.500 (88.297)	Acc@5 96.875 (98.866)
Epoch: [169][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 0.9499 (0.9465)	Acc@1 89.062 (88.230)	Acc@5 98.438 (98.886)
Epoch: [169][70/391]	Time 0.014 (0.015)	Data 0.002 (0.004)	Loss 0.9750 (0.9470)	Acc@1 85.156 (88.105)	Acc@5 99.219 (98.922)
Epoch: [169][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.0030 (0.9504)	Acc@1 85.938 (87.934)	Acc@5 97.656 (98.910)
Epoch: [169][90/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 0.8406 (0.9473)	Acc@1 88.281 (88.015)	Acc@5 99.219 (98.935)
Epoch: [169][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9106 (0.9504)	Acc@1 90.625 (87.856)	Acc@5 100.000 (98.948)
Epoch: [169][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0177 (0.9541)	Acc@1 84.375 (87.746)	Acc@5 99.219 (98.951)
Epoch: [169][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.8377 (0.9556)	Acc@1 92.188 (87.687)	Acc@5 100.000 (98.967)
Epoch: [169][130/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 0.9819 (0.9569)	Acc@1 88.281 (87.673)	Acc@5 99.219 (98.938)
Epoch: [169][140/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 0.9403 (0.9552)	Acc@1 86.719 (87.683)	Acc@5 99.219 (98.953)
Epoch: [169][150/391]	Time 0.012 (0.014)	Data 0.001 (0.003)	Loss 1.0407 (0.9563)	Acc@1 82.031 (87.603)	Acc@5 100.000 (98.981)
Epoch: [169][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8914 (0.9553)	Acc@1 89.062 (87.602)	Acc@5 99.219 (98.981)
Epoch: [169][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8769 (0.9567)	Acc@1 92.188 (87.532)	Acc@5 100.000 (98.963)
Epoch: [169][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1075 (0.9611)	Acc@1 84.375 (87.422)	Acc@5 98.438 (98.938)
Epoch: [169][190/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0450 (0.9622)	Acc@1 85.156 (87.373)	Acc@5 98.438 (98.920)
Epoch: [169][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0458 (0.9649)	Acc@1 81.250 (87.236)	Acc@5 100.000 (98.931)
Epoch: [169][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9646 (0.9669)	Acc@1 88.281 (87.163)	Acc@5 96.875 (98.915)
Epoch: [169][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0598 (0.9699)	Acc@1 89.844 (87.093)	Acc@5 96.094 (98.901)
Epoch: [169][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0564 (0.9721)	Acc@1 82.812 (87.054)	Acc@5 97.656 (98.874)
Epoch: [169][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0533 (0.9721)	Acc@1 85.156 (87.059)	Acc@5 97.656 (98.865)
Epoch: [169][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1051 (0.9756)	Acc@1 82.812 (86.952)	Acc@5 97.656 (98.845)
Epoch: [169][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9423 (0.9791)	Acc@1 89.844 (86.830)	Acc@5 99.219 (98.830)
Epoch: [169][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0099 (0.9812)	Acc@1 85.156 (86.768)	Acc@5 100.000 (98.824)
Epoch: [169][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9928 (0.9839)	Acc@1 86.719 (86.658)	Acc@5 100.000 (98.818)
Epoch: [169][290/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.1846 (0.9872)	Acc@1 75.781 (86.520)	Acc@5 97.656 (98.784)
Epoch: [169][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0241 (0.9890)	Acc@1 87.500 (86.480)	Acc@5 96.875 (98.770)
Epoch: [169][310/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 0.9112 (0.9905)	Acc@1 89.844 (86.440)	Acc@5 100.000 (98.759)
Epoch: [169][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9981 (0.9922)	Acc@1 87.500 (86.390)	Acc@5 98.438 (98.751)
Epoch: [169][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.3621 (0.9953)	Acc@1 73.438 (86.313)	Acc@5 96.875 (98.742)
Epoch: [169][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0364 (0.9961)	Acc@1 85.156 (86.306)	Acc@5 98.438 (98.733)
Epoch: [169][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9509 (0.9962)	Acc@1 86.719 (86.296)	Acc@5 99.219 (98.738)
Epoch: [169][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0003 (0.9981)	Acc@1 87.500 (86.219)	Acc@5 97.656 (98.743)
Epoch: [169][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1510 (1.0004)	Acc@1 82.031 (86.135)	Acc@5 99.219 (98.743)
Epoch: [169][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0110 (1.0020)	Acc@1 88.281 (86.122)	Acc@5 100.000 (98.725)
Epoch: [169][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 1.1630 (1.0041)	Acc@1 81.250 (86.064)	Acc@5 98.750 (98.718)
num momentum params: 26
[0.010000000000000002, 1.0041343613433837, 1.4824661445617675, 86.064, 63.62, tensor(0.5679, device='cuda:0', grad_fn=<DivBackward0>), 5.3324785232543945, 0.40341830253601074]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [170 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [170][0/391]	Time 0.063 (0.063)	Data 0.182 (0.182)	Loss 0.9239 (0.9239)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.219)
Epoch: [170][10/391]	Time 0.015 (0.021)	Data 0.001 (0.018)	Loss 0.9887 (0.9622)	Acc@1 86.719 (87.926)	Acc@5 99.219 (98.509)
Epoch: [170][20/391]	Time 0.014 (0.018)	Data 0.001 (0.010)	Loss 0.9170 (0.9570)	Acc@1 89.844 (87.649)	Acc@5 98.438 (98.735)
Epoch: [170][30/391]	Time 0.014 (0.017)	Data 0.001 (0.007)	Loss 0.9077 (0.9485)	Acc@1 89.844 (87.727)	Acc@5 100.000 (98.841)
Epoch: [170][40/391]	Time 0.015 (0.016)	Data 0.001 (0.006)	Loss 0.9752 (0.9444)	Acc@1 87.500 (87.824)	Acc@5 99.219 (98.990)
Epoch: [170][50/391]	Time 0.013 (0.016)	Data 0.001 (0.005)	Loss 0.9047 (0.9346)	Acc@1 89.062 (88.205)	Acc@5 100.000 (99.096)
Epoch: [170][60/391]	Time 0.023 (0.015)	Data 0.001 (0.004)	Loss 0.9661 (0.9369)	Acc@1 87.500 (88.281)	Acc@5 99.219 (99.116)
Epoch: [170][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 0.9451 (0.9382)	Acc@1 85.938 (88.083)	Acc@5 99.219 (99.120)
Epoch: [170][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.1561 (0.9459)	Acc@1 82.031 (87.780)	Acc@5 97.656 (99.103)
Epoch: [170][90/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 0.9629 (0.9494)	Acc@1 88.281 (87.689)	Acc@5 99.219 (99.073)
Epoch: [170][100/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 0.9262 (0.9473)	Acc@1 88.281 (87.740)	Acc@5 100.000 (99.080)
Epoch: [170][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9878 (0.9477)	Acc@1 90.625 (87.732)	Acc@5 99.219 (99.078)
Epoch: [170][120/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 0.9525 (0.9494)	Acc@1 89.062 (87.668)	Acc@5 98.438 (99.077)
Epoch: [170][130/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 0.8571 (0.9496)	Acc@1 91.406 (87.685)	Acc@5 100.000 (99.088)
Epoch: [170][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9408 (0.9504)	Acc@1 89.062 (87.672)	Acc@5 98.438 (99.086)
Epoch: [170][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9728 (0.9521)	Acc@1 87.500 (87.645)	Acc@5 98.438 (99.064)
Epoch: [170][160/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.8964 (0.9505)	Acc@1 88.281 (87.670)	Acc@5 99.219 (99.093)
Epoch: [170][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9534 (0.9545)	Acc@1 84.375 (87.527)	Acc@5 100.000 (99.086)
Epoch: [170][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9025 (0.9555)	Acc@1 88.281 (87.500)	Acc@5 99.219 (99.068)
Epoch: [170][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9571 (0.9599)	Acc@1 85.938 (87.316)	Acc@5 97.656 (99.059)
Epoch: [170][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0654 (0.9621)	Acc@1 83.594 (87.240)	Acc@5 98.438 (99.048)
Epoch: [170][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9077 (0.9643)	Acc@1 87.500 (87.189)	Acc@5 99.219 (99.048)
Epoch: [170][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0680 (0.9656)	Acc@1 85.156 (87.150)	Acc@5 99.219 (99.060)
Epoch: [170][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0549 (0.9675)	Acc@1 84.375 (87.098)	Acc@5 98.438 (99.053)
Epoch: [170][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0981 (0.9701)	Acc@1 85.156 (87.020)	Acc@5 96.094 (99.024)
Epoch: [170][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0260 (0.9709)	Acc@1 85.938 (87.024)	Acc@5 96.875 (99.016)
Epoch: [170][260/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 0.9991 (0.9727)	Acc@1 87.500 (86.988)	Acc@5 97.656 (99.003)
Epoch: [170][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9323 (0.9743)	Acc@1 89.062 (86.964)	Acc@5 100.000 (98.985)
Epoch: [170][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0572 (0.9763)	Acc@1 84.375 (86.866)	Acc@5 98.438 (98.974)
Epoch: [170][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9730 (0.9772)	Acc@1 87.500 (86.848)	Acc@5 99.219 (98.961)
Epoch: [170][300/391]	Time 0.014 (0.014)	Data 0.000 (0.002)	Loss 1.1501 (0.9801)	Acc@1 81.250 (86.755)	Acc@5 98.438 (98.946)
Epoch: [170][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9720 (0.9818)	Acc@1 86.719 (86.706)	Acc@5 100.000 (98.937)
Epoch: [170][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9646 (0.9846)	Acc@1 89.062 (86.614)	Acc@5 96.875 (98.924)
Epoch: [170][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9350 (0.9871)	Acc@1 88.281 (86.513)	Acc@5 99.219 (98.907)
Epoch: [170][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0922 (0.9890)	Acc@1 82.812 (86.446)	Acc@5 97.656 (98.877)
Epoch: [170][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9685 (0.9906)	Acc@1 90.625 (86.407)	Acc@5 99.219 (98.874)
Epoch: [170][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9520 (0.9920)	Acc@1 85.938 (86.362)	Acc@5 100.000 (98.870)
Epoch: [170][370/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0229 (0.9948)	Acc@1 85.938 (86.291)	Acc@5 99.219 (98.852)
Epoch: [170][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8605 (0.9956)	Acc@1 92.969 (86.272)	Acc@5 99.219 (98.846)
Epoch: [170][390/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 1.0514 (0.9964)	Acc@1 82.500 (86.244)	Acc@5 98.750 (98.842)
num momentum params: 26
[0.010000000000000002, 0.9963723378372192, 1.4912958526611328, 86.244, 63.42, tensor(0.5704, device='cuda:0', grad_fn=<DivBackward0>), 5.332336664199829, 0.39966607093811035]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [171 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [171][0/391]	Time 0.062 (0.062)	Data 0.177 (0.177)	Loss 0.9380 (0.9380)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)
Epoch: [171][10/391]	Time 0.018 (0.021)	Data 0.001 (0.017)	Loss 0.9180 (0.9392)	Acc@1 87.500 (89.205)	Acc@5 99.219 (99.219)
Epoch: [171][20/391]	Time 0.015 (0.018)	Data 0.001 (0.010)	Loss 1.0042 (0.9418)	Acc@1 81.250 (88.839)	Acc@5 100.000 (99.144)
Epoch: [171][30/391]	Time 0.013 (0.017)	Data 0.002 (0.007)	Loss 0.8728 (0.9311)	Acc@1 91.406 (89.037)	Acc@5 98.438 (99.143)
Epoch: [171][40/391]	Time 0.013 (0.016)	Data 0.002 (0.006)	Loss 0.8537 (0.9262)	Acc@1 92.969 (89.215)	Acc@5 99.219 (99.200)
Epoch: [171][50/391]	Time 0.014 (0.015)	Data 0.001 (0.005)	Loss 0.9075 (0.9337)	Acc@1 89.062 (88.710)	Acc@5 99.219 (99.173)
Epoch: [171][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 0.9242 (0.9327)	Acc@1 88.281 (88.768)	Acc@5 99.219 (99.168)
Epoch: [171][70/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 0.7958 (0.9275)	Acc@1 92.188 (88.875)	Acc@5 100.000 (99.208)
Epoch: [171][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.1312 (0.9342)	Acc@1 84.375 (88.696)	Acc@5 96.094 (99.132)
Epoch: [171][90/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 1.0665 (0.9404)	Acc@1 85.938 (88.599)	Acc@5 98.438 (99.056)
Epoch: [171][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9042 (0.9444)	Acc@1 89.844 (88.359)	Acc@5 99.219 (99.056)
Epoch: [171][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9539 (0.9468)	Acc@1 90.625 (88.331)	Acc@5 98.438 (99.036)
Epoch: [171][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9541 (0.9479)	Acc@1 87.500 (88.230)	Acc@5 99.219 (99.025)
Epoch: [171][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9640 (0.9547)	Acc@1 87.500 (88.031)	Acc@5 99.219 (98.992)
Epoch: [171][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9234 (0.9568)	Acc@1 88.281 (87.916)	Acc@5 100.000 (98.992)
Epoch: [171][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.8938 (0.9573)	Acc@1 89.062 (87.976)	Acc@5 100.000 (98.976)
Epoch: [171][160/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.1502 (0.9597)	Acc@1 81.250 (87.859)	Acc@5 98.438 (98.971)
Epoch: [171][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0980 (0.9627)	Acc@1 87.500 (87.783)	Acc@5 96.875 (98.945)
Epoch: [171][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0091 (0.9621)	Acc@1 88.281 (87.806)	Acc@5 99.219 (98.955)
Epoch: [171][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0762 (0.9629)	Acc@1 80.469 (87.692)	Acc@5 98.438 (98.965)
Epoch: [171][200/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 0.9889 (0.9649)	Acc@1 84.375 (87.574)	Acc@5 97.656 (98.966)
Epoch: [171][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1002 (0.9665)	Acc@1 81.250 (87.459)	Acc@5 98.438 (98.974)
Epoch: [171][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0609 (0.9689)	Acc@1 82.031 (87.369)	Acc@5 97.656 (98.961)
Epoch: [171][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0528 (0.9712)	Acc@1 81.250 (87.287)	Acc@5 97.656 (98.928)
Epoch: [171][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1266 (0.9725)	Acc@1 81.250 (87.237)	Acc@5 99.219 (98.933)
Epoch: [171][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0613 (0.9728)	Acc@1 79.688 (87.192)	Acc@5 99.219 (98.939)
Epoch: [171][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9107 (0.9740)	Acc@1 87.500 (87.087)	Acc@5 100.000 (98.931)
Epoch: [171][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0599 (0.9767)	Acc@1 83.594 (87.013)	Acc@5 98.438 (98.913)
Epoch: [171][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0442 (0.9773)	Acc@1 85.156 (86.961)	Acc@5 99.219 (98.932)
Epoch: [171][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1307 (0.9787)	Acc@1 82.812 (86.925)	Acc@5 97.656 (98.910)
Epoch: [171][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9302 (0.9800)	Acc@1 90.625 (86.911)	Acc@5 100.000 (98.915)
Epoch: [171][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1207 (0.9825)	Acc@1 81.250 (86.847)	Acc@5 98.438 (98.895)
Epoch: [171][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9445 (0.9836)	Acc@1 91.406 (86.831)	Acc@5 97.656 (98.873)
Epoch: [171][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1447 (0.9846)	Acc@1 78.906 (86.775)	Acc@5 98.438 (98.886)
Epoch: [171][340/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 1.0865 (0.9865)	Acc@1 84.375 (86.710)	Acc@5 96.875 (98.861)
Epoch: [171][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0115 (0.9872)	Acc@1 84.375 (86.701)	Acc@5 99.219 (98.858)
Epoch: [171][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0643 (0.9895)	Acc@1 85.938 (86.660)	Acc@5 98.438 (98.836)
Epoch: [171][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0711 (0.9915)	Acc@1 84.375 (86.592)	Acc@5 97.656 (98.821)
Epoch: [171][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0523 (0.9925)	Acc@1 86.719 (86.567)	Acc@5 96.875 (98.807)
Epoch: [171][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 0.8999 (0.9926)	Acc@1 90.000 (86.550)	Acc@5 98.750 (98.810)
num momentum params: 26
[0.010000000000000002, 0.9925943590545654, 1.4857061445713042, 86.55, 63.53, tensor(0.5713, device='cuda:0', grad_fn=<DivBackward0>), 5.318874359130859, 0.3975064754486084]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [172 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [172][0/391]	Time 0.066 (0.066)	Data 0.179 (0.179)	Loss 0.9560 (0.9560)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)
Epoch: [172][10/391]	Time 0.017 (0.021)	Data 0.001 (0.018)	Loss 0.8302 (0.9478)	Acc@1 90.625 (87.571)	Acc@5 99.219 (99.006)
Epoch: [172][20/391]	Time 0.015 (0.018)	Data 0.001 (0.010)	Loss 0.9180 (0.9409)	Acc@1 88.281 (88.095)	Acc@5 99.219 (99.033)
Epoch: [172][30/391]	Time 0.013 (0.017)	Data 0.001 (0.007)	Loss 0.8711 (0.9268)	Acc@1 89.844 (88.306)	Acc@5 98.438 (99.168)
Epoch: [172][40/391]	Time 0.014 (0.016)	Data 0.001 (0.006)	Loss 0.9455 (0.9282)	Acc@1 89.844 (88.319)	Acc@5 98.438 (99.181)
Epoch: [172][50/391]	Time 0.014 (0.016)	Data 0.001 (0.005)	Loss 0.9577 (0.9278)	Acc@1 84.375 (88.281)	Acc@5 99.219 (99.249)
Epoch: [172][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 0.8471 (0.9270)	Acc@1 91.406 (88.384)	Acc@5 100.000 (99.232)
Epoch: [172][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 0.8973 (0.9288)	Acc@1 85.156 (88.204)	Acc@5 100.000 (99.197)
Epoch: [172][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 0.9204 (0.9319)	Acc@1 89.844 (88.175)	Acc@5 98.438 (99.151)
Epoch: [172][90/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 0.9210 (0.9334)	Acc@1 88.281 (88.213)	Acc@5 98.438 (99.107)
Epoch: [172][100/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 0.9960 (0.9321)	Acc@1 84.375 (88.196)	Acc@5 96.875 (99.095)
Epoch: [172][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.1009 (0.9363)	Acc@1 82.812 (88.162)	Acc@5 100.000 (99.106)
Epoch: [172][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9212 (0.9399)	Acc@1 91.406 (88.036)	Acc@5 100.000 (99.103)
Epoch: [172][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0695 (0.9407)	Acc@1 84.375 (88.007)	Acc@5 98.438 (99.094)
Epoch: [172][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9878 (0.9424)	Acc@1 89.062 (87.927)	Acc@5 97.656 (99.069)
Epoch: [172][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9305 (0.9446)	Acc@1 83.594 (87.743)	Acc@5 99.219 (99.074)
Epoch: [172][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1924 (0.9475)	Acc@1 84.375 (87.684)	Acc@5 96.094 (99.025)
Epoch: [172][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9077 (0.9527)	Acc@1 90.625 (87.541)	Acc@5 100.000 (98.972)
Epoch: [172][180/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 0.9848 (0.9541)	Acc@1 89.844 (87.530)	Acc@5 97.656 (98.955)
Epoch: [172][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9892 (0.9555)	Acc@1 85.156 (87.471)	Acc@5 99.219 (98.994)
Epoch: [172][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0121 (0.9565)	Acc@1 85.156 (87.422)	Acc@5 100.000 (99.001)
Epoch: [172][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8218 (0.9565)	Acc@1 92.188 (87.456)	Acc@5 100.000 (98.985)
Epoch: [172][220/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0800 (0.9587)	Acc@1 83.594 (87.422)	Acc@5 98.438 (99.007)
Epoch: [172][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9021 (0.9603)	Acc@1 87.500 (87.392)	Acc@5 100.000 (98.999)
Epoch: [172][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9891 (0.9620)	Acc@1 88.281 (87.305)	Acc@5 98.438 (98.995)
Epoch: [172][250/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 0.8902 (0.9637)	Acc@1 91.406 (87.263)	Acc@5 100.000 (98.992)
Epoch: [172][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0345 (0.9645)	Acc@1 81.250 (87.219)	Acc@5 100.000 (98.991)
Epoch: [172][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0555 (0.9662)	Acc@1 87.500 (87.145)	Acc@5 96.094 (98.974)
Epoch: [172][280/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 0.8661 (0.9680)	Acc@1 92.188 (87.100)	Acc@5 100.000 (98.974)
Epoch: [172][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9114 (0.9712)	Acc@1 89.062 (87.025)	Acc@5 98.438 (98.961)
Epoch: [172][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8869 (0.9711)	Acc@1 92.188 (87.007)	Acc@5 100.000 (98.962)
Epoch: [172][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0622 (0.9728)	Acc@1 87.500 (86.975)	Acc@5 97.656 (98.942)
Epoch: [172][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9968 (0.9743)	Acc@1 85.156 (86.935)	Acc@5 98.438 (98.941)
Epoch: [172][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0055 (0.9762)	Acc@1 85.156 (86.863)	Acc@5 98.438 (98.947)
Epoch: [172][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0011 (0.9778)	Acc@1 86.719 (86.808)	Acc@5 97.656 (98.930)
Epoch: [172][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1178 (0.9793)	Acc@1 78.125 (86.739)	Acc@5 98.438 (98.925)
Epoch: [172][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9630 (0.9797)	Acc@1 86.719 (86.723)	Acc@5 98.438 (98.918)
Epoch: [172][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9676 (0.9805)	Acc@1 85.938 (86.693)	Acc@5 96.875 (98.916)
Epoch: [172][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0439 (0.9816)	Acc@1 85.938 (86.665)	Acc@5 98.438 (98.905)
Epoch: [172][390/391]	Time 0.018 (0.014)	Data 0.001 (0.002)	Loss 1.1175 (0.9830)	Acc@1 77.500 (86.610)	Acc@5 97.500 (98.896)
num momentum params: 26
[0.010000000000000002, 0.9830300804138183, 1.5062668490409852, 86.61, 63.27, tensor(0.5756, device='cuda:0', grad_fn=<DivBackward0>), 5.321213722229004, 0.39720869064331055]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [173 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [173][0/391]	Time 0.063 (0.063)	Data 0.181 (0.181)	Loss 0.9667 (0.9667)	Acc@1 87.500 (87.500)	Acc@5 98.438 (98.438)
Epoch: [173][10/391]	Time 0.015 (0.021)	Data 0.001 (0.017)	Loss 1.0898 (0.9550)	Acc@1 82.031 (87.358)	Acc@5 98.438 (98.722)
Epoch: [173][20/391]	Time 0.016 (0.018)	Data 0.001 (0.010)	Loss 0.9542 (0.9577)	Acc@1 89.062 (87.574)	Acc@5 99.219 (98.735)
Epoch: [173][30/391]	Time 0.013 (0.017)	Data 0.001 (0.007)	Loss 0.9017 (0.9520)	Acc@1 91.406 (87.576)	Acc@5 100.000 (98.967)
Epoch: [173][40/391]	Time 0.015 (0.016)	Data 0.001 (0.006)	Loss 1.0091 (0.9390)	Acc@1 86.719 (87.957)	Acc@5 99.219 (98.971)
Epoch: [173][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 0.8193 (0.9348)	Acc@1 92.188 (88.036)	Acc@5 99.219 (99.050)
Epoch: [173][60/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 0.8713 (0.9338)	Acc@1 92.188 (87.999)	Acc@5 99.219 (99.078)
Epoch: [173][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.0117 (0.9340)	Acc@1 85.156 (87.995)	Acc@5 98.438 (99.087)
Epoch: [173][80/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 0.9644 (0.9360)	Acc@1 89.062 (87.992)	Acc@5 99.219 (99.084)
Epoch: [173][90/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 0.9270 (0.9387)	Acc@1 87.500 (87.981)	Acc@5 97.656 (99.099)
Epoch: [173][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 0.9118 (0.9364)	Acc@1 91.406 (88.157)	Acc@5 99.219 (99.126)
Epoch: [173][110/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 0.8612 (0.9391)	Acc@1 91.406 (88.091)	Acc@5 99.219 (99.099)
Epoch: [173][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9916 (0.9382)	Acc@1 88.281 (88.178)	Acc@5 99.219 (99.077)
Epoch: [173][130/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 0.9799 (0.9411)	Acc@1 86.719 (88.108)	Acc@5 98.438 (99.070)
Epoch: [173][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9054 (0.9394)	Acc@1 90.625 (88.187)	Acc@5 97.656 (99.091)
Epoch: [173][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.8889 (0.9365)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.105)
Epoch: [173][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9850 (0.9419)	Acc@1 83.594 (88.111)	Acc@5 99.219 (99.068)
Epoch: [173][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8680 (0.9400)	Acc@1 92.969 (88.172)	Acc@5 98.438 (99.077)
Epoch: [173][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8932 (0.9420)	Acc@1 91.406 (88.130)	Acc@5 98.438 (99.055)
Epoch: [173][190/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0232 (0.9430)	Acc@1 84.375 (88.077)	Acc@5 98.438 (99.063)
Epoch: [173][200/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 0.9182 (0.9446)	Acc@1 87.500 (88.017)	Acc@5 99.219 (99.071)
Epoch: [173][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9131 (0.9476)	Acc@1 87.500 (87.892)	Acc@5 100.000 (99.063)
Epoch: [173][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0023 (0.9504)	Acc@1 89.844 (87.779)	Acc@5 99.219 (99.063)
Epoch: [173][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9086 (0.9539)	Acc@1 90.625 (87.656)	Acc@5 100.000 (99.056)
Epoch: [173][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0591 (0.9569)	Acc@1 84.375 (87.562)	Acc@5 98.438 (99.027)
Epoch: [173][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9964 (0.9580)	Acc@1 85.156 (87.556)	Acc@5 98.438 (98.988)
Epoch: [173][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0145 (0.9608)	Acc@1 82.812 (87.443)	Acc@5 99.219 (98.970)
Epoch: [173][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9460 (0.9623)	Acc@1 89.844 (87.388)	Acc@5 98.438 (98.959)
Epoch: [173][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9520 (0.9643)	Acc@1 86.719 (87.322)	Acc@5 99.219 (98.957)
Epoch: [173][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0040 (0.9649)	Acc@1 89.062 (87.309)	Acc@5 97.656 (98.961)
Epoch: [173][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8658 (0.9665)	Acc@1 89.062 (87.266)	Acc@5 100.000 (98.964)
Epoch: [173][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9481 (0.9682)	Acc@1 89.062 (87.199)	Acc@5 98.438 (98.947)
Epoch: [173][320/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0119 (0.9674)	Acc@1 85.938 (87.223)	Acc@5 98.438 (98.963)
Epoch: [173][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9351 (0.9692)	Acc@1 87.500 (87.162)	Acc@5 98.438 (98.954)
Epoch: [173][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9528 (0.9706)	Acc@1 84.375 (87.088)	Acc@5 98.438 (98.944)
Epoch: [173][350/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0066 (0.9728)	Acc@1 84.375 (87.006)	Acc@5 99.219 (98.936)
Epoch: [173][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0499 (0.9755)	Acc@1 84.375 (86.905)	Acc@5 99.219 (98.916)
Epoch: [173][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0063 (0.9763)	Acc@1 88.281 (86.868)	Acc@5 99.219 (98.918)
Epoch: [173][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9747 (0.9772)	Acc@1 87.500 (86.838)	Acc@5 99.219 (98.917)
Epoch: [173][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 1.1924 (0.9779)	Acc@1 80.000 (86.830)	Acc@5 92.500 (98.898)
num momentum params: 26
[0.010000000000000002, 0.9778929205322265, 1.4368873190879823, 86.83, 64.18, tensor(0.5781, device='cuda:0', grad_fn=<DivBackward0>), 5.305191993713379, 0.39371466636657715]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [174 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [174][0/391]	Time 0.060 (0.060)	Data 0.182 (0.182)	Loss 0.8949 (0.8949)	Acc@1 89.844 (89.844)	Acc@5 99.219 (99.219)
Epoch: [174][10/391]	Time 0.015 (0.021)	Data 0.002 (0.018)	Loss 1.0253 (0.9659)	Acc@1 85.156 (87.784)	Acc@5 100.000 (99.077)
Epoch: [174][20/391]	Time 0.015 (0.018)	Data 0.001 (0.010)	Loss 0.9553 (0.9395)	Acc@1 89.844 (88.356)	Acc@5 100.000 (99.330)
Epoch: [174][30/391]	Time 0.013 (0.017)	Data 0.001 (0.007)	Loss 0.9034 (0.9396)	Acc@1 89.844 (88.105)	Acc@5 99.219 (99.345)
Epoch: [174][40/391]	Time 0.013 (0.016)	Data 0.001 (0.006)	Loss 0.9328 (0.9399)	Acc@1 86.719 (87.843)	Acc@5 99.219 (99.219)
Epoch: [174][50/391]	Time 0.013 (0.015)	Data 0.001 (0.005)	Loss 0.9512 (0.9430)	Acc@1 88.281 (87.883)	Acc@5 100.000 (99.188)
Epoch: [174][60/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 0.8972 (0.9423)	Acc@1 92.188 (87.987)	Acc@5 99.219 (99.168)
Epoch: [174][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 0.9020 (0.9408)	Acc@1 89.844 (87.995)	Acc@5 100.000 (99.197)
Epoch: [174][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.0246 (0.9449)	Acc@1 84.375 (87.886)	Acc@5 99.219 (99.161)
Epoch: [174][90/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9213 (0.9475)	Acc@1 89.062 (87.852)	Acc@5 100.000 (99.159)
Epoch: [174][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9303 (0.9493)	Acc@1 89.062 (87.809)	Acc@5 99.219 (99.141)
Epoch: [174][110/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 0.9101 (0.9492)	Acc@1 89.062 (87.817)	Acc@5 100.000 (99.127)
Epoch: [174][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9660 (0.9498)	Acc@1 89.844 (87.836)	Acc@5 100.000 (99.141)
Epoch: [174][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9404 (0.9498)	Acc@1 87.500 (87.822)	Acc@5 100.000 (99.153)
Epoch: [174][140/391]	Time 0.011 (0.014)	Data 0.004 (0.003)	Loss 0.9739 (0.9537)	Acc@1 85.156 (87.688)	Acc@5 97.656 (99.108)
Epoch: [174][150/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 0.9647 (0.9528)	Acc@1 85.156 (87.650)	Acc@5 99.219 (99.105)
Epoch: [174][160/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.1118 (0.9536)	Acc@1 79.688 (87.597)	Acc@5 98.438 (99.107)
Epoch: [174][170/391]	Time 0.010 (0.014)	Data 0.001 (0.002)	Loss 0.7996 (0.9519)	Acc@1 90.625 (87.605)	Acc@5 100.000 (99.109)
Epoch: [174][180/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 0.9791 (0.9550)	Acc@1 86.719 (87.513)	Acc@5 99.219 (99.089)
Epoch: [174][190/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 0.9248 (0.9557)	Acc@1 89.844 (87.541)	Acc@5 100.000 (99.092)
Epoch: [174][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0470 (0.9570)	Acc@1 85.156 (87.512)	Acc@5 98.438 (99.087)
Epoch: [174][210/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 0.9245 (0.9598)	Acc@1 85.938 (87.422)	Acc@5 100.000 (99.060)
Epoch: [174][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9408 (0.9599)	Acc@1 89.844 (87.451)	Acc@5 98.438 (99.056)
Epoch: [174][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9363 (0.9621)	Acc@1 84.375 (87.385)	Acc@5 100.000 (99.026)
Epoch: [174][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0174 (0.9618)	Acc@1 82.031 (87.387)	Acc@5 98.438 (99.024)
Epoch: [174][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9814 (0.9638)	Acc@1 85.938 (87.329)	Acc@5 99.219 (99.004)
Epoch: [174][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9724 (0.9651)	Acc@1 89.844 (87.270)	Acc@5 98.438 (98.994)
Epoch: [174][270/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0052 (0.9673)	Acc@1 82.812 (87.171)	Acc@5 100.000 (98.968)
Epoch: [174][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2146 (0.9698)	Acc@1 83.594 (87.108)	Acc@5 97.656 (98.957)
Epoch: [174][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0068 (0.9712)	Acc@1 84.375 (87.062)	Acc@5 99.219 (98.964)
Epoch: [174][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9083 (0.9723)	Acc@1 89.844 (87.020)	Acc@5 99.219 (98.962)
Epoch: [174][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0951 (0.9724)	Acc@1 85.156 (87.040)	Acc@5 98.438 (98.973)
Epoch: [174][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8637 (0.9738)	Acc@1 91.406 (87.025)	Acc@5 98.438 (98.953)
Epoch: [174][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9067 (0.9741)	Acc@1 85.156 (87.014)	Acc@5 100.000 (98.952)
Epoch: [174][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0714 (0.9749)	Acc@1 81.250 (86.985)	Acc@5 100.000 (98.946)
Epoch: [174][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9833 (0.9752)	Acc@1 85.156 (86.972)	Acc@5 100.000 (98.947)
Epoch: [174][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1571 (0.9767)	Acc@1 79.688 (86.965)	Acc@5 96.875 (98.916)
Epoch: [174][370/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0354 (0.9766)	Acc@1 85.156 (86.965)	Acc@5 99.219 (98.922)
Epoch: [174][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0149 (0.9772)	Acc@1 85.156 (86.936)	Acc@5 99.219 (98.930)
Epoch: [174][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 1.1456 (0.9797)	Acc@1 81.250 (86.840)	Acc@5 98.750 (98.902)
num momentum params: 26
[0.010000000000000002, 0.9796731578063965, 1.531483981013298, 86.84, 63.23, tensor(0.5762, device='cuda:0', grad_fn=<DivBackward0>), 5.320535659790039, 0.404857873916626]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [175 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [175][0/391]	Time 0.061 (0.061)	Data 0.184 (0.184)	Loss 0.9081 (0.9081)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)
Epoch: [175][10/391]	Time 0.017 (0.021)	Data 0.002 (0.018)	Loss 0.8680 (0.9677)	Acc@1 91.406 (87.074)	Acc@5 99.219 (98.793)
Epoch: [175][20/391]	Time 0.015 (0.018)	Data 0.001 (0.010)	Loss 0.7947 (0.9562)	Acc@1 95.312 (87.909)	Acc@5 99.219 (98.958)
Epoch: [175][30/391]	Time 0.015 (0.017)	Data 0.001 (0.007)	Loss 0.9107 (0.9671)	Acc@1 85.938 (87.172)	Acc@5 99.219 (98.967)
Epoch: [175][40/391]	Time 0.010 (0.016)	Data 0.005 (0.006)	Loss 0.9684 (0.9629)	Acc@1 86.719 (87.309)	Acc@5 99.219 (99.104)
Epoch: [175][50/391]	Time 0.015 (0.016)	Data 0.001 (0.005)	Loss 0.9163 (0.9592)	Acc@1 85.938 (87.515)	Acc@5 100.000 (99.081)
Epoch: [175][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 0.7913 (0.9523)	Acc@1 92.188 (87.718)	Acc@5 100.000 (99.091)
Epoch: [175][70/391]	Time 0.012 (0.015)	Data 0.001 (0.004)	Loss 0.8150 (0.9463)	Acc@1 92.969 (87.940)	Acc@5 100.000 (99.120)
Epoch: [175][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 1.0011 (0.9490)	Acc@1 85.938 (87.915)	Acc@5 100.000 (99.113)
Epoch: [175][90/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 0.9909 (0.9474)	Acc@1 85.156 (87.929)	Acc@5 99.219 (99.133)
Epoch: [175][100/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9035 (0.9453)	Acc@1 89.062 (87.933)	Acc@5 99.219 (99.149)
Epoch: [175][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9335 (0.9439)	Acc@1 87.500 (87.993)	Acc@5 100.000 (99.169)
Epoch: [175][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9039 (0.9422)	Acc@1 85.938 (87.946)	Acc@5 100.000 (99.212)
Epoch: [175][130/391]	Time 0.014 (0.014)	Data 0.002 (0.003)	Loss 0.8499 (0.9440)	Acc@1 89.062 (87.900)	Acc@5 99.219 (99.165)
Epoch: [175][140/391]	Time 0.015 (0.014)	Data 0.001 (0.003)	Loss 0.8665 (0.9448)	Acc@1 89.844 (87.916)	Acc@5 99.219 (99.163)
Epoch: [175][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9423 (0.9439)	Acc@1 85.156 (87.966)	Acc@5 100.000 (99.183)
Epoch: [175][160/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0451 (0.9460)	Acc@1 86.719 (87.946)	Acc@5 100.000 (99.170)
Epoch: [175][170/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 1.1346 (0.9451)	Acc@1 80.469 (87.943)	Acc@5 96.875 (99.155)
Epoch: [175][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9477 (0.9482)	Acc@1 89.062 (87.815)	Acc@5 99.219 (99.167)
Epoch: [175][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9263 (0.9511)	Acc@1 88.281 (87.741)	Acc@5 99.219 (99.145)
Epoch: [175][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0265 (0.9517)	Acc@1 83.594 (87.671)	Acc@5 97.656 (99.137)
Epoch: [175][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9400 (0.9510)	Acc@1 86.719 (87.656)	Acc@5 98.438 (99.134)
Epoch: [175][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9506 (0.9527)	Acc@1 89.844 (87.617)	Acc@5 96.875 (99.113)
Epoch: [175][230/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 0.9966 (0.9542)	Acc@1 85.156 (87.601)	Acc@5 98.438 (99.087)
Epoch: [175][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8535 (0.9552)	Acc@1 89.062 (87.523)	Acc@5 99.219 (99.099)
Epoch: [175][250/391]	Time 0.011 (0.014)	Data 0.001 (0.002)	Loss 0.9289 (0.9567)	Acc@1 87.500 (87.428)	Acc@5 99.219 (99.097)
Epoch: [175][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8539 (0.9578)	Acc@1 92.969 (87.443)	Acc@5 99.219 (99.099)
Epoch: [175][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0268 (0.9588)	Acc@1 83.594 (87.428)	Acc@5 99.219 (99.092)
Epoch: [175][280/391]	Time 0.011 (0.014)	Data 0.004 (0.002)	Loss 1.0651 (0.9592)	Acc@1 86.719 (87.400)	Acc@5 98.438 (99.088)
Epoch: [175][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9703 (0.9597)	Acc@1 85.938 (87.403)	Acc@5 99.219 (99.087)
Epoch: [175][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9722 (0.9613)	Acc@1 88.281 (87.344)	Acc@5 98.438 (99.068)
Epoch: [175][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1027 (0.9635)	Acc@1 82.031 (87.274)	Acc@5 99.219 (99.071)
Epoch: [175][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8664 (0.9663)	Acc@1 89.844 (87.186)	Acc@5 99.219 (99.041)
Epoch: [175][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9908 (0.9676)	Acc@1 87.500 (87.132)	Acc@5 99.219 (99.046)
Epoch: [175][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1679 (0.9701)	Acc@1 84.375 (87.044)	Acc@5 97.656 (99.029)
Epoch: [175][350/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0056 (0.9718)	Acc@1 83.594 (86.981)	Acc@5 100.000 (99.025)
Epoch: [175][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0423 (0.9738)	Acc@1 86.719 (86.961)	Acc@5 98.438 (99.002)
Epoch: [175][370/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0475 (0.9753)	Acc@1 84.375 (86.934)	Acc@5 99.219 (98.981)
Epoch: [175][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1525 (0.9775)	Acc@1 82.812 (86.856)	Acc@5 96.094 (98.973)
Epoch: [175][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 1.0912 (0.9795)	Acc@1 85.000 (86.810)	Acc@5 97.500 (98.950)
num momentum params: 26
[0.010000000000000002, 0.9795096634292603, 1.4738222241401673, 86.81, 64.45, tensor(0.5766, device='cuda:0', grad_fn=<DivBackward0>), 5.311030864715576, 0.4061250686645508]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [176 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [176][0/391]	Time 0.072 (0.072)	Data 0.187 (0.187)	Loss 0.9476 (0.9476)	Acc@1 86.719 (86.719)	Acc@5 98.438 (98.438)
Epoch: [176][10/391]	Time 0.015 (0.022)	Data 0.001 (0.018)	Loss 0.9464 (0.9390)	Acc@1 89.062 (87.997)	Acc@5 99.219 (98.935)
Epoch: [176][20/391]	Time 0.016 (0.018)	Data 0.001 (0.010)	Loss 0.8340 (0.9358)	Acc@1 88.281 (88.579)	Acc@5 99.219 (98.958)
Epoch: [176][30/391]	Time 0.013 (0.017)	Data 0.002 (0.007)	Loss 0.8285 (0.9333)	Acc@1 93.750 (88.760)	Acc@5 100.000 (99.017)
Epoch: [176][40/391]	Time 0.013 (0.016)	Data 0.002 (0.006)	Loss 0.8416 (0.9281)	Acc@1 92.969 (88.929)	Acc@5 100.000 (99.143)
Epoch: [176][50/391]	Time 0.014 (0.016)	Data 0.002 (0.005)	Loss 0.9311 (0.9202)	Acc@1 85.938 (88.971)	Acc@5 99.219 (99.188)
Epoch: [176][60/391]	Time 0.013 (0.016)	Data 0.001 (0.005)	Loss 0.9661 (0.9272)	Acc@1 90.625 (88.870)	Acc@5 98.438 (99.180)
Epoch: [176][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 0.8913 (0.9278)	Acc@1 89.844 (88.908)	Acc@5 100.000 (99.197)
Epoch: [176][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 0.9790 (0.9261)	Acc@1 85.938 (88.841)	Acc@5 100.000 (99.248)
Epoch: [176][90/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 0.8393 (0.9248)	Acc@1 90.625 (88.796)	Acc@5 99.219 (99.262)
Epoch: [176][100/391]	Time 0.013 (0.015)	Data 0.002 (0.003)	Loss 1.0047 (0.9298)	Acc@1 85.156 (88.653)	Acc@5 98.438 (99.196)
Epoch: [176][110/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 0.9201 (0.9290)	Acc@1 87.500 (88.661)	Acc@5 99.219 (99.184)
Epoch: [176][120/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 1.0123 (0.9329)	Acc@1 85.156 (88.514)	Acc@5 97.656 (99.141)
Epoch: [176][130/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 0.9043 (0.9346)	Acc@1 86.719 (88.448)	Acc@5 99.219 (99.117)
Epoch: [176][140/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 0.9978 (0.9356)	Acc@1 86.719 (88.370)	Acc@5 98.438 (99.147)
Epoch: [176][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.1007 (0.9385)	Acc@1 81.250 (88.167)	Acc@5 98.438 (99.131)
Epoch: [176][160/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 0.9701 (0.9412)	Acc@1 85.938 (88.082)	Acc@5 97.656 (99.127)
Epoch: [176][170/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 0.9140 (0.9425)	Acc@1 87.500 (87.971)	Acc@5 99.219 (99.132)
Epoch: [176][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9681 (0.9456)	Acc@1 90.625 (87.910)	Acc@5 96.875 (99.107)
Epoch: [176][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0315 (0.9462)	Acc@1 86.719 (87.868)	Acc@5 98.438 (99.096)
Epoch: [176][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9716 (0.9460)	Acc@1 89.844 (87.861)	Acc@5 98.438 (99.094)
Epoch: [176][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8906 (0.9476)	Acc@1 88.281 (87.855)	Acc@5 99.219 (99.078)
Epoch: [176][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0948 (0.9500)	Acc@1 82.031 (87.783)	Acc@5 99.219 (99.067)
Epoch: [176][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0122 (0.9520)	Acc@1 86.719 (87.659)	Acc@5 97.656 (99.050)
Epoch: [176][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0811 (0.9539)	Acc@1 85.938 (87.633)	Acc@5 97.656 (99.047)
Epoch: [176][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0269 (0.9563)	Acc@1 89.062 (87.572)	Acc@5 97.656 (99.029)
Epoch: [176][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9844 (0.9581)	Acc@1 86.719 (87.500)	Acc@5 98.438 (99.024)
Epoch: [176][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0535 (0.9593)	Acc@1 86.719 (87.506)	Acc@5 98.438 (99.020)
Epoch: [176][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0544 (0.9599)	Acc@1 86.719 (87.508)	Acc@5 98.438 (99.021)
Epoch: [176][290/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 0.8425 (0.9609)	Acc@1 89.844 (87.457)	Acc@5 100.000 (99.023)
Epoch: [176][300/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0559 (0.9625)	Acc@1 84.375 (87.373)	Acc@5 96.875 (99.014)
Epoch: [176][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0460 (0.9638)	Acc@1 83.594 (87.274)	Acc@5 98.438 (99.023)
Epoch: [176][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0333 (0.9653)	Acc@1 85.938 (87.215)	Acc@5 97.656 (99.024)
Epoch: [176][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9830 (0.9670)	Acc@1 83.594 (87.118)	Acc@5 99.219 (99.018)
Epoch: [176][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9201 (0.9693)	Acc@1 89.844 (87.062)	Acc@5 97.656 (99.010)
Epoch: [176][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0042 (0.9719)	Acc@1 84.375 (86.995)	Acc@5 99.219 (98.989)
Epoch: [176][360/391]	Time 0.012 (0.014)	Data 0.001 (0.002)	Loss 1.1082 (0.9740)	Acc@1 85.156 (86.937)	Acc@5 98.438 (98.970)
Epoch: [176][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0832 (0.9756)	Acc@1 83.594 (86.881)	Acc@5 99.219 (98.981)
Epoch: [176][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8936 (0.9772)	Acc@1 88.281 (86.809)	Acc@5 100.000 (98.983)
Epoch: [176][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 0.8856 (0.9784)	Acc@1 90.000 (86.768)	Acc@5 100.000 (98.978)
num momentum params: 26
[0.010000000000000002, 0.9783612738990783, 1.493652001619339, 86.768, 63.58, tensor(0.5770, device='cuda:0', grad_fn=<DivBackward0>), 5.363872289657593, 0.4005756378173828]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [177 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [177][0/391]	Time 0.067 (0.067)	Data 0.166 (0.166)	Loss 0.9129 (0.9129)	Acc@1 90.625 (90.625)	Acc@5 98.438 (98.438)
Epoch: [177][10/391]	Time 0.015 (0.021)	Data 0.001 (0.017)	Loss 1.0342 (0.9342)	Acc@1 84.375 (88.068)	Acc@5 99.219 (99.432)
Epoch: [177][20/391]	Time 0.017 (0.018)	Data 0.001 (0.009)	Loss 0.8137 (0.9242)	Acc@1 91.406 (88.765)	Acc@5 99.219 (99.107)
Epoch: [177][30/391]	Time 0.014 (0.017)	Data 0.001 (0.007)	Loss 0.9366 (0.9165)	Acc@1 89.062 (88.886)	Acc@5 98.438 (99.194)
Epoch: [177][40/391]	Time 0.014 (0.016)	Data 0.001 (0.005)	Loss 1.0052 (0.9169)	Acc@1 85.156 (88.796)	Acc@5 98.438 (99.219)
Epoch: [177][50/391]	Time 0.014 (0.016)	Data 0.001 (0.005)	Loss 0.9896 (0.9211)	Acc@1 85.156 (88.572)	Acc@5 99.219 (99.219)
Epoch: [177][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 0.8873 (0.9179)	Acc@1 89.062 (88.730)	Acc@5 100.000 (99.283)
Epoch: [177][70/391]	Time 0.013 (0.015)	Data 0.002 (0.004)	Loss 0.9329 (0.9211)	Acc@1 89.062 (88.666)	Acc@5 99.219 (99.241)
Epoch: [177][80/391]	Time 0.013 (0.015)	Data 0.002 (0.003)	Loss 0.9296 (0.9209)	Acc@1 86.719 (88.628)	Acc@5 100.000 (99.277)
Epoch: [177][90/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 0.9679 (0.9222)	Acc@1 89.062 (88.633)	Acc@5 99.219 (99.253)
Epoch: [177][100/391]	Time 0.011 (0.014)	Data 0.001 (0.003)	Loss 0.9693 (0.9201)	Acc@1 86.719 (88.707)	Acc@5 99.219 (99.257)
Epoch: [177][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9706 (0.9198)	Acc@1 84.375 (88.725)	Acc@5 98.438 (99.219)
Epoch: [177][120/391]	Time 0.012 (0.014)	Data 0.002 (0.003)	Loss 0.9338 (0.9219)	Acc@1 89.062 (88.675)	Acc@5 98.438 (99.186)
Epoch: [177][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.7931 (0.9209)	Acc@1 92.969 (88.740)	Acc@5 99.219 (99.195)
Epoch: [177][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9137 (0.9234)	Acc@1 87.500 (88.580)	Acc@5 100.000 (99.230)
Epoch: [177][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9133 (0.9252)	Acc@1 89.062 (88.524)	Acc@5 100.000 (99.234)
Epoch: [177][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9354 (0.9275)	Acc@1 89.844 (88.490)	Acc@5 100.000 (99.209)
Epoch: [177][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9174 (0.9300)	Acc@1 90.625 (88.414)	Acc@5 98.438 (99.191)
Epoch: [177][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0204 (0.9324)	Acc@1 83.594 (88.376)	Acc@5 98.438 (99.167)
Epoch: [177][190/391]	Time 0.015 (0.014)	Data 0.000 (0.002)	Loss 0.9597 (0.9340)	Acc@1 89.062 (88.322)	Acc@5 99.219 (99.157)
Epoch: [177][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0245 (0.9350)	Acc@1 84.375 (88.293)	Acc@5 99.219 (99.129)
Epoch: [177][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9554 (0.9360)	Acc@1 84.375 (88.266)	Acc@5 100.000 (99.134)
Epoch: [177][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9252 (0.9364)	Acc@1 85.938 (88.249)	Acc@5 100.000 (99.141)
Epoch: [177][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9561 (0.9387)	Acc@1 88.281 (88.173)	Acc@5 99.219 (99.138)
Epoch: [177][240/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 0.8799 (0.9390)	Acc@1 92.188 (88.145)	Acc@5 100.000 (99.138)
Epoch: [177][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9155 (0.9409)	Acc@1 89.844 (88.070)	Acc@5 99.219 (99.128)
Epoch: [177][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9799 (0.9423)	Acc@1 88.281 (88.033)	Acc@5 97.656 (99.117)
Epoch: [177][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0004 (0.9458)	Acc@1 85.156 (87.898)	Acc@5 100.000 (99.095)
Epoch: [177][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0976 (0.9487)	Acc@1 83.594 (87.848)	Acc@5 97.656 (99.057)
Epoch: [177][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0476 (0.9511)	Acc@1 84.375 (87.742)	Acc@5 99.219 (99.055)
Epoch: [177][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.7965 (0.9520)	Acc@1 92.188 (87.692)	Acc@5 100.000 (99.053)
Epoch: [177][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9327 (0.9538)	Acc@1 89.062 (87.643)	Acc@5 99.219 (99.048)
Epoch: [177][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9354 (0.9556)	Acc@1 89.844 (87.600)	Acc@5 100.000 (99.051)
Epoch: [177][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9104 (0.9568)	Acc@1 89.844 (87.542)	Acc@5 99.219 (99.049)
Epoch: [177][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1925 (0.9588)	Acc@1 78.906 (87.461)	Acc@5 97.656 (99.033)
Epoch: [177][350/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0912 (0.9604)	Acc@1 81.250 (87.427)	Acc@5 99.219 (99.023)
Epoch: [177][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0756 (0.9625)	Acc@1 82.812 (87.385)	Acc@5 100.000 (99.015)
Epoch: [177][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9673 (0.9649)	Acc@1 89.844 (87.329)	Acc@5 99.219 (98.996)
Epoch: [177][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9402 (0.9660)	Acc@1 89.062 (87.283)	Acc@5 100.000 (98.993)
Epoch: [177][390/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 1.1224 (0.9680)	Acc@1 83.750 (87.222)	Acc@5 97.500 (98.972)
num momentum params: 26
[0.010000000000000002, 0.9679936010742187, 1.5215453064441682, 87.222, 63.46, tensor(0.5843, device='cuda:0', grad_fn=<DivBackward0>), 5.302329063415527, 0.4083974361419678]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [178 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [178][0/391]	Time 0.068 (0.068)	Data 0.180 (0.180)	Loss 0.9632 (0.9632)	Acc@1 86.719 (86.719)	Acc@5 98.438 (98.438)
Epoch: [178][10/391]	Time 0.014 (0.021)	Data 0.001 (0.018)	Loss 0.9395 (0.9751)	Acc@1 89.844 (87.074)	Acc@5 100.000 (99.290)
Epoch: [178][20/391]	Time 0.014 (0.018)	Data 0.001 (0.010)	Loss 0.8739 (0.9418)	Acc@1 92.188 (88.170)	Acc@5 97.656 (99.107)
Epoch: [178][30/391]	Time 0.014 (0.017)	Data 0.001 (0.007)	Loss 0.9394 (0.9362)	Acc@1 89.062 (88.306)	Acc@5 100.000 (99.093)
Epoch: [178][40/391]	Time 0.014 (0.016)	Data 0.001 (0.006)	Loss 0.9834 (0.9335)	Acc@1 90.625 (88.243)	Acc@5 97.656 (99.123)
Epoch: [178][50/391]	Time 0.013 (0.016)	Data 0.001 (0.005)	Loss 0.9561 (0.9386)	Acc@1 85.938 (88.036)	Acc@5 100.000 (99.112)
Epoch: [178][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 0.9011 (0.9420)	Acc@1 89.062 (87.923)	Acc@5 99.219 (99.078)
Epoch: [178][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 0.9054 (0.9376)	Acc@1 88.281 (88.039)	Acc@5 100.000 (99.153)
Epoch: [178][80/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 0.8688 (0.9341)	Acc@1 88.281 (88.030)	Acc@5 100.000 (99.199)
Epoch: [178][90/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 0.9883 (0.9339)	Acc@1 86.719 (87.989)	Acc@5 97.656 (99.159)
Epoch: [178][100/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 0.8998 (0.9315)	Acc@1 88.281 (88.142)	Acc@5 99.219 (99.126)
Epoch: [178][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0925 (0.9345)	Acc@1 79.688 (88.035)	Acc@5 99.219 (99.148)
Epoch: [178][120/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 0.7682 (0.9305)	Acc@1 93.750 (88.204)	Acc@5 100.000 (99.174)
Epoch: [178][130/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 0.8896 (0.9306)	Acc@1 89.844 (88.198)	Acc@5 100.000 (99.177)
Epoch: [178][140/391]	Time 0.013 (0.014)	Data 0.002 (0.003)	Loss 0.9799 (0.9298)	Acc@1 85.938 (88.209)	Acc@5 99.219 (99.174)
Epoch: [178][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.1266 (0.9324)	Acc@1 78.906 (88.105)	Acc@5 97.656 (99.120)
Epoch: [178][160/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9991 (0.9315)	Acc@1 84.375 (88.194)	Acc@5 98.438 (99.146)
Epoch: [178][170/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 0.9893 (0.9313)	Acc@1 86.719 (88.167)	Acc@5 99.219 (99.155)
Epoch: [178][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8928 (0.9330)	Acc@1 89.062 (88.091)	Acc@5 100.000 (99.163)
Epoch: [178][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9042 (0.9348)	Acc@1 87.500 (88.056)	Acc@5 100.000 (99.166)
Epoch: [178][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9334 (0.9384)	Acc@1 89.062 (87.916)	Acc@5 99.219 (99.157)
Epoch: [178][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9710 (0.9403)	Acc@1 89.062 (87.863)	Acc@5 98.438 (99.137)
Epoch: [178][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9845 (0.9422)	Acc@1 85.938 (87.839)	Acc@5 99.219 (99.120)
Epoch: [178][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0490 (0.9449)	Acc@1 85.156 (87.740)	Acc@5 99.219 (99.114)
Epoch: [178][240/391]	Time 0.013 (0.014)	Data 0.002 (0.002)	Loss 0.9017 (0.9456)	Acc@1 87.500 (87.711)	Acc@5 99.219 (99.096)
Epoch: [178][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9860 (0.9454)	Acc@1 90.625 (87.721)	Acc@5 99.219 (99.097)
Epoch: [178][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9065 (0.9465)	Acc@1 88.281 (87.656)	Acc@5 100.000 (99.099)
Epoch: [178][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9109 (0.9479)	Acc@1 88.281 (87.601)	Acc@5 99.219 (99.103)
Epoch: [178][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9686 (0.9495)	Acc@1 85.156 (87.558)	Acc@5 99.219 (99.105)
Epoch: [178][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9960 (0.9503)	Acc@1 85.938 (87.521)	Acc@5 98.438 (99.106)
Epoch: [178][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9904 (0.9520)	Acc@1 85.156 (87.464)	Acc@5 98.438 (99.099)
Epoch: [178][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1824 (0.9549)	Acc@1 82.031 (87.387)	Acc@5 99.219 (99.091)
Epoch: [178][320/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0247 (0.9568)	Acc@1 86.719 (87.310)	Acc@5 97.656 (99.095)
Epoch: [178][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8953 (0.9562)	Acc@1 89.844 (87.311)	Acc@5 98.438 (99.094)
Epoch: [178][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1002 (0.9569)	Acc@1 80.469 (87.301)	Acc@5 99.219 (99.079)
Epoch: [178][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0926 (0.9586)	Acc@1 79.688 (87.251)	Acc@5 99.219 (99.074)
Epoch: [178][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9938 (0.9600)	Acc@1 88.281 (87.223)	Acc@5 99.219 (99.067)
Epoch: [178][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0445 (0.9611)	Acc@1 84.375 (87.193)	Acc@5 98.438 (99.054)
Epoch: [178][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9228 (0.9613)	Acc@1 87.500 (87.182)	Acc@5 100.000 (99.059)
Epoch: [178][390/391]	Time 0.016 (0.014)	Data 0.001 (0.002)	Loss 1.0283 (0.9625)	Acc@1 81.250 (87.124)	Acc@5 100.000 (99.068)
num momentum params: 26
[0.010000000000000002, 0.9624573090362549, 1.5194364869594574, 87.124, 63.38, tensor(0.5878, device='cuda:0', grad_fn=<DivBackward0>), 5.33896279335022, 0.4021449089050293]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [179 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [179][0/391]	Time 0.066 (0.066)	Data 0.177 (0.177)	Loss 0.9397 (0.9397)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [179][10/391]	Time 0.014 (0.021)	Data 0.002 (0.017)	Loss 0.9200 (0.9117)	Acc@1 91.406 (88.636)	Acc@5 99.219 (99.716)
Epoch: [179][20/391]	Time 0.014 (0.018)	Data 0.001 (0.010)	Loss 0.8447 (0.9147)	Acc@1 92.188 (89.025)	Acc@5 100.000 (99.516)
Epoch: [179][30/391]	Time 0.014 (0.017)	Data 0.001 (0.007)	Loss 0.8399 (0.9065)	Acc@1 89.062 (89.189)	Acc@5 99.219 (99.446)
Epoch: [179][40/391]	Time 0.013 (0.016)	Data 0.001 (0.006)	Loss 0.9006 (0.9123)	Acc@1 91.406 (88.910)	Acc@5 98.438 (99.333)
Epoch: [179][50/391]	Time 0.016 (0.016)	Data 0.001 (0.005)	Loss 0.9958 (0.9162)	Acc@1 86.719 (88.557)	Acc@5 100.000 (99.372)
Epoch: [179][60/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 0.9544 (0.9187)	Acc@1 86.719 (88.627)	Acc@5 99.219 (99.308)
Epoch: [179][70/391]	Time 0.017 (0.015)	Data 0.001 (0.004)	Loss 0.8329 (0.9266)	Acc@1 93.750 (88.435)	Acc@5 98.438 (99.197)
Epoch: [179][80/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 0.9839 (0.9294)	Acc@1 86.719 (88.358)	Acc@5 98.438 (99.180)
Epoch: [179][90/391]	Time 0.014 (0.015)	Data 0.001 (0.003)	Loss 0.9457 (0.9312)	Acc@1 87.500 (88.324)	Acc@5 100.000 (99.245)
Epoch: [179][100/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 0.9579 (0.9330)	Acc@1 85.938 (88.258)	Acc@5 99.219 (99.196)
Epoch: [179][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.8323 (0.9309)	Acc@1 93.750 (88.338)	Acc@5 99.219 (99.169)
Epoch: [179][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.8163 (0.9283)	Acc@1 91.406 (88.410)	Acc@5 100.000 (99.167)
Epoch: [179][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9592 (0.9315)	Acc@1 86.719 (88.299)	Acc@5 99.219 (99.153)
Epoch: [179][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9740 (0.9320)	Acc@1 87.500 (88.265)	Acc@5 98.438 (99.158)
Epoch: [179][150/391]	Time 0.014 (0.014)	Data 0.001 (0.003)	Loss 1.0621 (0.9351)	Acc@1 86.719 (88.219)	Acc@5 97.656 (99.131)
Epoch: [179][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0283 (0.9361)	Acc@1 82.812 (88.160)	Acc@5 100.000 (99.146)
Epoch: [179][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1005 (0.9396)	Acc@1 83.594 (88.062)	Acc@5 98.438 (99.127)
Epoch: [179][180/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 0.8886 (0.9391)	Acc@1 92.969 (88.052)	Acc@5 98.438 (99.128)
Epoch: [179][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0714 (0.9423)	Acc@1 82.031 (87.938)	Acc@5 97.656 (99.116)
Epoch: [179][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0416 (0.9433)	Acc@1 88.281 (87.931)	Acc@5 96.875 (99.110)
Epoch: [179][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9623 (0.9455)	Acc@1 90.625 (87.867)	Acc@5 99.219 (99.104)
Epoch: [179][220/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 0.9187 (0.9464)	Acc@1 89.844 (87.868)	Acc@5 100.000 (99.095)
Epoch: [179][230/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0224 (0.9472)	Acc@1 83.594 (87.815)	Acc@5 100.000 (99.090)
Epoch: [179][240/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0426 (0.9501)	Acc@1 86.719 (87.733)	Acc@5 98.438 (99.076)
Epoch: [179][250/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8768 (0.9501)	Acc@1 91.406 (87.752)	Acc@5 100.000 (99.072)
Epoch: [179][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9836 (0.9515)	Acc@1 85.156 (87.698)	Acc@5 99.219 (99.069)
Epoch: [179][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1324 (0.9526)	Acc@1 82.812 (87.644)	Acc@5 97.656 (99.060)
Epoch: [179][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9532 (0.9538)	Acc@1 86.719 (87.592)	Acc@5 99.219 (99.055)
Epoch: [179][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1171 (0.9550)	Acc@1 81.250 (87.535)	Acc@5 97.656 (99.055)
Epoch: [179][300/391]	Time 0.015 (0.014)	Data 0.001 (0.002)	Loss 1.0195 (0.9572)	Acc@1 86.719 (87.458)	Acc@5 98.438 (99.045)
Epoch: [179][310/391]	Time 0.012 (0.014)	Data 0.003 (0.002)	Loss 1.0221 (0.9586)	Acc@1 85.938 (87.412)	Acc@5 98.438 (99.040)
Epoch: [179][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0102 (0.9605)	Acc@1 85.938 (87.366)	Acc@5 96.875 (99.019)
Epoch: [179][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1401 (0.9617)	Acc@1 84.375 (87.325)	Acc@5 96.875 (99.002)
Epoch: [179][340/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9474 (0.9637)	Acc@1 84.375 (87.253)	Acc@5 100.000 (98.997)
Epoch: [179][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9826 (0.9651)	Acc@1 87.500 (87.204)	Acc@5 98.438 (98.985)
Epoch: [179][360/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.2302 (0.9676)	Acc@1 76.562 (87.139)	Acc@5 98.438 (98.987)
Epoch: [179][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0567 (0.9694)	Acc@1 83.594 (87.075)	Acc@5 96.875 (98.974)
Epoch: [179][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1414 (0.9716)	Acc@1 78.125 (87.006)	Acc@5 100.000 (98.973)
Epoch: [179][390/391]	Time 0.023 (0.014)	Data 0.001 (0.002)	Loss 1.2348 (0.9728)	Acc@1 78.750 (86.972)	Acc@5 100.000 (98.972)
num momentum params: 26
[0.010000000000000002, 0.9728321496582031, 1.5847234272956847, 86.972, 62.59, tensor(0.5817, device='cuda:0', grad_fn=<DivBackward0>), 5.3340559005737305, 0.3991212844848633]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...

Epoch: [180 | 180] LR: 0.010000
module.conv1.weight [64, 3, 3, 3]
module.conv2.weight [128, 64, 3, 3]
module.conv3.weight [256, 128, 3, 3]
module.conv4.weight [256, 256, 3, 3]
module.conv5.weight [512, 256, 3, 3]
module.conv6.weight [512, 512, 3, 3]
module.conv7.weight [512, 512, 3, 3]
module.conv8.weight [512, 512, 3, 3]
Epoch: [180][0/391]	Time 0.071 (0.071)	Data 0.177 (0.177)	Loss 0.8849 (0.8849)	Acc@1 89.062 (89.062)	Acc@5 99.219 (99.219)
Epoch: [180][10/391]	Time 0.014 (0.022)	Data 0.002 (0.017)	Loss 1.0164 (0.9746)	Acc@1 87.500 (87.358)	Acc@5 97.656 (98.864)
Epoch: [180][20/391]	Time 0.013 (0.018)	Data 0.002 (0.010)	Loss 0.8679 (0.9605)	Acc@1 89.844 (87.723)	Acc@5 99.219 (98.958)
Epoch: [180][30/391]	Time 0.014 (0.017)	Data 0.001 (0.007)	Loss 0.9980 (0.9597)	Acc@1 85.156 (87.676)	Acc@5 99.219 (99.118)
Epoch: [180][40/391]	Time 0.014 (0.016)	Data 0.001 (0.006)	Loss 1.0779 (0.9576)	Acc@1 85.938 (87.710)	Acc@5 97.656 (99.162)
Epoch: [180][50/391]	Time 0.014 (0.016)	Data 0.002 (0.005)	Loss 0.9320 (0.9452)	Acc@1 87.500 (88.036)	Acc@5 99.219 (99.249)
Epoch: [180][60/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 0.9343 (0.9482)	Acc@1 91.406 (87.935)	Acc@5 97.656 (99.155)
Epoch: [180][70/391]	Time 0.013 (0.015)	Data 0.001 (0.004)	Loss 0.8638 (0.9402)	Acc@1 91.406 (88.193)	Acc@5 100.000 (99.175)
Epoch: [180][80/391]	Time 0.014 (0.015)	Data 0.001 (0.004)	Loss 0.7763 (0.9406)	Acc@1 95.312 (88.175)	Acc@5 100.000 (99.161)
Epoch: [180][90/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 0.9321 (0.9328)	Acc@1 89.844 (88.393)	Acc@5 99.219 (99.210)
Epoch: [180][100/391]	Time 0.013 (0.015)	Data 0.001 (0.003)	Loss 1.0769 (0.9357)	Acc@1 84.375 (88.320)	Acc@5 98.438 (99.219)
Epoch: [180][110/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0035 (0.9340)	Acc@1 86.719 (88.359)	Acc@5 97.656 (99.212)
Epoch: [180][120/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.8571 (0.9347)	Acc@1 92.188 (88.397)	Acc@5 99.219 (99.206)
Epoch: [180][130/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.9113 (0.9333)	Acc@1 89.844 (88.442)	Acc@5 99.219 (99.237)
Epoch: [180][140/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 1.0216 (0.9361)	Acc@1 83.594 (88.265)	Acc@5 99.219 (99.224)
Epoch: [180][150/391]	Time 0.013 (0.014)	Data 0.001 (0.003)	Loss 0.8253 (0.9347)	Acc@1 90.625 (88.297)	Acc@5 100.000 (99.234)
Epoch: [180][160/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8927 (0.9341)	Acc@1 89.844 (88.301)	Acc@5 100.000 (99.238)
Epoch: [180][170/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9407 (0.9342)	Acc@1 86.719 (88.300)	Acc@5 99.219 (99.219)
Epoch: [180][180/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0792 (0.9344)	Acc@1 83.594 (88.255)	Acc@5 98.438 (99.227)
Epoch: [180][190/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9257 (0.9361)	Acc@1 86.719 (88.216)	Acc@5 99.219 (99.219)
Epoch: [180][200/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0051 (0.9383)	Acc@1 85.156 (88.130)	Acc@5 98.438 (99.195)
Epoch: [180][210/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9315 (0.9383)	Acc@1 88.281 (88.144)	Acc@5 99.219 (99.208)
Epoch: [180][220/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9310 (0.9387)	Acc@1 89.062 (88.168)	Acc@5 98.438 (99.187)
Epoch: [180][230/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8966 (0.9405)	Acc@1 89.844 (88.092)	Acc@5 99.219 (99.182)
Epoch: [180][240/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 0.9367 (0.9413)	Acc@1 90.625 (88.093)	Acc@5 98.438 (99.180)
Epoch: [180][250/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0174 (0.9434)	Acc@1 86.719 (88.045)	Acc@5 98.438 (99.172)
Epoch: [180][260/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9864 (0.9440)	Acc@1 83.594 (87.991)	Acc@5 100.000 (99.165)
Epoch: [180][270/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8729 (0.9447)	Acc@1 88.281 (87.964)	Acc@5 99.219 (99.152)
Epoch: [180][280/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.8925 (0.9443)	Acc@1 89.062 (87.936)	Acc@5 99.219 (99.138)
Epoch: [180][290/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9312 (0.9449)	Acc@1 88.281 (87.911)	Acc@5 98.438 (99.130)
Epoch: [180][300/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0188 (0.9462)	Acc@1 86.719 (87.853)	Acc@5 97.656 (99.120)
Epoch: [180][310/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9822 (0.9484)	Acc@1 87.500 (87.769)	Acc@5 98.438 (99.116)
Epoch: [180][320/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1617 (0.9499)	Acc@1 82.031 (87.719)	Acc@5 98.438 (99.112)
Epoch: [180][330/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0491 (0.9519)	Acc@1 84.375 (87.658)	Acc@5 100.000 (99.110)
Epoch: [180][340/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 0.9663 (0.9539)	Acc@1 87.500 (87.617)	Acc@5 100.000 (99.106)
Epoch: [180][350/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 0.9207 (0.9551)	Acc@1 88.281 (87.558)	Acc@5 100.000 (99.090)
Epoch: [180][360/391]	Time 0.014 (0.014)	Data 0.001 (0.002)	Loss 1.0819 (0.9562)	Acc@1 83.594 (87.506)	Acc@5 97.656 (99.078)
Epoch: [180][370/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.1227 (0.9581)	Acc@1 82.031 (87.460)	Acc@5 97.656 (99.073)
Epoch: [180][380/391]	Time 0.013 (0.014)	Data 0.001 (0.002)	Loss 1.0924 (0.9597)	Acc@1 81.250 (87.385)	Acc@5 100.000 (99.069)
Epoch: [180][390/391]	Time 0.017 (0.014)	Data 0.001 (0.002)	Loss 1.1343 (0.9620)	Acc@1 78.750 (87.302)	Acc@5 98.750 (99.070)
num momentum params: 26
[0.010000000000000002, 0.9619636009216309, 1.5036629772186278, 87.302, 64.09, tensor(0.5897, device='cuda:0', grad_fn=<DivBackward0>), 5.333016395568848, 0.40512108802795405]
Non Pruning Epoch - module.conv1.weight: [64, 3, 3, 3]
Non Pruning Epoch - module.bn1.weight: [64]
Non Pruning Epoch - module.bn1.bias: [64]
Non Pruning Epoch - module.conv2.weight: [128, 64, 3, 3]
Non Pruning Epoch - module.bn2.weight: [128]
Non Pruning Epoch - module.bn2.bias: [128]
Non Pruning Epoch - module.conv3.weight: [256, 128, 3, 3]
Non Pruning Epoch - module.bn3.weight: [256]
Non Pruning Epoch - module.bn3.bias: [256]
Non Pruning Epoch - module.conv4.weight: [256, 256, 3, 3]
Non Pruning Epoch - module.bn4.weight: [256]
Non Pruning Epoch - module.bn4.bias: [256]
Non Pruning Epoch - module.conv5.weight: [512, 256, 3, 3]
Non Pruning Epoch - module.bn5.weight: [512]
Non Pruning Epoch - module.bn5.bias: [512]
Non Pruning Epoch - module.conv6.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn6.weight: [512]
Non Pruning Epoch - module.bn6.bias: [512]
Non Pruning Epoch - module.conv7.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn7.weight: [512]
Non Pruning Epoch - module.bn7.bias: [512]
Non Pruning Epoch - module.conv8.weight: [512, 512, 3, 3]
Non Pruning Epoch - module.bn8.weight: [512]
Non Pruning Epoch - module.bn8.bias: [512]
Non Pruning Epoch - module.fc.weight: [100, 512]
Non Pruning Epoch - module.fc.bias: [100]
[INFO] Storing checkpoint...
Best acc:
67.27

Total time:
1303.163862
[2021-06-20T03:10:07.683107] Command finished with return code 0


[2021-06-20T03:10:07.683558] The experiment completed successfully. Finalizing run...
Cleaning up all outstanding Run operations, waiting 900.0 seconds
1 items cleaning up...
Cleanup took 0.07126760482788086 seconds
[2021-06-20T03:10:08.020554] Finished context manager injector.
2021/06/20 03:10:08 Attempt 1 of http call to http://10.0.0.4:16384/sendlogstoartifacts/status
2021/06/20 03:10:08 Not exporting to RunHistory as the exporter is either stopped or there is no data.
Stopped: false
OriginalData: 2
FilteredData: 0.
2021/06/20 03:10:08 Process Exiting with Code:  0
2021/06/20 03:10:09 All App Insights Logs was send successfully
